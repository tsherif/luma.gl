{"componentChunkName":"component---node-modules-ocular-gatsby-src-templates-search-jsx","path":"/search","webpackCompilationHash":"f5e0c56a80e2caa63fa2","result":{"pageContext":{"isCreatedByStatefulCreatePages":false,"data":[{"excerpt":"Overview luma.gl is a set of Javascript components for the WebGL2 API in modern browsers. Versions These docs are for\n\n  \n Looking for an…","rawMarkdownBody":"# Overview\n\nluma.gl is a set of Javascript components for the WebGL2 API in modern browsers.\n\n\n## Versions\n\nThese docs are for\n<a href=\"https://github.com/uber/luma.gl/blob/7.2-release/docs\">\n  <img style=\"margin-bottom: -4px\" src=\"https://img.shields.io/badge/luma.gl-v7.2-brightgreen.svg?style=flat-square\" />\n</a> Looking for an older version?\n\n<a href=\"https://github.com/uber/luma.gl/blob/7.1-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-7.1-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/7.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-7.0-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/6.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-6.0-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/5.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-5.0-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/4.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-4.0-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/tree/3.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-3.0-green.svg?style=flat-square\" />\n</a>\n\n\n\n## Philosophy\n\nluma.gl's core philosophy is to expose the WebGL 2 API to developers, while providing fallbacks to WebGL 1 when necessary. The core use case for luma.gl is visualization of large datasets, but its design is generic enough for more general usage. Key aspects of that philosphy are:\n\n- **A WebGL2-first API** - luma.gl enables applications to code using the latest WebGL2 APIs and write their shaders in the latest GLSL 3.00 ES syntax, and (as far as possible) transparently keeps your application backwards compatible with WebGL1 (using WebGL extensions, shader transpilation and other techniques).\n- **Expose WebGL2 to Programmers** - while many WebGL frameworks make efforts to hide and wrap the WebGL2 API, luma.gl intentionally exposes it, providing JavaScript classes corresponding to WebGL objects defined in the [WebGL2 Specification](https://www.khronos.org/registry/webgl/specs/latest/2.0/).\n- **Simplify use of the WebGL2 API** - Using the raw WebGL API is notoriously verbose and fiddly. luma.gl's classes provide the standard WebGL2 objects and methods, but take care of all the tedious default parameters and object bindings behind the scenes.\n- **Shader Programming** - luma.gl's shadertools is a GLSL module system that provides extensive facilities for developing, modularizing, debugging and profiling GLSL shaders.\n- **Performance First** - luma.gl has strong focus on performance, which includes a preference for providing APIs on lower abstraction levels than some popular WebGL frameworks, and an emphasis of using features such as *instanced rendering* for large data sets.\n- **Doing Computations on the GPU** - A focus on use cases like GPU based computing using *transform feedback*, and other WebGL2 and [GPGPU](https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units) techniques.\n\n\n## History\n\nluma.gl was originally created in late 2015 as a fork of [PhiloGL](https://github.com/philogb/philogl) to provide high performance WebGL rendering capability for [deck.gl](https://github.com/uber/deck.gl) - a 3D visualization framework for large scale data. As deck.gl became increasingly popluar, luma.gl saw heavier usage.\n\nWebGL 2 introduced several powerful features related to general purpose GPU usage (GPGPU) and reducing driver overhead for drawing massive numbers of objects, both of significant interest in the domain of geospatial visualization. luma.gl is built to expose these new features, while providing polyfills wherever possible when falling back to WebGL 1.\n\nToday, luma.gl is the core 3D rendering library in the [vis.gl](http://vis.gl/) framework suite.\n\n\n## Comparison with other WebGL frameworks\n\nluma.gl is a strong choice if the following are priorities:\n * Low-level access to WebGL 2 constructs: programs, shaders, buffers, etc.\n * Access to the WebGL 2 API, with seamless fallbacks to WebGL 1 for functionality that can be polyfilled via, for example, WebGL 1 extensions.\n * A focus on drawing large number of objects with minimal overhead.\n\nNote, however that luma.gl is not a complete game engine or scenegraph library, as its priority is to provide low-level access to the GPU. There is some support for higher-level abstractions like a `Model` class and a scenegraph, but these are relatively thin layers over core WebGL constructs.\n\nFor some powerful examples of what can be achieved with luma.gl, take a look at [deck.gl](http://deck.gl/#/), [kepler.gl](https://kepler.gl/) and [avs.auto](https://avs.auto/#/).\n\n\n## Future\n\nWe share information about the direction of luma.gl in the following ways:\n\n* **[RFCs](https://github.com/uber/luma.gl/tree/7.2-release/dev-docs/RFCs)** - RFCs are technical writeups that describe proposed features in upcoming releases.\n* **[Roadmap Document](https://luma.gl/#/documentation/overview/roadmap)** - (this document) A high-level summary of our current direction for future releases.\n* **[Blog](https://medium.com/@vis.gl)** - We use the vis.gl blog to share information about what we are doing.\n* **[Github Issues](https://github.com/uber/luma.gl/issues)** - The traditional way to start or join a discussion.\n","slug":"docs","title":"Overview"},{"excerpt":"Getting Started To use luma.gl in an application, simply install it using : Note: While we'll use  for these instructions, as it's the tool…","rawMarkdownBody":"# Getting Started\n\nTo use luma.gl in an application, simply install it using `yarn`:\n\n```\nyarn add luma.gl\n```\n\nNote: While we'll use `yarn` for these instructions, as it's the tool we use for development, `npm` can be used as a drop-in substitute in most cases. A map of `npm` instructions to `yarn` is available [here](https://yarnpkg.com/lang/en/docs/migrating-from-npm/).\n\n## Using with Node.js\n\nluma.gl is built to run using [headless-gl](https://www.npmjs.com/package/gl) under Node.js, which can be extremely useful for unit testing. It is important to note that `headless-gl` only supports WebGL 1 and few extensions, so not all of luma.gl's features will be available.\n\nUse `yarn install gl` to install `headless-gl`. luma.gl will automatically use it when running under Node.js. You can then create a context using the `createGLContext` context function.\n\n```js\nimport 'luma.gl';\nimport {createGLContext, Model, ...} from '@luma.gl/core';\nconst gl = createGLContext({width, height, ...});\n```\n\n## Interoperation with Other WebGL Applications\n\nluma.gl is build to interoperate cleanly with other WebGL applications using the same WebGL context. This is critical in geospatial applications, where `luma.gl` is often rendering over a base map drawn by another application.\n\nThe key to luma.gl's interoperability is careful state management. luma.gl will track GL context changes and restore them after operations are complete.\n\n\n## Using luma.gl in Isorender Applications\n\nluma.gl is designed to support isorender application, i.e. the library can be loaded without problems under Node.js, as long as the application doesn't actually try to use WebGL (i.e. create WebGL contexts). However when luma.gl discovers that headless gl is not available it tries to give a helpful message explaining the situation. This can safely be ignored.\n\nRemember that you **can** actually create WebGL contexts under Node.js, as long as the headless `gl` is installed in your `node_modules` directory. More information on [using luma.gl with Node.js](/docs/get-started/README.md).\n\n\n## FAQ\n\nWe occasionally mark github issues that contain answers to questions that pop up repeatedly with the [`FAQ` label](https://github.com/uber/luma.gl/issues?utf8=%E2%9C%93&q=label%3AFAQ+).\n","slug":"docs/get-started","title":"Getting Started"},{"excerpt":"Examples luma.gl's suite of examples are an excellent way to learn how to use the API. They're the same examples showcased on the website…","rawMarkdownBody":"# Examples\n\nluma.gl's suite of examples are an excellent way to learn how to use the API. They're the same examples showcased on the [website](http://uber.github.io/luma.gl/#/examples/overview), but can be run and edited individually.\n\n## Running Examples\n\nTo run the examples, go to their directories, install and start, e.g:\n\n```\ncd examples/core/instancing\nyarn\nyarn start\n```\n\nThis will start a local development server and open the page in your browser. The example code will be in `app.js` in the example directly will automatically refresh the page.\n\n## Using the Latest Release Branch\n\nNote that luma.gl's `master` branch is its development branch and is often in flux. To ensure you're working with stable code, simply check out one of the release branches, e.g.\n\n`git checkout 7.2-release`\n\nTo see all available release branches:\n\n```\ngit branch | grep -release\n```\n","slug":"docs/get-started/examples","title":"Examples"},{"excerpt":"Development Environment To get started developing luma.gl, first make sure to install all dependancies from the repository root:  luma.gl's…","rawMarkdownBody":"# Development Environment\n\nTo get started developing luma.gl, first make sure to install all dependancies from the repository root:\n\n`yarn bootstrap`\n\nluma.gl's source code is in the `modules/` directory. Development is most easily done by running the examples in development mode, e.g.:\n\n```\ncd examples/core/instancing\nyarn\nyarn start-local\n```\n\nAny modifications made to the source or example code will cause the example to rebuild and the page to refresh, making quick iterations on code changes straightforward.\n\nTesting against the full website can be done by running `yarn start` in the the `website/`. This full website take longer to build but makes it easier to test against all examples. This can be helpful when making core changes to luma.gl. As with running the examples in development mode, a rebuild and page refresh will be triggered whenever source or website code is updated.\n\n\n## Testing\n\nTesting is performed on Travis CI and using a precommit hook. Local testing is supported on these environments:\n\n* `yarn test` - runs tests under node using headless.gl and a headless Chrome instance (using [SwiftShader](https://github.com/google/swiftshader)).\n* `yarn test browser` - Tests in your browser, may be helpful to quickly debug test case failures since it autoreloads on changes and gives you full access to your browser's debugger.\n\nWhen adding new features, please add relevant unit tests to the `test/` directory in the relevant module.\n\n### Helpful Hints\n- To only run one test from the suite for debugging purposes, change a call to `test` in the relevant spec to `test.only`. Remember to change this back before committing!\n- If a test fails in `headless`, but not in the browser, it's likely due to a difference in the contexts created (WebGL 1 versus 2), or the extensions available. Running in a browser without WebGL 2 support (e.g. Safari), might help narrow the issue down.\n","slug":"docs/developer-guide","title":"Development Environment"},{"excerpt":"Accessors \"Buffer accessor objects\" (or \"accessor objects\", or just \"accessors\" for short) are used to describe the structure of data…","rawMarkdownBody":"# Accessors\n\n\"Buffer accessor objects\" (or \"accessor objects\", or just \"accessors\" for short) are used to describe the structure of data contained in WebGL buffers (for more information see [`Buffers`](developers-guide/buffers.md)).\n\nWhen using `Buffer`s as input to shader programs, applications must tell WebGL how the data in the buffer is formatted, so that the GPU knows how to access buffers' memory. To enable applications to specify how the buffer memory should be accessed, luma.gl APIs that set attribute buffers accept buffer \"accessor objects\".\n\n## Accessor Object Fields\n\nThis is an overview of the object accessor fields that are available to applications to define format descriptions. These objects can contain the following fields, this is an excerpt from [`Accessor`](api-reference/webgl/accessor.md).\n\n| Property    | Auto Deduced | Default    | Comment |\n| ---         | ---          | ---        | ---        | ---     |\n| `buffer`    | No           | An accessor can optionally reference a specific buffer. Multiple accessors can point to the same buffer, providing different views or \"slices\" of the buffer's memory. |\n| `offset`    | No           | `0`        | Byte offset to start of data in buffer |\n| `stride`    | No           | `0`        | Extra bytes between each successive data element |\n| `type`      | Yes          | `GL.FLOAT` | Low level data type (`GL.BYTE`, `GL.SHORT`, ...) |\n| `size`      | Yes          | `1`        | Components per element (`1`-`4`) |\n| `divisor`   | Yes          | `0`        | Enables/disables instancing |\n| `normalize` | N/A          | `false`    | Normalize integers to [-1,1], or [0,1] if unsigned |\n| `integer`   | N/A          | `false`    | Disable conversion of integer values to floats **WebGL2** |\n\n\n## Combining Accessors with Buffers\n\nWhen setting attributes (e.g. using `Model.setProps({attributes: {attributeName: value, ...}}))`, each attribute value needs to contain both a buffer (a handle to the raw data uploaded to the GPU) and an accessor (describing how that data should be accessed).\n\nluma.gl provides three methods to specify attribute values so that both a buffer and an accessor are provided:\n* As a two-element array: `[buffer, accessor]`.\n* As an accessor, in which case the accessor object's `buffer` field should be set to the matching `Buffer`.\n* As a `Buffer`, in which case the `Buffer` objects `accessor` field should be set to the mathing `Accessor`.\n\nAll three methods have their uses: the first option gives the applications full freedom to dynamically select combinations of buffers and accessors, the second option is often the natural choice when working with interleaved buffers (see below), and the last choice is often the most convenient when just setting up an ad-hoc buffer for immediate use, as the accessor can be stored directly on the buffer, avoiding the need to manage separate objects.\n\n\n## Accessor Class vs Accessor Objects\n\nluma.gl provides the [`Accessor`](api-reference/webgl/accessor.md) helper class to help you work with accessor objects. For instance, the `Accessor` class supports merging of partial accessor objects, see below.\n\nNote that it is not necessary to use the `Accessor` class, as plain old JavaScript objects with the appropriate fields are also accepted by the various APIs that accept accessors. Use the style that works best for your application.\n\n\n### \"Partial\" Accessors\n\nluma.gl allows \"partial\" accessors to be created, and later combined. Usually many accessor fields can be left undefined (e.g. because defaults are sufficient, or because accessor auto-deduction has already deduced the information, see below).\n\nPartial accessors will be created automatically by `Program` when shaders are compiled and linked, and also by `Buffer` objects when they are created. Any application supplied accessors fields will then be merged in (override) these auto-deduceted fields, that can add any fine-tuning or override of parameters.\n\n\n### Accessor Auto Deduction\n\nluma.gl attempts to \"auto deduce\" as much accessor information as it can, for instance luma.gl can extract fields like `type` and `size` after shaders have been compiled.\n\nThis relieves applications from having to respecify the same thing multiple times. For instance if the application has already declared an attribute as `in vec2 size` in the vertex shader, it does not need to specify `size:2, type: GL.FLOAT` again in the accessor, when it sets the buffer in JavaScript, since this information will have been auto-deduced.\n\nIn many cases, when buffers are not shared between attributes (i.e. interleaved) and default behavior is desired, luma.gl applications often do not need to specify any `Accessor` at all.\n\n\n### Merging (Resolving) Accessors\n\nThe `Accessor` API allows for accessors to be merged (or \"resolved\") into a new `Accessor`. Accessor mmerging is mainly used internally in luma.gl to implement support for partial accessors and accessor auto deduction, but can be used by applications if necessary.\n\n\n### Data Interleaving\n\nUsing the`stride` and `offset` fields in accessor objects, it is possible to interleave two arrays so that the first two elements of one array are next to each other, then the next two elements etc.\n\n```\nconst interleavedBuffer = new Buffer(gl, accessor: {stride: 12 + 4}}); // Creates a partial accessor with `stride` in buffer.\n\nvertexArray.setAttributes({\n  // These accessors are merged with the `interleavedBuffer` accessor and any\n  // auto-deduced accessors\n  POSITIONS: new Accessor({offset: 0, buffer: interleavedBuffer})\n  COLORS: new Accessor({offset: 12, buffer: interleavedBuffer})\n})\n```\n\nFor more information see the article about attributes.\n\n\n### Using Different Size in Buffers and Shaders\n\nIt is possible to use different size memory attributes than specified by the GLSL shader code, by specifying a different size in the accessor compared to the GLSL shader variable declaration. Extra components in the Buffer memory will be ignored, missing components will be filled in from `(0.0, 0.0, 0.0, 1.0)`\n\n> Be aware that the headless gl integration does not support this feature due to limitations in headless gl.\n\n\n### glTF Format Accessors\n\n[glTF formatted files](https://www.khronos.org/gltf/). glTF files contain two JSON object arrays (\"bufferViews\" and \"accessors\") that describe how raw memory buffers are organized and should be interpreted.\n\nThe `Accessor` and `Buffer` class APIs have intentionally been designed to be a close representation when converting \"accessors\" and \"bufferViews\" stored in glTF files. Each glTF `accessor` can be mapped to a luma.gl `Accessor` and each glTF `bufferView` can be mapped to a luma.gl `Buffer`. For more details see [glTF mapping]().\n","slug":"docs/developer-guide/accessors","title":"Accessors"},{"excerpt":"Building Apps This article contains additional information on options for how to build luma.gl. Optimizing for Bundle Size luma.gl and luma…","rawMarkdownBody":"# Building Apps\n\nThis article contains additional information on options for how to build luma.gl.\n\n\n## Optimizing for Bundle Size\n\nluma.gl and luma.gl provide a lot of functionality and the amount of code these libraries contain will of course impact the size of your application bundle and your startup load time.\n\nThere are multiple techniques used in JavaScript.\n\n\n### Choosing a dist folder\n\nWhen installed from npm, luma.gl and related libraries come with three separate `dist` sub folders.\n\n| Folder     | `mainField` | Description   |\n| ---        | ---         | --- |\n| `dist/es6` | `esnext`    | The most compact distribution is with very few exceptions essentially untranspiled ES6/ES2015 code (via `babel-preset-env`). This is the smallest distribution, and is the best choice if you are only targeting modern \"evergreen\" browsers (e.g. not IE11 or older mobile devices). |\n| `dist/esm` | `module`    | Same as `dist/es5`, except `export` and `import` statements are left untranspiled to enable tree shaking. The main reason to use this distribution is if your are targeting older browsers (e.g. IE11 or older mobile devices). |\n| `dist/es5` | `main`      | All code is transpiled into ES5 and exports/imports are transpiled into `commonjs` requires. The main reason to use this distribution is if your bundler does not support tree-shaking using `import`/`export` syntax. |\n\nYou will have to check the documentation of your particular bundler to see what configuration options are available:\n\n* Webpack 2 and later will pick the `esm` distribution by default (the `module` main field)\n* Webpack 4 allows you to choose the `esnext` distribution by specifying a new `resolve.mainFields` array in your application's webpack config.\n* For other bundlers, please refer to the respective documentation to see if you can control which distribution to use. If not, expect the `es5` distribution to be used.\n\n\n### About Tree-Shaking\n\nluma.gl is designed to fully leverage tree-shaking. Tree-shaking should be possible with any supporting browser but development has currentle focusing on enabling the webpack 4 + babel 7 combination which provides excellent results.\n\nSome things to be aware of when working with tree-shaking:\n\n* At least in Webpack, tree shaking is done by the uglifier, which is typically only run as the very last step on production builds. This means that it is typically not possible to assess the benefits of tree shaking during development.\n* The lack of tree-shaking during development makes it hard to make statements about bundle size impact of a library just from looking at bundle sizes of development builds or the size of the library's npm module. Our recommendation is to always measure impact on your actual production builds.\n\n\n### Pay for What you Use\n\nNaturally, an application that uses all the functionality offered by a framework will benefit little from tree shaking, whereas a small app that only uses a few selected components should expect big savings.\n\nWhen we modularize luma.gl, we are less focused on the size of the entire library, and more on making sure that applications only pay for the features they actually use. Also we try to make the core set of functionality small.\n\n\n### Bundle Size Numbers\n\nSo, what kind of impact on bundle sizes should you expect when using luma.gl? When do you know if you have set up your bundler optimally. To help answer these questions, we provide some numbers you can compare against. luma.gl has scripts that measure the size of a minified bundle after each build, which allows us to provide comparison numbers between releases. This bundle imports the `Module` and `AnimationLoop` classes, which are the basic building blocks of most apps.\n\n| es6-production  | 6.1 Bundle/Zip | 6.0 Bundle/Zip |\n| ---             | ---            | ---            |\n| es6-production  | 144KB  / 42KB  | 181KB  / 51KB  |\n| esm-production  | 209KB  / 49KB  | 281KB  / 66KB  |\n| es5-production  | 408KB  / 88KB  | 422KB  / 93KB  |\n| es6-development | 787KB  / 123KB | 926KB  / 165KB |\n| esm-development | 1048KB / 150KB | 1167KB / 192KB |\n| es5-development | 961KB  / 142KB | 1052KB / 182KB |\n\n\n* Numbers represent the minified bundle size of a minimal application, bundled with Webpack 4, which means that the `ES6` and ESM numbers benefit from tree shaking.\n* The number in parenthesis are the compressed bundle sizes. This is an indication of the how much extra size will be added to your compressed app bundle if you import luma.gl.\n* For the ES6 and ESM dists, apps that use more luma.gl classes and features will see an increase in bundle size.\n\n\n### Future Work\n\nThis is not the final word on luma.gl bundle size. More work is being done to reduce the size of luma.gl and we are confident that even as fture releases will have more functionality, we will be able to keep the library code from growing and, more importantly, make luma.gl even more \"tree shakeable\", with the intention that apps should only \"pay for what they use\".\n\n\n## Remarks\n\n* **Optimizing for minified code** - Due to inclusion of sourcemaps etc, the bundle size impact of luma.gl tends to look more significant in development builds than in the final production builds. While reducing the size of the development libraries is also desirable, the current goal is to ensure the impact of adding luma.gl on the final, minified/uglified application bundle is as small as possible.\n* Compressed bundle sizes are calculated using `gzip -9`. Consider using slower `brotli` compression for static assests, it typically provides an additional 20% reduction.\n","slug":"docs/developer-guide/building-apps","title":"Building Apps"},{"excerpt":"GPU Buffers GPU buffers are effectively arrays of contiguous memory that has been \"uploaded\" to the GPU and can be accessed efficiently by…","rawMarkdownBody":"# GPU Buffers\n\nGPU buffers are effectively arrays of contiguous memory that has been \"uploaded\" to the GPU and can be accessed efficiently by the GPU.\n\nReferences:\n* [OpenGL Wiki: Buffer Object](https://www.khronos.org/opengl/wiki/Buffer_Object)\n\n\n## Buffer Features\n\nIn WebGL1, buffers can be:\n\n* initialized to a certain size\n* initialized to a size and data uploaded.\n* a sub section of the data can be updated\n\nBuffers were significantly improved in WebGL2. In WebGL2 it is possible to:\n\n* copy data directly between buffers on the GPU (without \"involving\" the CPU)\n* read back data from GPU buffers to the CPU\n\n\n## Buffer Uses\n\nIn WebGL1 buffers are mainly used to\n\n* store vertex attributes, i.e. long arrays of the same value (type), int float etc.\n\nIn WebGL2 buffers can also be used to:\n\n* Receive output of GPU computations\n* Store image data\n* Store uniforms\n\n\n## Buffer Types\n\nWebGL defines a number of binding points for buffers. These are all managed under the hood by luma.gl. In WebGL buffer can be used repeatedly to represent different types of data (i.e. bound to different WebGL binding points) with one exception.\n\nAny buffer that has been used to describe indices (`target: GL.ELEMENT_ARRAY_BUFFER`), can not be used in any other context.\n\n\n## Buffer Usage\n\nBuffers have a `usage` parameter that is a hint describing how they are updated. The default value is `GL.STATIC_DRAW`.\n\n\n## Performance Considerations\n\n### Memory Transfer\n\nThe cost of transferring memory between CPU and GPU depends on many factors. E.g. on whether your GPU is using a unified memory architecture or not, the memory bandwidth of your system etc.\n\nSome good rules of thumb:\n\n* Uploading memory to GPU buffers is typically very fast, but not completely free.\n* Download of memry from GPU buffers can be quite slow, due to synchronous WebGL API and GPU pipeline stalls.\n* Copying between GPU Buffers (WebGL2), while not free, should be considered very fast.\n\n\n### Buffer Updates\n\nWhen updating buffers setting the `usage` parameter on creation can have an impact.\n","slug":"docs/developer-guide/buffers","title":"GPU Buffers"},{"excerpt":"Configuring luma.gl Optional Imports luma.gl is currently published as a single package, however there are still some optional parts of the…","rawMarkdownBody":"# Configuring luma.gl\n\n## Optional Imports\n\nluma.gl is currently published as a single package, however there are still some optional parts of the library that are made available through the use of special imports.\n\n| Optional Import            | Description |\n| ---                        | --- |\n| `import GL from '@luma.gl/constants';` | Import static WebGL constant definitions |\n| `import '@luma.gl/debug';`  | Install optional WebGL debug support. Enables creation of debug contexts. Import before creating contexts. |\n| `import 'luma.gl/webgl1';` | Install optional support for running luma.gl on WebGL1-only browsers. Import before creating contexts. |\n\n\n## Running under Node.js\n\nSee get-started for information on installing headless-gl to run WebGL under Node.js.\n","slug":"docs/developer-guide/configuring","title":"Configuring luma.gl"},{"excerpt":"Drawing Draw Calls Draw calls run a program's shaders on staged GPU data. luma.gl provides ,  etc. Note that in WebGL2 it is possible to…","rawMarkdownBody":"# Drawing\n\n\n## Draw Calls\n\nDraw calls run a program's shaders on staged GPU data.\n\nluma.gl provides `Model.draw()`, `Program.draw()` etc.\n\nNote that in WebGL2 it is possible to disable the rasterization stage, preventing draw calls from actually drawing anything. This mainly is used in combination with transform feedback.\n\n\n## Clearing\n\nYou can use `model.clear()` to clear the default framebuffer, or `framebuffer.clear()` to clear a specific framebuffer, or just call `gl.clear()` directly.\n\n\n## Framebuffers\n\nFramebuffers are container objects that hold one or more textures and/or renderbuffers, representing color buffers, depth buffers, stencil buffers etc.\n\n\n## Renderbuffers vs Textures vs Framebuffers\n\nFramebuffers hold one or more textures and/or renderbuffers. Renderbuffers are optimized for rendering performance, whereas textures (when used as render targets) support readback of rendered pixels.\n\n\n## Parameters\n\nRendering is affected by WebGL parameters, such as blending, depth testing, culling, etc.\n\n\n### Viewports\n\nA viewport specifies how clip space will be mapped to pixels on the WebGL canvas.\n\n\n### Scissor Rects\n\nA scissor rect limits rendering on the current viewport.\n\n\n### Blending\n\n\n\n\n\n\n","slug":"docs/developer-guide/drawing","title":"Drawing"},{"excerpt":"WebGL Extensions This section provides an overview of available WebGL extensions. It describes luma's builtin support for extensions (and…","rawMarkdownBody":"# WebGL Extensions\n\nThis section provides an overview of available WebGL extensions. It describes luma's builtin support for extensions (and note that even if no built-in support is provided, the application can always work directly with any extensions it needs). The Khronos group's official list of [WebGL Extensions](https://www.khronos.org/registry/webgl/extensions/) is intimidatingly long, but it can be digested more easily by categorizing them into a few basic categories.\n\nMany extensions are used automatically by luma.gl to polyfill WebGL2 functionality on WebGL1 devices.\n\n## General Extensions\n\nThese extensions expose optional general capability that was not included in the initial standard perhaps due to performance or security concerns.\n\n| Extension | Enables | luma.gl support |\n| ---       | ---     | ---             |\n| [WEBGL_shared_resources](https://www.khronos.org/registry/webgl/WEBGL_shared_resources/) | Share resource between WebGL contexts | N/A |\n| [WEBGL_security_sensitive_resources](https://www.khronos.org/registry/webgl/WEBGL_security_sensitive_resources/) | Cross-origin resource loading | N/A |\n\n\n## Debug Extensions\n\nThese extensions expose additional information and capabilities that help debug and profile a WebGL program. luma.gl carefully uses these extensions under the hood to provide a better debug experience.\n\n| Extension | Enables | luma.gl support |\n| ---       | ---     | ---             |\n| [WEBGL_lose_context](https://www.khronos.org/registry/webgl/extensions/WEBGL_lose_context/) | Simulate context loss | N/A |\n| [WEBGL_debug_renderer_info](https://www.khronos.org/registry/webgl/extensions/WEBGL_debug_renderer_info/) | Returns strings identifying GPU | glGetDebugInfo, logged to console on startup |\n| WEBGL_debug_shaders | Gives access to translated shader source | `Shader` class method |\n| EXT_disjoint_timer_query | Enables async queries of GPU timings | Used to implement `Query` under WebGL1 |\n| EXT_disjoint_timer_query_webgl2 | Enables async queries of GPU timings | Built into WebGL2 `Query` object |\n\n\n## WebGL1 Extensions\n\nThese extensions expose various OpenGL ES 3.0 features that are often available on the target devices that run the OpenGL ES 2.0 based WebGL1 standard today.\n\nNote that many of these extensions are no longer available in WebGL2 as the functionality they enable is provided by default in WebGL2 (which requires an OpenGL ES 3.0 compliant device).\n\n| Extension                   | Enables | luma.gl support |\n| ---                         | ---     | ---             |\n| `OES_vertex_array_object`   | `VertexArray` in WebGL1 | Used as WebGL2 polyfill for `VertexArray` under WebGL1. Note that luma.gl also has a \"client side\" implmentation of this extenion which is used in case the extension is not available (e.g. under headless gl). |\n| `ANGLE_instanced_arrays`    | instanced draw functions in WebGL1 | luma's draw function automatically uses this extension when required |\n| `OES_texture_float`         | Enables Float32Array textures | |\n| `OES_texture_half_float`    | Enables Uint16Array / HALF_FLOAT_OES textures | |\n| `OES_standard_derivatives`  | Enables derivative functions in GLSL | |\n| `WEBGL_depth_texture`       | Enables storing depth buffers in textures | |\n| `OES_element_index_uint`    | Querying enables Uint32Array ELEMENTS | luma queries on startup to enable, app needs to query again it wants to test platform |\n| `EXT_frag_depth`            | Enables fragment shader to control depth value | |\n| `WEBGL_draw_buffers`        | Enables fragment shaders to draw to multiple framebuffers | |\n| `OES_texture_half_float_linear` | Enables linear filter for half float textures | |\n| `EXT_blend_minmax`          | Extends blending function | Polyfills WebGL2 MIN and MAX blending modes |\n| `EXT_shader_texture_lod`    | enables shader control of LOD | |\n| `EXT_texture_filter_anisotropic` | Enables anisotropic filtering | |\n| `OES_texture_float_linear`  | Enables linear filter for float textures | |\n| `OES_fbo_render_mipmap`     | Render to specific texture mipmap level | |\n| `EXT_sRGB`                  | sRGB encoded rendering | |\n| `WEBGL_color_buffer_float` | framebuffer render to 32 bit float color buffer | |\n| `EXT_color_buffer_half_float` | framebuffer render to half float color buffer | |\n| `EXT_float_blend` | blending with 32-bit floating point color buffers | |\n\n\n## WebGL2 Extensions\n\nThese extensions expose various OpenGL ES 3.1 and 3.2 features that are often available on target devices that run the OpenGL ES 3.0 based WebGL2 standard today. These extensions can bring OpenGL ES 3.1 or 3.2 capabilities to WebGL2 contexts, if the device supports them.\n\n| Extension | Enables | luma.gl support |\n| ---       | ---     | ---             |\n| EXT_color_buffer_float | framebuffer render to float color buffer | |\n\n\n## Proposed Extensions\n\nKhronos lists a couple of proposed extensions. They will be considered by luma.gl as they become available in browsers.\n\n| Extension                         | Enables | luma.gl support |\n| ---                               | ---     | ---             |\n| `EXT_clip_cull_distance` (WebGL2) | hardware clip/cull planes (ES3.2) | N/A |\n| `EXT_texture_storage`             | texture storage effiency | N/A |\n| `WEBGL_debug`                     | Debug events | N/A |\n| `WEBGL_dynamic_texture`           | frequently changin textures | N/A |\n| `WEBGL_subarray_uploads`          | Efficient buffer update | N/A |\n\n\n## Compressed Texture Format Extensions\n\nUsed to query if the GPU supports specific proprietary compressed texture formats.\n\nThe primary advantage of compressed texture formats is that in contrast to JPGs or PNGs, they do not have to be decompressed to be used by the GPU. As a non-scientific guideline, compressed texture formats might achieve about 4x compression, compared to say 16x compression for JPEG. So while they are usually slower to load, but they could allow 4x more textures to be stored in the same amount of GPU memory.\n\nThe main issue of compressed texture formats is that they tend to be highly propietary (patent-encumbered) and there tends to be royalty requirements when using them.\nNote that (presumably due to patent issues), finding a compressed texture format which is supported across a range of target devices can be challenging.\n\nTo side-step patent issues when using these formats an application would typically:\n\n1. generate these in external commercial applications (which have already licensed any supported formats).\n2. load them in binary form without touching the content\n3. Pass them directly to a texture, so that they are processed inside the GPU driver (which also has licensed the formats).\n\nFor these reasons, luma.gl leaves the support and handling of compressed texture formats to the application.\n\n| Extension                            | Enables | luma.gl support |\n| ---                                  | ---     | --- |\n| `WEBGL_compressed_texture_s3tc`      | Certain S3TC compressed texture formats | N/A |\n| `WEBGL_compressed_texture_atc`       | Certain AMD compressed texture formats | N/A |\n| `WEBGL_compressed_texture_pvrtc`     | Certain IMG compressed texture formats | N/A |\n| `WEBGL_compressed_texture_etc1`      | Certain compressed texture formats | N/A |\n| `WEBGL_compressed_texture_etc`       | Certain compressed texture formats | N/A |\n| `WEBGL_compressed_texture_astc`      | Certain compressed texture formats | N/A |\n| `WEBGL_compressed_texture_s3tc_srgb` | Certain compressed texture formats | N/A |\n","slug":"docs/developer-guide/extensions","title":"WebGL Extensions"},{"excerpt":"Lighting luma.gl allows the application to specify a set of lights. Note that lights do not affect anything on their own. They are…","rawMarkdownBody":"# Lighting\n\nluma.gl allows the application to specify a set of lights. Note that lights do not affect anything on their own. They are interpreted by materials (or more properly by each material models). So you will want to specify both lights and a material to use lighting.\n\n## Specifying Lights\n\nluma.gl specifies a standard set of lights. The intention is that each material model should support these lights, so that meshes rendering using different material models (shader stacks) in the same scene will still be lit in the same way.\n\nAll lights have a color. A neutral light would have a white color [255, 255, 255].\n\nNotes:\n* material characteristics such as metallicity and roughness may influence how and if the material is affected by lights, in particular ambient light.\n\n### Ambient Light\n\nAmbient light comes from all directions and is useful as base lighting.\n\n### Directional Light\n\nThis light has a direction but does not attenuate with distance, it is typically used to represent \"infinitely\" distant light sources such as the sun.\n\n### Point Light\n\nThis light has a position in space and attenuates by distance. It is typically used to represent a smaller light source such as a lamp.\n\n\n## Using Lights in Scenegraphs\n\n> It is not currently possible to place lights inside a scenegraph. The ability to place lights within the graph is desirable because this way they could follow the transformation of parent nodes. In addition, the expectaion is that lights inside the graph could be auto extracted before each render pass and automatically used as lighting uniforms during that render.\n\n\n### Other Light Sources\n\n* It may also be possible to specify an emissive map in a material.\n* Light maps can be \"pre-baked\" and add shadows\n* Effects like Shadows and SSAO (screen space ambient occlusion) can also affect lighting.\n\n\n## Specifying Material Models\n\nNiote that lights do not affect anything on their own. They are interpreted by the shader stacks associated with material models.\n","slug":"docs/developer-guide/ligthing","title":"Lighting"},{"excerpt":"glTF mapping to luma.gl luma.gl v7 API contains classes that closely follow the objects defined in the glTF2 specification, making the…","rawMarkdownBody":"# glTF mapping to luma.gl\n\nluma.gl v7 API contains classes that closely follow the objects defined in the [glTF2 specification](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0), making the instantiation of a glTF 2.0 file in luma.gl rather trivial. However it can still be good to be able to reference a map of how various concepts are loaded.\n\n## GLTF structure\n\n* `scene` on the highest level, a glTF file is a list of scenes, each scene containing a list of `nodes`.\n* `node` can hold a list of child nodes, and/or a `mesh`, and/or a `camera`. It also holds a transformation that should be applied to all of these.\n* `mesh` is a list of `primitives` (and optionally, also some \"morph weights\")\n* `primitive` is just a geometry: a draw mode, a bunch of accessors, optional indices (and optionally, also some \"morph targets\")\n\n\n## Top-level Mapping\n\n| glTF concept   | luma.gl class | |\n| ---            | ---           | |\n| `accessors`    | `Accessor`    | |\n| `animations`   | N/A | |\n| `asset`        | N/A | metadata, handled by loaders.gl |\n| `buffers`      | `ArrayBuffer` | |\n| `bufferView`   | `Buffer` | |\n| `cameras`      | N/A | |\n| `images`       | `HTMLImage`? | |\n| `materials`    | `Material` (7.0) | |\n| `meshes`       | `Group`/`Model` | |\n| `nodes`        | `Group`, `Model` | A single `node` can generate one or more of these objects |\n| `primitives`   | `Model` (7.0) | |\n| `programs`     | `Program` | |\n| `samplers`     | `Sampler` (WebGL2) or `Texture2D` (WebGL1) | |\n| `scene`        | N/A | Selects one scene from `scenes` |\n| `scenes`       | `Group`           |\n| `shaders`      | `Shader`          |\n| `skins`        | Not yet supported | |\n| `techniques`   | TBD? | |\n| `textures`     | `Texture2D`| |\n\n\n## Unsupported glTF Features\n\n* skins (needs new `Skin` class)\n* morph targets (`Primitive.targets`, `Mesh.weights`)\n* Animations (needs new `Animation` class)\n\n\n## Remarks\n\n* **Overloaded Nodes** - The biggest deviation from a one-to-one mapping comes from the mapping of the glTF `node` object which can contain several different things at the same time. For some background on why glTF nodes were designed the way they are, see for instance [this discussion](https://github.com/KhronosGroup/glTF/issues/13).\n","slug":"docs/developer-guide/gltf-mapping","title":"glTF mapping to luma.gl"},{"excerpt":"Debugging luma.gl has a number of provisions for debugging designed to help you save time during development. Seer Integration luma.gl is…","rawMarkdownBody":"# Debugging\n\nluma.gl has a number of provisions for debugging designed to help you save time during development.\n\n\n## Seer Integration\n\nluma.gl is integrated with the [`seer`](https://chrome.google.com/webstore/detail/seer/eogckabefmgphfgngjdmmlfbddmonfdh) Chrome extension, giving you a powerful tool for viewing and inspecting luma.gl state at runtime when developing in Chrome. Installing the extension gives you a new tab in the developer tools where you can:\n\n* See list of created `Models`\n* Inspect values of uniforms and vertex attributes\n* See GPU render timings for each model\n* and much more.\n\n\n## id strings\n\nMost classes in luma.gl allow you to supply and optional `id` string to their constructors. This allows you to later easily check in the debugger which object (which specific instance of that class) is involved in a stack trace.\n\n```js\nconst program = new Program(gl, {id: 'cube-program', ...});\nconst program = new Program(gl, {id: 'pyramid-program', ...});\n```\n\n`id`s that you provide are also used by the built-in logging.\n\n\n## Logging\n\nluma.gl has a logging mechanism. Set the global variable luma.log.priority to 3 (can be done in the browser console at any time) and luma will print tables for uniforms and attributes providing information about their values and types before each render call. This can be extremely helpful for checking that shaders are getting valid inputs.\n\n\n## Shader compilation errors\n\nluma.gl takes care to extract as much information as possible about shader compiler errors etc, and will throw exceptions with very detailed error strings when shaders fail to compile. luma.gl also injects and parses `glslify` \"shader names\", making it possible to name shaders inside the shader code, making it easier to identify which shader is involved when e.g shader parsing errors occur.\n\n\n## Parameter Validation\n\nluma.gl runs checks on attributes and buffers when they are being set, catching many trivial errors such as setting uniforms to `undefined` or wrong type (scalar vs array etc).\n\nBuffers will also have their first values checked to ensure that they are not NaN. As an example, setting uniforms to illegal values now throws an exception containing a helpful error message including the name of the problematic uniform.\n\n\n## Debug Mode Contexts\n\n> Warning: Debug contexts impose a significant performance penalty (due to waiting for the GPU after each WebGL call to check error codes) and should not be used in production builds.\n\nluma.gl is pre-integrated with the Khronos group's WebGL debug tools (the [WebGLDeveloperTools](https://github.com/KhronosGroup/WebGLDeveloperTools)) and can use these to \"instrument\" `WebGLRenderingContext`s.\n\nThe `WebGLDeveloperTools` are automatically installed when luma.gl is installed, but are not actually bundled into the application unless explicitly imported. This avoids impacting the size of production bundles built on luma.gl that typically do not need debug support.\n\nTo use debug support, first import the debug tools, then call `getDebugContext` to create a debug contexts from a normal WebGL context:\n\n```js\nimport '@luma.gl/debug';\nconst gl = getDebugContext(gl);\n```\n\nIf the debug tools haven't been imported, `getDebugContext` will print a warning and simply return the original context, so the debug code can be left in the applicatin even when debug support is not imported.\n\nWhen the `luma.log.debug` flag is set, a debug contexts does the following:\n\n* **Detects WebGL Errors** - Check the WebGL error status after each WebGL call and throws an exception if an error was detected, taking care to extract helpful information into the error message. Raw WebGL calls tend to either fail silently or log something cryptic in the console without making it clear what call generated the warning.\n\n* **Checks WebGL Parameters** - WebGL parameter checks help catch a number of common WebGL coding mistakes, which is important since bad parameters in WebGL often lead to hard to debug symptoms such as silent failures to render, or to inscrutable error messages in the console.\n\n\n\n\n","slug":"docs/developer-guide/debugging","title":"Debugging"},{"excerpt":"Loading Data Often 3D applications need to load assets like textures and models into memory. Data loading is not a part of luma.gl, however…","rawMarkdownBody":"# Loading Data\n\nOften 3D applications need to load assets like textures and models into memory.\n\nData loading is not a part of luma.gl, however an optional companion framework (loaders.gl) provides a rich suite of compatible loaders.\n\n## Loading Images and Textures\n\n`Texture` constructors accept any WebGL-supported texture image data sources such as `Image` objects and image data arrays. They also accept `Promise`s that resolve the those objects. This enables applications to pass the `Promise` from an image loading function directly to the texture constructor:\n\nFor basic image loading use cases, a very simple `loadImage` utility is included in luma.gl:\n\n```\nimport {Texture2D, loadImage} from '@luma.gl/core';\n\n// The following constructors are all equivalent:\nconst texture = new Texture2D(gl, url); // String argument, `loadImage` automatically called\nconst texture = new Texture2D(gl, {data: url}); // String `data`, `loadImage` automatically called\nconst texture = new Texture2D(gl, loadImage(url)); // Promise argument\nconst texture = new Texture2D(gl, {data: loadImage(url)}); // Promise `data`\n```\n\nNote: the luma.gl `Program.draw()` function will not render until all texture uniforms have been initialized (i.e. any promises have resolved).\n\n\nFor more advanced use cases, e.g. loading images in browser worker threads or Node.js, you can use custom image loading code or the `loadImage` utilities from loaders.gl.\n\n```\nimport {Texture2D} from '@luma.gl/core';\nimport {loadImage} from '@loaders.gl/core';\n\nconst texture = new Texture2D(gl, loadImage(url));\nconst texture = new Texture2D(gl, {data: loadImage(url)});\n```\n\n## Loading Meshes and Point Clouds\n\nRefer to loaders.gl for a suite of loaders supporting a variety of 3D formats.\n\n\n## Loading glTF Scenegraphs\n\nInstall `@loaders.gl/gltf`.\n\nSupport for Draco encoded glTF models is also available, however it requires installing and injecting the draco decoder into the gltf parser.\n","slug":"docs/developer-guide/loading-data","title":"Loading Data"},{"excerpt":"Portability luma.gl enables developers to write WebGL2-style applications that still work on older WebGL versions, and are portable across…","rawMarkdownBody":"# Portability\n\nluma.gl enables developers to write WebGL2-style applications that still work on older WebGL versions, and are portable across browsers and node, as well as across operating systems and GPUs.\n\n## WebGL Versions\n\n### Unified API\n\nluma.gl offers a single, WebGL2-based API for accessing WebGL functionality. This same API works regardless of whether a function is provided by WebGL2 or a WebGL1 extension.\n\nTaking advantage of WebGL1 extensions when available.\n\n### Polyfills\n\nWhen possible, \"polyfills\" are done on the `WebGLRenderingContext` level, meaning that many missing WebGL2 functions are injected into WebGL1 contexts, with implementations that transparently use WebGL1 extensions while providing the WebGL2 API.\n\nTBA - Couple of examples of polyfilled functionality (instanced rendering, ...)?\n\n\n### Feature Detection System\n\nluma.gl offers a feature detection system that is easier to work with than directly querying for WebGL extensions. The main advantages is that it allows a single function calls to determine whether a capability is present, regardless of whether it is available through a WebGL1 extension or WebGL2. It also offers a list of capability names that more accurately reflect the capability being queries, compare to the rather technical WebGL extension names.\n\n```js\nhasFeature();\n```\n\nTBA - Examples link to reference\n\n\n\n## GLSL Versions\n\nWebGL2 introduces GLSL version 3.00. While it introduces important new features, parts of the GLSL shader language syntax changed. This is a complication because when writing reusable shader code (such as a shader module), it would often be desirable for GLSL code to work in both GLSL 1.00 and 3.00 shaders.\n\nSee [shadertools].\n","slug":"docs/developer-guide/portability","title":"Portability"},{"excerpt":"Stencil Buffer Using Stencil Buffers The stencil buffer API supports a number of features which makes it look somewhat complex at first…","rawMarkdownBody":"# Stencil Buffer\n\n\n## Using Stencil Buffers\n\nThe stencil buffer API supports a number of features which makes it look somewhat complex at first glance, but the basic operations are turning on and off stencil testing.\n\n\n\n### Typical usage\n\nEnable stencil testing and set the actions to take whenever any of the tests succeed or fail:\n\n```js\nsetParameters({\n  stencilTest: true, // turn on stencil buffers\n  stencilOp: [GL.KEEP, GL.KEEP, GL.REPLACE] // update the stencil buffer if both stencil and depth tests pass\n  stencilFunc: [GL.ALWAYS, 1, 0xFF] // turn off stencil test: update the stencil buffer, regardless of current stencil value\n  stencilMask: 0xFF // mask that enables writing of all bits\n})\n\nclear(GL_STENCIL_BUFFER_BIT)\n\n// draw\n```\n\n```js\nsetParameters(gl, {\n  glStencilFunc(GL_NOTEQUAL, 1, 0xFF);\n  glStencilMask(0x00); // disable writing to the stencil buffer\n  glDisable(GL_DEPTH_TEST);\n})\n```\n\n\n### More advanced usage\n\n* Multiple Stencil Buffers: By using the bit-planes in the stencil buffer one can manage 8 different stencil buffers, and clip to any combination of these buffers.\n* Counting occlusions per fragment\n\n\n\n### Creating stencil buffers\n\nStencil buffers are not created by default.\n\n\n### Stencil Testing\n\nThe stencil test flag turns on both reading and writing to buffers.\n\n```js\nsetParameters(gl, {stencilTest: true})\n```\n\nThe stencil test by default is set to always pass. Typically an application wants the stencil buffer value to be compared against some other value.\n\n```js\nsetParameters(gl, {stencilFunc: [GL.GEQUAL, 0xFF, 0xFF]})\n```\n\n\n\n### Stencil Writing\n\nTo write to the stencil buffer:\n\n```js\nsetParameters(gl, {\n  stencilOp: [stencilTestFails, depthTestFails, stencilAndDepthTestPass]\n})\n```\n\nInitial values are `GL.KEEP` so nothing will be written to the stencil buffer unless the `stencilOp` is changed.\n\n| Enum           | Operation |\n| ---            | --- |\n| `GL.KEEP`      | Don't modify the current value (default) |\n| `GL.INVERT`    | Invert the current value |\n| `GL.ZERO`      | Set it to zero |\n| `GL.REPLACE`   | Replace with the masked fragment value |\n| `GL.INCR`      | Increment the current value, saturating if it would overflow (max is typically 255) |\n| `GL.INCR_WRAP` | Increment the current value, wrapping if it would overflow (256 => 0) |\n| `GL.DECR`      | Decrement the current value, setting to zero if it would underflow |\n| `GL.DECR_WRAP` | Decrement the current value, wrapping if it would underflow (0 => 256) |\n\n1: Meaning that it stops at the maximum representable integer at the stencil buffer's bitdepth. For an 8-bit stencil buffer, that would be 255.\n\n\n## Stencil mask\n\nWhere a 0 appears, the corresponding bit is write-protected. Initially, all bits are enabled for writing.\n\n```js\nsetParameters(gl, {stencilMask: 0xFF})\n```\n\n","slug":"docs/developer-guide/stencil-buffers","title":"Stencil Buffer"},{"excerpt":"Programs and Shaders A  performs the following duties: Holds, and links together, two shader programs (vertex and fragment shaders) so that…","rawMarkdownBody":"# Programs and Shaders\n\nA `Program` performs the following duties:\n\n* Holds, and links together, two shader programs (vertex and fragment shaders) so that they can be executed via a draw call.\n* Extracts information about attributes and uniforms from the linker.\n* Stores uniforms\n* Runs the linked shaders using the stored uniforms (as well as attributes from a `VertexArray` object and optionally output buffers from a `TransformFeedback` object).\n\nThe `Program` constructor always links shaders and queries the linkers output to extract an \"attribute configuration map\". This attribute configuration map can be transferred to `VertexArray` and `TransformFeedback` objects which allows those objects to accept the names of shader `in` and `out` parameters instead of numeric location indices.\n\n\n## Running Programs\n\nThe way to execute anything on the GPU happens through calls to `Program.draw()`, which runs the programs. Running the program (i.e the shaders) is customarily referred to as a \"draw call\", but does not necessarily draw anything on the screen.\n\n\nThe `Program.draw` call runs the shader\n\n```js\nconst program = new Program(gl, {vs, fs});\nprogram.setUniforms({...})\nprogram.draw({...});\n```\n\n## Updating Uniforms\n\nTo store new uniform values, call `Program.setUniforms()` (or `Model.setUniforms()`) with a uniforms object map.\n\nThe `Program.draw()` class accepts a uniforms object (map), which will set (i.e. store) the supplied uniforms on the `Program` just before drawing (and leave them set!).\n\nSetting uniforms in each draw call does allow for a very attractive \"functional\" programming style but for very draw call intensice programs it can slightly impact performance. For uniforms that change with each draw call, we don't have a choice, but for other uniforms it can be slightly more performance to set them outside of the render loop.\n\nExamples could be a `time` uniform that updates every frame, versus a `scale` uniform that changes only when the user manipulates a control in the application's user interface.\n\n\n## Configuring Vertex Attributes\n\n`VertexArray` objects allow the user to store a set of buffer bindings / constants that specify what values the various vertex shader `in` parameters (also known as \"attributes\") will have during a draw call.\n\n```js\nconst program = new Program();\nconst vertexArray = new VertexArray(gl, {\n  program,\n  attributes: {\n    ...\n  }\n});\n...\nprogram.draw({vertexArray, ...});\n```\n\n`VertexArray` objects need to be configured to match the expectations of a linked program, and the details of this configuration are rather technical, The good news is `VertexArray` objects can obtain most of the required configuration data from a `Program` instance. This data includes the name and types of attributes. In some cases, when configuration is needed, extra parameters can be added to a buffer.\n\n\n\nOnce configured, `VertexArray` objects can be manipulated independently of the program. And you can create multiple `VertexArray` objects that can be used with your program, and these `VertexArray` object can also be used with other programs (as long as they are created with identical parameters, i.e. same shaders etc).\n\n```js\nconst program = new Program(gl, {fs: FS, vs: VS});\nconst vertexArray1 = new VertexArray(gl, {program});\nconst vertexArray2 = new VertexArray(gl, {program});\nconst vertexArray3 = new VertexArray(gl, {program});\n...\nprogram.draw({vertexArray: vertexArray1, ...});\nprogram.draw({vertexArray: vertexArray2, ...});\nprogram.draw({vertexArray: vertexArray3, ...});\n\nconst program2 = new Program(gl, {fs: FS, vs: VS});\nprogram2.draw({vertexArray: vertexArray1, ...});\n```\n\n\n## Configuring TransformFeedback outputs\n\nTransformFeedback objects work very similarly to `VertexAttribute` objects\n\n```\nconst program = new Program();\nconst vertexArray = new VertexArray(gl, {program});\nconst transformFeedback = new TransformFeedback(gl, {program});\n...\nprogram.draw({vertexArray, transformFeedback...});\n```\n\nJust as with `VertexAttributes`, you can create multiple `TransformFeedback` objects for each program, and use them with any program built from (exactly) the same shaders.\n\n\n## Debugging Programs\n\nGetting all data properly configured before calling `Program.draw()` is key to correct exection. The result of mistakes is often just silent failure and black screens, and there are precious few ways to debug what has gone wrong. Because of this, luma.gl provides extensive validation and logging support, for more information see the [debugging]() article.\n\n\n## Remarks\n\n* There is a cost to updating uniforms. As a general guide, this cost should be considered quite small, but not completely free, and can compound when drawing many programs each with many uniforms. The cost is partly (but not completely) reduced since the `Program` class may do comparisons on uniform values before setting them to avoid unnecessary WebGL uniform updates.\n\n* The fact that uniforms are stored on the program object (as opposed in a separate \"uniform bank\" object) is often considered a design flaw in WebGL and OpenGL. Just like it is convenient to be able to use separate `VertexArray`s or `TransformFeedback` objects with the same program, it would be nice to be able to use separate uniform banks to quickly switch between different sets of uniforms. In WebGL1 one must create multiple program instances to store multipe uniform sets. In WebGL2 \"uniform buffers\" can somewhat compensate for the limitation, although they are not nearly as easy to use as the basic uniform API.\n","slug":"docs/developer-guide/programs-and-shaders","title":"Programs and Shaders"},{"excerpt":"Transform Feedback (WebGL2) Transform Feedback operations represent a GPGPU/GPU compute technique where GPU draw calls are configured so…","rawMarkdownBody":"# Transform Feedback (WebGL2)\n\nTransform Feedback operations represent a GPGPU/GPU compute technique where GPU draw calls are configured so that they write some specified outputs from the vertex shaders to (one or more) GPU memory buffers that have been provided by the application. Applications use transform feedback to data processing from CPU to GPU, where multiple parallel execution units will be used for processing. Data is handled in form of `Buffer` objects, i.e. data resides in the GPU memory.\n\nTransform Feedback operations write their output into `Buffer` instances. These buffers can then be directly set as attributes on `Model` or `VertexArray` for regular rendering operations.\n\nBuffers can be read back to the CPU, but this has a high performance penaltyh. Ideally, the application's logic can be designed so that CPU access is not required which avoids expensive CPU and GPU sync.\n\nTo run a single transform feedback operation:\n\n* Create a `Program` or a `Model` with varyings (`out` variables) declared in the vertex shader's GLSL code, and provide the names of these varyings to the `Program` constructor.\n* Use `Program.draw()` or `Model.draw()` with a `transformFeedback` parameter.\n* `Model.transform()` is equivalent to `Model.draw()` but automatically turns off the fragment shader stage.\n\nAlternatively, the more powerful `Transform` class is preferable if you don't want to deal with setting up `Program` and `TransformFeedback` instances, or if intend to run a repeating, double buffered transform feedback loop.\n\n\n## Usage\n\n```js\nimport {Transform} from '@luma.gl/core';\n```\n\n### Use case : Specify source and destination buffers.\n\nCreate a `Transform` object by passing, vs (vertex shader), source buffer(s), varyings (output variable names in vertex shader) and destination buffers. Then call `run` to perform one transform feedback iteration.\n\n```js\nconst VS = `\\\n#version 300 es\nattribute float inValue;\nvarying float outValue;\n\nvoid main()\n{\n  outValue = 2.0 * inValue;\n}\n`;\n\nconst sourceData = new Float32Array([10, 20, 31, 0, -57]);\nconst sourceBuffer = new Buffer(gl, {data: sourceData});\n\n// Default values applied for size (1) and type (gl.FLOAT)\nconst feedbackBuffer = new Buffer(gl, {byteLength: sourceData.length * 4});\n\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inValue: sourceBuffer\n  },\n  feedbackBuffers: {\n    outValue: feedbackBuffer\n  },\n  vs: VS,\n  varyings: ['outValue'],\n  elementCount: 5\n});\n\n// Perform one transform feedback iteration\ntransform.run();\n```\n\n### Use case : Create destination buffers automatically.\n\n`Transform` can internally create destination buffers (i.e. feedback buffers), when `feedbackMap` is provided. Each destination buffer is created with same settings and layout as corresponding source buffer as per `feedbackMap`.\n\n```js\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inValue: sourceBuffer\n  },\n  feedbackMap: {\n    inValue: 'outValue'\n  },\n  vs: VS,\n  varyings: ['outValue'],\n  elementCount: 5\n});\n\n```\n### Use case : Multiple iterations using swap().\n\nWhen `feedbackMap` is specified buffers can be swapped using a single call to `swap()`, this is useful for cases like particle simulation, where output of one transform feedback iteration is piped as input to the next iteration.\n\n```js\n\n// Setup Transform with `souceDestinationMap` as above\n\ntransform.run();\n\nlet bufferWithNewValues = transform.getBuffer('outValue');\n...\n// Render using 'bufferWithNewValues'\n...\n\n//swap buffers\ntransform.swap();\ntransform.run();\nbufferWithNewValues = transform.getBuffer('outValue');\n...\n// Render using 'bufferWithNewValues'\n...\n```\n\n### Use case : Update one or more buffers using update() method..\n\nOnce `Transform` object is constructed and used, one or more source or destination buffers can be updated using `update`.\n\n```js\n// transform is set up as above\n...\n\n// update buffer binding for 'inValue' attribute\nconst newSourceBuffer = new Buffer(gl, {data: newSourceData});\ntransform.update({\n  sourceBuffers: {\n    inValue: newSourceBuffer\n  }\n});\n\n// now data is provided from newly bound buffer.\ntransform.run();\n```\n","slug":"docs/developer-guide/transform-feedback","title":"Transform Feedback (WebGL2)"},{"excerpt":"Using GLSL 3.00 ES luma.gl makes it easy to write portable applications that work with the latest WebGL APIs (WebGL2 components and methods…","rawMarkdownBody":"# Using GLSL 3.00 ES\n\nluma.gl makes it easy to write portable applications that work with the latest WebGL APIs (WebGL2 components and methods in JavaScript and GLSL 3.00 ES in shaders), by providing a modern JavaScript components and transparently handling differences between WebGL and GLSL versions.\n\n\n## Automatic GLSL Code Transpilation\n\nIf one wishes to use GLSL 3.00 features in a shader, one has to make modifications to the shader so that it no longer runs on GLSL 1.00 code. For a small monolithic shader it may be less of an issue (e.g. if you need WebGL2 features, use GLSL 3.00, otherwise GLSL 1.00) but if the goal is to create reusable shader code that can run under both WebGL1 and WebGL2 and both in GLSL 1.00 and GLSL 3.00 shaders, then there are problems.\n\n\n### Textual replacement\n\nThe required modifications are very simple, and can mostly be done by a (fairly) simple series of textual replacements, as detailed in the proposal below.\n\n\n### Fragment Shader Outputs\n\nThe major complication is related to fragment shader outputs, that use built-in `gl_fragColor`/`gl_fragData[]` variables in GLSL 1.00, but must be declared as variables in GLSL 3.00. And any variable starting with `gl_` is reserved, so names must be changed.\n\n\n* Shader Assembler knows the target version of GLSL.\n* It applies as series of regular expressions (different between vertex and fragment shader) to replace basic constructs.\n* Users will need to avoid WebGL2 constructs if they wish their shaders to compile\n\n\n### Table of replacements\n\n#### Converting from GLSL 3.00 to 3.00\n\nTo enable portable code to be written, we must allow some non-conformant code in GLSL 3.00.\n\nMost importantly, `texture` in GLSL 3.00 might translate to either `texture2D` or `textureCube` in GLSL 1.00. Therefor we allow `textureCube` to be used in GLSL 3.00 code but automatically change it to `texture`.\n\n\n#### Converting from GLSL 3.00 to 1.00\n\nVertex Shader\n\n* `in` -> `attribute` - only beginning of line\n* `out` -> `varying` - only beginning of line\n\nFragment Shader\n\n* `in` -> `varying` - only beginning of line\n* `out` -> `gl_fragColor/gl_fragData[]` - only beginning of line, remove declaration\n\nCommon\n\n* `texture` -> `texture2D`\n\n\n### Converting from GLSL 1.00 to 3.00\n\nVertex Shader\n\n* `attribute` -> `in` - can be done with macro\n* `varying` -> `out` - can be done with macro\n\nFragment Shader\n\n* `varying` -> `out` - only beginning of line\n* `out` -> `gl_fragColor/gl_fragData[]` - only beginning of line, remove declaration, if multiple `out`s use gl_fragData\n\nCommon\n\n* `texture2D` -> `texture`\n* `textureCube` -> `texture`\n","slug":"docs/developer-guide/using-glsl-300-es","title":"Using GLSL 3.00 ES"},{"excerpt":"ShaderTools Overview shadertools is a GLSL shader module system built around a GLSL \"assembler\" that allows you build modular shaders. It…","rawMarkdownBody":"# ShaderTools\n\n## Overview\n\nshadertools is a GLSL shader module system built around a GLSL \"assembler\" that allows you build modular shaders. It addresses the lack of a module/import system in the GLSL language and allows you to import chunks of reusable shader code from modules into your shader source code, and organize your shader code in reusable modules.\n\n* Enables you to import and \"inject\" prepackaged modules of shader code into your shaders.\n* Allows you to package up reusable GLSL code as shader modules.\n* Adds GPU detection and a measure of portability your shaders.\n\n\n## Usage\n\nTo add/inject existing modules into your shaders, just add the modules parameter to your `assembleShaders` call:\n\n```js\nimport {shaderModule} from 'library-of-shader-modules';\nconst {vs, fs, getUniforms, moduleMap} = assembleShaders(gl, {\n  fs: '...',\n  vs: '...',\n  modules: [shaderModule],\n  ...\n})\n```\n\nTo create a new shader module, you need to create a descriptor object.\n\n```js\nconst MY_SHADER_MODULE = {\n  name: 'my-shader-module',\n  vs: ....\n  fs: null,\n  dependencies: [],\n  deprecations: [],\n  getUniforms\n};\n```\n\nThis object can be used as shader module directly:\n\n```js\nassembleShaders(gl, {..., modules: [MY_SHADER_MODULE]});\n```\n\n\n## Comparison with other WebGL shader module systems\n\nThe shadertools shader assembler is a GLSL source preprocessor. There are other systems available which can potentially be used in place of, or in combination with shadertools.\n\n\n### [glslify](https://github.com/glslify/glslify)\n\n* Lets shader modules be published (and consumed as) npm modules.\n* Does full GLSL shader parsing and renames symbols to avoid conflicts.\n* Note that glslify setups typically involve build tool plugins, which can be a complication.\n\nNote: shadertools doesn't touch the preprocessor definitions used by glslify, so running glslify either before or after shadertools should work fine.\n\n\n### [shadergraph](https://github.com/unconed/shadergraph)\n\n* Detailed matching of varyings between vertex and fragment shaders\n* Nice graph visualizer\n* Written in coffee-script which is a consideration if considering to fork or extend.\n*\n","slug":"docs/developer-guide/shadertools","title":"ShaderTools"},{"excerpt":"Module Structure luma.gl contains a lot of classes and functions that might make new users wonder where to get started. luma.gl therefore…","rawMarkdownBody":"# Module Structure\n\nluma.gl contains a lot of classes and functions that might make new users wonder where to get started. luma.gl therefore organize classes and functions into groups, as shown in the following table and also in the folder structure of the source code\n\n| Module                           | Description |\n| ---                              | --- |\n| src/webgl | A set of classes covering all **WebGL objects**. Currently luma.gl supports WebGL 2.0. These classes organize the WebGL2 API and makes it easy to work with in JavaScript. |\n| src/core | A set of common classes across all 3D graphics applications. They are on a higher abstraction level than the WebGL API. luma.gl's signature [`Model`](/docs/api-reference/core/model.md) class is in this folder. |\n| src/geometry | This folder contains a collection of geometric primitives extending from the base `Geometry` class, including `ConeGeometry`, `CubeGeometry`, `IcoSphereGeometry`, `PlaneGeometry`, `SphereGeometry`, `SphereGeometry`. They can be used to create [`Models`](/docs/api-reference/core/model.md) class with common geometries|\n| src/models | Some predefined subclasses of [`Models`](/docs/api-reference/core/model.md) created from simple geometries from the `src/geometry` folder|\n| src/io | Node.js and browser file loaders. Also enables using streams in browser. |\n| src/packages/events | A very simple browser event handling class used by luma.gl examples |\n| src/shadertools | luma.gl's internal shader module system and shader assembler utility |\n| src/webgl-utils | Miscellaneous utilies |\n\n## WebGL Classes\n\nThe heart of luma.gl is the `webgl` module, a set of JavaScript class wrappers covering all WebGL objects. From luma.gl v4,\nAfter creating a context, perhaps with luma.gl's [`createGLContext`](/docs/api-reference/webgl/context/context.md) function, you have can start instantiating luma.gl's WebGL2 classes: [`Buffer`](/docs/api-reference/webgl/buffer.md), [`FrameBuffer`](/docs/api-reference/webgl/framebuffer.md), [`RenderBuffer`](/docs/api-reference/webgl/renderbuffer.md), [`Program`](/docs/api-reference/webgl/program.md), [`Shader`](/docs/api-reference/webgl/shader.md), [`Texture2D`](/docs/api-reference/webgl/texture-2d.md), [`Texture3D`](/docs/api-reference/webgl/texture-3d.md), [`TextureCube`](/docs/api-reference/webgl/texture-cube.md), [`Query`](/docs/api-reference/webgl/query.md), [`TransformFeedback`](/docs/api-reference/webgl/transform-feedback.md), [`VertexArrayObject`](/docs/api-reference/webgl/vertex-array.md)\n\n## Core Classes\n\nThe `core` classes, with the signature [`Model`](/docs/api-reference/core/model.md) class, represents a set of objects that is common in most 3D rendering libraries or engines. These objects are at higher abstraction levels than the actual WebGL objects and that can serve as the basic building blocks for most 3D applications.\n\n* [`Model`](/docs/api-reference/core/model.md) - A renderable object with program, attributes, uniforms and other state required for rendering 3D objects on the screen\n* [`Geometry`](/docs/api-reference/core/geometry.md) - Holds attributes and drawType for a primitive geometric object\n* [`AnimationLoop`](/docs/api-reference/core/animation-loop.md) - A simple animation loop that connects with browser's animation mechanism\n\n<!---\n* [`Object3D`](api-reference/core/object3d) - Base class, golds position, rotation, scale (TBD)\n* [`Group`](api-reference/core/group) - Supports recursive travesal and matrix transformation\n-->\n\n## Basic Geometries and Models\n\nA `Geometry` object holds a set of attributes (native JavaScript arrays) (vertices, normals, texCoords, indices) and a `drawMode` prop to indicate how to interpret those vertices and normals as actual geometries.\n\nThere are several basic geometry classes predefined in luma.gl: `Geometry`, `ConeGeometry`, `CubeGeometry`, `IcoSphereGeometry`, `PlaneGeometry`, `SphereGeometry`, `SphereGeometry`. They are all subclasses of the `Geometry` class.\n\nCorresponding to those geometry objects, luma.gl also provides commonly used [`Model`](/docs/api-reference/core/model.md) classes that consist of basic geometries. These include [`Cone`](/docs/api-reference/core/scenegraph/geometries/cone.md), [`Cube`](/docs/api-reference/core/scenegraph/geometries/cube.md), [`Cylinder`](/docs/api-reference/core/scenegraph/geometries/cylinder.md), [`IcoSphere`](/docs/api-reference/core/scenegraph/geometries/ico-sphere.md), [`Plane`](/docs/api-reference/core/scenegraph/geometries/plane.md) and [`Sphere`](/docs/api-reference/core/scenegraph/geometries/sphere.md), etc...\n\n\nUsers are encouraged to write their own geometries and models and luma.gl could include them in its future releases.\n","slug":"docs/api-reference","title":"Module Structure"},{"excerpt":"Model Integration Note that the luma.gl  class is integrated with the  system. The shader you pass to the  class constructor will…","rawMarkdownBody":"# Model Integration\n\nNote that the luma.gl `Model` class is integrated with the `assembleShaders` system. The shader you pass to the `Model` class constructor will automatically be passed to `assembleShaders` if you supply `modules` parameter.\n\nBy passing your shaders to the `assembleShaders` function, the `shadertools` module adds platform detection and portability your shaders. In addition it also enables you to \"inject\" shader code (GLSL code) that has been packaged into reusable, composable \"modules\". And naturally, `shadertools` also allows you to create your own reusable shader modules.\n\n## Usage\n\n```js\nconst model = new Model(gl, {\n  fs: '...',\n  vs,\n  modules: [],\n});\n```\n\nTo use the shader module system directly to add/inject modules into your shaders, just call `assembleShaders`:\n```js\nconst {vs, fs, getUniforms, moduleMap} = assembleShaders(gl, {\n  fs: '...',\n  vs: '...',\n  modules: [...],\n  defines: {...}\n})\n```\n\nTo create a new shader module, you need to create the following object\n```js\nconst module = {\n  name: 'my-module',\n  vs: ....\n  fs: null,\n  dependencies: [],\n  deprecations: [],\n  getUniforms\n};\n```\n\nThis object can be used as shader module directly, or you can register it so that it can be referred to by name.\n```js\nnew Model(gl, {..., modules: [module]});\nregisterShaderModules([module]);\nnew Model(gl, {..., modules: ['my-module']});\n```\n","slug":"docs/developer-guide/shadertools/model-integration","title":"Model Integration"},{"excerpt":"Shader Assembly The  function provides a number of features that help applications build up shaders in a structured way. Features Version…","rawMarkdownBody":"# Shader Assembly\n\nThe `assembleShader` function provides a number of features that help applications build up shaders in a structured way.\n\n\n## Features\n\n### Version Handling\n\n* Version directive (like `#version 300 es`) must be the very first line in `vs` and `fs` shader if it exists, `assembleShaders` will make sure it is still the very first line in resolved shader.\n\n\n### Prologue Injection\n\nA two part prologue is injected by default:\n\n* A GPU indentification prologues, containing defines identifying GPU and driver to enable bug workarounds.\n* a GLSL feature detection prologue, simplifying writing code that works with GLSL extensions and across GLSL versions (WebGL1 and WebGL2)\n\n\n### \\#define Statement Injection\n\nA simple map of keys and values are injected as:\n\n```\n#define key1 value1\n#define key2 value2\n...\n```\n\nThe defines will be included before modules and can thus be used to affect modules.\n\n\n### Shader Module Import\n\nWill follow module dependencies and inject dependency tree in correct order\n\n\n### Shader Module Transpilation\n\n\n### Shader Code Injection\n\nShader injection allows shader code \"fragments\" to be inserted into existing shader code, allowing applications to add code to an existing shader without having to duplicate and directly modify its source code. One main use case is adding the few lines of code needed to use a new shader module in an existing shader.\n\n\n","slug":"docs/developer-guide/shadertools/shader-assembly","title":"Shader Assembly"},{"excerpt":"Using Shader Modules Usage To add/inject existing modules into your shaders, just add the modules parameter to your  call: To configure the…","rawMarkdownBody":"# Using Shader Modules\n\n## Usage\n\nTo add/inject existing modules into your shaders, just add the modules parameter to your `assembleShaders` call:\n\n```js\nimport {shaderModule} from 'library-of-shader-modules';\nconst {vs, fs, getUniforms, moduleMap} = assembleShaders(gl, {\n  fs: '...',\n  vs: '...',\n  modules: [shaderModule],\n  ...\n})\n```\n\nTo configure the shader module uniforms:\n\n```\nconst {vs, fs, getUniforms, ...} = assembleShaders(gl, {..., modules: [...]});\n\n// create a program with the returned shaders using your preferred WebGL library\n\nconst uniforms = getUniforms(props);\n\n// set returned uniforms on the program using your preferred WebGL library\n\n```\n\n\n## GLSL Versions and Shader Module Transpilation\n\nShader Modules are automatically converted (\"transpiled\") to the version of the shader you are importing them into.\n\n\n## Shader Code Injection\n\nBy using the `inject` parameter, code can be injected into existing shaders.\n","slug":"docs/developer-guide/shadertools/using-shader-modules","title":"Using Shader Modules"},{"excerpt":"Writing Shadertools Shader Modules Usage This object can be used as shader module directly: Alternatively, you can register it so that it…","rawMarkdownBody":"# Writing Shadertools Shader Modules\n\n\n## Usage\n\n\nThis object can be used as shader module directly:\n\n```js\nassembleShaders(gl, {..., modules: [MY_SHADER_MODULE]});\n```\n\nAlternatively, you can register it so that it can be referred to by name.\n\n```js\nregisterShaderModules([module]);\nassembleShaders(gl, {..., modules: ['my-module']});\n```\n\n\n## Structure of a Shader Module\n\n### Shader Module Type\n\nA shader module is either:\n\n* **Generic** - a set of generic GLSL functions that can be included either in a fragment shader or a vertex shader (or both). The `fp64` module is a good example of this type of module.\n* **Functional** - Contains specific vertex and/or fragment shader \"chunks\", often set up so that the vertex shader part sets up a `varying` used by the fragment shader part.\n\n\n### Shader Module Descriptor\n\nTo define a new shader module, you create a descriptor object that brings together all the necessary pieces:\n\n```js\nexport const MY_SHADER_MODULE = {\n  name: 'my-shader-module',\n  vs: '...',\n  fs: '...',\n  dependencies: [],\n  deprecations: [],\n  getUniforms\n};\n```\n\nDescriptor objects can define the following fields:\n\n* `name` (*String*, Required) - The name of the shader module.\n* `vs` - (String | null)\n* `fs` - (String | null)\n* `getUniforms` JavaScript function that maps JavaScript parameter keys to uniforms used by this module\n* `uniforms` (*Object*) - a light alternative to `getUniforms`, see below\n* `dependencies` (*Array*) - a list of other shader modules that this module is dependent on\n* `deprecations` (*Array*) - a list of deprecated APIs.\n\nIf `deprecations` is supplied, `assembleShaders` will scan GLSL source code for the deprecated constructs and issue a console warning if found. Each API is described in the following format:\n  - `type`: `uniform <type>` or `function`\n  - `old`: name of the deprecated uniform/function\n  - `new`: name of the new uniform/function\n  - `deprecated`: whether the old API is still supported.\n\n\n### GLSL Code\n\nThe GLSL code for a shader module typically contains:\n\n* a mix of uniform and varying declarations\n* one or more GLSL function definitions\n\n\n### getUniforms\n\nEach shader module provides a method to get a map of uniforms for the shader. This function will be called with two arguments:\n\n* `opts` - the module settings to update. This argument may not be provided when `getUniforms` is called to generate a set of default uniform values.\n* `context` - the uniforms generated by this module's dependencies.\n\nThe function should return a JavaScript object with keys representing uniform names and values representing uniform values.\n\nThe function should expect the shape of the dependency uniforms to vary based on what's passed in `opts`. This behavior is intended because we only want to recalculate a uniform if the uniforms that it depends on are changed. An example is the `project` and `project64` modules in deck.gl. When `opts.viewport` is provided, `project64` will receive the updated projection matrix generated by the `project` module. If `opts.viewport` is empty, then the `project` module generates nothing and so should `project64`.\n\n\n### uniforms\n\nIf the uniforms of this module can be directly pulled from user settings, they may declaratively defined by a `uniforms` object:\n\n```js\n{\n  name: 'my-shader-module',\n  uniforms: {\n    strength: {type: 'number', value: 1, min: 0, max: 1},\n    center: [0.5, 0.5]\n  }\n}\n```\n\nAt runtime, this map will be used to generate the uniforms needed by the shaders. If either `strength` or `center` is present in the user's module settings, then the user's value will be used; otherwise, the default value in the original definition will be used.\n\nEach uniform definition may contain the following fields:\n\n* `type` (*String*) - one of `number`, `boolean`, `array` or `object`\n* `value` - the default value of this uniform\n\nWith `type: 'number'`, the following additional fields may be added for validation:\n\n* `min` (*Number*)\n* `max` (*Number*)\n\nNote: `uniforms` is ignored if `getUniforms` is provided.\n\n\n### Platform Detection\n\nAlso does platform detection and injects `#define` statements enabling your shader to conditionally use code.\n","slug":"docs/developer-guide/shadertools/writing-shader-modules","title":"Writing Shadertools Shader Modules"},{"excerpt":"Multi Pass Rendering (Experimental) The multi pass rendering system allows you to describe a complex rendering pipeline as a sequence of…","rawMarkdownBody":"# Multi Pass Rendering (Experimental)\n\nThe multi pass rendering system allows you to describe a complex rendering pipeline as a sequence of render passes that you can then execute at a later stage.\n\nThis helps the programmer articulate how the rendering pipeline is defined, and also allows the use of a number of pre-defined post processing effects in combination with custom rendering.\n\n\n## Using Existing Passes\n\nThere are a number of pre-define passes available that can be composed in custom render pipelines.\n\n\n## Core Passes\n\n| Pass               | Description              |\n| ---                | ---                      |\n| `ClearPass`        | Clears the Screen        |\n| `RenderPass`       | Draws a list of models   |\n| `PickingPass`      | Draws a list of models into the picking buffer |\n| `CopyPass`         | Copies output a previous pass (e.g. to the screen) |\n| `RenderPass`       | Renders a list of models into the destination framebuffer |\n| `TexturePass`      | Renders a texture into the destination framebuffer |\n| `ShaderModulePass` | Automatically builds a render `Pass` from a compatible shader module |\n\n\n### Post Processing Passes\n\nA basic set of post processing samples are provided\n\n| Pass               | Description                     |\n| ---                | ---                             |\n| `ConvolutionPass`  | Screen space convolution, edge detection, blur, sharpening etc. |\n| `OutlinePass`      | Stencil buffer based outlining. |\n| `SSAOPass`         | Depth-buffer based Screen Space Ambient Occlusion |\n\n\n## Custom Passes\n\nThe multi pass rendering system is designed to be extensible and make it easy to implement new rendering passes. Additional post processing effects can easily be created or ported/adapted to the system.\n\n\n## Shader Module Passes\n\nShader modules that expose \"standard\" filtering and sampling functions can be given extra metadata (the `passes` field) enabling a `Pass` to be automatically instantiated. Look for `ShaderPass` badges in the documentation of shader modules.\n\n\n## The Canvas Class\n\nSince many render passes provide basic image processing effects, that can be desirable to use in non-WebGL focused applications, the multi pass render system comes with a Canvas class that makes it possible to use compatible shader modules directly with browser canvases without explcitly creating WebGL contexts, creating `Texture` instances etc.\n\n\n## How Rendering Passes work\n\n* Passes will render to the outputBuffer, unless `screen` is set to `true`.\n* If `swap` is set, buffers will be swapped.\n\n\n## Attributions / Credits\n\nThe luma.gl multi-pass rendering system was inspired by similar systems in other 3D frameworks, in particular by the `EffectComposer` system in THREE.js.\n","slug":"docs/developer-guide/multipass","title":"Multi Pass Rendering (Experimental)"},{"excerpt":"SnapshotTestRunner Client-side utility for browser-based WebGL render tests. This class is intended to be used with  from . Together they…","rawMarkdownBody":"# SnapshotTestRunner\n\nClient-side utility for browser-based WebGL render tests.\n\nThis class is intended to be used with `BrowserTestDriver` from `@probe.gl/test-utils`. Together they support the following workflow:\n\n* Launch a Puppeteer instance (headless or non-headless) to run a test application\n* In the test application, create a canvas and `WebGLContext`.\n* For each test case, render something to the `WebGLContext`, take a screenshot, and perform pixel-diffing with a pre-defined \"golden image\". Report the matching result.\n* Proceed to the next test case until done.\n\n## Example\n\nIn your node.js start script:\n\n```js\n// This is the script that runs in Node.js and starts the browser\nconst {BrowserTestDriver} = require('@probe.gl/test-utils');\nnew BrowserTestDriver().run({\n  server: {\n    // Bundles and serves the browser script\n    command: 'webpack-dev-server',\n    arguments: ['--env.render-test']\n  },\n  headless: true\n});\n```\n\nIn your script that is run on the browser:\n\n```js\nconst {SnapshotTestRunner} = require('@luma.gl/test-utils');\nconst {Cube} = require('@luma.gl/core');\n\nconst TEST_CASES = [\n  {\n    name: 'Render A Cube',\n    // `onRender` receives animation props from the AnimationLoop\n    onRender: ({gl, done}) => {\n      const model = new Cube(gl);\n      model.draw(...);\n      // ready for capture and diffing\n      done();\n    },\n    goldenImage: './test/render/golden-images/cube.png'\n  }\n];\n\nnew TestRender({width: 800, height: 600})\n  .add(TEST_CASES)\n  .run({\n    onTestFail: window.browserTestDriver_fail\n  })\n  .then(window.browserTestDriver_finish);\n```\n\n## Methods\n\n### constructor(props: Object)\n\n```\nnew SnapshotTestRunner(props)\n```\n\nCreate a SnapshotTestRunner instance. The `props` argument is forwarded to the [AnimationLoop](/docs/api-reference/core/animation-loop.md) constructor.\n\n### add(testCase: Array|Object)\n\nAdd one or a list of test cases. Each test case may contain the following fields:\n \n* `name` (String) - name of the test case.\n* `goldenImage` (String) - path to the golden image, relative to the root where the node script is executed.\n* `timeout` (Number) - time to wait for this test case to resolve (by calling the `done` callback) before aborting, in milliseconds. If not provided, fallback to the shared option that is passed to `SnapshotTestRunner.run`.\n* `imageDiffOptions` (Object) - image diffing options for this test case. See \"Image Diff Options\" section below.\n* `onInitialize` (Function) - called once when the test case starts. Receives a single object that is the [AnimationLoop callback parameters](/docs/api-reference/core/animation-loop.md#callback-parameters). If this callback returns an object or a promise, the content that it resolves to will be passed to `onRender` and `onFinalize` later.\n* `onRender` (Function) - called every animation frame when the test case is running. Receives a single object that is the [AnimationLoop callback parameters](/docs/api-reference/core/animation-loop.md#callback-parameters), plus the following:\n  - `done` (Function) - must be called when the test case is done rendering and ready for screen capture and comparison.\n* `onFinalize` (Function) - called once when the test case is done to finalize all resources. Receives a single object that is the [AnimationLoop callback parameters](/docs/api-reference/core/animation-loop.md#callback-parameters).\n\n### run(options: Object)\n\nRun all test cases.\n\nOptions:\n\n* `timeout` (Number) - time to wait for each test case to resolve (by calling the `done` callback) before aborting, in milliseconds. Default `2000`.\n* `imageDiffOptions` (Object) - image diffing options for all test cases. This will be overridden if a test case defines its own `imageDiffOptions`. See \"Image Diff Options\" section below.\n* `onTestStart` (Function) - callback when a test starts. Receives the current test case. Default logs the test name to console.\n* `onTestPass` (Function) - callback when a test passes. Receives the current test case and the diffing result. Default logs the pixel matching percentage to console.\n* `onTestFail` (Function) - callback when a test fails, either because the matching rate is below threshold or a critical error. Receives the current test case. Default logs the error message or the pixel matching percentage to console.\n\nReturns: a `Promise` that resolves when all test cases are done.\n\n\n## Members\n\n### isHeadless\n\nWhether the test is being run in headless mode. In headless mode, Chromium uses software render which behaves slightly differently from non-headless. Image diffing tolerance may need to be adjusted accordingly.\n\n\n## Image Diff Options\n\nThe test renderer and each test case may choose to override the default image diffing options. The following options from [captureAndDiffScreen](https://github.com/uber-web/probe.gl/blob/master/docs/api-reference/test-utils/browser-test-driver.md#browsertestdriver_captureanddiffscreenoptions--object) are supported:\n\n* `tolerance`\n* `threshold`\n* `includeAA`\n* `createDiffImage`\n* `saveOnFail`\n* `saveAs`\n\n","slug":"docs/api-reference/test-utils/snapshot-test-runner","title":"SnapshotTestRunner"},{"excerpt":"Accessor (Experimental) The  class is a helper class that describes how a buffers memory is structured and should be accessed. Accessors are…","rawMarkdownBody":"# Accessor (Experimental)\n\nThe `Accessor` class is a helper class that describes how a buffers memory is structured and should be accessed. Accessors are used.\n\nThe type of values, number of values per element, any offset and strides, etc. as well as some additional parameters relating to how the GPU should access buffer data (instance divisors, integer normalization etc).\n\nBy using multiple `Accessor` instances, the application can defined different \"views\" of the data in a single buffer.\n\nAccessors are immutable by design. Once they have been created they cannot be changed.\n\nAccessors can be resolved (merged) into a new Accessor. This is useful since while some accessor properties can be extracted directly from a program's shaders (and some can be extracted when data is set to the buffer), some properties needs to be set by the application.\n\n\n## Properties\n\n| Property    | Category    | Auto Deduce    | Default    | Comment |\n| ---         | ---         | ---            | ---        | ---     |\n| `offset`    | data layout | N/A            | `0`        | Byte offset to start of data in buffer |\n| `stride`    | data layout | N/A            | `0`        | Extra bytes between each successive data element |\n| `type`      | data type   | Vertex Shader/`Buffer.setData` | `GL.FLOAT` | Low level data type (`GL.BYTE`, `GL.SHORT`, ...) |\n| `size`      | data type   | Vertex Shader  | `1`        | Components per element (`1`-`4`) |\n| `divisor`   | instancing  | Attribute name | `0`        | Enables/disables instancing |\n| `normalize` | data access | N/A            | `false`    | Normalize integers to [-1,1], or [0,1] if unsigned |\n| `integer`   | data access | N/A            | `false`    | Disable conversion of integer values to floats **WebGL2** |\n\nNotes:\n\n* `type` and `size` values for attributes are read from the shaders when a program is created and linked, and normally do not need to be supplied. Also any attribute with `instance` in its name will automatically be given an instance divisor of `1`.\n* `divisor` is automatically set to `1` for any attribute that has some capitalization of `instance` in the name.\n* `offset` and `stride` are typically used to interleave data in buffers and are normally left undefined (i.e. `0`).\n* `normalize` and `integer` need to be enabled by applications through an `Accessor`.\n\n\n### `offset`\n\nByte offset to start of data in buffer\n\n### `stride`\n\n### `type`\n\nLow level data type (GL.BYTE, GL.SHORT, GL.FLOAT, GL.INT, ...)\n\n### `size`\n\nNumber of (1-4 values per vertex)\n\n### `divisor`: Number\n\nEnables/disables instancing.\n\n### `normalize`\n\nIf `true` normalizes integer values (`GL.BYTE`, ...). Signed values are normalized to [-1,1] and unsigned values are normalized to [0,1].\n\n### `integer` **WebGL2**\n\nDisable conversion of integer values to floats.\n\n\n## Static Methods\n\n### Accessor.merge(accessor1, accessor2, ...) : Accessor\n\nMerges a number of partial accessors into a merged accessor that can be used to set vertex attributes. Any unspecified accessor properties will be set to their default values.\n\nNote: Most applications do not need to merge accessors directly. Merging is done by the `VertexArray.setAttributes` method.\n\n\n## Methods\n\n### constructor(props : Object)\n\nCreates a new partial `Accessor`. The new object will be immutable, i.e. its values cannot be changed after creation.\n\n\n### `BYTES_PER_ELEMENT` : Number\n\nReturns the number of bytes per \"element\", based on the `type` field in the accessor. Asserts if type is not set.\n\n### `BYTES_PER_VERTEX` : Number\n\nReturns the number of bytes per \"vertex\", based on the `type` and `size` fields in the accessor. Asserts if `type` and `size` are not set.\n\n\n\n## Remarks: Auto-deduction\n\n* `type` and `size` are automatically inferred (through WebGL APIs that provide access to metadata extracted during compilation and linking of shader programs).\n* `divisor` - if attribute name starts with `instance...` this will be automatically set to `1`.\n* `offset` and `stride` are assumed to be 0 which corresponds to the simple non-interleaved case.\n* `integer` - if type is `GL.INT` or `GL.UINT`, then integer is automatically true, as floating point shader inputs cannot be mapped to such attributes.\n\n\n","slug":"docs/api-reference/webgl/accessor","title":"Accessor (Experimental)"},{"excerpt":"Device Pixels Most of the modern computers support retina or HD displays, which support either 2X or 4X number of pixels to the size of…","rawMarkdownBody":"# Device Pixels\n\nMost of the modern computers support retina or HD displays, which support either 2X or 4X number of pixels to the size of screen. By rendering to this bigger size window (Device) and then down sampling it to smaller window (CSS), produces sharp images, but at the cost of performance penalty by rendering more pixels.\n\n## useDevicePixels\n\n`luma.gl` provides control over this behavior using `AnimationLoop`'s [`useDevicePixels`](/docs/api-reference/core/animation-loop.md) prop. When `useDevicePixels` is set to true (default), it will use device's full retina/HD resolution for rendering, when `useDevicePixels` is false, it will use the same resolution as the screen window (CSS window).\n\nAs an experimental API, a custom ratio (Number) can be set to `useDevicePixels` prop, to use smaller or bigger ratio than actual device pixel ratio. This is for more advanced use cases, using the default value (`true`) is recommended for this prop. For any advanced use cases, when a value higher than actual device pixel ratio is used, `luma.gl` will first try to allocate internal resources to match this ratio, if it fails, it will reduce this ratio by half, until resources are successfully created.\n\nWhen a custom ratio is used, `window.devicePixel` ratio can't be used for converting between CSS and Device locations, instead following helper methods should be used.\n\n## Methods\n\n`luma.gl` offers following helper methods for converting from CSS to Device pixels.\n\n\n### cssToDeviceRatio(gl): Number\n\nReturns a Number, which is the ratio of Device buffer resolution size to CSS buffer resolution.\n\n* `gl` (WebGLContext) - WebGL context.\n\nReturns ratio (Number).\n\n\n### cssToDevicePixels(gl, cssPixel, yInvert) : Object\n\nConverts CSS pixel location to Device pixel range.\n\n* `gl` (WebGLContext) - WebGL context.\n* `cssPixels` (Array) - Array in [x, y] form, where x and y are location in CSS window.\n* `yInvert` (Boolean, optional, default: true) - when true it will perform y-inversion when converting to Device pixels.\n\nReturns an Object, `{x, y, width, height}` that represents entire range of device pixels that correspond to given cssPixel location. Following fields define the rectangle.\n * `x` (Number): lower x-coordinate\n * `y` (Number): lower y-coordinate\n * `width` (Number): width in pixels\n * `height` (Number): height in pixels\n When `devicePixelRatio` is <=1, `width` and `height` are equal to `one`, otherwise `width` and `height` are greater than one.\n","slug":"docs/api-reference/webgl/device-pixels","title":"Device Pixels"},{"excerpt":"Query A  object provides single unified API for using WebGL asynchronus queries, which include query objects ('Occlusion' and 'Transform…","rawMarkdownBody":"# Query\n\nA `Query` object provides single unified API for using WebGL asynchronus queries, which include query objects ('Occlusion' and 'Transform Feedback') and timer queries.\n\nSee also:\n\n* WebGL1 timer extension: [`EXT_disjoint_timer_query`](https://www.khronos.org/registry/webgl/extensions/EXT_disjoint_timer_query/)\n* WebGL2 timer extension: [`EXT_disjoint_timer_query_webgl2`](https://www.khronos.org/registry/webgl/extensions/EXT_disjoint_timer_query_webgl2/)\n\n\n## Usage\n\nUse a query to time GPU calls\n```js\nimport {Query, GL} from '@luma.gl/core';\n...\nconst timerQuery = new Query(gl);\n\n\n// In animation loop\nif (timerQuery.isResultAvailable() && !timerQuery.isTimerDisjoin()) {\n  result = timerQuery.getResult();\n}\n\n\n// Option #1\ntimerQuery.beginTimeElapsedQuery();\n// Option #2\n// timerQuery.begin(GL.TIME_ELAPSED_EXT)\n\n// Issue GPU calls\n\ntimerQuery.end();\n```\n\n\n## Query Types\n\nA query can be started by passing following query type to to `begin()` or by using corresponding begin* method.\n\n| Query Type | begin method | Description |\n| ------------------------------------------ | --------------------- | ------------ |\n| `GL_TIME_ELAPSED_EXT`                      | `beginTimeElapsedQuery()` | Time taken by GPU to fully complete a set of GL commands |\n| `GL.ANY_SAMPLES_PASSED`                    | `beginOcclusionQuery({conservative: false})` | Occlusion query: these queries detect whether an object is visible (whether the scoped drawing commands pass the depth test and if so, how many samples pass).\n| `GL.ANY_SAMPLES_PASSED_CONSERVATIVE`                    | `beginOcclusionQuery({conservative: true})` | Same as above above, but less accurate and faster version.\n| `GL.TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN`  | `beginTransformFeedbackQuery()` | Number of primitives that are written to transform feedback buffers.\n\nIn addition to above queries, Query object also provides `getTimeStamp` which returns GPU time stamp at the time this query is executed by GPU. Two sets of these methods can be used to calculate time taken by GPU for a set of GL commands.\n\n## Methods\n\n### static Query.isSupported(gl : WebGLRenderingContext, options : Object)\n\nReturns true if Query is supported by the WebGL implementation\n(depends on the EXT_disjoint_timer_query extension)/\nCan also check whether timestamp queries are available.\n\n* options.queries=false {Object}  - If true, checks if Query objects (occlusion/transform feedback) are supported\n* options.timers=false {Object}  - If true, checks if 'TIME_ELAPSED_EXT' queries are supported\n\nReturns: {Boolean} - Query API is supported with specified configuration\n\nOptions\n* queries = false,\n* timers = false,\n\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\n`new Query(gl, {})`\n\n\n### delete()\n\nDestroys the WebGL object. Rejects any pending query.\n* return {Query} - returns itself, to enable chaining of calls.\n\n\n### beginTimeElapsedQuery()\n\nShortcut for timer query (dependent on extension in both WebGL1 and 2)\n\n\n### Query.beginOcclusionQuery({conservative = false})\n\nShortcut for occlusion query (dependent on WebGL2)\n\n\n### beginTransformFeedbackQuery()\n\nShortcut for transform feedback query (dependent on WebGL2)\n\n\n### Query.begin(target)\n\nMeasures GPU time delta between this call and a matching `end` call in the GPU instruction stream.\n\nRemarks:\n* Due to OpenGL API limitations, after calling `begin()` on one Query\n  instance, `end()` must be called on that same instance before\n  calling `begin()` on another query. While there can be multiple\n  outstanding queries representing disjoint `begin()`/`end()` intervals.\n  It is not possible to interleave or overlap `begin` and `end` calls.\n* Triggering a new query when a Query is already tracking an\n  unresolved query causes that query to be cancelled.\n\n* target {GLenum}  - target to query\n* return {Query} - returns itself, to enable chaining of calls.\n\n\n### end\n\nInserts a query end marker into the GPU instruction stream.\nNote: Can be called multiple times.\n\nreturn {Query} - returns itself, to enable chaining of calls.\n\n\n### isResultAvailable\n\nreturn {Boolean} - true if query result is available\n\n\n### getResult\n\nReturns the query result\n\nreturn {Number} - query result. Semantics depend on query type\n\n\n### getTimerMilliseconds\n\nShorthand for getting timer query results and converting to milliseconds to match JavaScript conventions.\n\nreturn {Number} - measured time or timestamp, in milliseconds\n\n### isTimerDisjoint\n\nReturns `true` if the timer query was disjoint, indicating that timing results are invalid.\nThis is rare and might occur, for example, if the GPU was throttled while timing.\n\nreturn {Boolean} - true if timer query was disjoint\n\n\n### createPoll(limit = Number.POSITIVE_INFINITY)\n\nBegins polling `Query` once per frame to check if results are available.\n\n* limit {Number}  - Maximum number of frames to poll before rejecting the `Promise`.\n\nreturn {Promise} - Resolves to the `Query` result if it becomes available before `limit`\nframes have elapsed, and is rejected otherwise.\n\n\n## Remarks\n\n* Even when supported, timer queries can fail whenever a change in the GPU occurs that will make the values returned by this extension unusable for performance metrics, for example if the GPU is throttled mid-frame. This occurance is captured in `isTimerDisjoint` method.\n* Note that from a JavaScript perspective, where callback driven APIs are the norm, the functionality of the WebGL `Query` class seems limited. Many operations that require expensive roundtrips to the GPU (such as `readPixels`) that would obviously benefit from asynchronous queries, are not covered by the `Query` class.\n","slug":"docs/api-reference/webgl/query","title":"Query"},{"excerpt":"Renderbuffer s are WebGL Objects that contain textures. They are optimized for use as render targets, while vanilla s may not be, and are…","rawMarkdownBody":"# Renderbuffer\n\n`Renderbuffer`s are WebGL Objects that contain textures. They are optimized for use as render targets, while vanilla `Texture`s may not be, and are the logical choice when you do not need to sample (i.e. in a post-pass shader) from the produced image. If you do need to sample (such as when reading depth back in a second shader pass), use [`Texture`](/docs/api-reference/webgl/texture.md) instead. In addition, in WebGL2, `Renderbuffer` can do [Multisampling (MSAA)](https://www.khronos.org/opengl/wiki/Multisampling) just like standard framebuffer.\n\nFor additional information, see [OpenGL Wiki](https://www.opengl.org/wiki/Renderbuffer_Object)\n\n\n## Usage\n\nCreating a `Renderbuffer`\n```js\nconst renderbuffer = new Renderbuffer(gl, {format: GL.RGBA4, width: 100, height: 100});\n```\n\nReformatting/reinitializing a `Renderbuffer`\n```js\nconst renderbuffer = new Renderbuffer(gl, {format: GL.RGBA4, width: 100, height: 100});\nrenderbuffer.initialize({format: GL.RGB565, width: 50, height: 50});\n```\n\nResizing a `Renderbuffer`\n```js\nconst renderbuffer = new Renderbuffer(gl, {format: GL.RGBA4});\nrenderbuffer.resize({width: 200, height: 200});\n```\n\nAttaching a `Renderbuffer` to a `Framebuffer` (automatically resizes the `Renderbuffer`)\n```js\nframebuffer.attach({\n  [GL.DEPTH_ATTACHMENT]: new Renderbuffer(gl, {format: GL.DEPTH_COMPONENT16})\n });\n```\n\n## Members\n\n* `id` (string) - id for debugging\n* `handle` (`WebGLRenderbuffer`) - the underlying WebGLRenderbuffer object\n* `width` (number) - width of renderbuffer in pixels\n* `height` (number) - height of renderbuffer in pixels\n* `format` (number) - internal format of the renderbuffer (e.g. `GL.DEPTH_COMPONENT16`)\n* `samples` (number) - samples (always `0` in non-WebGL2 contexts)\n\n\n## Methods\n\n### getSamplesForFormat (static method)\n\nQueries valid sample counts for a `Renderbuffer` format. The sample counts can be provided as a parameter to the `Renderbuffer` constructor.\n\n`Renderbuffer.getSamplesForFormat({format})`\n\n* `format` (GLenum) - internal format of the renderbuffer (e.g. `GL.DEPTH_COMPONENT16`)\n\nReturns (Number[]) - An list of valid sample counts in descending order.\n\nIf multisampling is not supported the returned value will be `[0]`, e.g. signed and unsigned integer internal formats in WebGL2. Note that this method always returns `[0]` in WebGL1.\n\n### constructor\n\nCreates a new `Renderbuffer` and initalizes it by calling `initialize` with the provided parameters.\n\n`new Renderbuffer(gl, {id=, format, width, height, samples=})`\n\n* `gl` (WebGLRenderingContext) - gl context\n* `id`= (String) - optional string id\n* `format` (GLenum) - internal format of the renderbuffer (e.g. `GL.DEPTH_COMPONENT16`)\n* `width`=`1` (GLint) - width of renderbuffer in pixels\n* `height`=`1` (GLint) - height of renderbuffer in pixels\n* `samples`=0 (GLint) - (WebGL2) number of samples to be used for storage.\n\nWebGL References [gl.createRenderbuffer](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/createRenderbuffer), also see `initialize`.\n\n### initialize\n\nCreates and initializes a renderbuffer object's data store. Used to update a `Renderbuffer`s format and size after it was initially created.\n\n`Renderbuffer.initialize({format, width, height, samples=})`\n\n* `format` (GLenum) - internal format of the renderbuffer (e.g. `GL.DEPTH_COMPONENT16`)\n* `width`=`1` (GLint) - width of renderbuffer in pixels\n* `height`=`1` (GLint) - height of renderbuffer in pixels\n* `samples`=0 (GLint) - (WebGL2) number of samples to be used for storage.\n\nReturns itself to enable chaining\n\n* `initialize` erases the current content of the `Renderbuffer`.\n\n\nWebGL References [gl.renderbufferStorage](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/renderbufferStorage), [gl.renderbufferStorageMultisample](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/renderbufferStorageMultisample) (WebGL2), [gl.bindRenderbuffer](WebGLRenderingContext.bindRenderbuffer())\n\n### resize\n\nReinitializes the `Renderbuffer`'s data store with the new `width` and `height` but unchanged `format` (and `samples`, if available).\n\n`Renderbuffer.resize({width, height})`\n\n* `width` (GLint) - width of `Renderbuffer` in pixels\n* `height` (GLint) - height of `Renderbuffer` in pixels\n\nReturns itself to enable chaining\n\n* Checks if `width` or `height` have actually changed before calling `initialize`.\n* If a resize happens, `resize` erases the current content of the `Renderbuffer`.\n\nWebGL References see `initialize`.\n\n## Renderbuffer Formats\n\nThe \"internal\" format of the `Renderbuffer`.\n\n| Value                  | Description |\n| ---                    | --- |\n| `GL.RGBA4`             |  4 red bits, 4 green bits, 4 blue bits 4 alpha bits |\n| `GL.RGB565`            |  5 red bits, 6 green bits, 5 blue bits |\n| `GL.RGB5_A1`           |  5 red bits, 5 green bits, 5 blue bits, 1 alpha bit |\n| `GL.DEPTH_COMPONENT16` |  16 depth bits |\n| `GL.STENCIL_INDEX8`    |  8 stencil bits |\n\nThis table lists the basic formats supported in WebGL1. For a full table of formats supported in WebGL2 and via WebGL extensions, see [Texture](/docs/api-reference/webgl/texture.md).\n\n| Sized Internal Format   | Format               | Type | Depth Bits | Stencil Bits |\n| ---                     | ---                  | ---  | ---        | --- |\n| `GL.DEPTH_COMPONENT16`  | `GL.DEPTH_COMPONENT` | `GL.UNSIGNED_SHORT`, `GL.UNSIGNED_INT` | 16 | 0 |\n| `GL.DEPTH_COMPONENT24`  | `GL.DEPTH_COMPONENT` | `GL.UNSIGNED_INT` | 24 | 0 |\n| `GL.DEPTH_COMPONENT32F` | `GL.DEPTH_COMPONENT` | `GL.FLOAT` | f32 | 0 |\n| `GL.DEPTH24_STENCIL8`   | `GL.DEPTH_STENCIL`   | `GL.UNSIGNED_INT_24_8` | 24 | 8 |\n| `GL.DEPTH32F_STENCIL8`  | `GL.DEPTH_STENCIL`   | `GL.FLOAT_32_UNSIGNED_INT_24_8_REV` | f32 | 8 |\n\n\nWhen using the WEBGL_depth_texture extension:\n`GL.DEPTH_COMPONENT`\n`GL.DEPTH_STENCIL`\nWhen using the EXT_sRGB extension:\n`EXT.SRGB_EXT`\n`EXT.SRGB_ALPHA_EXT`\n\nWhen using a WebGL 2 context, the following values are available additionally:\n* `GL.R8`\n* `GL.R16F`\n* `GL.R32F`\n* `GL.R8UI`\n* `GL.RG8`\n* `GL.RG16F`\n* `GL.RG32F`\n* `GL.RGUI`\n* `GL.RGB8`\n* `GL.SRGB8`\n* `GL.RGB565`\n* `GL.R11F_G11F_B10F`\n* `GL.RGB9_E5`\n* `GL.RGB16F`\n* `GL.RGB32F`\n* `GL.RGB8UI`\n* `GL.RGBA8`\n* `GL.SRGB_APLHA8`\n* `GL.RGB5_A1`\n* `GL.RGBA4444`\n* `GL.RGBA16F`\n* `GL.RGBA32F`\n* `GL.RGBA8UI`\n\n\n## Parameters\n\n| Parameter                          | Type   | Read/Write |Description |\n| ---                                | ---    | ---        | --- |\n| `GL.RENDERBUFFER_WIDTH`            | GLint  | R | height of the image of renderbuffer |\n| `GL.RENDERBUFFER_HEIGHT`           | GLint  | R | height of the image of renderbuffer |\n| `GL.RENDERBUFFER_INTERNAL_FORMAT`  | GLenum | R | See below |\n| `GL.RENDERBUFFER_GREEN_SIZE`       | GLint  | R | resolution (bits) of green color |\n| `GL.RENDERBUFFER_BLUE_SIZE`        | GLint  | R | resolution (bits) of blue color |\n| `GL.RENDERBUFFER_RED_SIZE`         | GLint  | R | resolution (bits) of red color |\n| `GL.RENDERBUFFER_ALPHA_SIZE`       | GLint  | R | resolution (bits) of alpha component |\n| `GL.RENDERBUFFER_DEPTH_SIZE`       | GLint  | R | resolution (bits) of depth component |\n| `GL.RENDERBUFFER_STENCIL_SIZE`     | GLint  | R | resolution (bits) of stencil component |\n| `GL.RENDERBUFFER_SAMPLES` (WebGL2) | GLint  | R | |\n\n## Limits\n\n| Limit                      |                               | WebGL2   | WebGL1 |\n| ---                        |---                            | ---      | ---    |\n| `GL.MAX_RENDERBUFFER_SIZE` | Max renderbuffer width/height | `>=2048` | `>=1`  |\n| `GL.MAX_SAMPLES`           | Max samples for multisampling | `>=4`    | `0`    |\n\n\n## Remarks\n\n* The only way to work with a renderbuffer, besides creating it, is to attach it to a [`Framebuffer`](/docs/api-reference/webgl/framebuffer.md).\n* A `Renderbuffer` cannot be accessed by a shader in any way.\n* Multisampling is only available in WebGL2\n","slug":"docs/api-reference/webgl/renderbuffer","title":"Renderbuffer"},{"excerpt":"Resource Class Overview The  class is the base class of all WebGL resource classes (e.g. , , etc.) Usage Resources must be created through…","rawMarkdownBody":"# Resource Class\n\n## Overview\n\nThe `Resource` class is the base class of all WebGL resource classes (e.g. `Buffer`, `Texture`, etc.)\n\n## Usage\n\nResources must be created through subclasses, e.g.\n```js\nconst resource = new Buffer(gl);\n```\n\nDeleting a resource\n```js\nconst resource = new Buffer(gl);\nresource.delete();\n```\n\nGetting parameters\n```js\nconst resource = new Texture2d(gl);\nresource.getParameters(); // Returns object with values keyed by GL constants.\nresource.getParameters({keys: true}); // Returns object with keys and enum values converted to strings.\n```\n\n## Methods\n\n### constructor\n\n* `gl` - WebGL context, which is stored on the object.\n* `opts` - options\n* `opts.id` (string) - stores a string id, helpful for printing and debugging.\n* `opts.handle` - by supplying an existing handle, the object will be created\n  as a wrapper for that handle (instead of creating a new handle). This\n  allows you to use the luma.gl class methods to interface with WebGL resource\n  handles created using the raw WebGL API or through other WebGL frameworks.\n  luma.gl will make an attempt to extract information about the handle to\n  enable as much functionality as possible, although some operations may\n  not be possible on imported handles. Also, imported handles can\n  typically not be automatically reinitialized after context loss.\n\n### delete\n\n* Deletes any WebGL resources associated with this resources (i.e the underlying WebGLResource handle).\n\n### getParameter(pname)\n\nGets a given parameter from the resource.\n\n* Note querying for parameters in WebGL is slow and should be avoided in loops and other performance critical situations.\n\n### getParameters(parameters)\n\nGets list of parameters from the resource (or all parameters).\n\nIf the special parameter `keys` is set to true, keys and enumerations will be converted to strings.\n\n* Note querying for parameters in WebGL is slow and should be avoided in loops and other performance critical situations.\n* Note - querying without parameters returns all parameters. This can be useful during debugging.\n\n\n## Properties\n\n### `gl`\n\nThe WebGL context is stored on the object.\n\n### `id`\n\nStores a string id, helpful for printing and debugging.\n\n### `userData`\n\nAn empty object to which the application can add keys and values. Note that\nthe resource object. itself is sealed to prevent additional key being added,\nand any keys and values added directly to the underlying WebGL object will\nbe lost during WebGL context loss.\n","slug":"docs/api-reference/webgl/resource","title":"Resource Class"},{"excerpt":"Shader The  class are the base class for  class and  class Usage Create a pair of shaders Members  - holds the underlying  object…","rawMarkdownBody":"# Shader\n\nThe `Shader` class are the base class for `VertexShader` class and `FragmentShader` class\n\n\n## Usage\n\nCreate a pair of shaders\n```js\nconst fs = new VertexShader(gl, source);\nconst fs = new FragmentShader(gl, source);\n```\n\n## Members\n\n* `handle` - holds the underlying `WebGLShader` object\n\n\n## Constructor\n\n### Shader(gl : WebGLRenderingContext, source : String)\n\n* `source` - string containing shader instructions.\n\n\n\n## Remarks\n\n* Shader sources: A `Program` needs to be constructed with two strings containing source code for vertex and fragment shaders.\n* Default Shaders: luma.gl comes with a set of default shaders that can be used for basic rendering and picking.\n","slug":"docs/api-reference/webgl/shader","title":"Shader"},{"excerpt":"Texture3D (WebGL2) 3D textures hold basic volumetric textures and can be thought of 3-dimentional arrays with a width, height and depth…","rawMarkdownBody":"# Texture3D (WebGL2)\n\n3D textures hold basic volumetric textures and can be thought of 3-dimentional arrays with a width, height and depth. They hold image memory of a certain format and size, determined at initialization time. They can be sampled in shaders using the `texture` function with a 3D texture coordinate.\n\nMost texture related functionality is implemented by and documented on the [Texture](/docs/api-reference/webgl/texture.md) base class. For additional information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Texture).\n\n\n## Usage\n\nCreate a new 3D texture\n```js\nif (Texture3D.isSupported()) {\n  texture3D = new Texture3D(gl, {...});\n}\n```\n\n\n## Members\n\n* `handle` - The underlying `WebGLTexture`\n* `target` - Always `GL.TEXTURE_3D`\n* `width` - width of texture\n* `height` - height of texture\n* `depth` - depth of the texture\n* `format` - format of texture\n\n\n## Methods\n\n`Texture3D` is a subclass of the [Texture](texture.md) and [Resource](resource.md) classes and inherit all methods and members of those classes. Note that `setSubImageData` is not currently supported for 3D textures.\n\n\n### Texture3D.isSupported(gl)\n\nReturns true if the context supports creation of `Texture3Ds`.\n\n\n### constructor\n\n`new Texture3D(gl, {parameters})`;\n\n```\nconst texture = new Texture3D(gl, {\n  width: TEXTURE_DIMENSIONS,\n  height: TEXTURE_DIMENSIONS,\n  depth: TEXTURE_DIMENSIONS,\n  data: textureData,\n  format: gl.RED,\n  dataFormat: gl.R8\n});\n```\n\n* `gl` (WebGLRenderingContext) - gl context\n* `data`=`null` (*) - See below.\n* `width`=`0` (*Number*) - The width of the texture.\n* `height`=`0` (*Number*) - The height of the texture.\n* `depth`=`0` (*Number*) - The depth of the texture.\n* `mipmaps`=`true` (*Boolean*) - whether to generate mipmaps\n* `format` (*enum*, default `GL.RGBA`) - internal format that WebGL should use.\n* `type` (*enum*, default is autodeduced from format) - type of pixel data (GL.UNSIGNED_BYTE, GL.FLOAT etc).\n* `dataFormat` (*enum*, default is autodeduced from `format`) - internal format that WebGL should use.\n* `parameters`=`{}` (object) - texture\n\n\n## Limits\n\n* The maximum size of a `Texture3D` (width/height/depth) is implementation defined, it can be queried via `GL.MAX_3D_TEXTURE_SIZE` (at least 256).\n","slug":"docs/api-reference/webgl/texture-3d","title":"Texture3D (WebGL2)"},{"excerpt":"Texture2D 2D textures hold basic \"single image\" textures (although technically they can contain multiple mipmap levels). They hold image…","rawMarkdownBody":"# Texture2D\n\n2D textures hold basic \"single image\" textures (although technically they can contain multiple mipmap levels). They hold image memory of a certain format and size, determined at initialization time. They can be read from using shaders and written to by attaching them to frame buffers.\n\nMost texture related functionality is implemented by and documented on the [Texture](/docs/api-reference/webgl/texture.md) base class. For additional information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Texture).\n\n\n## Usage\n\nConstruct a new texture from an image\n```js\nconst texture = new Texture2D(gl, {\n  data: image,\n  parameters: {\n    [GL.TEXTURE_MAG_FILTER]: GL.NEAREST,\n    [GL.TEXTURE_MIN_FILTER]: GL.NEAREST\n  },\n  pixelStore: {\n    [GL.UNPACK_FLIP_Y_WEBGL]: true,\n  },\n  mipmaps: true\n});\n```\n\nConstruct a texture initialized with a data array\n```js\nconst texture = new Texture2D(gl, {\n  width: 2,\n  height: 1,\n  format: GL.RGB,\n  data: new Uint8Array([255, 0, 0,  0, 0, 255]),\n  parameters: {\n    [GL.TEXTURE_MAG_FILTER]: GL.NEAREST,\n    [GL.TEXTURE_MIN_FILTER]: GL.NEAREST\n  },\n  pixelStore: {\n    [GL.UNPACK_FLIP_Y_WEBGL]: true\n  },\n  mipmaps: true\n});\n```\n\nConstruct an empty 1x1 texture\n```js\nconst texture = new Texture2D(gl);\n```\n\nResize it (this clears the texture).\n```js\ntexture.resize({width: 10, height: 10});\n```\n\nWrite a sub image into the texture\n```js\ntexture.setSubImageData({pixels, x, y, width, height, level, type, dataFormat});\n```\n\nAccessing elements\n```js\nconsole.log(\n  texture2D.width,\n  texture2D.height,\n  texture2D.format,\n  texture2D.type,\n  texture2D.getParameter(GL.TEXTURE_MAG_FILTER)\n);\n```\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object | data : any)\n\n```\nimport {Texture2D} from '@luma.gl/core'\nconst texture1 = new Texture2D(gl, {\n  data: ...,\n  width: ...,\n  height: ...,\n  mipmaps: ...,\n  format: ...,\n  type: ...,\n  dataFormat: ...,\n  parameters: ...\n});\n```\n\nThere is also a short form where the image data (or a promise resolving to the image data) can be the second argument of the constructor:\n\n```\nimport {Texture2D} from '@luma.gl/core';\nimport {loadImage} from '@loaders.gl/core';\n\nconst texture1 = new Texture2D(gl, loadImage(url));\n// equivalent to\nconst texture1 = new Texture2D(gl, {data: loadImage(url)});\n\n```\n\n* `gl` (WebGLRenderingContext) - gl context\n* `data`=null (*) - If not provided (null), a solid color texture will be allocated of the specified size.\n* `width`=`0` (*Number*) - The width of the texture.\n* `height`=`0` (*Number*) - The height of the texture.\n* `mipmaps`= - (*Boolean*) - Generates mipmaps when true.\n* `format`=`GL.RGBA` (*GLenum* ) - internal format that WebGL should use.\n* `type`= (*enum*) - type of pixel data (`GL.UNSIGNED_BYTE`, `GL.FLOAT` etc). Default is autodeduced from `format`.\n* `dataFormat`= (*GLenum*) - internal format that WebGL should use. Default is autodeduced from `format`.\n* `parameters`=`{}` (*object*) - map of texture sampler parameters.\n* `pixelStore`=`{}` (*object*) - map of pixel store parameters (controls how `data` is interpreted when Textures are initialized from memory)\n\nNotes:\n* setting `mipmaps` to true when `format` set to `RGB32F` will fail, even though `RGB32F` is supported texture format (with EXT_color_buffer_float), it is not supported as renderable format.\n\nNote that since many of the constructor parameters are common to all the `Texture` classes they are detailed in [`Texture`](/docs/api-reference/webgl/texture.md). Pixel store parameters are specified in [State Management](/docs/api-reference/webgl/context/get-parameters.md)\n","slug":"docs/api-reference/webgl/texture-2d","title":"Texture2D"},{"excerpt":"TextureCube A texture cube holds six textures that represent faces of the cube. A main feature of s are that they can be passed to shaders…","rawMarkdownBody":"# TextureCube\n\nA texture cube holds six textures that represent faces of the cube. A main feature of `TextureCube`s are that they can be passed to shaders and sampled with a direction vector (looking out from the center of the cube) rather than a normal set of texture coordinates, see Usage below.\n\n`TextureCube`s are typically used to store environment maps. As an example, by rendering an environment into a texture cube, reflections in objects can then be rendered efficiently.\n\nMost texture related functionality is implemented by and documented on the [Texture](/docs/api-reference/webgl/texture.md) base class. For additional information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Texture).\n\n\n# Usage\n\nCreating a `TextureCube`\n```js\nconst textureCube = new TextureCube(gl, {width, height, dataFormat, pixels: {\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_X]: imagePosX,\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Y]: imagePosY,\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Z]: imagePosZ,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_X]: imageNegX,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Y]: imageNegY,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Z]: imageNegZ\n}});\n```\n\nCreating a `TextureCube` using multiple level-of-detail (LODs) images.\n```js\nconst textureCube = new TextureCube(gl, {width, height, dataFormat, pixels: {\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_X]: [imagePosX_LOD_0, imagePosX_LOD_1, imagePosX_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Y]: [imagePosY_LOD_0, imagePosY_LOD_1, imagePosY_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Z]: [imagePosZ_LOD_0, imagePosZ_LOD_1, imagePosZ_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_X]: [imageNegX_LOD_0, imageNegX_LOD_1, imageNegX_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Y]: [imageNegY_LOD_0, imageNegY_LOD_1, imageNegY_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Z]: [imageNegZ_LOD_0, imageNegZ_LOD_1, imageNegZ_LOD_2]\n}});\n```\n\nThis class supports _Async Textures_. You can provide promises (that resolve to images) instead of images.\nFor example `[GL.TEXTURE_CUBE_MAP_POSITIVE_X]: [promisePosX_LOD_0, promisePosX_LOD_1, promisePosX_LOD_2]`.\n\nReplacing one or more faces texture data\n```js\ntextureCube.setCubeMapImageData({width, height, dataFormat, pixels: {\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_X]: imagePosX,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Y]: imageNegY\n}});\n```\n\nPassing a `TextureCube` to a draw call...\n```js\nProgram.draw({\n  uniforms: {\n    cubemap: new TextureCube(gl, {...}),\n    textureDir: [1, 1, 1]\n  }\n});\n```\n\n...and accessing it in the shader\n\n```\n// GLSL\nuniform samplerCube cubemap;\nuniform vec3 textureDir;\n\nvoid main()\n{\n    vec4 color = texture(cubemap, textureDir);\n}\n```\n\n\n## Members\n\n* `handle` - the underlying `WebGLTexture`\n* `target` - Always `GL.TEXTURE_CUBE`\n* `depth` - Always `6`\n* `width` - width of the face textures\n* `height` - height of the face textures\n* `format` - format\n\n\n## Methods\n\n### TextureCube constructor\n\n```js\nnew Texture3D(gl, {\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_X]: faceSpecificationPosX,\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Y]: faceSpecificationPosY,\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Z]: faceSpecificationPosZ,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_X]: faceSpecificationNegX,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Y]: faceSpecificationNegY,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Z]: faceSpecificationNegZ,\n  parameters\n});\n```\n\n_faceSpecification_ can be:\n* A single image.\n* A single promise resolving in an image.\n* An array of images (for multiple _levels of detail_).\n* An array of promises each resolving in an image (for multiple _levels of detail_).\n\nFor every level of detail:\n* Needs to supply 6 images all of same size and format.\n* Images all need to be of the same square size, i.e. `width` and `height` must be the same.\n* The same `format`, `type` etc parameters will be applied to each cube face.\n\n\n## Limits\n\n* `GL.MAX_CUBE_MAP_TEXTURE_SIZE`\n","slug":"docs/api-reference/webgl/texture-cube","title":"TextureCube"},{"excerpt":"TransformFeedback (WebGL2)  objects holds state needed to perform transform feedback operations. They store the buffer bindings that are…","rawMarkdownBody":"# TransformFeedback (WebGL2)\n\n`TransformFeedback` objects holds state needed to perform transform feedback operations. They store the buffer bindings that are being recorded to. This makes it easy to switch between different sets of feedback buffer bindings (somewhat similar to how `VertexArrayObjects` hold input vertex buffers.\n\nThe state managed by `TransformFeedback` objects includes the buffers the GPU will use to record the requested varyings.\n\nWhen `TransformFeedback` objects must be \"activated\" (`TransformFeedback.begin`) before it can be used. There a number of caveats to be aware of when manually managing `TransformFeedback` object activation, see the remarks. For this reason, luma.gl [`Program.draw`](/docs/api-reference/webgl/program.md) call takes an optional `TransformFeedback` object as a parameter and activates and deactivates it before and after the draw call.\n\nFinally, note that when using transform feedback it is frequently desirable to turn off rasterization: `gl.enable(GL.RASTERIZER_DISCARD)` to prevent the fragment shader from running.\n\nFor more information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Transform_Feedback).\n\n\n## Usage\n\nSetting up a model object for transform feedback.\n\n```js\nconst model = new Model(gl, {\n  vs,\n  fs,\n  varyings: ['gl_Position', 'outputColor'],\n  ...\n});\n```\n\nSetting up a transform feedback object and binding buffers\n\n```js\nconst transformFeedback = new TransformFeedback(gl)\n  .setBuffer(0, bufferPosition)\n  .setBuffer(1, bufferColor);\n```\n\nWhen binding the buffers, index should be equal to the corresponding varying entry in `varyings` array passed to `Program` constructor.\n\nBuffers can also be bound using varying name if information about varyings are retrieved from `Program` object.\n\n```js\nconst transformFeedback = new TransformFeedback(gl, {\n  program: ..., // linked program, configuration will be read from it\n  buffers: {\n    outputColor: bufferColor,\n    gl_Position: bufferPosition\n  }\n});\n```\n\nRunning program (drawing) with implicit activation of transform feedback (will call `begin` and `end` on supplied `transformFeedback`)\n\n```js\nmodel.draw({\n  drawMode,\n  vertexCount,\n  ...,\n  transformFeedback\n});\n```\n\nRunning a transform feedback operation while turning off rasterization (drawing):\n\n```js\nmodel.transform({\n  drawMode,\n  ...,\n  transformFeedback\n});\n```\n\nor equivalently, just call draw with an additional parameter:\n\n```js\nconst parameters = {[GL.RASTERIZER_DISCARD]: true}\nmodel.draw({..., transformFeedback, parameters});\n```\n\n\n## Methods\n\n### constructor(gl : WebGL2RenderingContext, props: Object)\n\nSee `TransformFeedback.setProps` for parameters.\n\nWebGL APIs [`gl.createTransformFeedback`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/createTransformFeedback)\n\n\n### initialize(props : Object) : TransformFeedback\n\nReinitializes an existing `TransformFeedback` object with new props.\n\n\n### setProps(props : Object) : TransformFeedback\n\n* `props.program`= (Object) - Gets a mapping of varying name to buffer indices from a linked program if supplied.\n* `props.buffers`=(Object) - Map of location index or name to Buffer object or buffer parameters object. If buffer parameters object is supplied, it contains following fields.\n  * `buffer`=(Buffer) - Buffer object to be bound.\n  * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n  * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n* `props.bindOnUse`=`true` - If true, binds and unbinds buffers before and after use, rather than right away when set. Workaround for a possible [Khronos/Chrome bug](https://github.com/KhronosGroup/WebGL/issues/2346).\n\nNotes:\n\n* `buffers` - will get bound to indices in the `GL.TRANSFORM_FEEDBACK_BUFFER` target.\n\n\n### delete() : TransformFeedback\n\nDestroys a `TransformFeedback` object.\n\nWebGL APIS [`gl.deleteTransformFeedback`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/deleteTransformFeedback)\n\n\n### setBuffers(buffers: Object) : TransformFeedback\n\n* `buffers`=(Object) - Map of location index or name to Buffer object or buffer parameters object. If buffer parameters object is supplied, it contains following fields.\n  * `buffer`=(Buffer) - Buffer object to be bound.\n  * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n  * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n\nNotes:\n\n* To use `gl.bindBufferRange`, either `offsetInByts` or `byteSize` must be specified, when only one is specified, default value is used for the other, when both not specified, `gl.bindBufferBase` is used for binding.\n\nWebGL APIs [`gl.bindBufferBase`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/bindBufferBase), [`gl.bindBufferRange`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/bindBufferRange)\n\n\n### begin(primitiveMode : GLEnum) : TransformFeedback\n\nActivates transform feedback using the buffer bindings in this `TransformFeedback` object.\n\n* `primitiveMode` (`GLenum`) -\n\nreturns (`TransformFeedback`) - returns self to enable chaining\n\nNotes:\n\n* Buffers can not be accessed until `TransformFeedback.end` or `TransformFeedback.pause` have been called.\n* Buffers can not be changed until `TransformFeedback.end` or has been called, which includes doing anything which reads from or writes to any part of these buffers (outside of feedback writes, of course, or reallocating storage for any of these buffers).\n\n\nWebGL APIs [`gl.beginTransformFeedback`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/beginTransformFeedback)\n\n\n### end() : TransformFeedback\n\nreturns (`TransformFeedback`) - returns self to enable chaining\n\nWebGL APIs [`gl.endTransformFeedback`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/endTransformFeedback)\n\n\n## See also\n\n* `Program` constructor - `varyings` argument to specify which vertex shader outputs to expose to transform feedback operations.\n\n\n## Enumerations\n\n| Primitive Mode | Compatible Draw Modes |\n| ---            | --- |\n| `GL.POINTS`    | `GL.POINTS` |\n| `GL.LINES`     | `GL.LINES`, `GL.LINE_LOOP`, `GL.LINE_STRIP` |\n| `GL.TRIANGLES` | `GL.TRIANGLES`, `GL.TRIANGLE_STRIP`, `GL.TRIANGLE_FAN` |\n\n\n## Limits\n\n| Limit                                              | Value | Description |\n| ---                                                | ---   | --- |\n| `GL.MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS`       | >=4   | total number of variables that can be captured }\n| `GL.MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS`    | >=4   | number of components that any particular variable can contain |\n| `GL.MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS` | >= 64 |  total number of components in interleaved capture |\n| `GL.MAX_TRANSFORM_FEEDBACK_BUFFERS`                | TBD   | Advanced interleaving total number of buffers |\n\n\n## Remarks\n\nAbout `TransformFeedback` activation caveats\n\n* When activated, `TransformFeedback` are coupled to the \"current\" `Program`\n* Note that a started and unpaused TransformFeedback prevents the app from changing or re-linking the current program. So for instance, `Program.use` (`gl.useProgram`) cannot be called.\n","slug":"docs/api-reference/webgl/transform-feedback","title":"TransformFeedback (WebGL2)"},{"excerpt":"UniformBufferLayout (WebGL2) A helper class that lets the application describe the contents of a uniform block and then perform  calls on it…","rawMarkdownBody":"# UniformBufferLayout (WebGL2)\n\nA helper class that lets the application describe the contents of a uniform block and then perform `setUniforms({uniform: value})` calls on it, manipulating individual values without concern for memory layout requirements.\n\n\n## Usage\n\nCreate a `UniformBufferLayout` that matches the uniform block declaration in your shader\n\n```js\n#version 300 es\nlayout (std140) uniform matrix {\n    mat4 mvp;\n} matrixBlock;\n```\n\n```js\nconst matrixBlockLayout = new UniformBufferLayout({\n  mvp: GL.FLOAT_MAT4\n});\n```\n\nSetting values on a `UniformBufferLayout`:\n\n```js\n.setValues({\n  mvp: [1, 0, 0, 0,  0, 1, 0, 0,  0, 0, 1, 0,  0, 0, 0, 1]\n});\n```\n\nCreating a uniform buffer to hold the data required by the layout\n\n```js\nconst layout = new UniformBufferLayout({...});\nconst buffer = new Buffer(gl, {size: layout.getBytes()});\n```\n\nUpdating your actual uniform buffer\n\n```js\nconst layout = ...\nlayout.setValues({...})\nbuffer.subData({data: layout.getData()})\n```\n\nUpdating a minimal part of the actual uniform buffer\n\n```js\nconst {data, offset} = layout.getSubData();\nbuffer.subData({data, offset})\n```\n\nBinding your uniform buffer\n\n```js\nTBA\n```\n\n\n## Methods\n\n### constructor\n\nTakes a layout object and creates an internal layout description. Once constructed the layout cannot be changed. Once constructed the size of the required memory buffer is known, and the buffer layout provides a convenient interface for updating values.\n\nNote: The order and type of the uniforms in the layout object provided to the constructor must match the order and type of the uniform declarations in the GLSL uniform block\n\n\n### setValues\n\nSets uniform values.\n\n\n### getBytes\n\nReturns the number of bytes needed to hold all the uniforms in the layout, which can be used to create a `Buffer` with enough data to hold the entire memory layout.\n\n\n### getData\n\nReturns a `Float32Array` representing all the memory in the layout. The length of this array (* 4) will correspond to the value returned by `getBytes()`\n\n\n### getSubData\n\nReturns a `Float32Array` representing all the memory in the layout. The length of this array (* 4) will correspond to the value returned by `getBytes()`\n\n\n## Types\n\nUse the following WebGL types to declare uniforms corresponding to your GLSL data types.\n\n| GLSL Type | WebGL type |\n| ---       | --- |\n| `float`   | `GL.FLOAT` |\n| `vec2`    | `GL.FLOAT_VEC2` |\n| `vec3`    | `GL.FLOAT_VEC3` |\n| `vec4`    | `GL.FLOAT_VEC4` |\n| `int`     | `GL.INT` |\n| `ivec2`   | `GL.INT_VEC2` |\n| `ivec3`   | `GL.INT_VEC3` |\n| `ivec4`   | `GL.INT_VEC4` |\n| `uint`    | `GL.UNSIGNED_INT` |\n| `uvec2`   | `GL.UNSIGNED_INT_VEC2` |\n| `uvec3`   | `GL.UNSIGNED_INT_VEC3` |\n| `uvec4`   | `GL.UNSIGNED_INT_VEC4` |\n| `bool`    | `GL.BOOL` |\n| `bvec2`   | `GL.BOOL_VEC2` |\n| `bvec3`   | `GL.BOOL_VEC3` |\n| `bvec4`   | `GL.BOOL_VEC4` |\n| `mat2`    | `GL.FLOAT_MAT2` |\n| `mat3`    | `GL.FLOAT_MAT3` |\n| `mat4`    | `GL.FLOAT_MAT4` |\n| `mat2x3`  | `GL.FLOAT_MAT2x3` |\n| `mat2x4`  | `GL.FLOAT_MAT2x4` |\n| `mat3x2`  | `GL.FLOAT_MAT3x2` |\n| `mat3x4`  | `GL.FLOAT_MAT3x4` |\n| `mat4x2`  | `GL.FLOAT_MAT4x2` |\n| `mat4x3`  | `GL.FLOAT_MAT4x3` |\n\n\n## Remarks\n\n* WebGL requires the data representing the uniforms in to be laid out in memory according to specific rules (essentially some padding needs to be injected between successive values to facilitate memory access by the GPU).\n* Note that WebGL2 uniform buffers are just [Buffer](/docs/api-reference/webgl/buffer.md) objects and can be manipulated directly. The `UniformBufferLayout` class is not a WebGL2 object, it is just an optional helper class that makes it easy to create and update a block of memory with the required layout.\n* More information on the `std140` layout specification: [OpenGL spec](https://khronos.org/registry/OpenGL/specs/gl/glspec45.core.pdf#page=137)\n","slug":"docs/api-reference/webgl/uniform-buffer-layout","title":"UniformBufferLayout (WebGL2)"},{"excerpt":"Shadertools API Reference Functions  Can be used to \"name\" shader modules, making them available to  using module names rather than the…","rawMarkdownBody":"# Shadertools API Reference\n\n## Functions\n\n### `registerShaderModules`\n\nCan be used to \"name\" shader modules, making them available to `assembleShaders` using module names rather than the module definitions.\n\nNote: Can defeat three-shaking of unused shader modules (affects size of application JavaScript bundle).\n\n\n### `getModuleUniforms`\n\nTakes a list of shader module names and an object with options, and creates a combined uniform object that contains all necessary uniforms for all the modules injected into your shader.\n\n\n### `assembleShaders`\n\nTakes the source code of a vertex shader and a fragment shader, and a list of modules, defines, etc. Outputs resolved source code for both shaders, after adding prologue, adding defines, importing and transpiling modules, and injecting any shader fragments).\n\n* `vs` - vertex shader source\n* `fs` - fragment shader source code\n* `id` - `id` for the shader, will be used to inject shader names (using `#define SHADER_NAME`) if not already present in the source.\n* `prologue`=`true` (Boolean) - Will inject platform prologue (see below)\n* `defines`=`{}` (Object) - a map of key/value pairs representing custom `#define`s to be injected into the shader source\n* `modules`=`[]` (Array) - list of shader modules (either objects defining the module, or names of previously registered modules)\n* `inject`=`{}` (Object) - map of substituions\n\nReturns:\n* `vs` - the resolved vertex shader\n* `fs` - the resolved fragment shader\n* `getUniforms` - a combined `getUniforms` function covering all modules.\n* `moduleMap` - a map with all resolved modules, keyed by name\n\n### `createShaderHook(hook, [opts])`\n\nCreates a shader hook function that shader modules can injection code into. Shaders can call these functions, which will be no-ops by default. If a shader module injects code it will be executed upon the hook function call. This mechanism allows the application to create shaders that can be automatically extended by included shader modules.\n\n- `hook`: `vs:` or `fs:` followed by the name and arguments of the function, e.g. `vs:MYHOOK_func(inout vec4 value)`. Hook name without arguments\nwill also be used as the name of the shader hook\n- `opts.header` (optional): code always included at the beginning of a hook function\n- `opts.footer` (optional): code always included at the end of a hook function\n\n### `createModuleInjection(moduleName, opts)`\n\nDefine a code injection for a particular hook function (defined by `createShaderHook`) and shader module. The injection code will be inserted into the hook function whenever the shader module is included.\n\n- `moduleName`: the name of the module for which the injection is being defined\n- `opts.hook`: the shader hook to inject into. This can be a hook function defined by `createShaderHook` or a predefined injection key (see below),\nprefixed by `vs:` for the vertex shader or `fs:` for the fragment shader.\n- `opts.injection`: the injection code\n- `opts.order` (optional): the priority with which to inject code into the shader hook. Lower priority numbers will\nbe injected first\n\n\n## Constants and Values\n\n### Predefined Injection Hooks\n\n| Key              | Shader   | Description      |\n| ---              | ---      | ---              |\n| `vs:#decl`       | Vertex   | Inject at top of shader (declarations) |\n| `vs:#main-start` | Vertex   | Injected at the very beginning of main function |\n| `vs:#main-end`   | Vertex   | Injected at the very end of main function |\n| `fs:#decl`       | Fragment | Inject at top of shader (declarations) |\n| `fs:#main-start` | Fragment | Injected at the very beginning of main function |\n| `fs:#main-end`   | Fragment | Injected at the very end of main function |\n\n## Usage\n\n### Shader Module Code Injection\n\nShader module code injections involve three steps:\n- Defining a shader hook function using `createShaderHook`\n- Calling the hook function in a shader\n- Defining hook code injections for particular modules\n\nFor example, if the application wanted to automatically enable picking color filtering when the `picking` module is included in a program, first the shader hook would be defined:\n\n```js\ncreateShaderHook('fs:MYHOOK_fragmentColor(inout vec4 color)');\n```\n\nIn the fragment shader `main` function, the new hook function would called as follows:\n```js\nvoid main() {\n  //...\n  MYHOOK_fragmentColor(gl_FragColor)\n}\n```\n\nAnd the injection for the picking module would be defined as follows:\n\n```js\ncreateModuleInjection('picking', {\n  hook: 'fs:MYHOOK_fragmentColor',\n  injection: 'color = picking_filterColor(color);',\n  order: Number.POSITIVE_INFINITY\n});\n```\n\nIf the picking module were included, the function `MYHOOK_fragmentColor` would be updated to modify the input color. Without the picking module, the function would remain a no-op. The `priority` ensures the injection always\nappears last in the hook function, which is necessary for picking color filtering to work correctly.\n\nInjecting to a predefined hook would be done as follows:\n\n```js\ncreateModuleInjection('picking', {\n  hook: 'fs:#main-end',\n  injection: 'gl_FragColor = picking_filterColor(gl_FragColor);',\n  order: Number.POSITIVE_INFINITY\n});\n```\n\n\n### Injection Map\n\n`assembleShaders` (and `Model` constructor) will take a new `inject` argument that contains a map of:\n\n* keys indicating hooks (predefined or functions)\n* values representing code to be injected. This can be either a simple string or an object containing the `injection` string and an `order` indicating its priority.\n\nExamples:\n\n```\n  inject: {\n    'fs:#main-end': '  gl_FragColor = picking_filterColor(gl_FragColor)'\n  }\n```\n\n```js\ncreateShaderHook('fs:MYHOOK_fragmentColor(inout vec4 color)');\n\nnew Model(gl, {\n  vs,\n  fs: `void main() {\n    MYHOOK_fragmentColor(gl_FragColor);\n  }`,\n  modules: [picking]\n  inject: {\n    'fs:#main-start': 'gl_FragColor = vec4(1., 0., 0., 1.);';\n    'fs:MYHOOK_fragmentColor': {\n      injection: '  color = picking_filterColor(color);',\n      order: 9999\n  }\n});\n```\n\n\n### Remarks\n\n* Injection at the moment only allows code to be added, not replaced.\n* At the moment the implementation for injection are fairly simple. They depend on the shader code being well organized. For instance they require that the main function must come last in the app shader. In case of issues, try to make sure that line breaks, spacing etc are natural.\n\n\n","slug":"docs/api-reference/shadertools/assemble-shaders","title":"Shadertools API Reference"},{"excerpt":"picking (Shader Module) Provides support for color-coding-based picking. In particular, supports picking a specific instance in an instanced…","rawMarkdownBody":"# picking (Shader Module)\n\nProvides support for color-coding-based picking. In particular, supports picking a specific instance in an instanced draw call.\n\nColor based picking lets the application draw a primitive with a color that can later be used to index this specific primitive.\n\n## Usage\n\nIn your vertex shader, your inform the picking module what object we are currently rendering by supplying a picking color, perhaps from an attribute.\n```\nattribute vec3 aPickingColor;\nmain() {\n  picking_setPickingColor(aPickingColor);\n  ...\n}\n```\n\nIn your fragment shader, you simply apply (call) the `picking_filterPickingColor` filter function at the very end of the shader. This will return the normal color, or the highlight color, or the picking color, as appropriate.\n```\nmain() {\n  gl_FragColor = ...\n  gl_FragColor = picking_filterPickingColor(gl_FragColor);\n}\n```\nIf you would like to apply the highlight color to the currently selected element call `picking_filterHighlightColor` before calling `picking_filterPickingColor`. You can also apply other filters on the non-picking color (vertex or highlight color) by placing those instruction between these two function calls.\n\n ```\nmain() {\n   gl_FragColor = picking_filterHighlightColor(color);\n    ... apply any filters on gl_FragColor ...\n  gl_FragColor = picking_filterPickingColor(gl_FragColor);\n}\n\n```\n\n## JavaScript Functions\n\n### getUniforms\n\n`getUniforms` returns an object with key/value pairs representing the uniforms that the `picking` module shaders need.\n\n`getUniforms({enabled, })`\n\n* `enabled`=`true` (*boolean*) - Activates picking\n* `selectedIndex`=-1 (*number*) - The index of the selected item, or -1 if no selection.\n* `highlightColor`= (*array*)- Color used to highlight the currently selected\n* `active`=`false` (*boolean*) - Renders the picking colors instead of the normal colors. Normally only used with an off-screen framebuffer during picking.\n\nNote that the selected item will be rendered using `highlightColor`.\n\n\n## Vertex Shader Functions\n\n### `void picking_setPickingColor(vec3)`\n\nSets the color that will be returned by the fragment shader if color based picking is enabled. Typically set from a `pickingColor` uniform or a `pickingColors` attribute (e.g. when using instanced rendering, to identify the actual instance that was picked).\n\n\n## Fragment Shader Functions\n\n### picking_filterPickingColor\n\nIf picking active, returns the current vertex's picking color set by `picking_setPickingColor`, otherwise returns its argument unmodified.\n\n`vec4 picking_filterPickingColor(vec4 color)`\n\n### picking_filterHighlightColor\n\nReturns picking highlight color if the pixel belongs to currently selected model, otherwise returns its argument unmodified.\n\n`vec4 picking_filterHighlightColor(vec4 color)`\n\n## Remarks\n\n* It is strongly recommended that `picking_filterPickingColor` is called last in a fragment shader, as the picking color (returned when picking is enabled) must not be modified in any way (and alpha must remain 1) or picking results will not be correct.\n","slug":"docs/api-reference/shadertools/shader-module-picking","title":"picking (Shader Module)"},{"excerpt":"Overview The  module offers modular, reusable effects. Installation","rawMarkdownBody":"# Overview\n\nThe `@luma.gl/effects` module offers modular, reusable effects.\n\n## Installation\n\n    npm install @luma.gl/effects\n","slug":"docs/api-reference/effects/overview","title":"Overview"},{"excerpt":"addEvents Provides the  object to bind events to the canvas to interact with 3D objects. Examples: Setting rotation and zoom to a moon…","rawMarkdownBody":"# addEvents\n\nProvides the [`Events`](/#/documentation/api-reference/event) object to bind events to the canvas to interact with 3D objects.\n\n### Examples:\n\nSetting rotation and zoom to a moon object with drag and drop and mousewheel events.\n\n```js\nvar pos, camera, moon, app;\n\naddEvents(gl, {\n  onDragStart(e) {\n    pos = {\n      x: e.x,\n      y: e.y\n    };\n  },\n  onDragMove(e) {\n    var z = camera.position.z,\n        sign = Math.abs(z) / z;\n\n    moon.rotation.y += -(pos.x - e.x) / 100;\n    moon.rotation.x += sign * (pos.y - e.y) / 100;\n    moon.update();\n    pos.x = e.x;\n    pos.y = e.y;\n  },\n  onMouseWheel(e) {\n    e.stop();\n    camera.position.z += e.wheel;\n    camera.update();\n  }\n});\n```\n\nThe first parameter of each event callback function is an event wrapper object that contains as properties:\n\n* **event** (*element*) - The native event.\n* **x** (*number*) - The x position of the mouse pointer when the event was triggered.\n* **y** (*number*) - The y position of the mouse pointer when the event was triggered.\n* **posArray** (*array*) - If multiple events where triggered at the same time (like multiple fingers touching a screen), then the array of transformed positions will be here.\n* **stop** (*function*) - A method that can be called to stop the propagation of the event.\n* **wheel** (*number*) - Only on the mousewheel event. A number specifying the delta for the mouse scroll.\n* **isRightClick** (*boolean*) - Whether is right or left click.\n* **code** (*number*) - Available onKeyDown only. The key code number.\n* **key** (*string*) - Available onKeyDown only. The key pressed as a string. Can also be `enter`, `up`, `down`, `left`, `right`, `backspace`, `space`, `delete` and `esc`.\n* **shift** (*boolean*) - Available onKeyDown only. Whether the shift key is pressed.\n* **control** (*booleanr*) - Available onKeyDown only. Whether the control key is pressed.\n* **alt** (*boolean*) - Available onKeyDown only. Whether the alt key is pressed.\n* **meta** (*boolean*) - Available onKeyDown only. Whether the meta key is pressed.\n\n\n## Methods\n\n### addEvents\n\nCreates a set of events for the given domElement that can be handled through a callback.\n\n### Syntax:\n\n    Events.create(app, options);\n\n### Arguments:\n\n1. gl  - (*WebGLRenderingContext*) A WebGLRenderingContext object. Events are handled for the context's canvas element.\n5. options - (*object*) An object containing the following options:\n\n### Options:\n\n* cachePosition - (*boolean*, optional) Whether to cache the current position of the canvas or calculate it each time in the event loop. Default's `true`.\n* cacheSize - (*boolean*, optional) Whether to cache the size of the canvas or calculate it each time in the event loop. Default's `true`.\n* relative - (*boolean*, optional) Whether to calculate the mouse position as relative to the canvas position or absolute. Default's `true`.\n* centerOrigin - (*boolean*, optional) Whether to set the center (0, 0) coordinate to the center of the canvas or to the top-left corner. Default's `true`.\n* disableContextMenu - (*boolean*, optional) Disable the context menu (generally shown when the canvas is right clicked). Default's `true`.\n* enableTouch - (*boolean*, optional) Whether to append listeners to touch events. Default's `true`.\n* enableMouse - (*boolean*, optional) Whether to append listeners to mouse events. Default's `true`.\n* enableKeyboard - (*boolean*, optional) Whether to append listeners to keyboard events. Default's `true`.\n* bind - (*mixed*, optional) bind the *thisArg* in the callbacks to the specified object.\n* picking - (*boolean*, optional) Whether to use picking. Default's false.\n\n### Callbacks:\n\nYou can also provide callback functions for the events you need to\nhandle. The first parameter of the callback is the event object\ndescribed [here](/#/documentation/api-reference/event). If `picking` is set to `true` in the\noptions, then the second parameter of the callback may be an\n`O3D` that is the target of the mouse event. If no target\nexists for the mouse event then a falsy value will be provided. The\nfollowing callbacks are:\n\n* onClick - (*function*, optional) Handles the onClick event.\n* onRightClick - (*function*, optional) Handles the onRightClick event.\n* onDragStart - (*function*, optional) Handles the onDragStart event.\n* onDragMove - (*function*, optional) Handles the onDragMove event.\n* onDragEnd - (*function*, optional) Handles the onDragEnd event.\n* onDragCancel - (*function*, optional) Handles the onDragCancel event.\n* onTouchStart - (*function*, optional) Handles the onTouchStart event.\n* onTouchMove - (*function*, optional) Handles the onTouchMove event.\n* onTouchEnd - (*function*, optional) Handles the onTouchEnd event.\n* onTouchCancel - (*function*, optional) Handles the onTouchCancel event.\n* onTap - (*function*, optional) Handles the tap touch event.\n* onMouseMove - (*function*, optional) Handles the onMouseMove event.\n* onMouseEnter - (*function*, optional) Handles the onMouseEnter event.\n* onMouseLeave - (*function*, optional) Handles the onMouseLeave event.\n* onMouseWheel - (*function*, optional) Handles the onMouseWheel event.\n* onKeyDown - (*function*, optional) Handles the onKeyDown event.\n* onKeyUp - (*function*, optional) Handles the onKeyUp event.\n","slug":"docs/api-reference/addons/event","title":"addEvents"},{"excerpt":"Core API Reference The , with the signature  class, represent a set of fairly traditional 3D library classes on a slightly higher…","rawMarkdownBody":"# Core API Reference\n\nThe `core module`, with the signature [`Model`](/docs/api-reference/core/model.md) class, represent a set of fairly traditional 3D library classes on a slightly higher abstraction level than the WebGL2 API, that can serve as the basic building blocks for most applications.\n\nAlso contains a limited scene graph system that provides primitive hierarchy of 3D objects with positioning, grouping, traversal and scene support.\n\nNote that the `Model` class is in many ways the quintessential luma.gl class. It ties together many concepts in luma.gl and is a good place to start reading if you are new to the framework.\n\n\n## Classes\n\nThe core module provides the following classes\n\n* [`AnimationLoop`](/docs/api-reference/core/animation-loop.md) - render loop / app life cycle support\n* [`Model`](/docs/api-reference/core/model.md) - A renderable object with attributes and uniforms.\n* [`Geometry`](/docs/api-reference/core/geometry.md) - Holds attributes and drawType for a geometric primitive\n\n## Methods\n\n### encodePickingColor\n\nEncodes an index as a `Uint8Array([r, g, b])` format picking color\n\n`encodePickingColor(index)`\n\n* `index` - index to be decoded\nreturns the decoded color\n\n\n### decodePickingColor\n\nDecodes a picking color in `[r, g, b]` format to an index\n\n * @param {Uint8Array} color - color array to be decoded\n * @return {Array} - the decoded picking color\n\n\n### getNullPickingColor\n\nReturns the picking color that doesn't match any subfeature. Use if some graphics do not belong to any pickable subfeature.\n\n\n### pickModels\n","slug":"docs/api-reference/core","title":"Core API Reference"},{"excerpt":"AnimationLoopProxy (Experimental) This class is experimental. Its API may change between minor releases. Manages an AnimationLoop that runs…","rawMarkdownBody":"# AnimationLoopProxy (Experimental)\n\n> This class is experimental. Its API may change between minor releases.\n\nManages an [AnimationLoop](/docs/api-reference/core/animation-loop.md) that runs on a worker thread.\n\n## Usage\n\nCreate a worker:\n```js\n// animation-worker.js\nimport {\n  AnimationLoop, _AnimationLoopProxy as AnimationLoopProxy\n} from '@luma.gl/core';\n\nconst animationLoop = new AnimationLoop({...});\nAnimationLoopProxy.createWorker(animationLoop)(self);\n```\n\nUse a bundler e.g. Webpack to transpile and bundle `animation-worker.js` into a file e.g. `animation-worker.es5.js`. You can then use it as this:\n\n```js\nimport {_AnimationLoopProxy as AnimationLoopProxy} from '@luma.gl/core';\n\nnew AnimationLoopProxy(new Worker('animation-worker.es5.js')).start();\n```\n\n## Static Methods\n\n### createWorker\n\n```js\nAnimationLoopProxy.createWorker(animationLoop);\n```\n\nReturns a function `self => {...}` that sets up the message handling inside the worker thread when called with a [WorkerGlobalScope](https://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope) instance.\n\n## Methods\n\n### constructor(worker: Worker, props : Object)\n\n```js\nnew AnimationLoopProxy(worker, {\n  onInitialize,\n  onFinalize,\n  useDevicePixels,\n  autoResizeDrawingBuffer\n});\n```\n\n* `worker` - a [Worker](https://developer.mozilla.org/en-US/docs/Web/API/Worker) instance using code created from `AnimationLoopProxy.createWorker`.\n\n* `props.onInitialize` (callback) - if supplied, will be called once after first `start()` has been called, after page load completes and a context has been created.\n* `props.onFinalize`=`null` (callback) - Called once when animation is stopped. Can be used to delete objects or free any resources created during `onInitialize`.\n* `props.autoResizeDrawingBuffer`=`true` - If true, checks the canvas size every frame and updates the drawing buffer size if needed.\n* `props.useDevicePixels` - Whether to use `window.devicePixelRatio` as a multiplier, e.g. in `autoResizeDrawingBuffer` etc.\n\n### start([options : Object]) : AnimationLoopProxy\n\nInitializes and then (re)starts the animation\n\n```js\nanimationLoopProxy.start(options)\n```\n\n* `options.canvas` (string | HTMLCanvasElement) - A *string* containing the `id` of an existing HTML element or a *DOMElement* instance. If `null` or not provided, a new canvas will be created.\n\n### stop() : AnimationLoopProxy\n\nStops the animation\n\n```js\nanimationLoopProxy.stop();\n```\n\n### waitForRender() : Promise\n\nReturns a promise which resolves in the next frame after rendering has completed.\n\n```js\nconst loop = await animationLoop.waitForRender()\n// can now read pixels from webgl context\nloop.gl.readPixels(...)\n```\n\n### setProps(props: Object) : AnimationLoopProxy\n\n```js\nanimationLoopProxy.setProps({...props});\n```\n\n* `props.autoResizeDrawingBuffer` - Update the drawing buffer size to match the canvas size before each call to `onRenderFrame()`\n* `props.useDevicePixels` - Whether to use `window.devicePixelRatio` as a multiplier, e.g. in `autoResizeDrawingBuffer` etc.\n","slug":"docs/api-reference/core/animation-loop-proxy","title":"AnimationLoopProxy (Experimental)"},{"excerpt":"Geometry The Geometry class holds a collection of vertex array attributes representing a geometric primitive. A geometry is considered a…","rawMarkdownBody":"# Geometry\n\nThe Geometry class holds a collection of vertex array attributes representing a geometric primitive.\n\nA geometry is considered a \"primitive\" when it can be rendered with a single GPU draw call. Multiple geometry primitives can be composed into a composite geometry using the `Mesh` and `Model` classes.\n\nTo learn more about attributes refer to the `Accessor` class that holds metadata for each attributes.\n\n\n## Usage\n\nCreate a pyramid geometry (used in lesson 4 of learning WebGL examples).\n```js\nconst pyramidGeometry= new Geometry({\n  attributes: {\n    positions: new Float32Array([ ... ]),\n    colors: {\n      size: 4,\n      value: new Float32Array([ ... ])\n    }\n  }\n});\n```\n\n## Properties\n\n### `id` - (*string*, optional)\n\nAn id for the model. If not provided, a random unique identifier will be created.\n\n\n### drawMode : Number\n\nThe draw mode, or primitive type.\n\nSome options are `GL.TRIANGLES` (default), `GL.TRIANGLE_STRIP`, `GL.POINTS`, `GL.LINES`.\n\n\n### `attributes` - (*object*, optional)\n\nAn object with buffer/attribute names and buffer/attribute descriptors to be set before rendering the model.\n\n\n### attributes : Object\n\nA map of `Accessor` instances describing the geometry of this primitive.\n\n\n### indices : Accessor\n\nAn optional `Accessor` instance that contains the indices (aka elements) for this geometry. Can be `null` or `undefined` if this primitive doesn't use indices. Note that indices can also be stored inside `attributes`.\n\n\n### material : Object\n\nAn object with key/value pairs that indicate how various uniforms should be set up before the GPU draw call. The `Geometry` class itself does not directly use the contents of the `material` field, however other classes such as `Mesh` will refer to it if available, and normally expects it to be set to an instance of the `Material` class.\n\n\n## Methods\n\n### constructor(props : Object)\n\nThe constructor for the `Geometry` class. Use this to create a new `Geometry`.\n\n```js\nconst geometry = new Geometry(props);\n```\n\n\n### setProps(props : Object)\n\nUpdate properties\n\n\n\n## Types and Enumerations\n\n### drawMode\n\nFollows glTF/OpenGL/WebGL conventions:\n\n| Value | Primitive Mode   |\n| ---   | ---              |\n| `0`   | `POINTS`         |\n| `1`   | `LINES`          |\n| `2`   | `LINE_LOOP`      |\n| `3`   | `LINE_STRIP`     |\n| `4`   | `TRIANGLES`      |\n| `5`   | `TRIANGLE_STRIP` |\n| `6`   | `TRIANGLE_FAN`   |\n\n\n### Typical Attributes\n\n| Attribute      | Description      |\n| ---            | ---              |\n| `indices`      | (*array*, optional) An array of numbers describing the vertex indices for each face. |\n| `positions`    | (*array*, optional) An array of floats that describe the vertices of the model. |\n| `normals`      | (*array*, optional) An array of floats that describe the normals of the model. |\n| `texCoords`    | (*mixed*, optional) Can be an array of floats indicating the texture coordinates for the texture to be used or an object that has texture ids as  |keys and an array of floats as values.\n| `colors`       | (*array*, optional) An array of colors in RGBA. If just one color is specified that color will be used for all faces. |\n| `pickingColors` | (*array*, optional) A custom set of colors to render the object to texture when performing the color picking algorithm. |\n\n\n## Remarks\n\n* The Geometry class does not take a `WebGLRenderingContext` and is intentionally \n* The `Geometry` class holds the [glTF2 \"primitive\" specification](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0), although morph `targets` are not yet supported.\n","slug":"docs/api-reference/core/geometry","title":"Geometry"},{"excerpt":"loadFile, loadImage Minimal utilities to load files and images in the browser, typically used to initialize textures. Usage Creating a…","rawMarkdownBody":"# loadFile, loadImage\n\nMinimal utilities to load files and images in the browser, typically used to initialize textures.\n\n## Usage\n\nCreating a request to load images.\n```js\nimport {loadImage} from '@luma.gl/core';\nasync () {\n  const image = await loadImage('image1.png');\n  alert(\"images loaded! Now do something with the image\");\n}();\n```\n\nCreating a request to load images and create WebGL textures\n```js\nimport {loadImage} from '@luma.gl/core';\nconst image = await loadImage('image1.png');\nconst new Texture2D(gl, {data: image});\n```\n\nYou can also load text files\n```js\nimport {loadFile} from '@luma.gl/core';\nconst text = await loadFile(url);\n```\n\nFor more advanced loading you may want to consider using loaders.gl. these can parse complex formats and parsing works on Node.js, browser threads etc.\n```\nimport {loadFile} from '@loaders.gl/core';\nimport {OBJLoader} from '@loaders.gl/obj';\n\nloadFile(url, OBJLoader).then(data => {\n  // Application code here\n  ...\n});\n```\n\n\n### loadImage(url : String [, options: Object]) : Promise\n\nEnables loading of multiple remote images asynchronously and returns an array with all the images loaded.\n\n```\nconst image = await loadImages(url, options);\n```\n\n* `url` - (*String*) strings pointing to image url.\n\n\n### loadFile(url : String [, options: Object]) : Promise\n\nLoads remote data asynchronously via an http request (`fetch`). The domain serving the data must match the domain where the data is queried.\n","slug":"docs/api-reference/core/load-file","title":"loadFile, loadImage"},{"excerpt":"Material A material instance contains data that is used to populate uniforms for a specific shader stack See the developer-guide for more…","rawMarkdownBody":"# Material\n\nA material instance contains data that is used to populate uniforms for a specific shader stack\n\nSee the developer-guide for more information about materials\n\n\n\n## Properties\n\n### doubleSided : Boolean\n\nThe `doubleSided` property specifies whether the material is double sided. When this value is false, back-face culling is enabled. When this value is true, back-face culling is disabled and double sided lighting is enabled. The back-face must have its normals reversed before the lighting equation is evaluated.\n\n\n### alphaMode : Enum\n\nThe `alphaMode` property defines how the alpha value of the main factor and texture should be interpreted.\n\n`alphaMode` can be one of the following values:\n* `OPAQUE` - The rendered output is fully opaque and any alpha value is ignored.\n* `MASK` - The rendered output is either fully opaque or fully transparent depending on the alpha value and the specified alpha cutoff value. This mode is used to simulate geometry such as tree leaves or wire fences.\n* `BLEND` - The rendered output is combined with the background using the normal painting operation (i.e. the Porter and Duff over operator). This mode is used to simulate geometry such as guaze cloth or animal fur.\n\n> The `alpha` value itself is typically defined in the `baseColor` prop, e.g. for the for metallic-roughness material model.\n\n\n### alphaCutoff : Number\n\nWhen `alphaMode` is set to `MASK` the `alphaCutoff` property specifies the cutoff threshold. If the alpha value is greater than or equal to the `alphaCutoff` value then it is rendered as fully opaque, otherwise, it is rendered as fully transparent. `alphaCutoff` value is ignored for other modes.\n\n\n### normalMap: Texture2D \\| Sampler2D\n\nA tangent space normal map. Used to increase apparent detail of geometry.\n\n\n### normalMapScale : Number\n\nScale of normal map\n\n\n### normalMapCoords : Number\n\nSet of texture coords to use for normal map\n\n\n### occlusionMap: Texture2D \\| Sampler2D\n\nA tangent space occlusion map. Used to indicate areas of indirect lighting, shading e.g. corners etc.\n\n\n### occlusionMapScale : Number\n\nScale of occlusion map\n\n\n### occlusionMapCoords : Number\n\nSet of texture coords to use for occlusion map\n\n\n### emissiveMap: Texture2D \\| Sampler2D\n\nA tangent space emissive map. Used to add lights to models. For example, the headlights of a car model.\n\n\n### emissiveMapScale : Number\n\nScale of emissive map\n\n\n### emissiveMapCoords : Number\n\nSet of texture coords to use for emissive map\n\n\n\n\n\n### Metallic-Roughness Material Model\n\nAll parameters related to the metallic-roughness material model are defined under the `pbrMetallicRoughness` property of `material` object. The following example shows how a material like gold can be defined using the metallic-roughness parameters:\n\n```json\n{\n    \"baseColor\": [ 1.000, 0.766, 0.336, 1.0 ],\n    \"metallic\": 1.0,\n    \"roughness\": 0.0,\n    \"baseColorMap\": null,\n    \"metallicRoughnessMap\": null,\n}\n```\n\nThe metallic-roughness material model is defined by the following properties:\n\n\n### `baseColor` : Number\n\nThe base color of the material. The base color has two different interpretations depending on the value of metalness. When the material is a metal, the base color is the specific measured reflectance value at normal incidence (F0). For a non-metal the base color represents the reflected diffuse color of the material. In this model it is not possible to specify a F0 value for non-metals, and a linear value of 4% (0.04) is used.\n\n\n### `metallic` : Number\n\nThe metalness of the material\n\n\n### `roughness` : Number\n\nThe roughness of the material\n\n\n### metallicRoughnessTexture\n\nThe value for each property (`baseColor`, `metallic`, `roughness`) can be defined using factors or textures. The `metallic` and `roughness` properties are packed together in a single texture called `metallicRoughnessTexture`.\n\n```json\n{\n    \"pbrMetallicRoughness\": {\n        \"baseColor\": [ 0.5, 0.5, 0.5, 1.0 ],\n        \"baseColorMap\": null,\n        \"baseColorMapCoords\": 1,\n        \"metallic\": 1,\n        \"roughness\": 1,\n        \"metallicRoughnessMap\": null,\n        \"metallicRoughnessMapScale\": 1,\n        \"metallicRoughnessMapCoords\": 1,\n    },\n}\n```\n\nIf a texture is not given, all respective texture components within this material model are assumed to have a value of `1.0`. If both factors and textures are present the factor value acts as a linear multiplier for the corresponding texture values. The `baseColorTexture` is in sRGB space and must be converted to linear space before it is used for any computations.\n","slug":"docs/api-reference/core/material","title":"Material"},{"excerpt":"ShaderCache (Experimental) A cache of compiled shaders, keyed by shader source strings. Compilation of long shaders can be time consuming…","rawMarkdownBody":"# ShaderCache (Experimental)\n\nA cache of compiled shaders, keyed by shader source strings. Compilation of long shaders can be time consuming. By using a `ShaderCache`, the application can ensure that each shader is only compiled once.\n\n\n## Usage\n\n```js\nimport {_ShaderCache as ShaderCache} from '@luma.gl/core';\n```\n\n\n## Methods\n\n### constructor\n\nCreates a new `ShaderCache` object.\n\n`new ShaderCache(gl)`\n\nNote that only objects from a single context can be cached, any attempts to use this cache with other gl contexts will result in exceptions.\n\n\n### delete\n\n`ShaderCache.delete()`\n\nHint to delete any unused cached shaders (currently a no-op).\n\n\n### getVertexShader\n\nReturns a compiled `VertexShader` object corresponding to the supplied GLSL source code string, if possible from cache.\n\n`ShaderCache.getVertexShader(gl, source)`\n\n\n* `gl` {WebGLRenderingContext} - gl context\n* `source` {String} - Source code for shader\nreturns {VertexShader} - a compiled vertex shader\n\n\n### getFragmentShader\n\nReturns a compiled `FragmentShader` object corresponding to the supplied GLSL source code string, if possible from cache.\n\n`ShaderCache.getFragmentShader(gl, source)`\n\n* `gl` {WebGLRenderingContext} - gl context\n* `source` {String} - Source code for shader\nreturns {FragmentShader} - a compiled fragment shader\n","slug":"docs/api-reference/core/shader-cache","title":"ShaderCache (Experimental)"},{"excerpt":"createGLContext Provides functions to create and initialize a WebGL context, and to check for presence of WebGL and extensions. Provides the…","rawMarkdownBody":"# createGLContext\n\nProvides functions to create and initialize a WebGL context, and to check for presence of WebGL and extensions.\n\n* Provides the `createGLContext` method which can create WebGLContexts both in browsers and under Node.js.\n\nNote that the use of these functions is NOT required to use the remaining functions and classes in luma.gl.\n\nYou could e.g. manually create a WebGLContext by using canvas.getContext, or use a context created by another WebGL library.\nIn fact, luma.gl is explicitly designed to work with any WebGL context, and in contrast to some other approaches, luma.gl maintains no \"hidden state\" that might complicate composing your code with other WebGL based modules.\n\n\n## Usage\n\nCreate a WebGL context, autocreating a canvas\n```js\nimport {createGLContext} from '@luma.gl/core';\nconst gl = createGLContext(); // Prefers WebGL2 but falls back to WebGL1\n```\n\nCreate a WebGL2 context, failing gracefully if WebGL2 is not supported.\n```js\nimport {createGLContext} from '@luma.gl/core';\nconst gl = createGLContext({\n  webgl1: false,\n  throwOnError: false\n});\nif (!gl) {\n  console.error('WebGL2 not supported');\n}\n```\n\nCreate a WebGL context in an existing canvas, setting WebGL context attributes\n```js\nimport {createGLContext} from '@luma.gl/core';\nconst gl = createGLContext({\n  canvas: 'my-canvas-id',\n  stencil: true,       // Default render target gets a stencil buffer of at least 8 bits.\n  antialias: false,    // Turn of antialiasing\n  premultipliedAlpha: false, // turn off pre-multiplied alpha.\n  preserveDrawingBuffer: true, // Default render target buffers will not be automatically cleared\n});\n```\n\nCreate a headless WebGL context (under Node.js). `headless-gl` must be installed (`npm install gl`).\n```js\nimport {createGLContext} from '@luma.gl/core';\nconst gl = createGLContext({width: 100, height: 100});\n```\n\n\n## Methods\n\n\n### createGLContext\n\nCreates and returns a WebGL context, both in browsers and in Node.js.\n\n```\nconst gl = createGLContext(options);\n```\n\n* `options` (*Object*) - key/value pairs containing context creation options\n\n| Parameter               | Browser default | Headless default | Description |\n| ---                     | ---     | ---    | ---         |\n| `webgl2`                | `true`  | N/A    | If `true`, will attempt to create a WebGL2 context. Will silently fall back to WebGL1 contexts unless `webgl1` is set to `false`. |\n| `webgl1`                | `true`  | `true` | If `true`, will attempt to create a WebGL1 context. The `webgl2` flag has higher priority. |\n| `throwOnError`          | `true`  | `true` | Normally the context will throw an error on failure. If `false`, it will log to console instead. |\n| `break`          | `[]`  | N/A | Insert a break point (`debugger`) if one of the listed gl functions is called. |\n| `manageState`           | `true`  | `true` | Instrument the context to enable state caching and `withParameter` calls. Leave on unless you have special reasons not to. |\n| *Browser-only*            |         |        | |\n| `debug`                 | `false` | N/A    | WebGL API calls will be logged to the console and WebGL errors will generate JavaScript exceptions. Note the enabling debug mode has a signficant performance impact. |\n| `canvas`                | `null`  | N/A    | A *string* containing the `id` of an existing HTML element or a *DOMElement* instance. If `null` or not provided, a new canvas will be created. |\n| `alpha`                 | `true`  | N/A      | Default render target has an alpha buffer. |\n| `depth`                 | `true`  | N/A      | Default render target has a depth buffer of at least 16 bits. |\n| `stencil`               | `false` | N/A      | Default render target has a stencil buffer of at least 8 bits. |\n| `antialias`             | `true`  | N/A      | Boolean that indicates whether or not to perform anti-aliasing. |\n| `premultipliedAlpha`    | `true`  | N/A      | Boolean that indicates that the page compositor will assume the drawing buffer contains colors with pre-multiplied alpha.\n| `preserveDrawingBuffer` | `false` | N/A      | Default render target buffers will not be automatically cleared and will preserve their values until cleared or overwritten |\n| `failIfMajorPerformanceCaveat` |`false`| N/A | Do not create if the system performance is low.\n| Headless-only           |         |        | |\n| `width`                 | N/A     | `800`  | width (*number*) of the headless \"virtual screen\" render target. Ignored for browser contexts |\n| `height`                | N/A     | `600`  | height (*number*) of the headless \"virtual screen\" render target. Ignored for browser contexts |\n\n\n## Remarks\n\n* In browser environments, contexts are created via `HTMLCanvasElement.getContext`. If the `webgl2` option is set, this function will first try `webgl2` and then `experimental-webgl2`, before falling back to webgl1.\n* In Node.js environments, the context is created using headless-gl. In this case width and height options must be supplied as there is no canvas element to use as reference.\n","slug":"docs/api-reference/webgl/context/context","title":"createGLContext"},{"excerpt":"getContextInfo Returns an object containing following details. vendor: infoGL.UNMASKEDVENDORWEBGL || infoGL.VENDOR, renderer: infoGL…","rawMarkdownBody":"# getContextInfo\n\nReturns an object containing following details.\n\n* vendor: info[GL.UNMASKED_VENDOR_WEBGL] || info[GL.VENDOR],\n* renderer: info[GL.UNMASKED_RENDERER_WEBGL] || info[GL.RENDERER],\n* version: info[GL.VERSION],\n* shadingLanguageVersion: info[GL.SHADING_LANGUAGE_VERSION],\n* info,\n* limits,\n* webgl1MinLimits: gl.luma.webgl1MinLimits,\n* webgl2MinLimits: gl.luma.webgl2MinLimits\n","slug":"docs/api-reference/webgl/context/get-context-info","title":"getContextInfo"},{"excerpt":"getGLContextInfo Returns an object with following parameters as keys and corresponding value for each key. parameter 'GL.VENDOR' 'GL…","rawMarkdownBody":"# getGLContextInfo\n\nReturns an object with following parameters as keys and corresponding value for each key.\n\n| parameter |\n| --- |\n| 'GL.VENDOR' |\n| 'GL.RENDERER' |\n| 'GL.UNMASKED_VENDOR_WEBGL' |\n| 'GL.UNMASKED_RENDERER_WEBGL' |\n| 'GL.VERSION' |\n| 'GL.SHADING_LANGUAGE_VERSION' |\n","slug":"docs/api-reference/webgl/context/get-gl-context-info","title":"getGLContextInfo"},{"excerpt":"getFeatures This function returns an object containing all available features (as defined in the extension table) on this platform.","rawMarkdownBody":"# getFeatures\n\nThis function returns an object containing all available features (as defined in the [extension table](/docs/api-reference/webgl/context/has-features.md#optional-feature-detection)) on this platform.\n","slug":"docs/api-reference/webgl/context/get-features","title":"getFeatures"},{"excerpt":"getContextLimits Provides WebGL queries for max values. Definitions of all WebGL2 constants (whether defined by WebGL1, WebGL2 or extensions…","rawMarkdownBody":"# getContextLimits\n\nProvides WebGL queries for max values.\n\n* Definitions of all WebGL2 constants (whether defined by WebGL1, WebGL2 or extensions). This enables applications to directly query for any WebGL constant or limit without having to first determine what environment they are running on.\n\n* Enables apps to use the WebGL2 constant definitions to query any parameters supported by WebGL2 or extensions regardless of whether current platform actually supports them (returning some kind of \"sane\" defaults, usually 0).\n\nCheck a certain limit (whether through an extension under WebGL1 or through WebGL2)\n```js\nimport GL from '@luma.gl/constants';\nimport {getContextLimits} from '@luma.gl/core';\nconst limits = getContextLimits(gl);\nif (limits[GL.MAX_COLOR_ATTACHMENTS] > 0) { // it will be 0 for WebGL1\n   ...\n}\n```\n\nThere are a few additional capability query functions sprinkled through the luma.gl API. In particular, WebGL2 specific classes have an `isSupported` method that duplicates some of the queryies that can be made using the capability system\n```js\nimport {Query} from '@luma.gl/core';\nif (Query.isSupported(gl)) {\n  ...\n}\n\n## Methods\n\n### getContextLimits(gl)\n\nReturns an object with limits, each limit is an object with multiple values\n- `value` - the value of the limit in the current context\n- `webgl1` - the minimum allowed value of the limit for WebGL1 contexts\n- `webgl2` - the minimum allowed value of the limit for WebGL2 contexts\n\n### WebGL Limits\n\nIn addition to capabilities, luma.gl can also query the context for all limits.\n\n| Limits                               | WebGL2 | WebGL1 | Description |\n| ---                                  | ---    | ---    | --- |\n| `GL.ALIASED_LINE_WIDTH_RANGE`        |        | [1, 1] | |\n| `GL.ALIASED_POINT_SIZE_RANGE`        |        | [1, 1] | |\n| `GL.MAX_TEXTURE_SIZE`                | 2048   | 64     | |\n| `GL.MAX_CUBE_MAP_TEXTURE_SIZE`       |        | 16     | |\n| `GL.MAX_TEXTURE_IMAGE_UNITS`         |        | 8      | |\n| `GL.MAX_COMBINED_TEXTURE_IMAGE_UNITS`|        | 8      | |\n| `GL.MAX_VERTEX_TEXTURE_IMAGE_UNITS`  |        | 0      | |\n| `GL.MAX_RENDERBUFFER_SIZE`           |        | 1      | |\n| `GL.MAX_VARYING_VECTORS`             |        | 8      | |\n| `GL.MAX_VERTEX_ATTRIBS`              |        | 8      | |\n| `GL.MAX_VERTEX_UNIFORM_VECTORS`      |        | 128    | |\n| `GL.MAX_FRAGMENT_UNIFORM_VECTORS`    |        | 16     | |\n| `GL.MAX_VIEWPORT_DIMS`               |        | [0, 0] | |\n| `GL.MAX_TEXTURE_MAX_ANISOTROPY_EXT`  |  1.0   | 1.0    | ['EXT_texture_filter_anisotropic'](https://developer.mozilla.org/en-US/docs/Web/API/EXT_texture_filter_anisotropic) |\n\n| WebGL2 Limits                        | WebGL2 | WebGL1 (mock) | Description\n| ---                                  | ---    | ---           | --- |\n| `GL.MAX_3D_TEXTURE_SIZE`             | `256`  | `0`    | |\n| `GL.MAX_ARRAY_TEXTURE_LAYERS`        | `256`  | `0`    | |\n| `GL.MAX_CLIENT_WAIT_TIMEOUT_WEBGL`   | `0`    | `0`    | |\n| `GL.MAX_COLOR_ATTACHMENTS`           | `4`    | `0`    | |\n| `GL.MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS`| `0`|`0` | |\n| `GL.MAX_COMBINED_UNIFORM_BLOCKS`     | `0`    | `0`    | |\n| `GL.MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS`|`0`| `0`   | |\n| `GL.MAX_DRAW_BUFFERS`                | `4`    | `0`    | |\n| `GL.MAX_ELEMENT_INDEX`               | `0`    | `0`    | |\n| `GL.MAX_ELEMENTS_INDICES`            | `0`    | `0`    | |\n| `GL.MAX_ELEMENTS_VERTICES`           | `0`    | `0`    | |\n| `GL.MAX_FRAGMENT_INPUT_COMPONENTS`   | `0`    | `0`    | |\n| `GL.MAX_FRAGMENT_UNIFORM_BLOCKS`     | `0`    | `0`    | |\n| `GL.MAX_FRAGMENT_UNIFORM_COMPONENTS` | `0`    | `0`    | |\n| `GL.MAX_PROGRAM_TEXEL_OFFSET`        | `0`    | `0`    | |\n| `GL.MAX_SAMPLES`                     | `0`    | `0`    | |\n| `GL.MAX_SERVER_WAIT_TIMEOUT`         | `0`    | `0`    | |\n| `GL.MAX_TEXTURE_LOD_BIAS`            | `0`    | `0`    | |\n| `GL.MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS`|`0`|`0`| |\n| `GL.MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS` |`0`| `0` | |\n| `GL.MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS`|`0`|`0`| |\n| `GL.MAX_UNIFORM_BLOCK_SIZE`          | `0`    | `0`    | |\n| `GL.MAX_UNIFORM_BUFFER_BINDINGS`     | `0`    | `0`    | |\n| `GL.MAX_VARYING_COMPONENTS`          | `0`    | `0`    | |\n| `GL.MAX_VERTEX_OUTPUT_COMPONENTS`    | `0`    | `0`    | |\n| `GL.MAX_VERTEX_UNIFORM_BLOCKS`       | `0`    | `0`    | |\n| `GL.MAX_VERTEX_UNIFORM_COMPONENTS`   | `0`    | `0`    | |\n| `GL.MIN_PROGRAM_TEXEL_OFFSET`        | `0`    | `0`    | |\n| `GL.UNIFORM_BUFFER_OFFSET_ALIGNMENT` | `0`    | `0`    | |\n\n### getGLContextInfo(gl)\nReturns an object with following parameters as keys and corresponding value for each key.\n\n| parameter |\n| --- |\n| 'GL.VENDOR' |\n| 'GL.RENDERER' |\n| 'GL.UNMASKED_VENDOR_WEBGL' |\n| 'GL.UNMASKED_RENDERER_WEBGL' |\n| 'GL.VERSION' |\n| 'GL.SHADING_LANGUAGE_VERSION' |\n\n\n\n### getContextInfo(gl)\n\nReturns an object containing following details.\n* vendor: info[GL.UNMASKED_VENDOR_WEBGL] || info[GL.VENDOR],\n* renderer: info[GL.UNMASKED_RENDERER_WEBGL] || info[GL.RENDERER],\n* version: info[GL.VERSION],\n* shadingLanguageVersion: info[GL.SHADING_LANGUAGE_VERSION],\n* info,\n* limits,\n* webgl1MinLimits: gl.luma.webgl1MinLimits,\n* webgl2MinLimits: gl.luma.webgl2MinLimits\n\n\n## Remarks\n\n* WebGL1 only supports one color buffer format (RBG32F is deprecated)\n* WebGL2 supports multiple color buffer formats\n* Some extensions will not be enabled until they have been queries. luma always queries on startup to enable, app only needs to query again it wants to test platform.\n* The capability detection system works regardless of whether the app is running in a browser or in headless mode under Node.js.\n* Naturally, given that queries to driver and GPU are typically expensive in WebGL, the capabilities system will cache any queries.\n","slug":"docs/api-reference/webgl/context/get-context-limits","title":"getContextLimits"},{"excerpt":"isWebGL2 This function checks if an existing WebGL context is a WebGL2RenderingContext Method isWebGL2 A major check that can be done is…","rawMarkdownBody":"# isWebGL2\n\nThis function checks if an existing WebGL context is a WebGL2RenderingContext\n\n## Method\n\n### isWebGL2\n\nA major check that can be done is whether you are working with a `WebGL2RenderingContext`. An advantage of using this method is that it can correctly identify a luma.gl debug context (which is not a subclass of a `WebGL2RendringContext`).\n\n`isWebGL2(gl)`\n\n* `gl` (WebGLRenderingContext) - gl context\nReturns true if the context is a WebGL2RenderingContext.\n\nSee also: `isWebGLRenderingContext`.\n\n","slug":"docs/api-reference/webgl/context/is-webGL2","title":"isWebGL2"},{"excerpt":"resetParameters luma.gl enables a 'stateless' WebGL programming model. In this model, state settings can be passed as parameters to…","rawMarkdownBody":"# resetParameters\n\nluma.gl enables a 'stateless' WebGL programming model. In this model, state settings can be passed as parameters to rendering commands, or applied temporarily using `withParameters` rather than being set and unset directly on the global state. For more information, see the remarks.\n\nThe following functions are provided:\n* `resetParameters` - Resets all GL context parameters to their default values\n\n\n## Usage\n\nReset all parameters to their default values\n```js\nresetParameters(gl);\n```\n\n## Methods\n\n### resetParameters\n\n```js\nresetParameters(gl)\n```\nResets all gl context parameters to default values.\n\n* `gl` {WebGLRenderingContext} - context\nReturns no value.\n\nNote that technically, resetting context parameters does not fully reset the context, as buffer binding, z buffer values etc are not reset.\n","slug":"docs/api-reference/webgl/context/reset-parameters","title":"resetParameters"},{"excerpt":"KeyFrames Manages key frame animation data. Associates time points with arbitrary data and provides methods to access key times and data…","rawMarkdownBody":"# KeyFrames\n\nManages key frame animation data. Associates time points with arbitrary data and provides methods to access key times and data, and an interpolation factor, based on the current time.\n\n\n## Usage\n\n```js\nconst keyFrames = new KeyFrames([\n  [0, { val1: [1, 0, 1], val2: 0} ],\n  [500, { val1: [1, 1, 1], val2: 2} ],\n  [800, { val1: [0, 0, 1], val2: 1} ],\n  [1200, { val1: [0, 1, 0], val2: 4} ],\n  [1500, { val1: [1, 0, 1], val2: 5} ]\n]);\n\nkeyFrames.setTime(1000);\n\nkeyFrames.startIndex;      // => 2                            (i.e. key frame at time=800)\nkeyFrames.endIndex;        // => 3                            (i.e. key frame at time=1200)\nkeyFrames.factor;          // => 0.5                          (i.e. halfway between 800 and 1200)\nkeyFrames.getStartTime();  // => 800                          (i.e. time at index 2)\nkeyFrames.getEndTime();    // => 1200                         (i.e. time at index 3)\nkeyFrames.getStartData();  // => { val1: [0, 0, 1], val2: 1}  (i.e. data at index 2)\nkeyFrames.getEndData();    // => { val1: [0, 1, 0], val2: 4}  (i.e. data at index 3)\n\n```\n\n## Properties\n- `startIndex` (Number): Current start key frame index (i.e. the index of the key frame being interpolated from).\n- `endIndex` (Number): Current end key frame index (i.e. the index of the key frame being interpolated to).\n- `factor` (Number): A value between 0 and 1 representing the interpolation factor between the start and end key frame pair.\n\n## Methods\n\n### constructor(keyFrameData: Array)\n\nTakes an array of `[time, data]` pairs to initialize the key frames.\n\n\n### setKeyFrames(keyFrameData: Array)\n\nReplaces the current set of key frames with a new one. Takes the same argument as the constructor.\n\n\n### getStartTime() : Number\n\nReturns the time at the current start key frame index.\n\n\n### getEndTime() : Number\n\nReturns the time at the current end key frame index.\n\n\n### getStartData() : Any\n\nReturns the data at the current start key frame index (i.e. the data being interpolated from).\n\n\n### getEndData() : Any\n\nReturns the data at the current end key frame index (i.e. the data being interpolated to).\n\n\n### setTime(time: Number)\n\nSet the current time of the key frames.\n","slug":"docs/api-reference/addons/animation/key-frames","title":"KeyFrames"},{"excerpt":"withParameters Finally, luma.gl enables a 'stateless' WebGL programming model. In this model, state settings can be passed as parameters to…","rawMarkdownBody":"# withParameters\n\nFinally, luma.gl enables a 'stateless' WebGL programming model. In this model, state settings can be passed as parameters to rendering commands, or applied temporarily using `withParameters` rather than being set and unset directly on the global state. For more information, see the remarks.\n\nThe following functions are provided:\n* `withParameters` - Runs a function with a set of parameters temporarily applied\n\n\n## Usage\n\nSet parameters temporarily for a function call (automatically restoring them after the call)\n```js\nconst returnValue = withParameters(gl, {\n  depthTest: true\n}, () = {\n  // execute code with new parameters temporarily applied\n  program.draw(...);\n  ...\n  // parameters will be restored even the function throws an exception\n  if (...) {\n    throw new Error('Exception after setting parameters');\n  }\n\n  // Return value of the function will be returned from `withParameters`\n  return true;\n});\n\n// previous parameters are restored here\nprogram.draw(...);\n```\n\n## Methods\n\n### withParameters\n\nExecutes a function after temporarily setting the parameters. Will restore the parameters to their previously value after the completion of the function, even if the function exits with an exception.\n\n```js\nwithParameters(gl, {...params}, func)\n```\n* `gl` {WebGLRenderingContext} - context\n* `params` {Object} - any parameter names accepted by `setParameters`\n\nReturns: the value returned by `func`, if any.\n","slug":"docs/api-reference/webgl/context/with-parameters","title":"withParameters"},{"excerpt":"Timeline Manages an animation timeline, with multiple channels that can be running at different rates, durations, etc. Many methods…","rawMarkdownBody":"# Timeline\n\nManages an animation timeline, with multiple channels that can be running at different rates, durations, etc. Many methods (`play`, `pause`) assume that the `update` method is being called once per frame with a \"global time\". This automatically done for `AnimationLoop.timeline` object.\n\n## Parallel Times\n\nThe key concept at work in the `Timeline` is running multiple time frames in parallel:\n* Global Time: The \"system time\" as determined by the application. Used by `Timeline` to determine the rate at which to play.\n* Timeline Time: The \"parent\" time of all channels on the timeline. Can be played at the same rate as \"Global Time\" or manipulated manually.\n* Channel Time: Will update in lock step with \"Timeline Time\", but may move at different rates, loop, etc. depending on channel parameters.\n\n## Usage\n\nAutomatic update usage (assume `update` method is being called once per frame):\n```js\nanimationLoop.attachTimeline(new Timeline());\nconst timeline = animationLoop.timeline;\nconst channel1 = timeline.addChannel({\n  rate: 0.5,\n  duration: 4000,\n  repeat: Number.POSITIVE_INFINITY\n});\nconst channel2 = timeline.addChannel({\n  rate: 2,\n  delay: 500,\n  duration: 1000,\n  repeat: 3\n});\n\ntimeline.pause();\ntimeline.play();\n\nmodel.setUniforms({\n  uValue1: timeline.getTime(channel1);\n  uValue2: timeline.getTime(channel2);\n});\n```\n\nManual usage:\n```js\nconst timeline = new Timeline();\nconst channel1 = timeline.addChannel({\n  rate: 0.5,\n  duration: 4000,\n  repeat: Number.POSITIVE_INFINITY\n});\nconst channel2 = timeline.addChannel({\n  rate: 2,\n  delay: 500,\n  duration: 1000,\n  repeat: 3\n});\ntimeline.setTime(500);\n\nmodel.setUniforms({\n  uValue1: timeline.getTime(channel1);\n  uValue2: timeline.getTime(channel2);\n});\n```\n\n\n## Methods\n\n### addChannel([props: Object]) : Number\n\nAdd a new channel to the timeline. Returns a handle to the channel that can be use for subsequent interactions. Valid propeties are:\n* `rate` the speed of the channel's time relative to timeline time.\n* `delay` offset into timeline time at which channel time starts elapsing, in timeline time units.\n* `duration` the length of the channel time frame, in timeline time units.\n* `repeat` how many time to repeat channel time's timeline. Only meaningful if `duration` is finite.\n\n### removeChannel(handle : Number)\n\nRemove a channel from the timeline. `handle` should be a value that was returned by `addChannel`.\n\n### isFinished(handle : Number) : Boolean\n\nReturns whether the channel's time has completely elapsed.\n\n### getTime([handle : Number]) : Number\n\nReturn the current time of the channel indicated by `handle`. If no handle is provided, return timeline time.\n\n### setTime(time : Number)\n\nSet the timeline time to the given value.\n\n### play\n\nAllow timeline time to be updated by calls to `update`.\n\n### pause\n\nPrevent timeline time from being updated by calls to `update`.\n\n### reset\n\nReset timeline time to `0`.\n\n### attachAnimation(animation: Object, [channelHandle : Number]) : Number\n\nAttach an animation object (can be any object with a `setTime` method, e.g. [KeyFrames](./key-frames.md), `GLTFAnimator`) to the timeline, optionally attached to a specific channel referenced by `channelHandle`.\nThe animation object's time will be updated whenever the timeline updates. Returns a handle that can be used to reference the animation attachement.\n\n### detachAnimation(handle : Number)\n\nDetach an animation object from the timeline. `handle` should be a value that was returned by `attachAnimation`.\n\n### update(globalTime : Number)\n\nExpected to be called once per frame, with whatever is considered the \"system time\". Required for `play` and `pause` to work properly.\n","slug":"docs/api-reference/addons/animation/timeline","title":"Timeline"},{"excerpt":"BufferTransform  is an internal helper class for , responsible for managing resources and state required for reading from and/or writing to…","rawMarkdownBody":"# BufferTransform\n\n`BufferTransform` is an internal helper class for `Transform`, responsible for managing resources and state required for reading from and/or writing to `Buffer` objects. It auto creates `feedbackBufferes` when requested, creates `TransformFeedback` objects. Maintains all buffer bindings, when swapping is eanbled, two binding objects are created for easy switching of all WebGL resource binginds.\n\nNOTE: In following sections 'buffer transform' is used to refer to 'reading from and/or writing to `Buffer` objects'.\n\n## Constructor\n\n### Transform(gl : WebGL2RenderingContext, props: Object)\n\n* `gl` (`WebGLRenderingContext`) gl - context\n* `props` (`Object`, Optional) - contains following data.\n  * `sourceBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Attribute`, `Buffer` or attribute descriptor object.\n  * `feedbackBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader varying and value is the corresponding `Buffer` object or buffer params object. If a buffer params object is specified, it will contain following fields, these can be used to capture data into the buffer at particular offset and size.\n    * `buffer`=(Buffer) - Buffer object to be bound.\n    * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n    * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n  * `varyings` (`Array`, Optional) - Array of vertex shader varyings names. When not provided this can be deduced from `feedbackBuffers`.\n\n  NOTE: If only reading from `Buffer` objects, above optional props doesn't have to be supplied during construction, but can be supplied using `update` method. If writing to `Buffer` objects, either `varyings` or `feedbackBuffers` must be supplied.\n\n\n## Methods (Model props)\n\n### getDrawOptions(opts: Object) : Object\n\nReturns resources required when performing `Model.draw()` options.\n\n* `opts` (`Object`) - Any existing `opts.attributes` will be merged with new attributes.\n\nReturns an Object : {attributes, transformFeedback}.\n\n### updateModelProps(props: Object) : Object\n\nUpdates input `props` object with data required for buffer transform.\n\n  * `opts` (`Object`) - If writing to `Buffer` objects, `opts.varying` will be updated.\n\nReturns updated object.\n\n## Methods (Resource management)\n\n### setupResources(opts: Object)\n\nSets up internal resources needed writing to buffers.\n\n  * `opts` (`Object`) - contains following data.\n    * `model` (`Model`, Optional) - `Model` object that is used to perform draw operations.\n\n### swap()\n\nIf `feedbackMap` is provided during construction, performs source and feedback buffers swap as per the `feedbackMap`.\n\n### update(props: Object)\n\nUpdates buffer bindings for one or more source or feedback buffers.\n\n  * `props` (`Object`) - contains following data.\n    * `sourceBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Attribute`, `Buffer` or attribute descriptor object.\n    * `feedbackBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader varying and value is the corresponding `Buffer` object or buffer params object. If a buffer params object is specified, it will contain following fields, these can be used to capture data into the buffer at particular offset and size.\n      * `buffer`=(Buffer) - Buffer object to be bound.\n      * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n      * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n\n\n## Methods (Accessors)\n\n### getBuffer(varyingName : String) : Buffer\n\nReturns current feedback buffer corresponding to given varying name.\n\n  * `varyingName` (`String`) - varying name.\n\n### getData([options : Object]) : ArrayBufferView\n\nReads and returns data from current feedback buffer corresponding to the given varying name.\n\n  * `options.varyingName` (`String`, Optional) - when specified, first checks if there is a corresponding feedback buffer, if so reads data from this buffer and returns. When not specified, there must be target texture and data is read from this texture and returned.\n","slug":"docs/api-reference/core/transform/buffer-transform","title":"BufferTransform"},{"excerpt":"TextureTransform  is an internal helper class for , responsible for managing resources and state required for reading from and/or writing to…","rawMarkdownBody":"# TextureTransform\n\n`TextureTransform` is an internal helper class for `Transform`, responsible for managing resources and state required for reading from and/or writing to `Texture` objects. It auto creates `Texture` objects when requested, creates `Framebuffer` objects. Maintains all texture bindings, when swapping is eanbled, two binding objects are created for easy switching of all WebGL resource binginds.\n\nNOTE: In following sections 'texture transform' is used to refer to 'reading from and/or writing to `Texture` objects'.\n\n## Constructor\n\n### Transform(gl : WebGL2RenderingContext, props: Object)\n\n* `gl` (`WebGLRenderingContext`) gl - context\n* `props` (`Object`, Optional) - contains following data.\n  * `sourceTextures` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Texture` object.\n  * `targetTexture` (`Texture`|`String`, Optional) - `Texture` object to which data to be written. When it is a `String`, it must be one of the source texture attributes name, a new texture object is cloned from it.\n  * `targetTextureVarying` (`String`) : varying name used in vertex shader who's data should go into target texture.\n  * `swapTexture` (`String`) : source texture attribute name, that is swapped with target texture every time `swap()` is called.\n  * `fs` (`String`, Optional) - fragment shader string, when rendering to a texture, fragments can be processed using this custom shader, when not specified, pass through fragment shader will be used.\n\n\n## Methods (Model props)\n\n### getDrawOptions(opts: Object) : Object\n\nReturns options required when performing `Model.draw()` options.\n\n* `opts` (`Object`) - Any existing `opts.attributes` , `opts.parameters`, and `opts.uniforms` will be merged with new values.\n\nReturns an Object : {attributes, framebuffer, uniforms, discard, parameters}.\n\n### updateModelProps(props: Object) : Object\n\nUpdates input `props` object used to build `Model` object,  with data required for texture transform.\n\n  * `props` (`Object`) -  props for building `Model` object, it will updated with required options (`{vs, fs, modules, uniforms, inject}`) for texture transform.\n\nReturns updated object.\n\n## Methods (Resource management)\n\n### swap()\n\nIf `swapTexture` is provided during construction, performs source and feedback buffers swap as per the `swapTexture` mapping.\n\n### update(props: Object)\n\nUpdates bindings for source and target texture.\n\n  * `props` (`Object`) - contains following data.\n    * `sourceTextures` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Texture` object.\n    * `targetTexture` (`Texture`|`String`, Optional) - `Texture` object to which data to be written. When it is a `String`, it must be one of the source texture attributes name, a new texture object is cloned from it.\n\n\n## Methods (Accessors)\n\n### getTargetTexture() : Texture\n\nReturns current target texture object.\n\n### getData([options : Object]) : ArrayBufferView\n\nReads and returns data from current target texture.\n\n  * `options.packed` (Boolean, Optional, Default: false) - When true, data is packed to the actual size varyings. When false return array contains 4 values (R, G, B and A) for each element. Un-used element value will be 0 for R, G and B and 1 for A channel.\n\n### getFramebuffer() : Framebuffer\n\nReturns current `Framebuffer` object.\n","slug":"docs/api-reference/core/transform/texture-transform","title":"TextureTransform"},{"excerpt":"ModelNode Constructor ModelNode(gl: WebGLRenderingContext, props: Object) or ModelNode(model: Model, props: Object)  is the same props as…","rawMarkdownBody":"# ModelNode\n\n## Constructor\n\n### ModelNode(gl: WebGLRenderingContext, props: Object) _or_ ModelNode(model: Model, props: Object)\n\n* `props` is the same props as `Model`\n* Additionally you can pass `props.managedResources` array of objects that this model owns.\nWill automatically call `delete()` on all of them when you call `ModelNode.delete()`\n\n## Methods\n\n","slug":"docs/api-reference/core/scenegraph/model-node","title":"ModelNode"},{"excerpt":"GroupNode A  is a subclass of  that holds a list of  children. Since . A  can be a child of another  and thus be used to create hierarchical…","rawMarkdownBody":"# GroupNode\n\nA `GroupNode` is a subclass of `ScenegraphNode` that holds a list of `ScenegraphNode` children. Since . A `GroupNode` can be a child of another `GroupNode` and thus be used to create hierarchical scene graphs.\n\n\n## Usage\n\nAdd a moon and a box models to the group.\n```js\n// Add objects to the group\ngroup.add(moon, box);\n```\n\nAdd a moon and a box models to the group. Then remove them.\n```js\n// Add objects to the group\ngroup.add(moon, box);\n// Remove the moon\ngroup.remove(moon);\n```\n\n\n## Properties\n\n`Model` extends the `ScenegraphNode` class and inherits the transformation matrix properties from that class.\n\n\n### children : ScenegraphNode[]\n\n\n## Methods\n\n\n### constructor(props : Object)\n\nCreate an instance of `GroupNode`.\n\n\n### setProps(props : Object)\n\nUpdates properties.\n\n\n### add(node : ScenegraphNode [, ...])\n\nAdd one or more `ScenegraphNode` objects to the `GroupNode`.\n\n`group.add(model);`\n\nA variable argument list of [ScenegraphNode]() instances.\n\n\n### remove(node: Node)\n\nRemoves an [ScenegraphNode](object-3d.html) object from the GroupNode.\n\n    group.remove(model);\n\n* model - (*object*) The scene graph node to be removed.\n","slug":"docs/api-reference/core/scenegraph/group-node","title":"GroupNode"},{"excerpt":"ScenegraphNode The  is a base class for objects in the luma.gl scene graph, such as ,  and . It holds the transformation matrix (i.e. the…","rawMarkdownBody":"# ScenegraphNode\n\nThe `ScenegraphNode` is a base class for objects in the luma.gl scene graph, such as `Model`, `Group` and `Camera`. It holds the transformation matrix (i.e. the position, orientation and scale) of the object.\n\n\n## Usage\n\n`ScenegraphNode` is a base class, normally only instantiated via base classes.\n\n```\nconst model = new Model();\nmodel\n  .setPosition([0, 1, 2])\n  .update();\n```\n\n\n\n## Properties\n\nA Model instance has a number of public properties that can be accessed/modified:\n\n* `position` (*object*) - A `Vector3` indicating the position of the Model.\n* `rotation` (*object*) - A `Vector3` indicating the rotation of the Model.\n* `scale` (*object*) - A `Vecto3` indicating the scaling of the Model.\n* `matrix` (*object*) - A `Matrix4` containing information about position, rotation and scale.\n\nThis matrix gets updated each time the method `update` is called on a Model instance.\n\n\n## Properties\n\n### matrix (`Number[16]`)\n\nThe model matrix of this scenegraph node.\n\n\n## Methods\n\n### constructor(props : Object)\n\n```\nvar node = new Model(gl, props);\n```\n\n\n### setProps(props: Object)\n\n* `position` (`Number[3]`) - Sets the position part of the matrix\n* `rotation` (`Number[3]`) - Sets the rotation part of the matrix\n* `scale` (`Number[3]`) - Sets the scale part of the matrix\n\n\nNote that setting orientation props does not actually update the object's matrix. `update()` must be called.\n\n\n### update() - DEPRECATED\n\nUpdate the model matrix. Useful to update changes to the `position`, `rotation` or `scale` properties.\n\n```\nnode.update();\n```\n\n\n## Remarks\n\n* Before luma.gl v7, `ScenegraphNode` was called `Object3D`.\n","slug":"docs/api-reference/core/scenegraph/scenegraph-node","title":"ScenegraphNode"},{"excerpt":"Canvas (Experimental) This document is still being written.  is a unique class that makes it possible to use filter-style image processing…","rawMarkdownBody":"# Canvas (Experimental)\n\n> This document is still being written.\n\n`Canvas` is a unique class that makes it possible to use filter-style image processing shader modules in a standard JavaScript application, without using the rest of the luma.gl API.\n\nThe `Canvas` class was inspired by the `canvas` class in the glfx API.\n\n\n## Usage\n\n\n```js\n<script src=\"glfx.js\"></script>\n<script>\n\nwindow.onload = function() {\n    // try to create a WebGL canvas (will fail if WebGL isn't supported)\n    try {\n        var canvas = fx.canvas();\n    } catch (e) {\n        alert(e);\n        return;\n    }\n\n    // convert the image to a texture\n    var image = document.getElementById('image');\n    var texture = canvas.texture(image);\n\n    // apply the ink filter\n    canvas.draw(texture).ink(0.25).update();\n\n    // replace the image with the canvas\n    image.parentNode.insertBefore(canvas, image);\n    image.parentNode.removeChild(image);\n\n    // Note: instead of swapping the <canvas> tag with the <img> tag\n    // as done above, we could have just transferred the contents of\n    // the image directly:\n    //\n    //     image.src = canvas.toDataURL('image/png');\n    //\n    // This has two disadvantages. First, it is much slower, so it\n    // would be a bad idea to do this repeatedly. If you are going\n    // to be repeatedly updating a filter it's much better to use\n    // the <canvas> tag directly. Second, this requires that the\n    // image is hosted on the same domain as the script because\n    // JavaScript has direct access to the image contents. When the\n    // two tags were swapped using the previous method, JavaScript\n    // actually doesn't have access to the image contents and this\n    // does not violate the same origin policy.\n};\n\n</script>\n<img id=\"image\" src=\"image.jpg\">\n```\n\n## Methods\n\n### Canvas Constructor\n\nvar canvas = new Canvas();\n\nBefore you can apply any filters you will need a canvas, which stores the result of the filters you apply. Canvas creation is done through `new Canvas()`, which creates and returns a new WebGL <canvas> tag with additional methods specific to glfx.js. This call will throw an error message if the browser doesn't support WebGL.\n\n### Canvas.destroy()\n\nTextures will be garbage collected eventually when they are no longer referenced, but this method will free GPU resources immediately.\n\n\n### installFiltersAsMethods(filters : Object)\n\nInstalls a map of shader filters as methods on the `Canvas` instance, as an alternative to calling them using `Canvas.filter`.\n\n### replace(node : HTMLElement)\n\n\n### setTexture(element)\n\nCreates a texture that initially stores the image from an HTML element. Notice that texture() is a method on a canvas object, which means if you want to use the same image on two canvas objects you will need two different textures, one for each canvas.\n\n* `element` - The HTML element to store in the texture, either an <img>, a <canvas>, or a <video>.\n\nThis replaces the internal contents of the canvas with the image stored in texture. All filter operations take place in a chain that starts with canvas.draw() and ends with canvas.update().\n\nLoads the image from an HTML element into the texture. This is more efficient than repeatedly creating and destroying textures.\n\nelement The HTML element to store in the texture, either an <img>, a <canvas>, or a <video>.\nDestroy Texture\n\n\n### update()\n\nUpdate Screen\n\nThis replaces the visible contents of the canvas with the internal image result. For efficiency reasons, the internal image buffers are not rendered to the screen every time a filter is applied, so you will need to call update() on your canvas after you have finished applying the filters to be able to see the result. All filter operations take place in a chain that starts with canvas.draw() and ends with canvas.update().\n\n\n### filter(shaderModule, props)\n\n### contents()\n\n### getPixelArray()\n\nGet a Uint8 array of pixel values: [r, g, b, a, r, g, b, a, ...]\nLength of the array will be width * height * 4.\n","slug":"docs/api-reference/core/multipass/canvas","title":"Canvas (Experimental)"},{"excerpt":"ProgramManager The  manages the creation and caching of programs. It allows the application to request a program based on a vertex shader…","rawMarkdownBody":"# ProgramManager\n\nThe `ProgramManager` manages the creation and caching of programs. It allows the application to request a program based on a vertex shader, fragment shader and set of defines, modules and code injections. The `ProgramManager` will return the requested program, creating it the first time, and re-using a cached version if it is requested more than once. It also allows for the definition of hook functions and module code injections to be inserted into shaders.\n\n\n## Usage\n\n```js\nconst pm = new ProgramManager(gl);\n\nconst vs = `\nattribute vec4 position;\n\nvoid main() {\n#ifdef MY_DEFINE\n  gl_Position = position;\n#else\n  gl_Position = position.wzyx;\n#endif\n}\n`;\n\nconst fs = `\nvoid main() {\n  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);\n  MY_SHADER_HOOK(gl_FragColor);\n}\n`;\n\npm.addShaderHook('fs:MY_SHADER_HOOK(inout vec4 color)');\n\npm.addModuleInjection(picking, {\n  hook: 'fs:#MY_SHADER_HOOK',\n  injection: 'color = picking_filterColor(color);',\n  order: Number.POSITIVE_INFINITY\n});\n\npm.addDefaultModule(dirlight); // Will be included in all following programs\n\nconst program1 = pm.get({vs, fs});   // Basic, no defines, only default module\nconst program2 = pm.get({vs, fs});   // Cached, same as program 1, use count 2\nconst program3 = pm.get({  // New program, with different source based on define\n  vs,\n  fs,\n  defines: {\n    MY_DEFINE: true\n  }\n});\n\nconst program4 = pm.get({  // New program, with different source based on module and its injection\n  vs,\n  fs,\n  defines: {\n    MY_DEFINE: true\n  },\n  modules: [picking]\n});\n\nconst program5 = pm.get({  // Cached, same as program 4, use count 2\n  vs,\n  fs,\n  defines: {\n    MY_DEFINE: true\n  },\n  modules: [picking]\n});\n\npm.release(program1); // Cached program still available, use count 1\npm.release(program2); // Cached program deleted\npm.release(program3); // Cached program deleted\npm.release(program4); // Cached program still available, use count 1\npm.release(program5); // Cached program deleted\n```\n\n\n## Methods\n\n### get(opts : Object) : Program\n\nGet a program that fits the parameters provided. If one is already cached, return it, otherwise create and cache a new one.\n`opts` can include the following (see `assembleShaders` for details):\n* `vs`: Base vertex shader source.\n* `fs`: Base fragment shader source.\n* `defines`: Object indicating `#define` constants to include in the shaders.\n* `modules`: Array of module objects to include in the shaders.\n* `inject`: Object of hook injections to include in the shaders.\n\n### `addDefaultModule(module: Object)`\n\nAdd a module that will automatically be added to any programs created by the program manager.\n\n### `removeDefaultModule(module: Object)`\n\nRemove a module that is automatically being added to programs created by the program manager.\n\n### `addShaderHook(hook : String, [opts : Object])`\n\nCreates a shader hook function that shader modules can injection code into. Shaders can call these functions, which will be no-ops by default. If a shader module injects code it will be executed upon the hook function call. This mechanism allows the application to create shaders that can be automatically extended by included shader modules.\n\n- `hook`: `vs:` or `fs:` followed by the name and arguments of the function, e.g. `vs:MYHOOK_func(inout vec4 value)`. Hook name without arguments\nwill also be used as the name of the shader hook\n- `opts.header` (optional): code always included at the beginning of a hook function\n- `opts.footer` (optional): code always included at the end of a hook function\n\n### `addModuleInjection(module : Object, opts : Object)`\n\nDefine a code injection for a particular hook function (defined by `addShaderHook`) and shader module. The injection code will be inserted into the hook function whenever the shader module is included.\n\n- `module`: module object for which the injection is being defined\n- `opts.hook`: the shader hook to inject into. This can be a hook function defined by `addShaderHook` or a predefined injection key (see below),\nprefixed by `vs:` for the vertex shader or `fs:` for the fragment shader.\n- `opts.injection`: the injection code\n- `opts.order` (optional): the priority with which to inject code into the shader hook. Lower priority numbers will\nbe injected first\n\n### getUniforms(program : Program) : Object\n\nReturns an object containing all the uniforms defined for the program. Returns `null` if `program` isn't managed by the `ProgramManager`.\n\n### release(program : Program)\n\nIndicate that a program is no longer in use. When all references to a program are released, the program is deleted.\n\n\n","slug":"docs/api-reference/core/resource-management/program-manager","title":"ProgramManager"},{"excerpt":"ClearPass (Experimental) Clears the output buffer. Takes the same parameters as the  call. Usage Clear the  Methods constructor(gl…","rawMarkdownBody":"# ClearPass (Experimental)\n\nClears the output buffer. Takes the same parameters as the `clear` call.\n\n## Usage\n\nClear the `outputBuffer`\n\n```\n  new ClearPass(gl)\n```\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nCreates a new `ClearPass` instance\n\n\n## Properties\n\nInherits properties from `Pass`\n\n","slug":"docs/api-reference/core/multipass/clear-pass","title":"ClearPass (Experimental)"},{"excerpt":"CompositePass (Experimental) Holds a list of render passes ( instances), possibly including other  instances. Usage Clear the  Methods…","rawMarkdownBody":"# CompositePass (Experimental)\n\nHolds a list of render passes (`Pass` instances), possibly including other `CompositePass` instances.\n\n\n## Usage\n\nClear the `outputBuffer`\n\n```\n  new CompositePass(gl)\n```\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nCreates a new `CompositePass` instance\n\n\n## Properties\n\nInherits properties from `Pass`\n\n\n### `passes`: Array (Default: `[]`)\n\nAn array of `Pass` subclass instances\n\n","slug":"docs/api-reference/core/multipass/composite-pass","title":"CompositePass (Experimental)"},{"excerpt":"CopyPass (Experimental) Copies the input buffer to the output buffer or the screen. Usage Copy output of the previous pass (the ) to the…","rawMarkdownBody":"# CopyPass (Experimental)\n\nCopies the input buffer to the output buffer or the screen.\n\n## Usage\n\nCopy output of the previous pass (the `inputBuffer`) to the screen\n\n```js\n  new CopyPass(gl, {screen: true}),\n```\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nCreates a new `CopyPass` instance\n\n\n## Properties\n\nInherits properties from `Pass`\n\n","slug":"docs/api-reference/core/multipass/copy-pass","title":"CopyPass (Experimental)"},{"excerpt":"Pass (Experimental) Base class for all render passes. Props  : Boolean (default ) Whether this pass should be executed.  : Boolean (default…","rawMarkdownBody":"# Pass (Experimental)\n\nBase class for all render passes.\n\n\n## Props\n\n\n### `enabled` : Boolean (default `true`)\n\nWhether this pass should be executed.\n\n\n### `screen` : Boolean (default: `false`)\n\nWhether this pass should render to screen.\n\n\n### `swap` : Boolean (default: `false`)\n\nSwap the frame buffers after this pass has finished rendering.\n\n","slug":"docs/api-reference/core/multipass/pass","title":"Pass (Experimental)"},{"excerpt":"ShaderModulePass (Experimental) Automatically creates a rendering pass from a compatible shader module. Look for the 'ShaderPass' badge in…","rawMarkdownBody":"# ShaderModulePass (Experimental)\n\nAutomatically creates a rendering pass from a compatible shader module. Look for the 'ShaderPass' badge in the documentation of shader modules.\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nCreates a new `ShaderModulePass` instance\n\n\n## Remarks\n\n* The created rendering pass can be a composite pass.\n","slug":"docs/api-reference/core/multipass/shader-module-pass","title":"ShaderModulePass (Experimental)"},{"excerpt":"RenderPass (Experimental) Renders a scene (list of models) Usage Clear the  Methods constructor(gl : WebGLRenderingContext, props : Object…","rawMarkdownBody":"# RenderPass (Experimental)\n\nRenders a scene (list of models)\n\n\n## Usage\n\nClear the `outputBuffer`\n\n```\n  new RenderPass(gl)\n```\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nCreates a new `ClearPass` instance\n\n\n## Properties\n\nInherits properties from `Pass`\n\n### `models` : Array (Default: `[]`)\n\nScenegraph (models) to be rendered\n","slug":"docs/api-reference/core/multipass/render-pass","title":"RenderPass (Experimental)"},{"excerpt":"PBRMaterial Implements the PBR (Physically-Based Rendering) material system specified in the core glTF standard. The metallic-roughness…","rawMarkdownBody":"# PBRMaterial\n\nImplements the PBR (Physically-Based Rendering) material system specified in the core glTF standard. The metallic-roughness material model specified in the glTF2 standard enables glTF files to be rendered consistently across platforms.\n\n> glTF extensions that influence the material model are not currently supported.\n\nReferences:\n\n* This page draws a lot of content from [glTF 2.0 Materials section](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#materials).\n\n\n## Extends Material\n\n`PBRMaterial` implements the common recommended material properties recommended in the base `Material` class.\n\n\n### Metallic-Roughness Material Model\n\nAll parameters related to the metallic-roughness material model are defined under the `pbrMetallicRoughness` property of `material` object. The following example shows how a material like gold can be defined using the metallic-roughness parameters:\n\n```json\n{\n    \"baseColor\": [ 1.000, 0.766, 0.336, 1.0 ],\n    \"metallic\": 1.0,\n    \"roughness\": 0.0,\n    \"baseColorTexture\": null,\n    \"metallicRoughnessTexture\": null,\n}\n```\n\nThe metallic-roughness material model is defined by the following properties:\n* `baseColor` - The base color of the material\n* `metallic` - The metalness of the material\n* `roughness` - The roughness of the material\n\nThe base color has two different interpretations depending on the value of metalness. When the material is a metal, the base color is the specific measured reflectance value at normal incidence (F0). For a non-metal the base color represents the reflected diffuse color of the material. In this model it is not possible to specify a F0 value for non-metals, and a linear value of 4% (0.04) is used.\n\nThe value for each property (`baseColor`, `metallic`, `roughness`) can be defined using factors or textures. The `metallic` and `roughness` properties are packed together in a single texture called `metallicRoughnessTexture`. \n\n```json\n{\n    \"pbrMetallicRoughness\": {\n        \"baseColor\": [ 0.5, 0.5, 0.5, 1.0 ],\n        \"baseColorTexture\": null,\n        \"baseColorTextureCoord\": 1,\n        \"metallic\": 1,\n        \"roughness\": 1,\n        \"metallicRoughnessTexture\": null,\n        \"metallicRoughnessTexture\": null,\n        \"metallicRoughnessTextureCoord\": 1,\n    },\n}\n```\n\nIf a texture is not given, all respective texture components within this material model are assumed to have a value of `1.0`. If both factors and textures are present the factor value acts as a linear multiplier for the corresponding texture values. The `baseColorTexture` is in sRGB space and must be converted to linear space before it is used for any computations.\n\nFor example, assume a value of `[0.9, 0.5, 0.3, 1.0]` in linear space is obtained from an RGBA `baseColorTexture`, and assume that `baseColorFactor` is given as `[0.2, 1.0, 0.7, 1.0]`.\nThen, the result would be\n```\n[0.9 * 0.2, 0.5 * 1.0, 0.3 * 0.7, 1.0 * 1.0] = [0.18, 0.5, 0.21, 1.0]\n```\n\n### Calculating Reflectance\n\nThe following equations show how to calculate bidirectional reflectance distribution function (BRDF) inputs (*c<sub>diff</sub>*, *F<sub>0</sub>*, *&alpha;*) from the metallic-roughness material properties. In addition to the material properties, if a primitive specifies a vertex color using the attribute semantic property `COLOR_0`, then this value acts as an additional linear multiplier to `baseColor`.\n\n`const dielectricSpecular = rgb(0.04, 0.04, 0.04)`\n<br>\n`const black = rgb(0, 0, 0)`\n\n*c<sub>diff</sub>* = `lerp(baseColor.rgb * (1 - dielectricSpecular.r), black, metallic)`\n<br>\n*F<sub>0</sub>* = `lerp(dieletricSpecular, baseColor.rgb, metallic)`\n<br>\n*&alpha;* = `roughness ^ 2`\n\n\n","slug":"docs/api-reference/core/materials/pbr-material","title":"PBRMaterial"},{"excerpt":"Material The  class is the base class of materials. It is recommended that all materials implemente the following properties however you…","rawMarkdownBody":"# Material\n\nThe `Material` class is the base class of materials. It is recommended that all materials implemente the following properties however you will need to check the documentation of each material:\n\n\n## Common Materials Properties\n\n| Property      | Default  | Comments |\n| ---           | ---      | ---      |\n| `doubleSided` | `false`  | |\n| `alphaMode`   | `OPAQUE` | `OPAQUE`, `MASK` OR `BLEND` |\n\n### Common Materials Maps\n\n| Property              | Default  | Comments |\n| ---                   | ---      | ---      |\n| `normalTexture`       | `null`   | |\n| `normalTextureScale`  | `1`      | |\n| `normalTextureCoords` | `1`      | |\n\n\n## Property Descriptions\n\n### Double Sided\n\nThe `doubleSided` property specifies whether the material is double sided. When this value is false, back-face culling is enabled. When this value is true, back-face culling is disabled and double sided lighting is enabled. The back-face must have its normals reversed before the lighting equation is evaluated.\n\n\n### Alpha Coverage\n\nThe `alpha` value is typically defined in the `baseColor` prop, e.g. for the for metallic-roughness material model.\n\nThe `alphaMode` property defines how the alpha value of the main factor and texture should be interpreted.\n\n`alphaMode` can be one of the following values:\n* `OPAQUE` - The rendered output is fully opaque and any alpha value is ignored.\n* `MASK` - The rendered output is either fully opaque or fully transparent depending on the alpha value and the specified alpha cutoff value. This mode is used to simulate geometry such as tree leaves or wire fences.\n* `BLEND` - The rendered output is combined with the background using the normal painting operation (i.e. the Porter and Duff over operator). This mode is used to simulate geometry such as guaze cloth or animal fur.\n\n When `alphaMode` is set to `MASK` the `alphaCutoff` property specifies the cutoff threshold. If the alpha value is greater than or equal to the `alphaCutoff` value then it is rendered as fully opaque, otherwise, it is rendered as fully transparent. `alphaCutoff` value is ignored for other modes.\n\n>**Implementation Note for Real-Time Rasterizers:** Real-time rasterizers typically use depth buffers and mesh sorting to support alpha modes. The following describe the expected behavior for these types of renderers.\n>* `OPAQUE` - A depth value is written for every pixel and mesh sorting is not required for correct output.\n>* `MASK` - A depth value is not written for a pixel that is discarded after the alpha test. A depth value is written for all other pixels. Mesh sorting is not required for correct output.\n>* `BLEND` - Support for this mode varies. There is no perfect and fast solution that works for all cases. Implementations should try to achieve the correct blending output for as many situations as possible. Whether depth value is written or whether to sort is up to the implementation. For example, implementations can discard pixels which have zero or close to zero alpha value to avoid sorting issues.\n\n\n## Common Material Maps\n\nThe material definition provides for common maps that can also be used with different material models, including the metallic-roughness material model selected by the core glTF standard.\n\n| Map       | Description                           | Rendering impact when map is not supported  |\n|---------- | ----------------------------          | ------------------------------------------- |\n| Normal    | A tangent space normal map.           | Geometry will appear less detailed than authored. |\n| Occlusion | Indicates areas of indirect lighting. | Model will appear brighter in areas that should be darker. |\n| Emissive  | Controls the color and intensity of the light being emitted by the material. | Model with lights will not be lit. For example, the headlights of a car model will be off instead of on. |\n\nEach material map has the following properties:\n\n* A texture (or sampler)\n* A scale\n* A texture coordinate set\n\n\n> **Implementation Note:** If an implementation is resource-bound and cannot support all the maps defined it will drop these optional maps from the bottom.\n","slug":"docs/api-reference/core/materials/material","title":"Material"},{"excerpt":"PhongMaterial A material class specifies reflection properties of a shiny surface, uses Blinn-Phong model for underlying implementation…","rawMarkdownBody":"# PhongMaterial\n\nA material class specifies reflection properties of a shiny surface, uses [Blinn-Phong](https://en.wikipedia.org/wiki/Blinn%E2%80%93Phong_shading_model) model for underlying implementation. \n\n\n## Usage\n\nCreate a material class\n```js\nconst phongMaterial = new PhongMaterial({\n  ambient: 0.2,\n  diffuse: 0.5,\n  shininess: 32,\n  specularColor: [255, 255, 255]\n});\n```\n\n## Methods\n\n### constructor\n\nThe constructor for the `PhongMaterial` class. Use this to create a new `PhongMaterial`.\n\n```js\nconst phongMaterial = new PhongMaterial({ambient, diffuse, shininess, specularColor});\n```\n\n* `ambient` - (*number*,) Ambient light reflection ratio, default value is `0.4`.\n* `diffuse` - (*number*) Diffuse light reflection ratio, default value is `0.6`.\n* `shininess` - (*number*) Parameter to control specular highlight radius, default value is `32`.\n* `specularColor` - (*array*) Color applied to specular lighting, default value is `[30, 30, 30]`.\n","slug":"docs/api-reference/core/materials/phong-material","title":"PhongMaterial"},{"excerpt":"AmbientLight Create an ambient light source which illuminates all the objects equally.Ambient light comes from all directions, adding…","rawMarkdownBody":"# AmbientLight\n\nCreate an ambient light source which illuminates all the objects equally.Ambient light comes from all directions, adding ambient light ensures that object colors are rendered but does not show structure in 3D objects like directional and point lights do. Only one ambient light is supported.\n\n\n## Usage\n\nCreate an ambient light source with color and intensity.\n```js\nconst ambientLight= new AmbientLight({\n  color: [128, 128, 0],\n  intensity: 2.0\n});\n```\n\n## Methods\n\n### constructor\n\nThe constructor for the `AmbientLight` class. Use this to create a new `AmbientLight`.\n\n```js\nconst ambientLight = new AmbientLight({color, intensity});\n```\n\n* `color` - (*array*,)  RGB color of ambient light source, default value is `[255, 255, 255]`.\n* `intensity` - (*number*) Strength of ambient light source, default value is `1.0`.\n","slug":"docs/api-reference/core/lights/ambient-light","title":"AmbientLight"},{"excerpt":"MultiPassRenderer (Experimental) Renders a list of render passes Usage Methods constructor(gl : WebGLRenderingContext, passes : Array…","rawMarkdownBody":"# MultiPassRenderer (Experimental)\n\nRenders a list of render passes\n\n## Usage\n\n```js\nimport {\n  _MultiPassRenderer as MultiPassRenderer,\n  _ClearPass as ClearPass,\n  _RenderPass as RenderPass,\n  _CopyPass as CopyPass\n} from '@luma.gl/core';\n\nclass AppAnimationLoop extends AnimationLoop {\n\n  onInitialize({gl}) {\n\n    this.multiPassRenderer = new MultiPassRenderer(gl, [\n      new ClearPass(gl),\n\n      new RenderPass(gl, {\n        models: [this.model]\n      }),\n\n      new ConvolutionPass(gl, {\n         kernel: ConvolutionPass.KERNEL.EMBOSS\n      }),\n\n      new CopyPass(gl, {screen: true})\n    ]);\n  }\n\n  onRender(animationProps) {\n    this.multiPassRenderer.render(this.animationProps);\n  }\n});\n```\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, passes : Array)\n\n\n### render(animationProps : Object)\n\nRenders (recursively, in case any CompositePasses are present) all the render passes.\n","slug":"docs/api-reference/core/multipass/multi-pass-renderer","title":"MultiPassRenderer (Experimental)"},{"excerpt":"DirectionalLight Create a directional light source which emits from a specific direction.A directional light can be considered \"infinitely…","rawMarkdownBody":"# DirectionalLight\n\nCreate a directional light source which emits from a specific direction.A directional light can be considered \"infinitely\" far away (like the Sun) and does not attenuate with distance. At most 5 directional lights can be supported.\n\n\n## Usage\n\nCreate a directional light source with color, intensity and direction.\n```js\nconst directionalLight= new DirectionalLight({\n  color: [128, 128, 0],\n  intensity: 2.0,\n  direction: [0, -100, -100]\n});\n```\n\n## Methods\n\n### constructor\n\nThe constructor for the `DirectionalLight` class. Use this to create a new `DirectionalLight`.\n\n```js\nconst directionalLight = new DirectionalLight({color, intensity, direction});\n```\n\n* `color` - (*array*,)  RGB color of directional light source, default value is `[255, 255, 255]`.\n* `intensity` - (*number*) Strength of directional light source, default value is `1.0`.\n* `direction` - (*array*,)  3D vector specifies the direction the light comes from, default value is `[0, 0, -1]`.\n","slug":"docs/api-reference/core/lights/directional-light","title":"DirectionalLight"},{"excerpt":"PointLight Create a point light source which emits from a point in all directions.Point lights attenuation is not available. At most…","rawMarkdownBody":"# PointLight\n\nCreate a point light source which emits from a point in all directions.Point lights attenuation is not available. At most 5 directional lights can be supported.\n\n\n## Usage\n\nCreate a point light source with color, intensity and position.\n```js\nconst pointLight= new PointLight({\n  color: [128, 128, 0],\n  intensity: 2.0,\n  position: [0, 0, 200]\n});\n```\n\n## Methods\n\n### constructor\n\nThe constructor for the `PointLight` class. Use this to create a new `PointLight`.\n\n```js\nconst pointLight = new PointLight({color, intensity, position});\n```\n#### Parameters\n\n* `color` - (*array*,)  RGB color of point light source, default value is `[255, 255, 255]`.\n* `intensity` - (*number*) Strength of point light source, default value is `1.0`.\n* `position` - (*array*,)  Location of point light source, default value is `[0, 0, 1]`.\n* `attenuation` - (*array*,)  Attenuation of point light source based on distance.\nIn order of Constant, Linear, Exponential components.\nFor details see [this tutorial](http://ogldev.atspace.co.uk/www/tutorial20/tutorial20.html).\nUse `[1, 0, 0]` for no attenuation. Default value is `[0, 0, 1]`.\n","slug":"docs/api-reference/core/lights/point-light","title":"PointLight"},{"excerpt":"Cone Creates a cone geometry. The generated geometry will have  and ,  and  attributes. Usage Create a  of base radius 2 and height…","rawMarkdownBody":"# Cone\n\nCreates a cone geometry.\n\nThe generated geometry will have `indices` and `POSITION`, `NORMAL` and `TEXCOORD_0` attributes.\n\n## Usage\n\nCreate a `Cone` of base radius 2 and height 3.\n```js\nimport {Cone} from '@luma.gl/core';\nconst cone = new Cone({\n  radius: 2,\n  height: 3,\n  cap: true\n});\n```\n\n## Inheritance\n\n`Cone` extends [`Geometry`](/docs/api-reference/core/geometry.md).\n\n## Methods\n\n### constructor(props : Object)\n\nThe constructor for the Cone class. Use this to create a new Cone.\n\n- `props.radius` (*number*): The radius of the base of the cone.\n- `props.cap`=`false` (*boolean*, optional): Whether to put the cap on the base of the cone.\n- `props.nradial`=`10` (*number*): Number of vertices used to create the disk for a given height.\n- `props.nvertical`=`10` (*number*): Number of vertices for the height.\n","slug":"docs/api-reference/core/geometries/cone-geometry","title":"Cone"},{"excerpt":"Cube Create a cube geometry. The generated geometry will have  and ,  and  attributes. Usage Inheritance  extends  Methods constructor(props…","rawMarkdownBody":"# Cube\n\nCreate a cube geometry.\n\nThe generated geometry will have `indices` and `POSITION`, `NORMAL` and `TEXCOORD_0` attributes.\n\n## Usage\n\n```js\nimport {Cube} from '@luma.gl/core';\nconst cube = new Cube();\n```\n\n## Inheritance\n\n`CubeGeometry` extends [`Geometry`](/docs/api-reference/core/geometry.md)\n\n## Methods\n\n### constructor(props : Object)\n\nCreates a new Cube.\n","slug":"docs/api-reference/core/geometries/cube-geometry","title":"Cube"},{"excerpt":"Cylinder Creates a cylinder geometry. The generated geometry will have  and ,  and  attributes. Usage Create a white Cylinder of radius…","rawMarkdownBody":"# Cylinder\n\nCreates a cylinder geometry.\n\nThe generated geometry will have `indices` and `POSITION`, `NORMAL` and `TEXCOORD_0` attributes.\n\n## Usage\n\nCreate a white Cylinder of radius 2 and height 3.\n\n```js\nimport {Cylinder} from '@luma.gl/core';\nconst cylinder = new Cylinder({\n  radius: 2,\n  height: 3\n});\n```\n\n## Inheritance\n\n`CylinderGeometry` extends [`Geometry`](/docs/api-reference/core/geometry.md)\n\n## Methods\n\n### constructor(props : Object)\n\nThe constructor for the Cylinder class. Use this to create a new Cylinder.\n\n* `props.height`= - (*number*) The height of the cylinder.\n* `props.radius`= - (*number*) The radius of the cylinder.\n* `props.nradial`=`10` - (*number*) The number of vertices for the disk.\n* `props.nvertical`=`10` - (*number*) The number of vertices for the height.\n* `props.verticalAxis`=`y` - (*string*) The axis along which the height is measured. One of `x`, `y`, `z`.\n* `props.topCap`=`false` - (*boolean*) Whether to put the cap on the top of the cylinder.\n* `props.bottomCap`=`false` - (*boolean*) Whether to put the cap on the bottom\n  part of the cylinder.\n","slug":"docs/api-reference/core/geometries/cylinder-geometry","title":"Cylinder"},{"excerpt":"IcoSphere Creates a sphere geometry by subdividing an Icosahedron. The generated geometry will have  and ,  and  attributes. Usage Create an…","rawMarkdownBody":"# IcoSphere\n\nCreates a sphere geometry by subdividing an Icosahedron.\n\nThe generated geometry will have `indices` and `POSITION`, `NORMAL` and `TEXCOORD_0` attributes.\n\n## Usage\n\nCreate an IcoSphere of radius 1\n\n```js\nimport {IcoSphere} from '@luma.gl/core';\nconst sphere = new IcoSphere({\n  iterations: 1\n});\n```\n\n## Inheritance\n\n`IcoSphereGeometry` extends [`Geometry`](/docs/api-reference/core/geometry.md)\n\n## Methods\n\n### constructor(props : Object)\n\nThe constructor for the IcoSphere class. Use this to create a new IcoSphere.\n\n* `props.iterations`=`0` - (*number*) The number of iterations used to subdivide the Icosahedron.\n","slug":"docs/api-reference/core/geometries/ico-sphere-geometry","title":"IcoSphere"},{"excerpt":"Plane Creates a plane geometry. The generated geometry will have  and ,  and  attributes. Usage Create a XZ plane. Inheritance  extends…","rawMarkdownBody":"# Plane\n\nCreates a plane geometry.\n\nThe generated geometry will have `indices` and `POSITION`, `NORMAL` and `TEXCOORD_0` attributes.\n\n## Usage\n\nCreate a XZ plane.\n```js\nimport {Plane} from '@luma.gl/core';\nconst plane = new Plane({\n  type: 'x,z',\n  xlen: 10,\n  zlen: 20,\n  nx: 5,\n  nz: 5,\n  offset: 0\n});\n```\n\n## Inheritance\n\n`PlaneGeometry` extends [`Geometry`](/docs/api-reference/core/geometry.md)\n\n## Methods\n\n### constructor(props : Object)\n\nThe constructor for the Plane class. Use this to create a new Plane.\n\n* `props.type` - (*string*) Whether is a XY, YZ or XZ plane. Possible values are `x,y`, `x,z`, `y,z`.\n* `props.xlen` - (*number*) The length along the x-axis. Only used in `x,z` or `x,y` planes.\n* `props.ylen` - (*number*) The length along the y-axis. Only used in `y,z` or `x,y` planes.\n* `props.zlen` - (*number*) The length along the z-axis. Only used in `x,z` or `y,z` planes.\n* `props.nx` - (*number*) The number of subdivisions along the x-axis. Only used in `x,z` or `x,y` planes.\n* `props.ny` - (*number*) The number of subdivisions along the y-axis. Only used in `y,z` or `x,y` planes.\n* `props.nz` - (*number*) The number of subdivisions along the z-axis. Only used in `x,z` or `y,z` planes.\n* `props.offset` - (*number*) For XZ planes, the offset along the y-axis. For XY planes, the offset along the z-axis. For YZ planes, the offset along the x-axis.\n","slug":"docs/api-reference/core/geometries/plane-geometry","title":"Plane"},{"excerpt":"SphereGeometry Creates a sphere geometry. The generated geometry will have  and ,  and  attributes. Usage Create a white SphereGeometry of…","rawMarkdownBody":"# SphereGeometry\n\nCreates a sphere geometry.\n\nThe generated geometry will have `indices` and `POSITION`, `NORMAL` and `TEXCOORD_0` attributes.\n\n## Usage\n\nCreate a white SphereGeometry of radius 2\n\n```js\nimport {SphereGeometry} from '@luma.gl/core';\nconst sphere = new SphereGeometry({\n  radius: 2\n});\n```\n\n## Inheritance\n\n`SphereGeometry` extends [`Geometry`](/docs/api-reference/core/geometry.md)\n\n## Methods\n\n### constructor(props : Object)\n\nThe constructor for the SphereGeometry class. Use this to create a new SphereGeometry.\n\n* `props.nlat`=`10` - (*number*, optional) The number of vertices for latitude.\n* `props.nlong`=`10` - (*number*, optional) The number of vertices for longitude.\n* `props.radius`=`1` - (*number*, optional) The radius of the sphere.\n","slug":"docs/api-reference/core/geometries/sphere-geometry","title":"SphereGeometry"},{"excerpt":"Geometry Holds a geometric primitive. While the  class itself is WebGL-independent and essentially a \"mathematical\" description of a…","rawMarkdownBody":"# Geometry\n\nHolds a geometric primitive.\n\nWhile the `Geometry` class itself is WebGL-independent and essentially a \"mathematical\" description of a geometrric primitive, it contains all the information needed to create WebGL `Buffers` and render the geometry.\n\n\n## Static Fields\n\n### Geometry.MODE\n\nCorresponds to the WebGL draw mode constants.\n\n| Primitive Mode   | Comment                |\n| ---              | ---  |\n| `Geometry.MODE.POINTS`          | - |\n| `Geometry.MODE.LINES`          | - |\n| `Geometry.MODE.LINE_LOOP`      | - |\n| `Geometry.MODE.LINE_STRIP`     | - |\n| `Geometry.MODE.TRIANGLES`      | - |\n| `Geometry.MODE.TRIANGLE_STRIP` | - |\n| `Geometry.MODE.TRIANGLE_FAN`   | - |\n\n\n## Fields\n\n### id : String\n\nString id, mainly intended for debugging.\n\n### mode : Number\n\nDescribes how primitives are to be read from the vertex arrays. Will be a A valid WebGL draw mode, one of the\n`Geometry.MODE` constants.\n\n\n### drawMode : Number\n\nReturns same value as `mode`.\n\n\n### attributes : Object\n\nReturns an object map with attribute names as keys and attribute accessor objects as values.\n\nEach accessor object will have at minimum:\n* A `value` field that is a typed array\n* A `size` field that indicates how many components per vertex.\n\n### indices : Object | undefined\n\nIf present, the `indices` will be an object that at minimum has:\n* A `value` field that is a typed array, either `Uint32Array` or `Uint16Array`\n* A `size` field that is always `1`.\n\n### vertexCount\n\nThe number of vertices. If `instances` are present, this is the length of the instance array. Otherwise it is determined by vertex array and size.\n\n\n## Functions\n\n### constructor(props : Object)\n\n- `props.mode` (Number): The draw mode, one of the `Geometry.MODE` constants.\n- `props.drawMode` (Number): Alternative to `props.mode`, only one of them should be specified.\n- `props.vertexCount`= (Number): Optionally sets the number of vertices to draw.\n- `props.attributes` (Object): Map of attribute names to accessor objects.\n- `props.indices`= (Object | undefined): If supplied, an accessor object for the indices array.\n\n","slug":"docs/api-reference/core/base/geometry","title":"Geometry"},{"excerpt":"CameraNode Holds a projection matrix that is positioned in a scenegraph so that it can follow parent transformations. Inherits from . Fields…","rawMarkdownBody":"# CameraNode\n\nHolds a projection matrix that is positioned in a scenegraph so that it can follow parent transformations.\n\nInherits from `ScenegraphNode`.\n\n## Fields\n\n### projectionMatrix\n\n\n## Methods\n\n### constructor(props : Object)\n\nCreates a new `Camera` instance.\n\n* `props` - See `Camera.setProps` for valid props.\n\n\n### setProps(props: Object)\n\n* `props.projectionMatrix`\n\nSee `ScenegraphNode.setProps` for additional valid props.\n","slug":"docs/api-reference/core/scenegraph/wip/camera-node","title":"CameraNode"},{"excerpt":"MeshNode A  instance holds an arrays of  primitives. A  is typically used to to create a composite geometry. Splitting one mesh into…","rawMarkdownBody":"# MeshNode\n\nA `MeshNode` instance holds an arrays of `Geometry` primitives. A `MeshNode` is typically used to to create a composite geometry.\n\n\n* Splitting one mesh into primitives could be useful to limit number of indices per draw call.\n\n\n\n\n## Properties\n\n### primitives : Primitives[]\n\nList of primitives (`Geometry` instances) in this mesh. Note that a primitive can be used in more than one mesh.\n\n\n## Methods\n\n\n### constructor(props : Object)\n\nThe constructor for the `MeshNode` class. Use this to create a new `MeshNode`.\n\n```js\nconst geometry = new MeshNode({primitives: ...});\n```\n\n\n### setProps(props : Object)\n\nUpdates the specified properties.\n\n\n\n## Remarks\n\n* The `MeshNode` class is modeled after the [glTF 2.0 mesh](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#meshes), but does not yet support morph `weights`.\n\n","slug":"docs/api-reference/core/scenegraph/wip/mesh-node","title":"MeshNode"},{"excerpt":"Cone A scenegraph model node with a . Usage Create a cone of base radius 2 and height 3. Inheritance  extends  extends  Methods constructor…","rawMarkdownBody":"# Cone\n\nA scenegraph model node with a [`ConeGeometry`](/docs/api-reference/core/geometries/cone-geometry).\n\n## Usage\n\nCreate a cone of base radius 2 and height 3.\n```js\nimport {Cone} from '@luma.gl/core';\nconst cone = new Cone(gl, {\n  radius: 2,\n  height: 3,\n  cap: true\n});\n```\n\n## Inheritance\n\n`Cone` extends [`ModelNode`](/docs/api-reference/core/scenegraph/model-node.md) extends [`ScenegraphNode`](/docs/api-reference/core/scenegraph/scenegraph-node.md)\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nThe constructor for the Cone class. Use this to create a new Cone.\n\n* `props.nradial` - (*number*, optional) The number of vertices used to create the disk for a given height. Default's 10.\n* `props.nvertical` - (*number*, optional) The number of vertices for the height. Default's 10.\n* `props.radius` - (*number*) The radius of the base of the cone.\n* `props.cap` - (*boolean*, optional) Whether to put the cap on the base of the cone. Default's false.\n","slug":"docs/api-reference/core/scenegraph/geometries/cone","title":"Cone"},{"excerpt":"Cube A scenegraph model node with a . Usage Create a : Inheritance  extends  extends  Methods constructor(gl : WebGLRenderingContext, props…","rawMarkdownBody":"# Cube\n\nA scenegraph model node with a [`CubeGeometry`](/docs/api-reference/core/geometries/cube-geometry).\n\n## Usage\n\nCreate a `Cube`:\n\n```js\nimport {Cube} from '@luma.gl/core';\nconst cube = new Cube(gl);\n```\n\n## Inheritance\n\n`Cube` extends [`ModelNode`](/docs/api-reference/core/scenegraph/model-node.md) extends [`ScenegraphNode`](/docs/api-reference/core/scenegraph/scenegraph-node.md)\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nCreates a new Cube.\n\nAccepts the same properties and options as `ModelNode` constructor but has preset for `vertices`, `normals` and `indices`.\n","slug":"docs/api-reference/core/scenegraph/geometries/cube","title":"Cube"},{"excerpt":"Cylinder A scenegraph model node with a . Usage Create a white Cylinder of radius 2 and height 3. Inheritance  extends  extends  Methods…","rawMarkdownBody":"# Cylinder\n\nA scenegraph model node with a [`CylinderGeometry`](/docs/api-reference/core/geometries/cube-geometry).\n\n\n## Usage\n\nCreate a white Cylinder of radius 2 and height 3.\n\n```js\nimport {Cylinder} from '@luma.gl/core';\nconst cylinder = new Cylinder(gl, {\n  radius: 2,\n  height: 3\n});\n```\n\n## Inheritance\n\n`Cylinder` extends [`ModelNode`](/docs/api-reference/core/scenegraph/model-node.md) extends [`ScenegraphNode`](/docs/api-reference/core/scenegraph/scenegraph-node.md)\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nThe constructor for the Cylinder class. Use this to create a new Cylinder.\n\n* `props.height`= - (*number*) The height of the cylinder.\n* `props.radius`= - (*number*) The radius of the cylinder.\n* `props.nradial`=`10` - (*number*) The number of vertices for the disk.\n* `props.nvertical`=`10` - (*number*) The number of vertices for the height.\n* `props.verticalAxis`=`y` - (*string*) The axis along which the height is measured. One of `x`, `y`, `z`.\n* `props.topCap`=`false` - (*boolean*) Whether to put the cap on the top of the cylinder.\n* `props.bottomCap`=`false` - (*boolean*) Whether to put the cap on the bottom\n  part of the cylinder.\n","slug":"docs/api-reference/core/scenegraph/geometries/cylinder","title":"Cylinder"},{"excerpt":"IcoSphere A scenegraph model node with an . Usage Create a white IcoSphere of radius 1. Inheritance  extends  extends  Methods constructor…","rawMarkdownBody":"# IcoSphere\n\nA scenegraph model node with an [`IcoSphereGeometry`](/docs/api-reference/core/geometries/cube-geometry).\n\n## Usage\n\nCreate a white IcoSphere of radius 1.\n\n```js\nimport {IcoSphere} from '@luma.gl/core';\nconst sphere = new IcoSphere(gl, {\n  iterations: 1\n});\n```\n\n## Inheritance\n\n`IcoSphere` extends [`ModelNode`](/docs/api-reference/core/scenegraph/model-node.md) extends [`ScenegraphNode`](/docs/api-reference/core/scenegraph/scenegraph-node.md)\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nThe constructor for the IcoSphere class. Use this to create a new IcoSphere.\n\n* `props.iterations`=`0` - (*number*) The number of iterations used to subdivide the Icosahedron.\n","slug":"docs/api-reference/core/scenegraph/geometries/ico-sphere","title":"IcoSphere"},{"excerpt":"Plane A scenegraph model node with an . Usage Create a white XZ plane. Inheritance  extends  extends  Methods constructor(gl…","rawMarkdownBody":"# Plane\n\nA scenegraph model node with an [`PlaneGeometry`](/docs/api-reference/core/geometries/cube-geometry).\n\n## Usage\n\nCreate a white XZ plane.\n```js\nimport {Plane} from '@luma.gl/core';\nconst plane = new Plane(gl, {\n  type: 'x,z',\n  xlen: 10,\n  zlen: 20,\n  nx: 5,\n  nz: 5,\n  offset: 0\n});\n```\n\n## Inheritance\n\n`Plane` extends [`ModelNode`](/docs/api-reference/core/scenegraph/model-node.md) extends [`ScenegraphNode`](/docs/api-reference/core/scenegraph/scenegraph-node.md)\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nThe constructor for the Plane class. Use this to create a new Plane.\n\n* `props.type` - (*string*) Whether is a XY, YZ or XZ plane. Possible values are `x,y`, `x,z`, `y,z`.\n* `props.xlen` - (*number*) The length along the x-axis. Only used in `x,z` or `x,y` planes.\n* `props.ylen` - (*number*) The length along the y-axis. Only used in `y,z` or `x,y` planes.\n* `props.zlen` - (*number*) The length along the z-axis. Only used in `x,z` or `y,z` planes.\n* `props.nx` - (*number*) The number of subdivisions along the x-axis. Only used in `x,z` or `x,y` planes.\n* `props.ny` - (*number*) The number of subdivisions along the y-axis. Only used in `y,z` or `x,y` planes.\n* `props.nz` - (*number*) The number of subdivisions along the z-axis. Only used in `x,z` or `y,z` planes.\n* `props.offset` - (*number*) For XZ planes, the offset along the y-axis. For XY planes, the offset along the z-axis. For YZ planes, the offset along the x-axis.\n","slug":"docs/api-reference/core/scenegraph/geometries/plane","title":"Plane"},{"excerpt":"Sphere A scenegraph model node with an . Usage Create a white Sphere of radius 2 Inheritance  extends  extends  Methods constructor(gl…","rawMarkdownBody":"# Sphere\n\nA scenegraph model node with an [`SphereGeometry`](/docs/api-reference/core/geometries/cube-geometry).\n\n## Usage\n\nCreate a white Sphere of radius 2\n\n```js\nimport {Sphere} from '@luma.gl/core';\nconst sphere = new Sphere(gl, {\n  radius: 2\n});\n```\n\n## Inheritance\n\n`Sphere` extends [`ModelNode`](/docs/api-reference/core/scenegraph/model-node.md) extends [`ScenegraphNode`](/docs/api-reference/core/scenegraph/scenegraph-node.md)\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nThe constructor for the Sphere class. Use this to create a new Sphere.\n\n* `props.nlat`=`10` - (*number*, optional) The number of vertices for latitude.\n* `props.nlong`=`10` - (*number*, optional) The number of vertices for longitude.\n* `props.radius`=`1` - (*number*, optional) The radius of the sphere.\n","slug":"docs/api-reference/core/scenegraph/geometries/sphere","title":"Sphere"},{"excerpt":"Attributes Attributes (aka \"vertex attributes\") are used to specify the data that the GPU should work on. Attributes contain input data to…","rawMarkdownBody":"# Attributes\n\nAttributes (aka \"vertex attributes\") are used to specify the data that the GPU should work on. Attributes contain input data to the the first shader stage in the GPU rendering pipeline (aka the vertex shader). Attributes are the main mechanism through which the application feeds data to the GPU.\n\nTo help apps set up and manage attributes, luma.gl provides the `VertexArray` class (which manages a WebGL `VertexArrayObject`).\n\nReferences:\n\n* [OpenGL Wiki: Vertex Specification](https://www.khronos.org/opengl/wiki/Vertex_Specification) - Detailed technical information about how vertex attributes are handled by OpenGL. Not suitable for beginners, but worth a read if you want a deeper understanding of what is going on.\n* [OpenGL Wiki: Vertex Specification Best Practices](https://www.khronos.org/opengl/wiki/Vertex_Specification_Best_Practices) - An easier read, worthwhile if you are thinking about making changes to your vertex attributes to increase performance performance.\n\n\n## Overview\n\n### VertexArrays\n\nTo provide data to the GPU, the program need to set up one or more \"attributes\" (the exact number depends on how many attributes the vertex shader program is using). These vertex attributes are stored in a luma.gl `VertexArray` instance.\n\nA `VertexArray` can be thought of as a small conceptual array (typically around 16 entries long) referenced by indices (aka \"locations\") from 0 and up, where each location contains one attribute.\n\nEach attribute is a an array of numbers stored in GPU Memory (together with some metadata describing how the GPU should access that memory).\n\n\n### Attribute Properties and Accessors\n\nApart from the data that will be accessible in shaders, a `VertexArray` manages the following properties for each attribute:\n\n- Data type information: `size` (1-4 values per vertex), `type`\n- Data layout information: `offset`, `stride`.\n- An instance `divisor` (which enables/disables instancing) **WebGL2/Extension**.\n- An integer normalization policy (see below).\n- An integer conversion policy (see below) **WebGL2**.\n\n\n### Attribute Locations\n\nMethods in this class take a `location` index to specify which vertex attribute in the array they are operating on. This location needs to be matched with the location (i.e. index) selected by the compiler when compiling a Shader. Therefore it is usually better to work with symbolic names for vertex attributes, which is supported by other luma.gl classes.\n\n\n### Using Program Metadata\n\nAfter a `Program` compiles and links its shaders, it extracts information about which attributes, uniforms etc were found in the shader, which locations these were mapped to, and information about data types etc based on the declarations in the shader code.\n\nThis information can be used by the `VertexArray` class and enables applications to specify attributes in a symbolic way, rather than referring to locations by numbers.\n\n```js\nconst program = new Program(gl, {vs, fs});\nconst vertexAttribute = new VertexAttribute(gl, {program}); // Reads attribute metadata from program\nvertexAttribute.setAttributes({color: ...}); // Now possible to reference attributes by name\n```\n\n\n### Buffer Attributes\n\nThe \"standard\" use case is to allocate on buffer per attribute:\n\n```js\nvertexArray.setAttributes({\n  positions: new Buffer(gl, {...}),\n  colors: new Buffer({offset: BUFFER2_START, ...})\n});\n```\n\n### Constant Attributes\n\nluma.gl provides extensive support for [constant attributes](https://www.khronos.org/opengl/wiki/Vertex_Specification#Non-array_attribute_values).\n\n```js\nvertexArray.setAttributes({\n  colors: new Uint8Array([1, 0, 0, 1])\n});\n```\n\nRemarks:\n\n* The term \"constant attribute\" is luma.gl-specific. WebGL/OpenGL literature usually talks about \"disabled\" attributes, or \"non-array\" attributes.\n* Constant attributes are not considered a high-priority use case by OpenGL GPU driver developers, so using constants may not be faster than using buffers, and native OpenGL apps are  sometimes recommended to avoid them, e.g. by creating \"dummy\" buffers with repeated constants.\n* However, in WebGL applications, the tradeoffs are different. The cost of allocating and populating big arrays using JavaScript on the CPU is higher and typically worth avoiding, even if this comes at some cost in GPU rendering speed, and memory savings are also more valuable in browser environments.\n\n\n### Attributes as Views into Buffers\n\nBy working with offsets, it is possible to have several attributes reference different memory areas in a single buffer. To make this work, set several attributes to the same buffer, with different metadata/accessor information for each.\n\n```js\nconst largeBuffer = new Buffer(gl, ...);\nconst BUFFER1_START = 0;\nconst BUFFER1_START = 100;\n\nvertexArray.setAttributes({\n  positions: [largeBuffer, new Accessor({offset: BUFFER1_START, ...})],\n  colors: [largeBuffer, new Accessor({offset: BUFFER2_START, ...})]\n});\n```\n\n### Interleaving Data\n\nBy working with strides and offsets you can \"interleave\" several attributes in a single buffer.\n\n| position1 | color1  | position2 | color2  | position3 | color3  |\n| ---       | ---     | ---       | ---     | ---       | ---     |\n| [x,y,z]   | [r,g,b] | [x,y,z]   | [r,g,b] | [x,y,z]   | [r,g,b] |\n\n```js\nconst interleavedBuffer = new Buffer(gl, ...);\nconst STRIDE = 3 * 4 + 3 * 1; // 3 floats (x,y,z) and 3 bytes (r,g,b)\nconst COLOR_OFFSET = 3 * 4; // 3 floats (x,y,z)\n\nvertexArray.setAttributes({\n  positions: [interleavedBuffer, new Accessor({stride: STRIDE, offset: 0, ...})],\n  colors: [interleavedBuffer, new Accessor({stride: STRIDE, offset: COLOR_OFFSET, ...})]\n});\n```\n\nNote: The performance gains of interleaving data will vary between GPUs. On modern desktop GPUs the difference may be small enough (or even slightly negative) such that the additional complexity is not justified. However, the gains might be more noticeable on less powerful platforms (e.g. mobile or older GPUs) and therefore still worthwhile overall. Profiling is recommended.\n\n\n### Instanced Attributes\n\nAttributes can be instanced by adding a divisor to the accessor\n\n\n### Streaming Attributes\n\nSpecial techniques like double buffering, \"nulling\", etc can be applied to improve performance when frequently updating (\"streaming\") attributes. See references above.\n\n\n### Integer to Float Conversion and Normalization\n\nInteger values in attributes (e.g in an `Int32Array`) are converted to floats before being passed to the shader.\n\nIn addition, normalization, maps values stored in an integer format to a normalized floating point range before they are passed to the shader:\n* `[-1,1]` (SNORM, for signed integers)\n* `[0,1]` (UNORM, for unsigned integers)\n\nIn WebGL2, it is possible to disable automatic conversion of integers to integers, enabling shaders to work directly with integer values. This works with all the integer types: `gl.BYTE`, `gl.UNSIGNED_BYTE`, `gl.SHORT`, `gl.UNSIGNED_SHORT`, `gl.INT` and `gl.UNSIGNED_INT`.\n\n\n### Transform Feedback\n\n For transform feedback operations, the `TransformFeedback` class holds the output buffers that will receive data from vertex shader varyings, complementing the `VertexArray` class which holds the input values. It is worth noting that the `TransformFeedback` class is quite similar to the `VertexArray` class in concept and API, they both read metadata from `Program` instances, etc.\n\n\n## Background: How the GPU Accesses Attributes\n\nGPUs shaders perform parallel processing on \"vertices\", and one \"value\" in each attribute is made available to the particular shader invocation that processes the corresponding \"vertex\".\n\nAt the start of shader execution, these indices (or 'locations') are matched with small integer indices assigned to shader attributes during shader compilation and program linking. This makes the data the application has set up in the vertex attributes available during shader execution. Vertex attributes thus represent one of the primary mechanisms for communication between JavaScript code and GPU code (GLSL shaders).\n\n* Attributes contains the data for each vertex, i.e. each GPU call.\n* Attributes are typically backed by a [`WebGLBuffer`](/docs/api-reference/webgl/buffer.md) that stores unique values for each vertex/instance, combined with information about the layout of data in the memory managed by the buffer.\n* Attributes can also be set to a single \"constant\" vertex value instead of a full buffer/array. This single value will then be passed to every invocation of the vertex shader effectively representing a constant attribute value. A typical example could be to specify a single color for all vertices, instead of providing a buffer with unique colors per vertex.\n\n\n## Remarks\n\nThere are a suprising number of API complications and \"gotchas\" when using WebGL VertexArrayObjects. The various issues and version differences described here are handled by the luma.gl `VertexArray` API.\n\n* Constant attributes: In raw WebGL, constant values are stored on the WebGL context, not the `VertexArrayObject`. Also these \"global\" values are reset every time a vertex attribute is enabled (set to a buffer). luma.gl transparently works around this by updating the constants on the WebGLRenderingContext every time a `VertexArray` is bound.\n* Constant attributes: Attribute location 0 cannot be set to a constant (i.e. cannot be disabled) in desktop OpenGL and in some desktop browsers (notably desktop Safari) this limitation also affects WebGL. In these cases, luma.gl transparently works around this issue by creating a buffer with the constant value repeated.\n\n* WebGL2: The raw WebGL APIs for `WebGLVertexArray`s are exposed differently in the WebGL1 extension and WebGL2. As always, the luma.gl `VertexArray` class transparently handles the necessary API detection and selection.\n* `ANGLE_instanced_arrays`: This extension allows instance divisors to be set, enabling instanced rendering under WebGL1.\n* **`OES_VertexArray` Extension** Enables the application to create and \"VertexArray\"s to save and restore the entire global vertex attribute array with a single operation.\n\n\n### WebGL2\n\n* Setting instance divisors no longer requires a WebGL extension.\n* `VertexArrays` no longer require using a WebGL extension.\n* Adds support for exposing integer attribute values directly to shaders (without those values first being auto-converted to floats) The improvements cover both constant and buffer-valued attributes.\n","slug":"docs/developer-guide/attributes","title":"Attributes"},{"excerpt":"Materials References: This page draws a lot of content from glTF 2.0 Materials section. Concepts Material Models The material system can…","rawMarkdownBody":"# Materials\n\nReferences:\n\n* This page draws a lot of content from [glTF 2.0 Materials section](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#materials).\n\n\n## Concepts\n\n## Material Models\n\nThe material system can support different material models (shader stacks). The core glTF standard uses the metallic-roughness material model, but others can also be used, programmatically or via glTF extensions.\n\n\n### Default Material\n\nThe default material, used when a mesh does not specify a material, is defined to be a material with no properties specified. All the default values of [`material`](#reference-material) apply. Note that this material does not emit light and will be black unless some lighting is present in the scene.\n\n\n### Point and Line Materials\n\nThe glTF specification does not define size and style of non-triangular primitives (such as POINTS or LINES). However, the following recommendations are provided for consistency:\n\n* POINTS and LINES should have widths of 1px in viewport space.\n* For LINES with `NORMAL` and `TANGENT` properties, render with standard lighting including normal maps.\n* For POINTS or LINES with no `TANGENT` property, render with standard lighting but ignore any normal maps on the material.\n* For POINTS or LINES with no `NORMAL` property, don't calculate lighting and instead output the `COLOR` value for each pixel drawn.\n\n\n## Common Materials Properties\n\n### Double Sided\n\nThe `doubleSided` property specifies whether the material is double sided. When this value is false, back-face culling is enabled. When this value is true, back-face culling is disabled and double sided lighting is enabled. The back-face must have its normals reversed before the lighting equation is evaluated.\n\n\n### Alpha Coverage\n\nThe `alpha` value is typically defined in the `baseColor` prop, e.g. for the for metallic-roughness material model.\n\nThe `alphaMode` property defines how the alpha value of the main factor and texture should be interpreted.\n\n`alphaMode` can be one of the following values:\n* `OPAQUE` - The rendered output is fully opaque and any alpha value is ignored.\n* `MASK` - The rendered output is either fully opaque or fully transparent depending on the alpha value and the specified alpha cutoff value. This mode is used to simulate geometry such as tree leaves or wire fences.\n* `BLEND` - The rendered output is combined with the background using the normal painting operation (i.e. the Porter and Duff over operator). This mode is used to simulate geometry such as guaze cloth or animal fur.\n\n When `alphaMode` is set to `MASK` the `alphaCutoff` property specifies the cutoff threshold. If the alpha value is greater than or equal to the `alphaCutoff` value then it is rendered as fully opaque, otherwise, it is rendered as fully transparent. `alphaCutoff` value is ignored for other modes.\n\n>**Implementation Note for Real-Time Rasterizers:** Real-time rasterizers typically use depth buffers and mesh sorting to support alpha modes. The following describe the expected behavior for these types of renderers.\n>* `OPAQUE` - A depth value is written for every pixel and mesh sorting is not required for correct output.\n>* `MASK` - A depth value is not written for a pixel that is discarded after the alpha test. A depth value is written for all other pixels. Mesh sorting is not required for correct output.\n>* `BLEND` - Support for this mode varies. There is no perfect and fast solution that works for all cases. Implementations should try to achieve the correct blending output for as many situations as possible. Whether depth value is written or whether to sort is up to the implementation. For example, implementations can discard pixels which have zero or close to zero alpha value to avoid sorting issues.\n\n\n\n## Common Material Maps\n\nMaterial maps have the following properties:\n\n* A texture (or sampler)\n* A scale\n* A texture coordinate set\n\n\n### Common Material Maps\n\nThe material definition provides for common maps that can also be used with different material models, including the metallic-roughness material model selected by the core glTF standard.\n\n| Map       | Description                           | Rendering impact when map is not supported  |\n|---------- | ----------------------------          | ------------------------------------------- |\n| Normal    | A tangent space normal map.           | Geometry will appear less detailed than authored. |\n| Occlusion | Indicates areas of indirect lighting. | Model will appear brighter in areas that should be darker. |\n| Emissive  | Controls the color and intensity of the light being emitted by the material. | Model with lights will not be lit. For example, the headlights of a car model will be off instead of on. |\n\n> **Implementation Note:** If an implementation is resource-bound and cannot support all the maps defined it will drop these optional maps from the bottom.\n\n\nThe following examples shows how a normal mao can be added to a material:\n\n```json\n{\n    \"normalTexture\": null,\n    \"normalTextureScale\": 2,\n    \"normalTextureCoords\": 1\n}\n```\n\n\n### Metallic-Roughness Material Model\n\nThe metallic-roughness material model specified in the glTF 2 standard enables glTF files to be rendered consistently across platforms.\n\nAll parameters related to the metallic-roughness material model are defined under the `pbrMetallicRoughness` property of `material` object. The following example shows how a material like gold can be defined using the metallic-roughness parameters:\n\n```json\n{\n    \"baseColor\": [ 1.000, 0.766, 0.336, 1.0 ],\n    \"metallic\": 1.0,\n    \"roughness\": 0.0,\n    \"baseColorTexture\": null,\n    \"metallicRoughnessTexture\": null,\n}\n```\n\n\nThe metallic-roughness material model is defined by the following properties:\n* `baseColor` - The base color of the material\n* `metallic` - The metalness of the material\n* `roughness` - The roughness of the material\n\nThe base color has two different interpretations depending on the value of metalness. When the material is a metal, the base color is the specific measured reflectance value at normal incidence (F0). For a non-metal the base color represents the reflected diffuse color of the material. In this model it is not possible to specify a F0 value for non-metals, and a linear value of 4% (0.04) is used.\n\nThe value for each property (`baseColor`, `metallic`, `roughness`) can be defined using factors or textures. The `metallic` and `roughness` properties are packed together in a single texture called `metallicRoughnessTexture`. \n\n```json\n{\n    \"pbrMetallicRoughness\": {\n        \"baseColor\": [ 0.5, 0.5, 0.5, 1.0 ],\n        \"baseColorTexture\": null,\n        \"baseColorTextureCoord\": 1,\n        \"metallic\": 1,\n        \"roughness\": 1,\n        \"metallicRoughnessTexture\": null,\n        \"metallicRoughnessTexture\": null,\n        \"metallicRoughnessTextureCoord\": 1,\n    },\n}\n```\n\nIf a texture is not given, all respective texture components within this material model are assumed to have a value of `1.0`. If both factors and textures are present the factor value acts as a linear multiplier for the corresponding texture values. The `baseColorTexture` is in sRGB space and must be converted to linear space before it is used for any computations.\n\nFor example, assume a value of `[0.9, 0.5, 0.3, 1.0]` in linear space is obtained from an RGBA `baseColorTexture`, and assume that `baseColorFactor` is given as `[0.2, 1.0, 0.7, 1.0]`.\nThen, the result would be\n```\n[0.9 * 0.2, 0.5 * 1.0, 0.3 * 0.7, 1.0 * 1.0] = [0.18, 0.5, 0.21, 1.0]\n```\n\n### Calculating Reflectance\n\nThe following equations show how to calculate bidirectional reflectance distribution function (BRDF) inputs (*c<sub>diff</sub>*, *F<sub>0</sub>*, *&alpha;*) from the metallic-roughness material properties. In addition to the material properties, if a primitive specifies a vertex color using the attribute semantic property `COLOR_0`, then this value acts as an additional linear multiplier to `baseColor`.\n\n`const dielectricSpecular = rgb(0.04, 0.04, 0.04)`\n<br>\n`const black = rgb(0, 0, 0)`\n\n*c<sub>diff</sub>* = `lerp(baseColor.rgb * (1 - dielectricSpecular.r), black, metallic)`\n<br>\n*F<sub>0</sub>* = `lerp(dieletricSpecular, baseColor.rgb, metallic)`\n<br>\n*&alpha;* = `roughness ^ 2`\n\n\n","slug":"docs/developer-guide/materials","title":"Materials"},{"excerpt":"Writing GLSL Shaders GLSL Versions and Compatibility The GLSL versions discussed here are the two GLSL versions supported by WebGL2, namely…","rawMarkdownBody":"# Writing GLSL Shaders\n\n## GLSL Versions and Compatibility\n\n> The GLSL versions discussed here are the two GLSL versions supported by WebGL2, namely GLSL 3.00 ES and GLSL 1.00 ES. The ES suffix indicates that they are related to the OpenGL ES standards used by WebGL. For simplicity, we will often refer to the GLSL version numbers without the `ES` suffix.\n\nWhile WebGL1 supports only GLSL 1.00 ES (with four extensions), WebGL2 introduces the choice of writing shaders in GLSL version 3.00 ES. While GLSL 3.00 ES introduces important new features, some parts of the language syntax has changed.\n\nThese syntax differences between versions can be a complication when writing shader code that is inteded to run both on WebGL1 and WebGL2 environments. In particular when creating reusable code for shader modules, it is desirable to be able to write GLSL code that can work in both GLSL 3.00 and 1.00 shaders.\n\n\n## GLSL \"Transpilation\"\n\nThe shadertools system lets developers write shader source code using the new GLSL 3.00 ES syntax. This allows shader modules to be used in new GLSL 3.00 ES shaders, while relying on the shader assembler system to automatically convert (\"transpile\") the GLSL code to GLSL 1.00 ES when needed to run in GLSL 1.00 ES shaders or under WebGL1.\n\nUsing the compatiblity guidelines below, it is possible to write highly portable shaders. In rare cases it can require deviating from writing pure GLSL 3.00 ES in some cases.\n\nNaturally, \"transpiled\" GLSL 3.00 ES shaders will only compile successfully in GLSL 1.00 ES if they don't use any GLSL 3.00 ES unique features.\n\n\n## Writing Portable Shader Modules\n\nIf your shader unconditionally needs features that are unique to GLSL 3.00, you should of course use GLSL 3.00 directly. In this case your GLSL code will never run on GLSL 1.00 so no need to make it compatible. But if your shader uses GLSL 1.00 features and extensions only, then you may want to make some extra effort to ensure it runs under WebGL1 if required.\n\nSeveral of the syntactic changes between GLSL 1.00 ES and 3.00 ES relate to shader input/outputs. It is recommended that shader modules let the calling, top level shaders define attribute inputs and fragment shader outputs. The exception is of course \"varyings\" which are typically defined by shader modules that provide both a vertex and fragment shader components, in which case it is recommended that shaders use `out` and `in` syntax rather than `varying`.\n\n* Definition of vertex shader attributes should be done in the top level shader.\n* Definition of and assignment to `gl_FragColor`, `gl_FragDepth` and `gl_FragData` or their counterparts should be done in the top level fragment shader. That is, shader modules can calculate the required values but typically do not actually assign to the shader output variables. This makes shader module code independent of the naming of the output variables.\n\n\n#### From GLSL 1.00 to 3.00\n\nReferences\n\n* [Shaderific's Guide on how to update shaders to GLSL 3.00]http://www.shaderific.com/blog/2014/3/13/tutorial-how-to-update-a-shader-for-opengl-es-30\n\nluma.gl can also attempt to do a simple conversion code from GLSL 1.00 to GLSL 3.00. It is essentially the reverse of the mapping described in the matrix above.\n\n\n## Conditional Code\n\n\n## Testing GLSL Code\n\nTBA\n\n\n## GLSL Syntax Conversion Reference\n\nThe shader assembler replaces keywords to ensure compatibility between GLSL 3.00 ES and GLSL 1.00 ES code per the following rules.\n\nTBD - Should the tables be moved to the shader module reference docs?\n\n\nVertex Shaders\n\n| 3.00 ES         | 1.00 ES     | Comment         |\n| ---             | ---         | ---             |\n| `in`            | `attribute` |                 |\n| `out`           | `varying`   |                 |\n\nFragment Shaders\n\n| 3.00 ES         | 1.00 ES        | Comment |\n| ---             | ---            | ---     |\n| `in`            | `varying`      |         |\n| `out`           | `gl_FragColor` |         |\n| `out`           | `gl_FragData`  |         |\n| `texture`       | `texture2D`    | `texture` will be replaced with `texture2D` to ensure 1.00 code is correct. See note on `textureCube` below. |\n| `textureCube` * | `textureCube`  | `textureCube` is not valid 3.00 syntax, but must be used to ensure 1.00 code is correct, because `texture` will be substituted with `texture2D` when transpiled to 100. Also `textureCube` will be replaced with correct `texture` syntax when transpiled to 300. |\n| `gl_FragDepth`  | `gl_FragDepthEXT` | WebGL1: **EXT_frag_depth** |\n\n\n| 3.00 ES             | 1.00 ES                | Comment |\n| ---                 | ---                    | --- |\n| `texture2DLod`      | `texture2DLodEXT`      | WebGL1: **EXT_shader_texture_lod** |\n| `texture2DProjLod`  | `texture2DProjLodEXT`  | WebGL1: **EXT_shader_texture_lod** |\n| `texture2DProjLod`  | `texture2DProjLodEXT`  | WebGL1: **EXT_shader_texture_lod** |\n| `textureCubeLod`    | `textureCubeLodEXT`    | WebGL1: **EXT_shader_texture_lod** |\n| `texture2DGrad`     | `texture2DGradEXT`     | WebGL1: **EXT_shader_texture_lod** |\n| `texture2DProjGrad` | `texture2DProjGradEXT` | WebGL1: **EXT_shader_texture_lod** |\n| `texture2DProjGrad` | `texture2DProjGradEXT` | WebGL1: **EXT_shader_texture_lod** |\n| `textureCubeGrad`   | `textureCubeGradEXT`   | WebGL1: **EXT_shader_texture_lod** |\n\n\n### Not currently handled\n\nFragment shader `out`s are not well handled at the moment.\n| **EXT_draw_buffers** |\n| `glFragData[]` |\n\n\n## Appendix - New Features in GLSL 3.00\n\nThe following features are only available in GLSL 3.00 and cannot be directly emulated in 1.00.\n\n\n#### Texture sizes and Pixel Fetch\n\nShaders have access to texture sizes and can query by pixel coordinates instead of uv coordinates.\n\n```\nvec2 size = textureSize(sampler, lod)\nvec4 values = texelFetch(sampler, ivec2Position, lod);\n```\n\n#### Texture Arrays and 3D textures\n\n```\nvec4 color = texture(sampler2DArray, vec3(u, v, index));\nvec4 color = texture(sampler3D, vec3(u, v, depth));\n```\n\n#### Non-constant loops\n\n\n\n#### Matrix functions\n\n```\nmat4 m = inverse(matrix);\nmat4 t = transpose(matrix);\n```\n\n#### Integer textures, attributes and math\n\nIn WebGL2 you can have integer attributes and integer textures.\n\nGLSL 3.00 ES allows you to do integer math in the shaders, including bit manipulations of integers.\n\n\n#### Uniform Buffer Objects\n\n\n#### Transform Feedback\n\n\n\n\n## Concepts\n\nA shader module is either:\n* **Generic** - a set of generic GLSL functions that can be included either in a fragment shader or a vertex shader (or both). The `fp64` module is a good example of this type of module.\n* **Functional** - Contains specific vertex and/or fragment shader \"chunks\", often set up so that the vertex shader part sets up a `varying` used by the fragment shader part.\n\nTo define a shader module, you must specify the following fields:\n* `name` (*String*) - the name of the shader module\n* `dependencies` (*Array*) - a list of other shader modules that this module is dependent on\n* `deprecations` (*Array*) - a list of deprecated APIs. If supplied, `assembleShaders` will scan the source for usage and issue a console warning. Each API is described in the following format:\n  - `type`: `uniform <type>` or `function`\n  - `old`: name of the deprecated uniform/function\n  - `new`: name of the new uniform/function\n  - `deprecated`: whether the old API is still supported\n* `getUniforms` JavaScript function that maps JavaScript parameter keys to uniforms used by this module\n* `vs`\n* `fs`\n\n\n### GLSL Code\n\nThe GLSL code for a shader module typically contains:\n* a mix of uniform and varying declarations\n* one or more GLSL function definitions\n\n\n### getUniforms\n\nEach shader module provides a method to get a map of uniforms for the shader. This function will be called with two arguments:\n- `opts` - the module settings to update. This argument may not be provided when `getUniforms` is called to generate a set of default uniform values.\n- `context` - the uniforms generated by this module's dependencies.\n\nThe function should return a JavaScript object with keys representing uniform names and values representing uniform values.\n\nThe function should expect the shape of the dependency uniforms to vary based on what's passed in `opts`. This behavior is intended because we only want to recalculate a uniform if the uniforms that it depends on are changed. An example is the `project` and `project64` modules in deck.gl. When `opts.viewport` is provided, `project64` will receive the updated projection matrix generated by the `project` module. If `opts.viewport` is empty, then the `project` module generates nothing and so should `project64`.\n\n\n### Platform Detection\n\nAlso does some platform detection and injects `#define` statements enabling\nyour shader to conditionally use code.\n\n\n## Remarks\n\n* **No Vertex Attributes** - At the moment shader modules are not expected to use attributes. It is up to the root application shaders to define attributes and call GLSL functions from the imported shader modules with the appropriate attributes. This is just a convention, not a hard limitation.\n","slug":"docs/developer-guide/shadertools/writing-glsl-shaders","title":"Writing GLSL Shaders"},{"excerpt":"Buffer A  is a WebGL object that stores an chunk of memory allocated by the GPU. This memory can be accessed directly by the GPU and is used…","rawMarkdownBody":"# Buffer\n\nA `Buffer` is a WebGL object that stores an chunk of memory allocated by the GPU. This memory can be accessed directly by the GPU and is used to store things like vertex data, pixel data retrieved from images or the framebuffer, etc. The `Buffer` class provides mechanism for allocating such memory, together with facilities for copying data to and from the GPU (usually via JavaScript typed arrays).\n\nFor additional information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Buffer_Object).\n\n\n## Usage\n\n```js\nimport {Buffer} from '@luma.gl/core';\n```\n\nCreating a generic buffer\n```js\nconst buffer = new Buffer(gl);\n```\n\nCreating an elements buffer\n```js\nconst buffer = new Buffer(gl, {target: GL.ELEMENT_ARRAY_BUFFER});\n```\n\nAllocating memory in a buffer\n```js\nconst buffer = new Buffer(gl, {byteLength: 200});\nconst buffer = new Buffer(gl).initialize({byteLength: 200});\n```\n\nAllocating and initializing a buffer\n```js\nconst buffer = new Buffer(gl, {\n  target: GL.ELEMENTS_ARRAY_BUFFER,\n  data: new Uint32Array([1, 2, 3])\n});\nconst buffer = new Buffer(gl, new Float32Array([1, 2, 3])); // Allocate+init 12 bytes of GPU memory\nconst buffer = new Buffer(gl, 200); // Allocate 200 bytes of GPU memory\n```\n\nUpdating a buffer\n```js\nconst buffer = new Buffer(gl, {byteLength: 200})\nbuffer.subData(new Float32Array(...));\n```\n\nCopying data between buffers (WebGL2)\n```js\nconst sourceBuffer = ...\nconst destinationBuffer = ...\n\n// To copy 32 bytes from sourceBuffer to destinationBuffer\ndestinationBuffer.copyData({sourceBuffer, size: 32});\n\n// To copy 32 bytes from sourceBuffer at 8 byte offset into\n// destinationBuffer at 16 byte offset.\ndestinationBuffer.copyData({\n  sourceBuffer,\n  readOffset: 8,\n  writeOffset: 16,\n  size: 32\n});\n```\n\nGetting data from a buffer (WebGL2)\n```js\nconst buffer = ...;\n\n// To get all the data from buffer\nconst data = buffer.getData();\n\n// To get all the data from buffer starting from byteOffset 8\n// into existing ArrayBufferView.\nconst existingArray = ...\nconst data = buffer.getData({dstData: existingArray, srcByteOffset: 8});\n// Maximum possible elements will be copied based buffer and dstData size.\n\n// To get 5 elements from source buffer starting from byteOffset 8\n// into existing ArrayBufferView starting from 3rd element position.\nconst existingArray = ...\nconst data = buffer.getData({dstData: existingArray, srcByteOffset: 8, dstOffset: 3, length: 5});\n\n```\n\n\n## Members\n\n##### `handle` : `WebGLBuffer`\n\nHolds the underlying WebGL object reference.\n\n\n##### `byteLength` : Number\n\nNumber of bytes of allocated memory.\n\n\n#### `bytesUsed` : Number\n\nSame as `byteLength` unless the `Buffer.reallocate` has been called with a value smaller than the actual length of the buffer.\n\n\n##### `accessor` : `Accessor`\n\nHolds an `Accessor` instance. By default it contains type information that is automatically deducted from the type of data used to initialize the buffer, but the application can store any `Accessor` it wants with the `Buffer`. This can simplify handling of buffer related data in many basic use cases (e.g. when buffers are not shared by multiple attributes etc).\n\n\n## Constructor\n\n### Buffer(gl : WebGLRenderingContext, props : Object | TypedArray | Number)\n\nCreates a new `Buffer`. Multiple signatures are supported:\n\n```js\nconst buffer = new Buffer(gl, {target, ...initOptions, accessor, ...accessorOptions});\n```\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `target`= (*GLenum*, optional) - the type of buffer, see below.\n* `...initOptions` (*Object*) - options passed on to `initialize`.\n* `accessor` - options used to create the `accessor`\n* `...accessorOptions` (DEPRECATED) - options passed on to `setAccessor`. Use `accessor` instead.\n\n```js\nconst buffer = new Buffer(gl, typedArray);\n```\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `typedArray` - typed array with values that should be used to size and initialize the new GPU buffer. Short hand for `new Buffer({data: typedArray})`.\n\n```js\nconst buffer = new Buffer(gl, byteLength);\n```\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `byteLength` - specifies the number of bytes that should be allocated (but not initialized). Short hand for `new Buffer({byteLength})`.\n\nThe newly constructed buffer will either be a an \"element\" buffer used for storing vertex indices, or a \"generic\" buffer that can be used to store other things. To create an element buffer, specify `target: GL.ELEMENT_ARRAY_BUFFER`. If target is not specified, it will be a generic buffer that can be used in a variety of situations.\n\n* In WebGL1, the default target is `GL.ARRAY_BUFFER` which will work as a \"generic\" (i.e. non-element) buffer.\n* In WebGL2, the default target is `GL.COPY_READ_BUFFER` which means the buffer can work either as a generic buffer and an element buffer. This will be determined when it is first used with (bound to) a specific target. From that point on, WebGL will consider it either as an element buffer or a generic buffer.\n\n\n## Methods\n\n### initialize(props : Object) : Buffer\n\nAllocates and optionally initializes buffer memory/data store (releasing any previously allocated memory).\n\nAlso extracts characteristics of stored data, hints for vertex attribute.\n\n```js\nBuffer.initialize({data, byteLength, usage=, dataType=, size=, accessor=, ...accessorOptions})\nBuffer(gl, typedArray);\nBuffer(gl, byteLength);\n``````\n\n* `data` (ArrayBufferView) - contents\n* `byteLength` (Number) - the size of the buffer object's data store.\n* `usage`=`GL.STATIC_DRAW` (GLenum) - Allocation hint for GPU driver.\n* `accessor` (Object) - object with accessor props to be stored as accessor.\n* `...accessorOptions` (DEPRECATED) -  parameters passed to `setAccessor`\n\n\n### reallocate(byteLength : Number) : Buffer\n\nIf necessary, increases buffer size to `byteLength`. Does not decrease the buffer's size if already long enough.\n\n* `byteLength` (Number) - the minimum size of the buffer object's data store.\n\nReturns:\n\n* `true` - if reallocation happened (in which case any stored data was invalidated).\n* `false` - if the `Buffer` was already big enough in which case any uploaded data remains intact.\n\n\n### subData({data , offset=, srcOffset=, length=}) : Buffer\n\nUpdates part or all of a buffer's allocated memory.\n\n`Buffer.subData({data, offset=, srcOffset=, length=})`\n\n* `data` (`ArrayBufferView`) - length is inferred unless provided\n* `offset`=`0` - Offset into buffer\n* `srcOffset`=`0` -  WebGL2: Offset into srcData\n* `length` - WebGL2: Number of bytes to be copied\n\n\n### copyData(options : Object) : Buffer (WebGL2)\n\nCopies part of the data of another buffer into this buffer. The copy happens on the GPU and is expected to be efficient.\n\n`Buffer.copyData({sourceBuffer, readOffset=, writeOffset=, size})`\n\n* `options.sourceBuffer` (`Buffer`) - the buffer to read data from.\n* `options.readOffset`=`0` (GLint) - byte offset from which to start reading from the buffer.\n* `options.writeOffset`=`0` (GLint) - byte offset from which to start writing to the buffer.\n* `options.size` (GLsizei) - byte count, specifying the size of the data to be copied.\n\nNote:\n\n* `readOffset`, `writeOffset` and `size` must all be greater than or equal to zero.\n* `readOffset + sizereadOffset + size` must not exceeed the size of the source buffer object\n* `writeOffset + sizewriteOffset + size` must not exceeed the size of the buffer bound to writeTarget.\n* If the source and destination are the same buffer object, then the source and destination ranges must not overlap.\n\n\n### getData() : TypedArray (WebGL2)\n\nReads data from buffer into an `ArrayBufferView` or `SharedArrayBuffer`.\n\n`Buffer.getData({dstData, srcByteOffset, srcOffset, length})`\n\n* `dstData`=`null` (`ArrayBufferView` | `SharedArrayBuffer` | `null`)  - memory to which to write the buffer data. New ArrayBufferView allocated with correct type if not provided.\n* `srcByteOffset`=`0` (GLintptr) - byte offset from which to start reading from the buffer.\n* `srcOffset`=`0` (GLuint) - element index offset where to start reading the buffer.\n* `length`=`0` (GLuint)  Optional, Element count to be copied, optimal value calculated when not provided.\n\nReturns a typed array containing the data from the buffer (if `dstData` was supplied it will be returned, otherwise this will be a freshly allocated array).\n\n\n### getElementCount([accessor : Accessor]) : Number\n\nReturns number of elements in the buffer. In a buffer created with Float32Array typed array, each float is an element and takes 4 bytes (or 32 bits).\n\n\n### setAccessor(accessor : Accessor | Object) : Buffer\n\nAllows you to optionally describe the accessor properties of the data in the buffer. This does not affect the buffer itself, but if supplied can avoid having to supply this data again when you use this buffer as an attribute later (see `VertexArray.setAttributes`).\n\nFor details on accessor props, see the documentation for the [`Accessor`]() class.\n\n\n## Types\n\n### Usage\n\n| Usage             | WebGL2 | WebGL1 | Description |\n| ---               | ---    | ---    | ---         |\n| `GL.STATIC_DRAW`  | Yes    | Yes    | Buffer will be used often and not change often. Contents are written to the buffer, but not read. |\n| `GL.DYNAMIC_DRAW` | Yes    | Yes    | Buffer will be used often and change often. Contents are written to the buffer, but not read. |\n| `GL.STREAM_DRAW`  | Yes    | Yes    | Buffer will not be used often. Contents are written to the buffer, but not read. |\n| `GL.STATIC_READ`  | Yes    | No     | Buffer will be used often and not change often. Contents are read from the buffer, but not written. |\n| `GL.DYNAMIC_READ` | Yes    | No     | Buffer will be used often and change often. Contents are read from the buffer, but not written. |\n| `GL.STREAM_READ`  | Yes    | No     | Buffer will not be used often. Contents are read from the buffer, but not written. |\n| `GL.STATIC_COPY`  | Yes    | No     | Buffer will be used often and not change often. Contents are neither written or read by the user. |\n| `GL.DYNAMIC_COPY` | Yes    | No     | Buffer will be used often and change often. Contents are neither written or read by the user. |\n| `GL.STREAM_COPY`  | Yes    | No     | Buffer will be used often and not change often. Contents are neither written or read by the user. |\n\n### Parameters\n\n| Parameter         | Type   | Value |\n| ---               | ---    | ---   |\n| `GL.BUFFER_SIZE`  | GLint  | The size of the buffer in bytes   |\n| `GL.BUFFER_USAGE` | GLenum | The `usage` pattern of the buffer |\n\n\n### \"Manually\" Binding Buffers\n\nIf you are an experienced WebGL or OpenGL programmer you are probably used to constantly binding buffers. Buffer binding and unbinding is handled internal by luma.gl methods and applications typically do not need to bind buffers.\n\nTo support use cases integrating with external libraries or raw webgl code, it is of course possible to \"manually\" bind and unbind luma.gl `Buffer` instances:\n\n```js\nconst buffer = ...;\nbuffer.bind({target: GL.ARRAY_BUFFER});\n...\nbuffer.unbind({target: GL.ARRAY_BUFFER});\n```\nWebGL2 examples\n```js\nbuffer.bind({target: GL.PIXEL_PACK_BUFFER});\nbuffer.bind({target: GL.PIXEL_UNPACK_BUFFER});\nbuffer.bind({target: GL.TRANSFORM_FEEDBACK_BUFFER, index: 0});\nbuffer.bind({target: GL.UNIFORM_BUFFER, index: 0, offset: ..., size: ...});\nbuffer.unbind({target: GL.UNIFORM_BUFFER, index: 0});\n```\n\n\n## Remarks\n\n* All instance methods in a buffer (unless they return some documented value) are chainable.\n* While transferring memory between CPU and GPU takes some time, once the memory is available as a buffer on the GPU it can be very efficiently used as inputs and outputs by the GPU.\n\nNote that in WebGL, there are two types of buffers:\n* \"element\" buffers. These can only store vertex attributes with indices (a.k.a \"elements\") and can only be used by binding them to the `GL.ELEMENT_ARRAY_BUFFER` before draw calls.\n* \"generic\" buffers. These can be used interchangeably to store different types of data, including (non-index) vertex attributes.\n\nFor more on the `GL.ELEMENT_ARRAY_BUFFER` restrictions in WebGL, see [this page](https://www.khronos.org/registry/webgl/specs/1.0/#webgl_gl_differences) for WebGL1 and [this page](https://www.khronos.org/registry/webgl/specs/2.0/#webgl_gl_differences) for WebGL2.\n","slug":"docs/api-reference/webgl/buffer","title":"Buffer"},{"excerpt":"Framebuffer A  is a WebGL container object that the application can use for \"off screen\" rendering. A framebuffer does not itself contain…","rawMarkdownBody":"# Framebuffer\n\nA `Framebuffer` is a WebGL container object that the application can use for \"off screen\" rendering. A framebuffer does not itself contain any image data but can optionally contain attachments (one or more color buffers, a depth buffer and a stencil buffer) that store data. Attachments must be in the form of `Texture`s and `Renderbuffer`s.\n\nFor additional information, see OpenGL Wiki [Framebuffer](https://www.khronos.org/opengl/wiki/Framebuffer) and [Framebuffer Object](https://www.khronos.org/opengl/wiki/Framebuffer_Object)\n\n\n## Functionality\n\nluma.gl adds\n\n\n\n## Usage\n\nCreating a framebuffer with default color and depth attachments\n\n```js\nconst framebuffer = new Framebuffer(gl, {\n  width: window.innerWidth,\n  height: window.innerHeight,\n  color: true,\n  depth: true\n});\n\n```\n\nAttaching textures and renderbuffers\n\n```js\nframebuffer.attach({\n  [GL.DEPTH_ATTACHMENT]: new Renderbuffer(gl, {...}),\n  [GL.COLOR_ATTACHMENT0]: new Texture(gl, {...}),\n  [GL.COLOR_ATTACHMENT1]: [new TextureCube(gl, {...}), GL.TEXTURE_CUBE_MAP_POSITIVE_X],\n  [GL.COLOR_ATTACHMENT2]: [new TextureArray2D(gl, {...}), 0],\n  [GL.COLOR_ATTACHMENT3]: [new TextureArray2D(gl, {...}), 1],\n  [GL.COLOR_ATTACHMENT4]: [new Texture3D(gl, {..., depth: 8}), 2]\n});\nframebuffer.checkStatus(); // optional\n```\n\nResizing a framebuffer to the size of a window. Resizes all attachements with a single `framebuffer.resize()` call\n\n\n```js\n// Note: this resizes (and possibly clears) all attachments\nframebuffer.resize({width: window.innerWidth, height: window.innerHeight});\n```\n\nClearing a framebuffer\n\n```js\nframebuffer.clear();\nframebuffer.clear({color: [0, 0, 0, 0], depth: 1, stencil: 0});\n```\n\nSpecifying a framebuffer for rendering in each render calls\n\n```js\nconst offScreenBuffer = new Framebuffer();\nprogram1.draw({\n  framebuffer: offScreenBuffer,\n  parameters: {}\n});\nmodel.draw({\n  framebuffer: null, // the default drawing buffer\n  parameters: {}\n});\n```\n\nBinding a framebuffer for multiple render calls\n\n```js\nconst framebuffer1 = ...;\nconst framebuffer2 = ...;\nwithParameters(gl, {framebuffer: framebuffer1}, () => {\n  // Any draw call that doesn't specify a framebuffer will now draw into framebuffer1\n  program1.draw({...}); // -> framebuffer1\n  program2.draw({...}); // -> framebuffer1\n  // Explicit specification of framebuffer overrides (for that call only)\n  program2.draw({framebuffer: framebuffer1, ...); // -> framebuffer2\n  program2.draw({...}); // -> framebuffer1\n});\n// framebuffer1 is not longer bound\n```\n\n### Reading, copying or blitting data from a Framebuffer attachment.\n\nFor reading data into CPU memory check [`readPixelsToArray`](/docs/api-reference/webgl/copy-and-blit.md)\n\nFor reading into a Buffer object (GPU memory), doesn't result in CPU and GPU sync, check [`readPixelsToBuffer`](/docs/api-reference/webgl/copy-and-blit.md)\n\nFor reading into a Texture object (GPU memory), doesn't result in CPU and GPU sync, check [`copyToTexture`](/docs/api-reference/webgl/copy-and-blit.md)\n\nFor blitting between framebuffers (WebGL2), check [`blit`](/docs/api-reference/webgl/copy-and-blit.md)\n\n\n### Using Multiple Render Targets\n\nSpecify which framebuffer attachments the fragment shader will be writing to when assigning to `gl_FragData[]`\n\n```js\nframebuffer.update({\n  drawBuffers: [\n    GL.COLOR_ATTACHMENT0, // gl_FragData[0]\n    GL.COLOR_ATTACHMENT1, // gl_FragData[1]\n    GL.COLOR_ATTACHMENT2, // gl_FragData[2]\n    GL.COLOR_ATTACHMENT3  // gl_FragData[3]\n  ]\n})\n```\n\nWriting to multiple framebuffer attachments in GLSL fragment shader\n\n```\n#extension GL_EXT_draw_buffers : require\nprecision highp float;\nvoid main(void) {\n  gl_FragData[0] = vec4(0.25);\n  gl_FragData[1] = vec4(0.5);\n  gl_FragData[2] = vec4(0.75);\n  gl_FragData[3] = vec4(1.0);\n}\n```\n\nClearing a specific draw buffer in a framebuffer (WebGL2)\n```js\nframebuffer.clear({\n  [GL.COLOR]: [0, 0, 1, 1], // Blue\n  [GL.COLOR]: new Float32Array([0, 0, 0, 0]), // Black/transparent\n  [GL.DEPTH_BUFFER]: 1, // Infinity\n  [GL.STENCIL_BUFFER]: 0, // no stencil\n});\n\nframebuffer.clear({\n  [GL.DEPTH_STENCIL_BUFFER]: [1, 0], // Infinity, no stencil\n});\n```\n\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nCreates a new framebuffer, optionally creating and attaching `Texture` and `Renderbuffer` attachments.\n\n```\nnew Framebuffer(gl, {\n  id,\n  width,\n  height,\n  attachments,\n  color,\n  depth,\n  stencil\n})\n```\n\n* `id`= - (*String*) - An optional name (id) of the buffer.\n* `width`=`1` - (*number*) The width of the framebuffer.\n* `height`=`1` - (*number*) The height of the framebuffer.\n* `attachments`={} - (*Object*, optional) - a map of Textures and/or Renderbuffers, keyed be \"attachment points\" (see below).\n* `color` - shortcut to the attachment in `GL.COLOR_ATTACHMENT0`\n* `depth` - shortcut to the attachment in `GL.DEPTH_ATTACHMENT`\n* `stencil` - shortcut to the attachment in `GL.STENCIL_ATTACHMENT`\n\nThe luma.gl `Framebuffer` constructor enables the creation of a framebuffer with all the proper attachments in a single step and also the `resize` method makes it easy to efficiently resize a all the attachments of a `Framebuffer` with a single method.\n\nWhen no attachments are provided during `Framebuffer` object creation, new resources are created and used as default attachments for enabled targets (color and depth).\nFor color, new `Texture2D` object is created with no mipmaps and following filtering parameters are set.\n\n| Texture parameter       | Value |\n| ---                     | --- |\n| `GL.TEXTURE_MIN_FILTER` | `GL.LINEAR` |\n| `GL.TEXTURE_MAG_FILTER` | `GL.LINEAR` |\n| `GL.TEXTURE_WRAP_S`     | `GL.CLAMP_TO_EDGE` |\n| `GL.TEXTURE_WRAP_T`     | `GL.CLAMP_TO_EDGE` |\n\nFor depth, new `Renderbuffer` object is created with `GL.DEPTH_COMPONENT16` format.\n\n\n### delete()\n\nDestroys the underlying WebGL object. When destroying `Framebuffer`s it can be important to consider that a `Framebuffer` can manage other objects that may also need to be destroyed.\n\n\n### initialize(props : Object) : Framebuffer\n\nInitializes the `Framebuffer` to match the supplied parameters. Unattaches any existing attachments, attaches any supplied attachments. All new attachments will be resized if they are not already at the right size.\n\n`Framebuffer.initialize({width, height})`\n\n* `width`=`1` - (*number*) The width of the framebuffer.\n* `height`=`1` - (*number*) The height of the framebuffer.\n* `attachments`={} - (*Object*, optional) - a map of Textures and/or Renderbuffers, keyed be \"attachment points\" (see below).\n* `color` - shortcut to the attachment in `GL.COLOR_ATTACHMENT0`\n* `depth` - shortcut to the attachment in `GL.DEPTH_ATTACHMENT`\n* `stencil` - shortcut to the attachment in `GL.STENCIL_ATTACHMENT`\n\n\n### update(options: Object) : Framebuffer\n\nUpdates Framebuffers attachments using provided Texture and Renderbuffer objects. Optionally sets read and draw buffers when using WebGL2 context.\n\n* `attachments` - a map of attachments.\n* `readBuffer` - Buffer to be set as read buffer (WebGL2)\n* `drawBuffers` - Buffers to be set as draw buffers (WebGL2)\n* `clearAttachments` - When set to true, will first unattach all  binding points, default value is `false`.\n* `resizeAttachments` - When set to true, all attachments will be re-sized to Framebuffers size, default value is `true`.\n\n### resize({width: Number, height: Number}) : Framebuffer\n\n`Framebuffer.resize({width, height})`\n\nResizes all the `Framebuffer`'s current attachments to the new `width` and `height` by calling `resize` on those attachments.\n\n* `width` (GLint) - width of `Framebuffer` in pixels\n* `height` (GLint) - height of `Framebuffer` in pixels\n\nReturns itself to enable chaining\n\n* Each attachment's `resize` method checks if `width` or `height` have actually changed before reinitializing their data store, so calling `resize` multiple times with the same `width` and `height` does not trigger multiple resizes.\n* If a resize happens, `resize` erases the current content of the attachment in question.\n\nWebGL References see `initialize`.\n\n\n### attach(attachments : Object, options: Object) : Framebuffer\n\nUsed to attach or unattach `Texture`s and `Renderbuffer`s from the `Framebuffer`s various attachment points.\n\n`Framebuffer.attach(attachments)`\n\n* `attachments` - a map of attachments.\n* options\n  * `clearAttachments` - When set to true, will first unattach all  binding points, default value is `false`.\n  * `resizeAttachments` - When set to true, all attachments will be re-sized to Framebuffers size, default value is `true`.\n\n\nReturns itself to enable chaining.\n\nThe key of an attachment must be a valid attachment point, see below.\n\nThe following values can be provided for each attachment\n* `null` - unattaches any current binding\n* `Renderbuffer` - attaches the `Renderbuffer`\n* `Texture` - attaches the `Texture`\n* [`Texture`, layer=0 (Number), mipmapLevel=0 (Number)] - attaches the specific layer from the `Texture` (WebGL2)\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.framebufferRenderbuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/framebufferRenderbuffer),\n[`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer),\n[`gl.framebufferTexture2D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/framebufferTexture2D),\n[`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer),\n[`gl.framebufferTextureLayer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/framebufferTextureLayer),\n[`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer) (This is for WebGL2 only)\n\n\n### checkStatus() : Framebuffer\n\nCheck that the framebuffer contains a valid combination of attachments\n\n[`gl.checkFramebufferStatus`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/checkFramebufferStatus), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n\n### clear(options: Object) : Framebuffer\n\nClears the contents (pixels) of the framebuffer attachments.\n\n* `options.color` (Boolean or Array) - clears all active color buffers (any selected `drawBuffer`s) with either the provided color or the default color.\n* `options.depth`\n* `options.stencil`\n* `options.drawBuffers`=`[]` - An array of color values, with indices matching the buffers selected by `drawBuffers` argument.\n\nNotes:\n* The scissor box bounds the cleared region.\n* The pixel ownership test, the scissor test, dithering, and the buffer writemasks affect the operation of `clear`.\n* Alpha function, blend function, logical operation, stenciling, texture mapping, and depth-buffering are ignored by `clear`.\n\n### invalidate (WebGL2)\n\nSignals to the GL that it need not preserve the pixels of a specified region of the framebuffer (by default all pixels of the specified framebuffer attachments are invalidated).\n\nParameters\n* attachments - list of attachments to invalidate\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.invalidateFramebuffer`](WebGL2RenderingContext.invalidateFramebuffer()), [`gl.invalidateSubFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/invalidateSubFramebuffer), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n## Limits\n\n* `GL.MAX_COLOR_ATTACHMENTS` - The maximum number of color attachments supported. Can be `0` in WebGL1.\n* `GL.MAX_DRAW_BUFFERS` - The maximum number of draw buffers supported. Can be `0` in WebGL1, which means that `gl_FragData[]` is not available in shaders.\n\nIt is possible that you can have a certain number of attachments, but you can't draw to all of them at the same time.\n\n\n## Framebuffer Parameters\n\n### Framebuffer Attachment Points\n\n| Attachment Point              | Description |\n| ---                           | --- |\n| `GL.COLOR_ATTACHMENT0`   | Attaches the texture to one of the framebuffer's color buffers |\n| `GL.COLOR_ATTACHMENT`{1-15}   | Attaches the texture to one of the framebuffer's color buffers |\n| `GL.DEPTH_ATTACHMENT`         | Attaches the texture to the framebuffer's depth buffer |\n| `GL.STENCIL_ATTACHMENT`       | Attaches the texture to the framebuffer's stencil buffer |\n| `GL.DEPTH_STENCIL_ATTACHMENT` | Combined depth and stencil buffer |\n\n* The attachment point `GL.BACK` refersn to the default framebuffer's back buffer.\n\n* The set of available attachments is larger in WebGL2, and also the extensions `WEBGL_draw_buffers` and `WEBGL_depth_texture` provide additional attachments that match or exceed the WebGL2 set.\n\n\n### Framebuffer Attachment Values\n\nThe following values can be provided for each attachment point\n* `null` - unattaches any current binding\n* `Renderbuffer` - attaches the `Renderbuffer`\n* `Texture2D` - attaches at mipmapLevel 0 of the supplied `Texture2D`.\n* [`Texture2D`, 0, mipmapLevel] - attaches the specified mipmapLevel from the supplied `Texture2D` (WebGL2), or cubemap face. The second element in the array must be `0`. In WebGL1, mipmapLevel must be 0.\n* [`TextureCube`, face (Number), mipmapLevel=0 (Number)] - attaches the specifed cubemap face from the `Texture`, at the specified mipmap level. In WebGL1, mipmapLevel must be 0.\n* [`Texture2DArray`, layer (Number), mipmapLevel=0 (Number)] - attaches the specifed layer from the `Texture2DArray`, at the specified mipmap level.\n* [`Texture3D`, layer (Number), mipmapLevel=0 (Number)] - attaches the specifed layer from the `Texture3D`, at the specified mipmap level.\n\n\n## Remarks\n\n* In the raw WebGL API, creating a set of properly configured and matching textures and renderbuffers can require a lot of careful coding and boilerplate.\n* This is further complicated by many capabilities (such as support for multiple color buffers and various image formats) depending on WebGL extensions or WebGL versions.\n","slug":"docs/api-reference/webgl/framebuffer","title":"Framebuffer"},{"excerpt":"Readback, Copy and Blit  offers a set of functions that copy or blit data from and to Texture and Framebuffer objects. Image data can also…","rawMarkdownBody":"# Readback, Copy and Blit\n\n`luma.gl` offers a set of functions that copy or blit data from and to Texture and Framebuffer objects. Image data can also be copied into Buffer, TypedArray, Images or Urls.\n\n\n## Readback Functions\n\n### readPixelsToArray(source : Framebuffer|Texture [, options: Object]) : TypedArray\n\nReads data from a `Framebuffer` or `Texture` object into a TypedArray object and returns it. A new TypedArray object is created when not provided. This method requires a sync between CPU and GPU as pixel values are copied from GPU texture memory to CPU Array object memory. This could introduce a delay as it waits for GPU to finish updating the texture. For asynchronous read, check `copyToBuffer` method.\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n\n  Optional parameters:\n  * `options.sourceX` - (*number*, default: 0) X offset of the area to be copied,\n  * `options.sourceY` - (*number*, default: 0) Y offset of the area to be copied,\n  * `options.sourceFormat` - (*GLenum*, default: GL.RGBA) The format of the data.\n  * `options.sourceAttachment` - (*GLenum*, default: `COLOR_ATTACHMENT0`) Used to deduce the `type` when not provided.\n  * `options.target` - (*TypedArray*, default: null) Array object, into which data to be copied, new object is created when not provided.\n  * `options.sourceWidth` - (*number*, default: source width) The width of the area to be copied.\n  * `options.sourceHeight` - (*number*, default: source height) The height of the area to be copied.\n  * `options.sourceType` - (*GLenum*, default: type of `pixelArray` or `UNSIGNED_BYTE`) The type of the data.\n\nNotes:\n  * Reading from floating point textures is dependent on an extension both in WebGL1 and WebGL2.\n  * When supported, the `{format: GL.RGBA, type: GL.FLOAT, ...}` combination becomes valid for reading from a floating-point color buffer.\n  * When color attachment is a float texture with format less than 4 channels, i.e, `GL.R32F`, or  `GL.RG32F`, `readPixels` should still be called with a 4 component `format`(`GL.RGBA`), and default value (R:0, G:0, B: 0 and A: 1) will be returned for un-used channel.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.readPixels`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/readPixels), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n### readPixelsToBuffer(source : Framebuffer|Texture, options: Object) : Buffer (WebGL2)\n\nReads data from a `Framebuffer` or `Texture` object into A `Buffer` object and returns it. A new `Buffer` object is created when not provided. This method avoids a sync between CPU and GPU as pixel values are copied from GPU texture memory to GPU Buffer memory. This method returns right away without any delays.\n\nA CPU and GPU sync will be triggered when the returned buffer data is read using `buffer.getData()`, but applications can delay this read, which can reduces the delay due to the sync, or the sync can be completely avoided by using the `Buffer` as the source of input to the GPU (either as `ARRAY_BUFFER` or `PIXEL_UNPACK_BUFFER`).\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n\n  Optional parameters:\n  * `options.sourceX` - (*number*, default: 0) X offset of the area to be copied,\n  * `options.sourceY` - (*number*, default: 0) Y offset of the area to be copied,\n  * `options.sourceFormat` - (*GLenum*, default: GL.RGBA) The format of the data.\n  * `options.target` - (*Buffer*) Buffer object, into which data to be copied, new object is created when not provided.\n  * `options.targetByteOffset` - (*number*, default: 0) Byte offset from which data should be copied into buffer.\n  * `options.sourceWidth` - (*number*, default: source.width) The width of the area to be copied,\n  * `options.sourceHeight` - (*number*, default: source.height) The height of the area to be copied,\n  * `options.sourceType` - (*GLenum*, default: type of `target` or `UNSIGNED_BYTE`) The type of the data.\n\nNotes:\n  * Reading from floating point textures is dependent on an extension both in WebGL1 and WebGL2.\n  * When supported, the `{format: GL.RGBA, type: GL.FLOAT, ...}` combination becomes valid for reading from a floating-point color buffer.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.readPixels`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/readPixels), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer), [`gl.bindBuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindBuffer)\n\n\n## Copy Functions\n\n### copyToDataUrl(source : Framebuffer|Texture, options: Object) : Data URL\n\nReads data form a `Texture` or `Framebuffer` object and returns a `Data URL` containing the pixel data in PNG format.\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n\n  Optional parameters:\n  * `options.sourceAttachment` - (*GLenum*, default: `COLOR_ATTACHMENT0`) Used to deduce the `type` when not provided.\n  * `options.targetMaxHeight` - (*number*, default: Number.MAX_SAFE_INTEGER) Maximum height of the image to be in returned Data URL.\n\nNote:\n  * Works only under a browser environment, doesn't work under Node.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.readPixels`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/readPixels), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n### copyToImage(source : Framebuffer|Texture, options: Object) : Image\n\nReads data form a `Texture` or `Framebuffer` object and copies it to provided image, new `Image` instance is created if not provided.\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n\n  Optional parameters:\n  * `options.sourceAttachment` - (*GLenum*, default: `COLOR_ATTACHMENT0`) Used to deduce the `type` when not provided.\n  * `options.targetImage` - (`Image`, Optional) `Image` to to which pixel data to be copied, new one is created if not provide.\n\nNote:\n  * Works only under a browser environment, doesn't work under Node.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.readPixels`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/readPixels), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n### copyToTexture(source : Framebuffer|Texture, target: Texture|GL-enum, options: Object) : Texture\n\nCopies pixels from a `Framebuffer` or `Texture` object into the specified area of a two-dimensional texture image or cube-map texture image. (gl.copyTexImage2D, gl.copyTexSubImage2D and gl.copyTexSubImage3D wrapper)\n\n  * `source` (`Texture` or `Framebuffer`) - If provided this object will be bound and data copied from it.\n  * `target` (`Texture` or `GL enum`) - Texture object or GL enum specifying the target binding point, to which data to be copied. If target binding point is specified, it is assumed that a valid texture object is already bound.\n  * `options.sourceX` (`GLint`, optional, default: 0) - x coordinate of the lower left corner where to start copying.\n  * `options.sourceY` (`GLint`, optional, default: 0) - y coordinate of the lower left corner where to start copying.\n  * `options.targetX` (`GLint`, optional) - X offset with in target texture.\n  * `options.targetY` (`GLint`, optional) - Y offset with in target texture.\n  * `options.targetZ` (`GLint`, optional, WebGL2) - Z offset with in target texture, when using copying into 2D Array of 3D texture.\n  * `options.width` (`GLint`, optional, default: texture.width) - Width of the pixel rectangle to be copied.\n  * `options.height` (`GLint`, optional, default: texture.height) - Height of the pixel rectangle to be copied.\n\nNotes:\n  * `targetX`, `targetY`, `targetZ` : when an offset is specified, it implies we are copying data into a sub region of the target texture and internally `gl.copyTexSubImage2D` or `gl.copyTexSubImage3D` are used based on the `target`, for these cases it is assumed that target texture has enough GPU memory already allocated. When none of the offsets are specified, `gl.copyTexImage2D` is used to copy data to entire target region and GPU memory is allocated if needed, target texture GPU memory doesn't have to be pre-allocated.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.copyTexImage2D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/copyTexImage2D), [`gl.copyTexSubImage2D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/copyTexSubImage2D) and [`gl,copyTexSubImage3D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/copyTexSubImage3D)\n\n\n## Blit Functions\n\n### blit(options: Object) : (WebGL2)\n\nCopies a rectangle of pixels from a `Texture` or `Framebuffer` object into a `Texture` or `Framebuffer` object.\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n  * `options.target` (`Texture` or `Framebuffer`) - This object will be bound and data is copied into it.\n  * `options.sourceAttachment` (`GLenum`, default: `COLOR_ATTACHMENT0`) - Attachment index from which data to be copied from.\n  * `options.sourceX0` (`GLint`, default: `0`) - Lower X bound of copy rectangle in source.\n  * `options.sourceY0` (`GLint`, default: `0`) - Lower Y bound of copy rectangle in source.\n  * `options.sourceX1` (`GLint`) - Higher X bound of copy rectangle in source.\n  * `options.sourceY1` (`GLint`) - Higher Y bound of copy rectangle in source.\n  * `options.targetX0` (`GLint`, default: `0`) - Lower X bound of copy rectangle in destination.\n  * `options.targetY0` (`GLint`, default: `0`) - Lower Y bound of copy rectangle in destination.\n  * `options.targetX1` (`GLint`) - Higher X bound of copy rectangle in destination.\n  * `options.targetY1` (`GLint`) - Higher Y bound of copy rectangle in destination.\n  * `options.mask` (`GLbitfild`, default: `0`) - A `GLbitfield` specifying a bitwise OR mask indicating which buffers are to be copied, possible buffers masks are `GL.COLOR_BUFFER_BIT`, `GL.DEPTH_BUFFER_BIT` and ` GL.STENCIL_BUFFER_BIT`\n  * `options.color` (`Boolean`, default: `true`) - When true `GL.COLOR_BUFFER_BIT` is added to the mask.\n  * `options.depth` (`Boolean`, default: `false`) - When true `GL.DEPTH_BUFFER_BIT` is added to the mask.\n  * `options.stencil` (`Boolean`, default: `false`) - When true `GL.STENCIL_BUFFER_BIT` is added to the mask.\n  * `options.filter`=`GL.NEAREST` - specifies interpolation mode if stretching is needed. `GL.LINEAR` can be used exclusively for color buffers.\n\nNotes:\n  * There are a number of restrictions when blitting between integer and floating point formats.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.blitFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/blitFramebuffer), [`gl.readBuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/readBuffer), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n","slug":"docs/api-reference/webgl/copy-and-blit","title":"Readback, Copy and Blit"},{"excerpt":"Program A  contains a matched pair of vertex and fragment shaders that can be exectued on the GPU by calling . Programs handle compilation…","rawMarkdownBody":"# Program\n\nA `Program` contains a matched pair of vertex and fragment [shaders](/docs/api-reference/webgl/shader.md) that can be exectued on the GPU by calling `Program.draw()`. Programs handle compilation and linking of shaders, and store uniform values. They provide `draw` call which allows the application to run the shaders on specified input data.\n\n## Usage\n\nCreating a program\n\n```js\n  const program = new Program(gl, {\n    id: 'my-program',\n    vs: vertexShaderSourceString,\n    fs: fragmentShaderSourceString\n  });\n```\n\nSet or update uniforms, in this case world and projection matrices\n\n```js\nprogram.setUniforms({\n  uMVMatrix: view,\n  uPMatrix: projection\n});\n```\n\nCreate a `VertexArray` to store buffer values for the vertices of a triangle and drawing\n\n```js\nconst program = new Program(gl, {vs, fs});\n\nconst vertexArray = new VertexArray(gl, {program});\n\nvertexArray.setAttributes({\n  aVertexPosition: new Buffer(gl, {data: new Float32Array([0, 1, 0, -1, -1, 0, 1, -1, 0])})\n});\n\nprogram.draw({vertexArray, ...});\n```\n\nCreating a program for transform feedback, specifying which varyings to use\n\n```js\nconst program = new Program(gl, {vs, fs, varyings: ['gl_Position']});\n```\n\n\n## Members\n\n* `gl` : `WebGLRenderingContext`\n* `handle` : `WebGLProgram` - The WebGL `WebGLProgram` instance.\n* `id` : `String` - `id` string for debugging.\n\n\n## Constructor\n\n### Program(gl : WebGLRenderingContext, props : Object)\n\nCreates a new program using the supplied vertex and fragment shaders. The shaders are compiled into WebGLShaders and is created and the shaders are linked.\n\n```js\n\tconst program = new Program(gl, {\n    id: 'my-identifier',\n    vs: vertexShaderSource,\n    fs: fragmentShaderSource,\n    varyings: ['gl_Position', 'vColor']\n  });\n```\n\n* `id` (`string`, optional) - string id (to help indentify the program during debugging).\n* `vs` (`VertexShader`|`String`) - A vertex shader object, or source as a string.\n* `fs` (`FragmentShader`|`String`) - A fragment shader object, or source as a string.\n* `varyings` WebGL2 (`String[]`) - a list of names of varyings.\n* `bufferMode`=`GL.SEPARATE_ATTRIBS` WebGL2 (`GLenum`) - Optional, specifies how transform feedback should store the varyings.\n\n| `GL.TRANSFORM_FEEDBACK_BUFFER_MODE` | Description |\n| ---                                 | --- |\n| `GL.SEPARATE_ATTRIBS`               | One varying per buffer |\n| `GL.INTERLEAVED_ATTRIBS`            | Multiple varyings per buffer |\n\nWebGL References [WebGLProgram](https://developer.mozilla.org/en-US/docs/Web/API/WebGLProgram), [gl.createProgram](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/createProgram)\n\n\n### delete() : Program\n\nDeletes resources held by program. Note: Does not currently delete shaders (to enable shader caching).\n\n\n## Methods\n\n### initialize(props : Object) : Program\n\nRelinks a program. Takes the same options as the constructor\n\n\n### setUniforms(uniforms : Object) : Program\n\nSets named uniforms from a map, ignoring names\n\n* `key` (*String*) - The name of the uniform to be set. The name of the uniform will be matched with the name of the uniform declared in the shader. You can set more uniforms on the Program than its shaders use, the extra uniforms will simply be ignored.\n* `value` (*mixed*) - The value to be set. Can be a float, an array of floats, a typed array, a boolean, `Texture` etc. The values must match the declarations in the shader.\n\n[gl.useProgram](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/useProgram)\n\n\n### draw(opts) : Program\n\n`Program.draw` is the entry point for running shaders, rendering and (optionally calculating data using transform feedback techniques).\n\n```js\n  Program.draw({\n    vertexArray,\n\n    uniforms = {},\n    transformFeedback = null,\n    samplers = {},\n    parameters = {},\n\n    drawMode = GL.TRIANGLES,\n    vertexCount,\n    offset = 0,\n    isIndexed = false,\n    indexType = GL.UNSIGNED_SHORT,\n    isInstanced = false,\n    instanceCount = 0,\n\n    start = 0,\n    end=\n  })\n```\n\nMain parameters\n\n* `vertexArray` - a `VertexArray` object that will be bound and unbound before and after the draw call.\n* `uniforms`=`{}` - a map of uniforms that will be set just before the draw call (and remain set after the call).\n* `samplers`=`{}` - a map of texture `Sampler`s that will be bound before the draw call.\n* `parameters` - temporary gl settings to be applied to this draw call.\n* `transformFeedback`=`null` - optional `TransformFeedback` object containing buffers that will receive the output of the transform feedback operation.\n\nPotentially autodeduced parameters\n\n* `drawMode`=`GL.TRIANGLES` - geometry primitive format of vertex data\n* `vertexCount` - number of vertices to draw\n* `offset`=`0` - first vertex to draw\n* `isIndexed`=`false` - use indices in the \"elements\" buffer\n* `indexType`=`GL.UNSIGNED_SHORT` - must match the type of the \"elements\" buffer\n* `isInstanced`=`false` - Set to enable instanced rendering.\n* `instanceCount`=`0` - Number of instances\n\nParameters for drawing a limited range (WebGL2 only)\n\n* `start` - hint to GPU, activates `gl.drawElementsRange` (WebGL2)\n* `end` - hint to GPU, activates `gl.drawElementsRange` (WebGL2)\n\nReturns: `true` if successful, `false` if draw call is blocked due to missing resources.\n\nNotes:\n\n* Runs the shaders in the program, on the attributes and uniforms.\n* Indexed rendering uses the element buffer (`GL.ELEMENT_ARRAY_BUFFER`), make sure your attributes or `VertexArray` contains one.\n* If a `TransformFeedback` object is supplied, `transformFeedback.begin()` and `transformFeedback.end()` will be called before and after the draw call.\n* A `Sampler` will only be bound if there is a matching Texture with the same key in the supplied `uniforms` object.\n\nThe following WebGL APIs are called in this function:\n\n[gl.useProgram](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/useProgram),\n[gl.drawElements](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/drawElements),\n[gl.drawRangeElements](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/drawRangeElements) (WebGL2),\n[gl.drawArrays](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/drawArrays),\n[gl.drawElementsInstanced](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/drawElementsInstanced) (WebGL2),\n[gl.drawArraysInstanced](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/drawArraysInstanced) (WebGL2),\n[gl.getExtension](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/getExtension), [ANGLE_instanced_arrays](https://developer.mozilla.org/en-US/docs/Web/API/ANGLE_instanced_arrays),\n[gl.drawElementsInstancedANGLE](https://developer.mozilla.org/en-US/docs/Web/API/ANGLE_instanced_arrays/drawElementsInstancedANGLE),\n[gl.drawArraysInstancedANGLE](https://developer.mozilla.org/en-US/docs/Web/API/ANGLE_instanced_arrays/drawArraysInstancedANGLE)\n\n\n## Constants\n\n### Limits\n\n| Limit                               | Value          | Description |\n| ---                                 | ---            | --- |\n| `GL.MAX_VERTEX_TEXTURE_IMAGE_UNITS` | >= 0 (GLint)   | |\n| `GL.MAX_RENDERBUFFER_SIZE`          | >= 1 (GLint)   | |\n| `GL.MAX_VARYING_VECTORS`            | >= 8 (GLint)   | |\n| `GL.MAX_VERTEX_ATTRIBS`             | >= 8 (GLint)   | |\n| `GL.MAX_VERTEX_UNIFORM_VECTORS`     | >= 128 (GLint) | |\n| `GL.MAX_FRAGMENT_UNIFORM_VECTORS`   | >= 16 (GLint)  | |\n| `GL.TRANSFORM_FEEDBACK_VARYING_MAX_LENGTH` (WebGL2)  | - | - |\n\n\n### Parameters\n\nUse with `Program.getParameter(parameter)`\n\n| Parameter | Type | Description\n| --- | --- | --- |\n| `GL.DELETE_STATUS`     | GLboolean | If true, program has been flagged for deletion (by calling `Program.delete()`), but the delete is pending because program is still part of current rendering state |\n| `GL.LINK_STATUS`       | GLboolean | Indicates whether last link operation was successful. Program linking is performed by luma on program initialization |\n| `GL.VALIDATE_STATUS`   | GLboolean | Result of last `gl.validateProgram()` operation |\n| `GL.ATTACHED_SHADERS`  | GLint     | Number of attached shaders (`0`, `1` or `2`) |\n| `GL.ACTIVE_ATTRIBUTES` | GLint     | Number of active attribute variables to a program |\n| `GL.ACTIVE_UNIFORMS`   | GLint     | Number of active attribute variables to a program |\n| `GL.TRANSFORM_FEEDBACK_BUFFER_MODE`  | GLenum |  (WebGL2) Buffer capture mode, `GL.SEPARATE_ATTRIBS` or `GL.INTERLEAVED_ATTRIBS` |\n| `GL.TRANSFORM_FEEDBACK_VARYINGS`     | GLint  | (WebGL2) Number of varying variables to capture in transform feedback mode. |\n| `GL.ACTIVE_UNIFORM_BLOCKS`           | GLint  | (WebGL2) Number of uniform blocks containing active uniforms. |\n","slug":"docs/api-reference/webgl/program","title":"Program"},{"excerpt":"VertexArrayObject The WebGL  object holds a map of \"buffers\" that will be made available as input data to shaders during a draw call…","rawMarkdownBody":"# VertexArrayObject\n\nThe WebGL `VertexArrayObject` object holds a map of \"buffers\" that will be made available as input data to shaders during a draw call, similar to how a `TransformFeedback` object holds a set of `Buffer` instances that will receive output data from shaders.For `Buffer` objects, the `VertexArrayObject` also stores some additional information about how that data in the buffer should be accessed, such as offsets, strides, etc.\n\nHowever, the use of `VertexArrayObject` is problematic in WebGL1. While it is crucial for the operation of a program, its presence under WebGL1 is dependent on an [extension](https://webglstats.com/webgl/extension/OES_vertex_array_object) that is fairly common, but not universally available. In particular it is not available in headless gl which is essential for running tests under Node.js.\n\nTherefore, in basic WebGL environments where the `VertexArrayObject` is not supported, luma.gl ensures that one (\"fake\") instance of the `VertexArrayObject` class can still be obtained, emulating the default (`null` handle) `VertexArrayObject`. This instance has the `isDefaultArray` flag set, and applications can adapt their behavior accordingly, while still using the same API to manage vertex attributes, albeit with a small performance loss. Since there is a considerable amount of work required to handle both cases, luma.gl also provides a higher level `VertexArray` class that works around these issues and provided additional conveniences.\n\n> It is usually not necessary to create neither `VertexArrayObject` nor `VertexArray` instances in luma.gl applications. It is often simpler to just provides attributes directly to the [`Model`](/docs/api-reference/core/model.md) class. Still, it can be useful to review this documentation to understand how attributes are handled by WebGL.\n\nFor more information on WebGL `VertexArrayObject`s, see the [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Vertex_Specification#Vertex_Array_Object).\n\n\n## Usage\n\nImport the `VertexArrayObject` class so that your app can use it:\n\n```js\nimport {VertexArrayObject} from '@luma.gl/core';\n```\n\nGetting the global `VertexArrayObject` for a WebGL context\n\n```js\nconst vertexArray = VertexArray.getDefaultArray(gl);\n```\n\nCreate a new VertexArray\n\n```js\nconst vao = new VertexArray(gl);\n}\n```\n\nAdding attributes to a VertexArray\n\n```js\nconst vertexArray = new VertexArray(gl);\nvertexArray.setBuffer(location, buffer);\n```\n\nDeleting a VertexArray\n\n```js\nvertexArrayObject.delete();\n```\n\nSetting a constant vertex attribute\n\n```js\nimport {VertexArray} from '@luma.gl/core';\nconst vao = new VertexArray(gl);\nvao.setConstant(0, [0, 0, 0]);\n```\n\n## Methods\n\n`VertexArrayObject` inherits from `Resource`.\n\n\n### VertexArray(gl : WebGLRenderingContext, props : Object)\n\nCreates a new VertexArray\n\n* `props` (Object) - passed through to `Resource` superclass constructor and to `initialize`\n\n\n### VertexArray.getDefaultArray() : VertexArray\n\nReturns the \"global\" `VertexArrayObject`.\n\nNote: The global `VertexArrayObject` object is always available. Binds the `null` VertexArrayObject.\n\n\n### initialize(props : Object) : VertexArray\n\nReinitializes a `VertexArrayObject`.\n\n* `attributes`=`{}` (`Object`) - map of attributes, can be keyed by index or names, can be constants (small arrays), `Buffer`, arrays or typed arrays of numbers, or attribute descriptors.\n* `elements`=`null` (`Buffer`) - optional buffer representing elements array (i.e. indices)\n* `program` - Transfers information on vertex attribute locations and types to this vertex array.\n\n\n### setConstant(values : Array) : VertexArray\n\nSets a constant value for a vertex attribute. When this `VertexArrayObject` is used in a `Program.draw()` call, all Vertex Shader invocations will get the same value.\n\n`VertexArray.setConstant(location, array);`\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `location` (*GLuint*) - index of the attribute\n\nWebGL APIs:\n[vertexAttrib4[u]{f,i}v](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/vertexAttrib)\n\n\n### setBuffer(nameOrLocation, buffer : Buffer [, accessor : Object]) : VertexArray\n\nBinds the specified attribute in this vertex array to the supplied buffer\n\n* Set a location in vertex attributes array to a buffer, specifying\n* its data layout and integer to float conversion and normalization flags\n\n`setBuffer(location, buffer);`\n`setBuffer(location, buffer, {offset = 0, stride = 0, normalized = false, integer = false});`\n\n* `location` (*GLuint* | *String*) - index/ordinal number of the attribute\n* `buffer` (*WebGLBuffer*|*Buffer*) - WebGL buffer to set as value\n\n[gl.vertexAttrib{I}Pointer](), [gl.vertexAttribDivisor](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/vertexAttribDivisor)\n\n\n### getParameter(pname, location) : *\n\nQueries a vertex attribute location.\n\n* `pname` (GLenum) - Which parameter to query. See table of parameter constants below for values.\n* **location** (*Number*) - index of attributes\n\nNote that in WebGL queries are generally slow and should be avoided in performance critical code sections.\n\n\n## Types, Constants, Enumarations\n\n\n### getParameter Constants\n\n| Parameter                           | Type         | Value |\n| ---                                 | ---          | ---   |\n| `GL.VERTEX_ATTRIB_ARRAY_BUFFER_BINDING` | `WebGLBuffer` (not `Buffer`) | Get currently bound buffer |\n| `GL.VERTEX_ATTRIB_ARRAY_ENABLED`    | `GLboolean`  | true if the vertex attribute at this index is enabled |\n| `GL.VERTEX_ATTRIB_ARRAY_SIZE`       | `GLint`      | indicating the size of an element of the vertex array. |\n| `GL.VERTEX_ATTRIB_ARRAY_STRIDE`     | `GLint`      | indicating the number of bytes between successive elements in  |the array. 0 means that the elements are sequential.\n| `GL.VERTEX_ATTRIB_ARRAY_TYPE`       | `GLenum`     | The array type. One of\n`GL.BYTE`, `GL.UNSIGNED_BYTE`, `GL.SHORT`, `GL.UNSIGNED_SHORT`, `GL.FIXED`, `GL.FLOAT`. |\n| `GL.VERTEX_ATTRIB_ARRAY_NORMALIZED` | `GLboolean`  | true if fixed-point data types are normalized for the vertex attribute array at the given index. |\n| `GL.CURRENT_VERTEX_ATTRIB`          | `Float32Array(4)` | The current value of the vertex attribute at the given index. |\nWhen using a WebGL 2 context, the following values are available additionally:\n| `GL.VERTEX_ATTRIB_ARRAY_INTEGER`    | `GLboolean`  | true if an integer data type is in the vertex attribute array at the given index. |\n| `GL.VERTEX_ATTRIB_ARRAY_DIVISOR`    | `GLint`      | The frequency divisor used for instanced rendering. |\n\n\n## Attribute Accessors\n\nWhen setting `Buffer` attributes, additional data can be provided to specify how the buffer should be accessed. This data can be stored directly on the `Buffer` accessor or supplied to `.setBuffer`.\n\n* `target`=`buffer.target` (*GLuint*, ) - which target to bind to\n* `size` (*GLuint*)  - number of values (components) per element (1-4)\n* `type` (*GLuint*)  - type of values (e.g. gl.FLOAT)\n* `normalized` (*boolean*, false) - normalize integers to [-1,1] or [0,1]\n* `integer` (*boolean*, false) - `WebGL2` disable int-to-float conversion\n* `stride` (*GLuint*, 0) - supports strided arrays\n* `offset` (*GLuint*, 0) - supports strided arrays\n* `layout.normalized`=`false` (GLbool) - normalize integers to [-1,1], [0,1]\n* `layout.integer`=`false` (GLuint) - WebGL2 only, disable int-to-float conv.\n\n* `divisor` - Sets the frequency divisor used for instanced rendering (instances that pass between updates of attribute). Usually simply set to 1 or 0 to enable/disable instanced rendering. 0 disables instancing, >=1 enables it.\n\nNotes:\n\n* The application can enable normalization by setting the `normalized` flag to `true` in the `setBuffer` call.\n* **WebGL2** The application can disable integer to float conversion when running under WebGL2, by setting the `integer` flag to `true`.\n* [`glVertexAttribIPointer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/vertexAttribIPointer) specifies *integer* data formats and locations of vertex attributes. Values are always left as integer values. Only accepts the integer types gl.BYTE, gl.UNSIGNED_BYTE, gl.SHORT, gl.UNSIGNED_SHORT, gl.INT, gl.UNSIGNED_INT\n\nNotes about Instanced Rendering\n\n* About setting `divisor` in attributes: Instanced attributes requires WebGL2 or a (widely supported) WebGL1 extension. Apps can use the luma.gl feature detection system to determine if instanced rendering is available, though the extension is so ubiquitously supported that many apps just make the assumption: [instanced_arrays](https://webglstats.com/webgl/extension/ANGLE_instanced_arrays).\n* An attribute is referred to as **instanced** if its divisor value is non-zero.\n* The divisor modifies the rate at which vertex attributes advance when rendering multiple instances of primitives in a single draw call.\n* If divisor is zero, the attribute at slot index advances once per vertex.\n* If divisor is non-zero, the attribute advances once per divisor instances of the set(s) of vertices being rendered.\n\n\n","slug":"docs/api-reference/webgl/vertex-array-object","title":"VertexArrayObject"},{"excerpt":"VertexArray The  class (like its lower level counterpart, the ) manages an \"array\" of values (\"buffers\") that will be made available as…","rawMarkdownBody":"# VertexArray\n\nThe `VertexArray` class (like its lower level counterpart, the `VertexArrayObject`) manages an \"array\" of values (\"buffers\") that will be made available as input data to shaders during a draw call. For each WebGL `Buffer`, the `VertexArray` also stores some additional information about how that data in the buffer should be accessed, such as offsets, strides, etc, and whether the attribute is instanced.\n\nThe `VertexArray` class provides the following features on top of the lower level `VertexArrayObject` class:\n\n* Reads a \"program configuration\", enabling attributes to be set using names instead of locations\n* Avoids duplicating information already specified in shaders, such as size and type of attributes.\n* Automatic deduction of draw parameters from currently set attributes\n* Handles the \"constant attribute 0\" complication that is common on desktop WebGL browsers.\n* Can generated debug output of attribute bank\n\n* Can fall back to sharing single `VertexArrayObject` across all `VertexArray` objects.\n\n> The `VertexArray` is a wrapper class around the `VertexArrayObject` class which encapsulates the underlying WebGL object. The `VertexArrayObject` class has a number of complications that the `VertexArray` takes care of.\n\n> It is usually not necessary to create `VertexArray` instances in luma.gl applications. The application can just supply a map of `attributes` to the [`Model`](/docs/api-reference/core/model.md) class, and rely on that class to automatically manage the vertex attributes array and supply it to any draw calls (e.g. when rendering, picking etc). Still, it can be useful to review this documentation to better understand how attributes are handled.\n\nFor more information on the WebGL `VertexArrayObject`, see the [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Vertex_Specification#Vertex_Array_Object).\n\n\n## Usage\n\nImport the `VertexArray` class so that your app can use it:\n\n```js\nimport {VertexArray} from '@luma.gl/core';\n```\n\nCreate a new VertexArray\n\n```js\nconst vao = new VertexArray(gl);\n}\n```\n\nDeleting a VertexArray\n\n```js\nvertexArrayObject.delete();\n```\n\nAdding attributes to a VertexArray: without program metadata, buffers must be specified using location indices\n\n```\nconst vertexArray2 = new VertexArray(gl);\nvertexArray2.setBuffers({\n  0: new Buffer({data: new Float32Array([...]), ...})\n});\n```\n\nAdding attributes to a VertexArray: adding a program configuration enables setting attributes by name\n\n```js\n// Register attribute info extracted from program shaders\nconst program = new Program(gl, ...);\nconst vertexArray = new VertexArray(gl, {program});\n\n// Now it is possible to set buffers using attribute names\nvertexArray.setAttributes({\n  aColor: new Buffer(gl, new Uint8Array([...]))\n});\n\nSetting a set of attributes and an elements array\n\n```js\nconst vertexArray = new VertexArray(gl, {\n  attributes: {\n    elements: new Buffer(gl, {target: GL.ELEMENT_ARRAY_BUFFER, data: new Uint32Array([...])}),\n  \tpositions: new Buffer(gl, {data: new Float32Array([...])})\n  }\n}\n\nSetting a constant vertex attribute\n\n```js\nimport {VertexArray} from '@luma.gl/core';\nconst vao = new VertexArray(gl);\nvao.setConstant(0, [0, 0, 0]);\n```\n\n## Constructor\n\n### VertexArray(gl : WebGLRenderingContext, props : Object)\n\nCreates a new VertexArray\n\n* `props` (Object) - passed through to `Resource` superclass constructor and to `initialize` it.\n\n\n## Methods\n\n### initialize(props : Object) : VertexArray\n\nReinitializes a `VertexArray`.\n\n* `attributes`=`{}` (`Object`) - map of attributes, can be keyed by index or names, can be constants (small arrays), `Buffer`, arrays or typed arrays of numbers, or attribute descriptors.\n* `elements`=`null` (`Buffer`) - optional buffer representing elements array (i.e. indices)\n* `program` - Transfers information on vertex attribute locations and types to this vertex array.\n\n\n### setAttributes(attributes : Object) : VertexArray\n\nSets named uniforms from a map.\n\n```js\nprogram.setAttributes(attributes : Object);\n```\n\n* `attributes` - (*object*) An object with key value pairs matching a buffer name and its value respectively.\n\nAttributes is an object with key-value pairs: `{nameOrLocation: value, ....}`.\n\n* `nameOrLocation` - (*string|number*) The name of the attribute as declared in the shader, or the location specified by a layout qualifier in the shader. The name can contain an offset to the actual location in the format of `name__LOCATION_0`. This is useful for setting *mat* type attributes. See the section at the bottom for more details.\n* `value` - (*Buffer|Array|typed array*) An attribute value must be a `Buffer` or a typed array.\n\nEach value can be an a `Buffer`, an `Array` starting with a `Buffer` or a typed array.\n\n* Typed Array - Sets a constant value as if `.setConstant(value)`  was called.\n* `Buffer` - Binds the atttribute to a buffer, using buffer's accessor data as if `.setBuffer(value)` was called.\n* `Array` - Binds the atttribute to a buffer, with extra accessor data overrides. Expects a two element array with `[buffer : Buffer, accessor : Object]`. Binds the attribute to the buffer as if ` .setBuffer(buffer, accessor)` was called.\n\n\n### setConstant(value : Array  [, accessor : Object]) : VertexArray\n\nSets a constant value for a vertex attribute. When this `VertexArray` is used in a `Program.draw()` call, all Vertex Shader invocations will get the same value.\n\n`VertexArray.setConstant(location, array);`\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `location` (*GLuint*) - index of the attribute\n\nWebGL APIs:\n[vertexAttrib4[u]{f,i}v](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/vertexAttrib)\n\n\n### setBuffer(nameOrLocation, buffer : Buffer [, accessor : Object]) : VertexArray\n\nBinds the specified attribute in this vertex array to the supplied buffer\n\n* Set a location in vertex attributes array to a buffer, specifying\n* its data layout and integer to float conversion and normalization flags\n\n`setBuffer(location, buffer);`\n`setBuffer(location, buffer, {offset = 0, stride = 0, normalized = false, integer = false});`\n\n* `location` (*GLuint* | *String*) - index/ordinal number of the attribute\n* `buffer` (*WebGLBuffer*|*Buffer*) - WebGL buffer to set as value\n\n[gl.vertexAttrib{I}Pointer](), [gl.vertexAttribDivisor](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/vertexAttribDivisor)\n\n\n### setElementBuffer(buffer : Buffer [, accessor : Object]) : VertexArray\n\nBinds the supplied buffer as index buffer (`GL.ELEMENT_ARRAY_BUFFER`).\n\n\n## Attribute Accessors\n\nWhen setting `Buffer` attributes, additional data can be provided to specify how the buffer should be accessed. This data can be stored directly on the `Buffer` accessor or supplied to `.setBuffer`.\n\n* `target`=`buffer.target` (*GLuint*, ) - which target to bind to\n* `size` (*GLuint*)  - number of values (components) per element (1-4)\n* `type` (*GLuint*)  - type of values (e.g. gl.FLOAT)\n* `normalized` (*boolean*, false) - normalize integers to [-1,1] or [0,1]\n* `integer` (*boolean*, false) - `WebGL2` disable int-to-float conversion\n* `stride` (*GLuint*, 0) - supports strided arrays\n* `offset` (*GLuint*, 0) - supports strided arrays\n* `layout.normalized`=`false` (GLbool) - normalize integers to [-1,1], [0,1]\n* `layout.integer`=`false` (GLuint) - WebGL2 only, disable int-to-float conv.\n\n* `divisor` - Sets the frequency divisor used for instanced rendering (instances that pass between updates of attribute). Usually simply set to 1 or 0 to enable/disable instanced rendering. 0 disables instancing, >=1 enables it.\n\n\n## Notes about Integer Attributes\n\n* The application can enable normalization by setting the `normalized` flag to `true` in the `setBuffer` call.\n* **WebGL2** The application can disable integer to float conversion when running under WebGL2, by setting the `integer` flag to `true`.\n* [`glVertexAttribIPointer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/vertexAttribIPointer) specifies *integer* data formats and locations of vertex attributes. Values are always left as integer values. Only accepts the integer types gl.BYTE, gl.UNSIGNED_BYTE, gl.SHORT, gl.UNSIGNED_SHORT, gl.INT, gl.UNSIGNED_INT\n\n\n## Notes about Instanced Rendering\n\n* About setting `divisor` in attributes: Instanced attributes requires WebGL2 or a (widely supported) WebGL1 extension. Apps can use the luma.gl feature detection system to determine if instanced rendering is available, though the extension is so ubiquitously supported that many apps just make the assumption: [instanced_arrays](https://webglstats.com/webgl/extension/ANGLE_instanced_arrays).\n* An attribute is referred to as **instanced** if its divisor value is non-zero.\n* The divisor modifies the rate at which vertex attributes advance when rendering multiple instances of primitives in a single draw call.\n* If divisor is zero, the attribute at slot index advances once per vertex.\n* If divisor is non-zero, the attribute advances once per divisor instances of the set(s) of vertices being rendered.\n\n## Notes about setting *mat* type attributes\n\n* Setting a **mat** type in the shader requires to manually add an *offset* to the location.\n* This can be done by using special name format `name__LOCATION_0`. This will add 0 to the *LOCATION* resulting in no change. `name__LOCATION_1` will add **1**.\n* For example:\n  * if we have the following declaration in the shader:\n```\nattribute mat4 matrix;\n```\n  * We should specify `matrix__LOCATION_0`, `matrix__LOCATION_1`, `matrix__LOCATION_2` **and** `matrix__LOCATION_3` as *vec4*.\n","slug":"docs/api-reference/webgl/vertex-array","title":"VertexArray"},{"excerpt":"glfx Shader Modules Screen space effects packaged as reusable shader modules in  based on the glfx library. Attribution / License This is a…","rawMarkdownBody":"# glfx Shader Modules\n\n\nScreen space effects packaged as reusable shader modules in `@luma.gl/effects` based on the [glfx library](http://evanw.github.io/glfx.js/).\n\n\n## Attribution / License\n\nThis is a repackaging of shader code from [Evan Wallace](https://github.com/evanw/glfx.js)'s glfx library.\n\nThe code and documentation is included here under MIT license.\n\n## Usage\n\nImport brightnessContrast shader module\n\n```js\n    import {brightnessContrast} from '@luma.gl/effects';\n```\n\n## Shader Modules\n\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/mountain.jpg\" />\n        <p><i>Original Image</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### brightnessContrast\n\nProvides additive brightness and multiplicative contrast control.\n\n* `brightness` -1 to 1 (-1 is solid black, 0 is no change, and 1 is solid white). Default value is `0`.\n* `contrast`   -1 to 1 (-1 is solid gray, 0 is no change, and 1 is maximum contrast). Default value is `0`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/brightness.jpg\" />\n        <p><i>Brightness / Contrast Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### hueSaturation\n\nProvides rotational hue and multiplicative saturation control. RGB color space can be imagined as a cube where the axes are the red, green, and blue color values.\n\nHue changing works by rotating the color vector around the grayscale line, which is the straight line from black (0, 0, 0) to white (1, 1, 1).\n\nSaturation is implemented by scaling all color channel values either toward or away from the average color channel value.\n\n* `hue` -1 to 1 (-1 is 180 degree rotation in the negative direction, 0 is no change, and 1 is 180 degree rotation in the positive direction). Default value is `0`.\n* `saturation` -1 to 1 (-1 is solid gray, 0 is no change, and 1 is maximum contrast). Default value is `0`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/hue.jpg\" />\n        <p><i>Hue / Saturation Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### noise\n\nAdds black and white noise to the image.\n\n* `amount`   0 to 1 (0 for no effect, 1 for maximum noise). Default value is `0.5`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/noise.jpg\" />\n        <p><i>Noise Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### sepia\n\n\nGives the image a reddish-brown monochrome tint that imitates an old photograph.\n\n* `amount` 0 to 1 (0 for no effect, 1 for full sepia coloring). Default value is `0.5`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/sepia.jpg\" />\n        <p><i>Sepia Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### vibrance\n\nModifies the saturation of desaturated colors, leaving saturated colors unmodified.\n\n* `amount` -1 to 1 (-1 is minimum vibrance, 0 is no change, and 1 is maximum vibrance). Default value is `0`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/vibrance.jpg\" />\n        <p><i>Vibrance Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### vignette\n\nAdds a simulated lens edge darkening effect.\n\n* `size`     0 to 1 (0 for center of frame, 1 for edge of frame). Default value is `0.5`.\n* `amount`   0 to 1 (0 for no effect, 1 for maximum lens darkening). Default value is `0.5`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/vignette.jpg\" />\n        <p><i>Vignette Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### tiltShift\n\nSimulates the shallow depth of field normally encountered in close-up photography, which makes the scene seem much smaller than it actually is. This filter assumes the scene is relatively planar, in which case the part of the scene that is completely in focus can be described by a line (the intersection of the focal plane and the scene). An example of a planar scene might be looking at a road from above at a downward angle. The image is then blurred with a blur radius that starts at zero on the line and increases further from the line.\n\n * `start`          [x, y] coordinate of the start of the line segment. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0, 0]`.\n * `end`            [x, y] coordinate of the end of the line segment. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[1, 1]`.\n * `blurRadius`     The maximum radius of the pyramid blur in pixels. Default value is `15`.\n * `gradientRadius` The distance in pixels from the line at which the maximum blur radius is reached. Default value is `200`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/tilt_shift.jpg\" />\n        <p><i>Tilt Shift Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### triangleBlur\n\nThis is the most basic blur filter, which convolves the image with a pyramid filter. The pyramid filter is separable and is applied as two perpendicular triangle filters.\n\n* `radius` The radius of the pyramid in pixels convolved with the image. Default value is `20`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/triangle_blur.jpg\" />\n        <p><i>Triangle Blur Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### zoomBlur\n\nBlurs the image away from a certain point, which looks like radial motion blur.\n\n* `center`  [x, y] coordinate of the blur origin. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `strength` The strength of the blur. Values in the range 0 to 1 are usually sufficient, where 0 doesn't change the image and 1 creates a highly blurred image. Default value is `0.3`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/zoom_blur.jpg\" />\n        <p><i>Zoom Blur Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n###  colorHalftone\n\n Simulates a CMYK halftone rendering of the image by multiplying pixel values with a four rotated 2D sine wave patterns, one each for cyan, magenta, yellow, and black.\n\n* `center` [x, y] coordinate of the pattern origin. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `angle`  The rotation of the pattern in radians. Default value is `1.1`.\n* `size`   The diameter of a dot in pixels. Default value is `4`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/color_halftone.jpg\" />\n        <p><i>Color Halftone Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### dotScreen\n\nSimulates a black and white halftone rendering of the image by multiplying pixel values with a rotated 2D sine wave pattern.\n\n* `center`  [x, y] coordinate of the pattern origin. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `angle`   The rotation of the pattern in radians. Default value is `1.1`.\n* `size`    The diameter of a dot in pixels. Default value is `3`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/dot_screen.jpg\" />\n        <p><i>Dot Screen Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### edgeWork\n\nPicks out different frequencies in the image by subtracting two copies of the image blurred with different radii.\n\n* `radius` The radius of the effect in pixels. Default value is `2`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/edge_work.jpg\" />\n        <p><i>Edge Work Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### hexagonalPixelate\n\nRenders the image using a pattern of hexagonal tiles. Tile colors are nearest-neighbor sampled from the centers of the tiles.\n\n* `center` [x, y] coordinate of the pattern center. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `scale`  The width of an individual tile in pixels. Default value is `10`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/hexagon.jpg\" />\n        <p><i>Hexagonal Pixelate Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### ink\n\nSimulates outlining the image in ink by darkening edges stronger than a certain threshold. The edge detection value is the difference of two copies of the image, each blurred using a blur of a different radius.\n\n* `strength` The multiplicative scale of the ink edges. Values in the range 0 to 1 are usually sufficient, where 0 doesn't change the image and 1 adds lots of black edges. Negative strength values will create white ink edges instead of black ones. Default value is `0.25`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/ink.jpg\" />\n        <p><i>Ink Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### bulgePinch\n\nBulges or pinches the image in a circle.\n\n* `center`  [x, y] coordinate of the center of the circle of effect. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `radius`  The radius of the circle of effect in pixels. Default value is `200`.\n* `strength` -1 to 1 (-1 is strong pinch, 0 is no effect, 1 is strong bulge). Default value is `0.5`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/bulge_pinch.jpg\" />\n        <p><i>Bulge Pinch Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### swirl\n\nWarps a circular region of the image in a swirl.\n\n* `center` [x, y] coordinate of the center of the circular region. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `radius` The radius of the circular region in pixels. Default value is `200`.\n* `angle`  The angle in radians that the pixels in the center of the circular region will be rotated by. Default value is `3`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/swirl.jpg\" />\n        <p><i>Swirl Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## Remarks\n\n* Coordinate is based on the original image. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner.\n","slug":"docs/api-reference/effects/glfx-shader-modules","title":"glfx Shader Modules"},{"excerpt":"AnimationLoop Manages an animation loop and optionally a WebGL context and a WebGL canvas. It provides a number of features related to…","rawMarkdownBody":"# AnimationLoop\n\nManages an animation loop and optionally a WebGL context and a WebGL canvas. It provides a number of features related to initialization and animation of a WebGL context.\n\n* Provides a number of commonly needed variables as part of the `context` object which is passed to `onRender` and `onFinalize` callbacks.\n* Objects returned by `onInitialize` will be appended to `context` object hence available to `onRender` and `onFinalize`.\n* To avoid problems with page load timing, move context creation to the `onCreateContext` method.\n* By default, `onRender` method manages resizing of canvas, viewport and framebuffer.\n* Makes it easy to wait for the HTML page to load before creating a canvas and WebGL resources.\n\nReferences:\n\n* [WebGL Fundamentals](https://webglfundamentals.org/webgl/lessons/webgl-anti-patterns.html#drawingbuffer) contains excellent information on the subtleties of the how the WebGL context's drawing buffer and the HTML canvas interact.\n* When running in the browser, this class uses [`requestAnimationFrame`](https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame)\n\n\n## Usage\n\nAutocreates a canvas/context\n```js\nimport {AnimationLoop, ClipSpace} from '@luma.gl/core';\n\nconst animationLoop = new AnimationLoop({\n  onInitialize({gl}) {\n    // Keys in the object returned here will be available in onRender\n    return {\n      clipSpaceQuad: new ClipSpace({gl, fs: FRAGMENT_SHADER})\n    };\n  },\n  onRender({tick, clipSpaceQuad}) {\n    // Tick is autoupdated by AnimationLoop\n    clipSpaceQuad.setUniforms({uTime: tick * 0.01}).draw();\n  }\n});\n\nanimationLoop.start();\n```\n\nUse a canvas in the existing DOM through its HTML id\n```js\nanimationLoop.start({canvas: 'my-canvas'});\n```\n\n## Methods\n\n### constructor(props : Object)\n\n```js\nnew AnimationLoop({\n  onCreateContext,\n  onInitialize,\n  onFinalize,\n  onRender,\n\n  autoResizeViewport,\n  autoResizeDrawingBuffer\n});\n```\n\n* `props.onCreateContext`=`null` (callback) - function without parameters that returns a `WebGLRenderingContext`. This callback will be called exactly once, after page load completes.\n* `props.onInitialize` (callback) - if supplied, will be called once after first `start()` has been called, after page load completes and a context has been created.\n* `props.onRender`=`null` (callback) - Called on every animation frame.\n* `props.onFinalize`=`null` (callback) - Called once when animation is stopped. Can be used to delete objects or free any resources created during `onInitialize`.\n* `props.autoResizeViewport`=`true` - If true, calls `gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight)` each frame before `onRender` is called. Set to false to control viewport size.\n* `props.autoResizeDrawingBuffer`=`true` - If true, checks the canvas size every frame and updates the drawing buffer size if needed.\n* `props.useDevicePixels` - Whether to use `window.devicePixelRatio` as a multiplier, e.g. in `autoResizeDrawingBuffer` etc. Refer to `Experimental API` section below for more use cases of this prop.\n* `props.gl`=`null` (WebGLContext) - If supplied, will render into this external context instead of creating a new one.\n* `props.glOptions`=`{}` (object) - Options to create the WebGLContext with. See [createGLContext](/docs/api-reference/webgl/context/context.md).\n* `props.debug`=`false` (bool) - Enable debug mode will provide more validations and error messages, but less performant.\n* `props.createFramebuffer`=`false` (bool) - If true, will make a `framebuffer` (FrameBuffer) parameter available to `onInitialize` and `onRender` callbacks.\n\n\n### start([options : Object]) : AnimationLoop\n\nRestarts the animation\n\n`animationLoop.start(options)`\n\n* `options`=`{}` (object) - Options to create the WebGLContext with. See [createGLContext](/docs/api-reference/webgl/context/context.md).\n\n### stop() : AnimationLoop\n\nStops the animation\n\n`animationLoop.stop()`\n\n### waitForRender() : Promise\n\nReturns a promise which resolves in the next frame after rendering and the `onRender` callback have completed.\n\n```js\nconst loop = await animationLoop.waitForRender()\n// can now read pixels from webgl context\nloop.gl.readPixels(...)\n```\n\n### redraw() : AnimationLoop\n\nImmediately invokes a redraw (call `onRender` with updated animation props). Only use if the canvas must be updated synchronously.\n\n### setNeedsRedraw(reason : String) : AnimationLoop\n\n`animationLoop.setNeedsRedraw(reason)`\n\n* `reason` (`String`) - A human readable string giving a hint as to why redraw was needed (e.g. \"geometry changed\").\n\nIf set, the value will be provided as the `needsRedraw` field to the `onRender` callback.\n\nNotes:\n* `onRender` will be called for each animation frame regardless of whether this flag is set, and the redraw reason is automatically cleared.\n* If called multiple times, the `reason` provided in the first call will be remembered.\n* `AnimationLoop` automatically sets this flag if the WebGL context's drawing buffer size changes.\n\n\n### setProps(props : Object) : AnimationLoop\n\n`animationLoop.setProps({...props})`\n\n* `props.autoResizeViewport` - Call `gl.viewport` before each call to `onRender()`\n* `props.autoResizeDrawingBuffer` - Update the drawing buffer size to match the canvas size before each call to `onRender()`\n* `props.useDevicePixels` - Whether to use `window.devicePixelRatio` as a multiplier, e.g. in `autoResizeDrawingBuffer` etc.\n\n### attachTimeline(timeline: Timeline)\n\nAttach an `Timeline` object to the animation loop. Allows time produced for animations to be paused, played, etc. See `Timeline` documentation for more info.\n\n\n### detachTimeline()\n\nDetach the currently attached timeline from the animation loop.\n\n\n### toDataURL\n\nReturns returns a `Promise` that resolves to the data URL of the canvas once drawing operations are complete for the current frame. The data URL can be used as the `src` for an HTML image element.\n\n`animationLoop.toDataURL()`\n\n\n## Callback Parameters\n\nThe callbacks `onInitialize`, `onRender` and `onFinalize` that the app supplies to the `AnimationLoop`, will be called with an object containing named parameters:\n\n| Parameter | Type | Description |\n| ---       | ---  | --- |\n| `_animationLoop` | `AnimationLoop` | (**experimental**) The calling `AnimationLoop` instance |\n| `gl`      | `WebGLRenderingContext` | This `AnimationLoop`'s gl context. |\n| `canvas`  | `HTMLCanvasElement` or `OffscreenCanvas` | The canvas associated with this context. |\n| `width`   | The drawing buffer width, in \"device\" pixels (can be different from canvas.width). |\n| `height`  | The drawing buffer height, in \"device\" pixels (can be different from canvas.width). |\n| `aspect`  | The canvas aspect ratio (width/height) to update projection matrices |\n| `useDevicePixels` | Boolean indicating if canvas is utilizes full resolution of Retina/\n| `needsRedraw` | `String` | Redraw flag (will be automatically set if drawingBuffer resizes) |\n| `time`    | `Number` | Milliseconds since `AnimationLoop` was created (monotonic). |\n| `tick`    | `Number` | Counter that updates for every frame rendered (monotonic). |\n| `framebuffer` | `FrameBuffer` | Availabel if `createFrameBuffer: true` was passed to the constructor. |\n| `_mousePosition` | `[x, y]` or `null` | (**experimental**) Current mouse position over the canvas. |\n| `_offScreen` | `Boolean` | (**experimental**) If the animation loop is rendering to an OffscreenCanvas. |\n| `_timeline` | `Trimeline` | (**experimental**) `Timeline` object tracking the animation timeline and channels. |\n| ...       | Any fields in the object that was returned by the `onInitialize` method. |\n\n### Frame timers\n* The animation loop tracks GPU and CPU render time of each frame the in member properties `cpuTime` and `gpuTime`. If `gpuTime` is set to `-1`, then the timing for the last frame was invalid and should not be used (this rare and might occur, for example, if the GPU was throttled mid-frame).\n\n\n## Experimental API (`useDevicePixels`)\n\n`useDevicePixels` can accept a custom ratio (Number), instead of `true` or `false`. This allows rendering to a much smaller or higher resolutions. When using high value (usually more than device pixel ratio), it is possible it can get clamped down, this happens due to system memory limitation, in such cases a warning will be logged to the browser console. For additional details check device pixels [`document`]((/docs/api-reference/webgl/device-pixels.md)).\n\n## Remarks\n\n* You can instantiate multiple `AnimationLoop` classes in parallel, rendering into the same or different `WebGLRenderingContext`s.\n* Works both in browser and under Node.js.\n* All `AnimationLoop` methods can be chained.\n* Postpones context creation until the page (i.e. all HTML) has been loaded. At this time it is safe to specify canvas ids when calling [`createGLContext`](/docs/api-reference/webgl/context/context.md).\n* The supplied callback function must return a WebGLRenderingContext or an error will be thrown.\n* This callback registration function should not be called if a `WebGLRenderingContext` was supplied to the AnimationLoop constructor.\n","slug":"docs/api-reference/core/animation-loop","title":"AnimationLoop"},{"excerpt":"Model A  is a subclass of  that holds a reference to a mesh with a transformation matrix that describes its position and orientation. A…","rawMarkdownBody":"# Model\n\nA `Group` is a subclass of `ScenegraphNode` that holds a reference to a mesh with a transformation matrix that describes its position and orientation.\n\nA `Model` holds all the data necessary to draw an object, e.g.:\n\n* **shaders** (via a [`Program`](/docs/api-reference/webgl/program.md) instance)\n* **uniforms** these can also reference textures.\n* **vertex attributes** (holds a [`Mesh`] or a [`Geometry`](/docs/api-reference/core/geometry.md) instance, plus any additional attributes for instanced rendering)\n\nThe `Model` class also provides the following features:\n\n* Shader Module integration: [see `Shader Modules`](/docs/developer-guide/shadertools/README.md)\n* Automatic creation of GPU `Buffer`s from typed array attributes\n* Detailed debug logging of draw calls\n* Exposes the functionality provided by the managed WebGL resources\n* Animation of uniforms\n* Detailed stats including timing of draw calls\n\n\n## Usage\n\n### Provide attribute data using Geometry object\n\nCreate model object by passing shaders, uniforms, geometry and render it by passing updated uniforms.\n\n```js\n// construct the model.\nconst model =  new Model(gl, {\n  vs: VERTEX_SHADER,\n  fs: FRAGMENT_SHADER,\n  uniforms: {uSampler: texture},\n  geometry: geometryObject,\n})\n\n// and on each frame update any uniforms (typically matrices) and call render.\nmodel\n  .setUniforms({\n    uPMatrix: currentProjectionMatrix,\n    uMVMatrix: current ModelViewMatrix\n  })\n  .draw();\n```\n\n### Provide attribute data using Buffer\n\nWhen using `Buffer` objects, data remains on GPU and same `Buffer` object can be shared between multiple models.\n\n```js\n// construct the model.\nconst model =  new Model(gl, {\n  vs: VERTEX_SHADER,\n  fs: FRAGMENT_SHADER,\n  uniforms: {uSampler: texture},\n  attributes: {\n    attributeName1: bufferObject,\n    attributeName2: [new Buffer(gl, new Float32Array(...)), {size: 3, type: GL.FLOAT}]\n  }\n  drawMode: gl.TRIANGLE_FAN,\n  vertexCount: 3,\n})\n\n// and on each frame update any uniforms (typically matrices) and call render.\nmodel\n  .setUniforms({\n    uPMatrix: currentProjectionMatrix,\n    uMVMatrix: current ModelViewMatrix\n  })\n  .draw();\n```\n\n### Provide attribute data using VertexArray object\n\nA `VertexArray` object can be build and passed to `Model.draw()` to provide attribute data. Attribute data can be changed by changing `VertexArray` object.\n\n```js\n// construct the model.\nconst model =  new Model(gl, {\n  vs: VERTEX_SHADER,\n  fs: FRAGMENT_SHADER,\n  uniforms: {uSampler: texture},\n  drawMode: gl.TRIANGLE_FAN,\n  vertexCount: 3,\n})\n\nconst ATTRIBUTE1_LOCATION = 0;\nconst ATTRIBUTE2_LOCATION = 1;\nconst vertexArray1 = new VertexArray(gl, {\n  buffers: {\n    [ATTRIBUTE1_LOCATION]: buffer1,\n    [ATTRIBUTE2_LOCATION]: buffer2\n  }\n});\nconst vertexArray2 = new VertexArray(gl, {\n  buffers: {\n    [ATTRIBUTE1_LOCATION]: buffer3,\n    [ATTRIBUTE2_LOCATION]: buffer4\n  }\n});\n\n//Render using attribute data from vertexArray1.\nmodel.draw({\n  uniforms: {\n    uPMatrix: currentProjectionMatrix,\n    uMVMatrix: currentModelViewMatrix\n  },\n  vertexArray: vertexArray1\n});\n\n// Switch attribute data to vertexArray2\nmodel.draw({\n  uniforms: {\n    uPMatrix: currentProjectionMatrix,\n    uMVMatrix: currentModelViewMatrix\n  },\n  vertexArray: vertexArray2\n});\n```\n\n## Properties\n\n`Model` extends the `BaseModel` class and inherits all properties from that class.\n\n\n### moduleSettings : Object\n\nany uniforms needed by shader modules.\n\n\n### uniforms : Object\n\nuniform values to be used for drawing.\n\n\n### onBeforeRender\n\nfunction to be called before every time this model is drawn.\n\n\n### onAfterRender\n\nfunction to be called after every time this model is drawn.\n\n\n### mesh\n\n`Mesh` instance.\n\n\n## Deprecated Properties in v7\n\n\n### geometry\n\n`Geometry` object, from which attributes, vertex count and drawing mode are deduced.\n\n\n### isInstanced : Boolean\n\ndefault value is false.\n\n\n### instanceCount : Number\n\ndefault value is 0.\n\n\n### vertexCount : Number\n\nwhen not provided will be deduced from `geometry` object.\n\n\n\n\n## Constructor\n\n### Model(gl: WebGLRenderingContext, props: Object)\n\nThe constructor for the Model class. Use this to create a new Model.\n\nThe following props can only be specified on construction:\n\n* `vs` - (VertexShader|*string*) - A vertex shader object, or source as a string.\n* `fs` - (FragmentShader|*string*) - A fragment shader object, or source as a string.\n* `varyings` (WebGL2) - An array of vertex shader output variables, that needs to be recorded (used in TransformFeedback flow).\n* `bufferMode` (WebGL2) - Mode to be used when recording vertex shader outputs (used in TransformFeedback flow). Default value is `gl.SEPARATE_ATTRIBS`.\n* `modules` - shader modules to be applied.\n* `program` - pre created program to use, when provided, vs, ps and modules are not used.\n* `shaderCache` - (ShaderCache) - Compiled shader (Vertex and Fragment) are cached in this object very first time they got compiled and then retrieved when same shader is used. When using multiple Model objects with duplicate shaders, use the same shaderCache object for better performance.\n\n\n### delete() : Model\n\nFree WebGL resources associated with this model\n\n\n## Methods\n\n### setProps(props : Object) : Model\n\nUpdates properties\n\n\n### isAnimated() : Boolean\n\nReturns `true` if the model is animated (i.e. needs to be redrawn every frame).\n\n\n### getProgram() : Program\n\nGet model's `Program` instance\n\n\n### getUniforms() : Object\n\nReturns map of currently stored uniforms\n\n### setUniforms(uniforms : Object) : Model\n\nStores named uniforms {key, value}\n\n\n### updateModuleSettings(moduleSettings : Object) : Model\n\n\n### draw(options : Object) : Model\n\nRenders the model with provided uniforms, attributes and samplers\n\n```js\nmodel.draw({\n  moduleSettings = null,\n  uniforms = {},\n  attributes = {},\n  samplers = {},\n  parameters = {},\n  settings,\n  framebuffer = null,\n  vertexArray = null,\n  transformFeedback = null\n});\n```\n\n`Model.draw()` calls `Program.draw()` but adds and extends the available parameters as follows:\n\n* `moduleSettings`=`null` (Object) - any uniforms needed by shader modules.\n* `attributes`=`{}` (Object) - attribute definitions to be used for drawing. In additions to `Buffer` and constant values, `Model`s can also accept typed arrays and attribute descriptor objects which it converts to buffers.\n* `uniforms`=`{}` (Object) - uniform values to be used for drawing. In addition to normal uniform values, `Model` can also accept function valued uniforms which will be evaluated before every draw call.\n* `animationProps` (Object) - if any function valued uniforms are set on the `Model`, `animationProps` must be provided to the draw call. The `animationProps` are passed as parameter to the uniform functions.\n\nThe remaining draw options are passed directly to `Program.draw()`:\n\n* `uniforms`=`{}` (Object) - uniform values to be used for drawing.\n* `samplers`=`{}` (Object) - texture mappings to be used for drawing.\n* `parameters`=`{}` (Object) - temporary gl settings to be applied to this draw call.\n* `framebuffer`=`null` (`Framebuffer`) - if provided, renders into the supplied framebuffer, otherwise renders to the default framebuffer.\n* `transformFeedback` - an instance `TranformFeedback` object, that gets activated for this rendering.\n* `vertexArray` - an instance of `VertexArray` object, that holds required buffer bindings for vertex shader inputs.\n\n\n### transform(options : Object) : Model\n\nRenders the model with provided uniforms, and samplers. Calls `Program.draw()` with rasterization turned off.\n\n* `discard`=`true` (Boolean) - Turns off rasterization\n* `feedbackBuffers`=`null` (Object) - Optional map of feedback buffers. A `TransformFeedback` object will be created, initialized with these buffers, and passed to `Model.draw`.\n* `unbindModels`=`[]` (Model[]) - Array of models whose VertexAttributes will be temporarily unbound during the transform feeback to avoid triggering a possible [Khronos/Chrome bug](https://github.com/KhronosGroup/WebGL/issues/2346).\n.\n\n```js\nmodel.transform({\n  discard:\n});\n```\n\n\n\n## Deprecated Methods in v7\n\n### getDrawMode() : Enum\n\nGets the WebGL drawMode\n\n\n### getVertexCount() : GLInt\n\nGets vertex count\n\nNote: might be autocalculated from `Geometry`\n\n\n### getInstanceCount() : GLInt\n\nDefaults to 0\n\n\n### getAttributes() : Object\n\nGet a map of named attributes\n\n\n### setDrawMode() : Model\n\nSets the WebGL `drawMode`.\n\n`GL.POINTS` etc.\n\n\n### setVertexCount() : Model\n\nSets the number of vertices\n\n\n### setInstanceCount() : Model\n\nHow many instances will be rendered\n\n\n### setGeometry() : Model\n\nUse a `Geometry` instance to define attribute buffers\n\n\n### setAttributes(attributes : Object) : Model\n\nSets map of attributes (passes through to [VertexArray.setAttributes](/docs/api-reference/webgl/vertex-array.md))\n\n\n## Remarks\n\n* The `Model` class is arguably the most useful class for typical applications. It manages the WebGL resources needed to perform draw calls and provide additional functionality as described below.\n","slug":"docs/api-reference/core/model","title":"Model"},{"excerpt":"Transform (WebGL2) The  class provides easy interface to perform Transform Feedback operations on given data. Applications can use this…","rawMarkdownBody":"# Transform (WebGL2)\n\nThe `Transform` class provides easy interface to perform Transform Feedback operations on given data. Applications can use this class to move data processing from CPU to GPU, where multiple parallel execution units will be used for processing. Data is handled in form of `Buffer` objects, i.e. data resides in the GPU memory. Output of this class can directly set as attributes on `Model` or `VertexArray` for regular rendering operations, CPU access is not required hence avoids expensive CPU and GPU sync.\n\n`Transform` class creates and holds `Model` and `TransformFeedback` instances.\n\nThis class is only supported when using `WebGL2RenderingContext`.\n\n\n### Use case : Specify source and destination buffers.\n\nCreate a `Transform` object by passing, vs (vertex shader), source buffer(s), varyings (output variable names in vertex shader) and destination buffers. Then call `run` to perform one transform feedback iteration.\n\n```js\nconst VS = `\\\n#version 300 es\nattribute float inValue;\nvarying float outValue;\n\nvoid main()\n{\n  outValue = 2.0 * inValue;\n}\n`;\n\nconst sourceData = new Float32Array([10, 20, 31, 0, -57]);\nconst sourceBuffer = new Buffer(gl, {data: sourceData});\n\n// Default values applied for size (1) and type (gl.FLOAT)\nconst feedbackBuffer = new Buffer(gl, {byteLength: sourceData.length * 4});\n\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inValue: sourceBuffer\n  },\n  feedbackBuffers: {\n    outValue: feedbackBuffer\n  },\n  vs: VS,\n  varyings: ['outValue'],\n  elementCount: 5\n});\n\n// Perform one transform feedback iteration\ntransform.run();\n```\n\n### Use case : Create destination buffers automatically.\n\n`Transform` can internally create destination buffers (i.e. feedback buffers), when `feedbackMap` is provided. Each destination buffer is created with same settings and layout as corresponding source buffer as per `feedbackMap`.\n\n```js\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inValue: sourceBuffer\n  },\n  feedbackMap: {\n    inValue: 'outValue'\n  },\n  vs: VS,\n  varyings: ['outValue'],\n  elementCount: 5\n});\n\n```\n### Use case : Multiple iterations using swap().\n\nWhen `feedbackMap` is specified buffers can be swapped using a single call to `swap()`, this is useful for cases like particle simulation, where output of one transform feedback iteration is piped as input to the next iteration.\n\n```js\n\n// Setup Transform with `feedbackMap` as above\n\ntransform.run();\n\nlet bufferWithNewValues = transform.getBuffer('outValue');\n...\n// Render using 'bufferWithNewValues'\n...\n\n//swap buffers\ntransform.swap();\ntransform.run();\nbufferWithNewValues = transform.getBuffer('outValue');\n...\n// Render using 'bufferWithNewValues'\n...\n```\n\n### Use case : Update one or more buffers using update() method..\n\nOnce `Transform` object is constructed and used, one or more source or destination buffers can be updated using `update`.\n\n```js\n// transform is set up as above\n...\n\n// update buffer binding for 'inValue' attribute\nconst newSourceBuffer = new Buffer(gl, {data: newSourceData});\ntransform.update({\n  sourceBuffers: {\n    inValue: newSourceBuffer\n  }\n});\n\n// now data is provided from newly bound buffer.\ntransform.run();\n```\n\n### Use case : Reading source data from texture object (Experimental)\n\nIn addition to reading data from Buffer objects, Transform can read from texture objects. Transform allows to access texture data in the same way as buffer data and internally generates required texture co-ordinates and sample instructions.\n\n```js\n// simple shader that adds data from a buffer and texture to generate new buffer.\n\nconst vs = `\\\n#version 300 es\nin float inBuffer;\nin float inTexture;\nout float outBuffer;\n\nvoid main()\n{\n  outBuffer = inTexture + inBuffer;\n}`;\n\nconst sourceBuffer = new Buffer(...);\nconst sourceTexture = new Texture2D(...);\n\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inBuffer: sourceBuffer\n  },\n  // specify source texture object using input attribute name\n  _sourceTextures: {\n    inTexture: sourceTexture\n  },\n  vs,\n  feedbackMap: {\n    inBuffer: 'outBuffer'\n  },\n  elementCount\n});\n\ntransform.run();\n\n// resulting buffer contains sum of input buffer and texture data.\nconst outData = transform.getBuffer('outBuffer').getData();\n\n```\n\n### Use case : Generating a texture object (Experimental)\n\nIn addition to reading data from a texture object, Transform can generate texture object, by rendering data into it offline. Source data can be either buffer(s), texture(s) or any combination.\n\n```js\nconst vs = `\\\n#version 300 es\nin vec4 inTexture;\nout vec4 outTexture;\n\nvoid main()\n{\n  outTexture = 2. *  inTexture;\n}\n`\nconst sourceTexture = new Texture2D(...);\nconst transform = new Transform(gl2, {\n  _sourceTextures: {\n    inTexture: sourceTexture\n  },\n  _targetTexture: 'inTexture',\n  _targetTextureVarying: 'outTexture',\n  vs,\n  elementCount\n});\n\ntransform.run();\n\nconst outTexture = transform._getTargetTexture();\n\n```\n\n\n## Constructor\n\n### Transform(gl : WebGL2RenderingContext, props: Object)\n\nConstructs a `Transform` object. It then creates destination buffers if needed and binds the buffers to `Model` and `TransformFeedback` objects.\n\n* `gl` (`WebGL2RenderingContext`) gl - context\n* `props.sourceBuffers` (`Object`) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Attribute`, `Buffer` or attribute descriptor object.\n* `props.feedbackBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader varying and value is the corresponding `Buffer` object or buffer params object. If a buffer params object is specified, it will contain following fields, these can be used to capture data into the buffer a particular offset and size.\n  * `buffer`=(Buffer) - Buffer object to be bound.\n  * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n  * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n* `props.vs` (`String`) - vertex shader string.\n* `props.modules` - shader modules to be applied.\n* `props.varyings` (`Array`) - Array of vertex shader varyings names. When not provided this can be deduced from `feedbackMap`. Either `varyings` or `feedbackMap` must be provided.\n* `props.feedbackMap` (`Object`, Optional) - key and value pairs, where key is a vertex shader attribute name and value is a vertex shader varying name.\n* `props.drawMode` (`GLEnum` = gl.POINTS, Optional) - Draw mode to be set on `Model` and `TransformFeedback` objects during draw/render time.\n* `props.elementCount` (`Integer`) - Number set to vertex count when rendering the model.\n#### Experimental ####\n* `props._sourceTextures` (`Object`) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Texture2D` object.\n* `props._targetTexture` (`Texture2D` or `String`) - Defines texture object that is used as color attachment for rendering. If `Texture2D` object, it is used as is, if `String`, it must be one of the source texture attributes name, a new texture object is cloned from corresponding texture and used as color attachment.\n* `props._targetTextureVarying` (`String`) : varying name used in vertex shader who's data should go into target texture.\n* `props._swapTexture` (`String`) : source texture attribute name, that is swapped with target texture every time `swap()` is called.\n* `props._fs` (`String`, Optional) - fragment shader string, when rendering to a texture, fragments can be processed using this custom shader, when not specified, pass through fragment shader will be used.\n\nNotes:\n\n* Internally, creates `Model`, `TransformFeedback` and `Framebuffer` instances.\n\n\n### delete() : Transform\n\nDeletes all owned resources, `Model`, `TransformFeedback` and any `Buffer` objects that are crated internally.\n\n\n## Methods\n\n### getBuffer(varyingName : String) : Buffer\n\nReturns current destination buffer corresponding to given varying name.\n\n* `varyingName` (`String`) - varying name.\n\n\n### getData([options : Object]) : ArrayBufferView\n\nReads and returns data from current destination buffer corresponding to the given varying name. When no 'varyingName' is provided, it reads and returns data from current target texture.\n\n* `options.varyingName` (`String`, Optional) - when specified, first checks if there is a corresponding feedback buffer, if so reads data from this buffer and returns. When not specified, there must be target texture and data is read from this texture and returned.\n* `options.packed` (Boolean, Optional, Default: false) - applicable only when reading data from target texture, when true, data is packed to the actual size varyings. When false return array contains 4 values (R, G, B and A) for each element. Un-used element value will be 0 for R, G and B and 1 for A channel.\n\n\n### getFramebuffer() : Framebuffer\n\nWhen rendering to a texture, i.e. `_targetTexture` is set, `Transform` class internally setups a `Framebuffer` object. `getFramebuffer()` returns this `Framebuffer` object.\n\n### run({uniforms : Object, unbindModels : Object}) : Transform\n\nPerforms one transform feedback iteration.\n\n* `uniforms`=`null` (`Object` = {}, Optional) - Sets uniforms before rendering.\n* `unbindModels`=`[]` (Model[]) - Array of models whose VertexAttributes will be temporarily unbound during the transform feedback to avoid triggering a possible [Khronos/Chrome bug](https://github.com/KhronosGroup/WebGL/issues/2346).\n\n\n### update(props) : Transform\n\nUpdates buffer bindings with provided buffer objects for one or more source or destination buffers.\n\n* `props.sourceBuffers` (`Object`) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Attribute`, `Buffer` or attribute descriptor object.\n* `props.feedbackBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader varying and value is the corresponding `Buffer` object.\n* `props.elementCount` (`Integer`, Optional) - Number set to vertex count when rendering the model. If not supplied, the previously set element count is used.\n\n\n### swap() : Transform\n\nSwaps source and destination buffers and textures. Buffer swapping is performed when `feedbackMap` is provided and texture swapping is performed when `_swapTexture` is provided. If buffer swapping is needed, `sourceBuffers` and `feedbackBuffers` supplied to the constructor and/or the `update` method must be `Buffer` objects.\n\n\n### \\_getTargetTexture() : Texture2D/null (EXPERIMENTAL)\n\nWhen transform is setup to render to a texture, returns current target texture, otherwise null.\n","slug":"docs/api-reference/core/transform","title":"Transform (WebGL2)"},{"excerpt":"hasFeatures and hasFeature Provides WebGL feature detection. WebGL capabilities can vary quite dramatically between browsers (from minimal…","rawMarkdownBody":"# hasFeatures and hasFeature\n\nProvides WebGL feature detection.\n\nWebGL capabilities can vary quite dramatically between browsers (from minimal WebGL1 (e.g. headless-gl) to WebGL1 with dozens of extensions to full WebGL2, which also has a growing number of extensions). Unfortunately, the raw WebGL API sometimes expose the same functionalities through APIs that are slightly different and not exactly compatible.\n\nTo simplify detecting and working with conditionally available capabilities (or \"features\") luma.gl provides:\n\n* A set of functions (e.g. [`isWebGL2`](/docs/api-reference/webgl/context/is-webGL2.md), [`getFeatures`](/docs/api-reference/webgl/context/get-features.md) and [`hasFeatures`](/docs/api-reference/webgl/context/has-features.md), described in this document) that enable you to check if the application is currently running on an environment that supports a certain feature (regardless of whether it is supported through e.g. WebGL2 or a WebGL1 extension).\n\nIn addition, luma.gl's WebGL classes transparently use WebGL extensions or WebGL2 APIs as appropriate, meaning that the amount of conditional logic in application code can be kept to a minimum. Once you have established that a capability exists, luma.gl offers you one unified way to use it.\n\n\n## Usage\n\nCheck if a feature is available (whether as a WebGL1 or WebGL2 extension or through WebGL2)\n```js\nimport {hasFeature, FEATURES} from '@luma.gl/core';\nif (hasFeature(gl, FEATURES.INSTANCED_RENDERING)) {\n   // Will work both on WebGL1 (via extension) and WebGL2 via the standard API\n   program.draw({instanceCount: ..., ....});\n}\n```\n\nAnother example of feature detection\n```js\nimport {hasFeature, FEATURES} from '@luma.gl/core';\n// Checks if `Query` objects can do async queries of GPU timings\nif (hasFeature(gl, FEATURES.TIMER_QUERY)) {\n   ...\n}\n// Alternatively - do the same query using raw extensions\nif (hasFeature(gl, 'EXT_disjoint_timer_query') || hasFeature(gl, 'EXT_disjoint_timer_query_webgl2')) {\n   ...\n}\n```\n\n\nThere are a few additional capability query functions sprinkled through the luma.gl API. In particular, WebGL2 specific classes have an `isSupported` method that duplicates some of the queryies that can be made using the capability system\n```js\nimport {Query} from '@luma.gl/core';\nif (Query.isSupported(gl)) {\n  ...\n}\n\n## Methods\n\n### hasFeature\n\nAllows the app to query whether a capability is supported without being concerned about how it is being provided (WebGL2, an extension etc)\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* capability (`String`) - capability name (can be a webgl extension name or a luma.gl `FEATURES` constant).\n\n### hasFeatures\n\nAllows the app to query whether a capability is supported without being concerned about how it is being provided (WebGL2, an extension etc)\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* feature (`String`|`String[]`) - capability name (can be a webgl extension name or a luma.gl `FEATURES` constant).\n\n## WebGL Feature Detection\n\n### WebGL2 Classes with some WebGL1 support\n\nNote that luma has a few WebGL2 classes that **can** be instantiated under WebGL1\n* `VertexAttributeObject`. Can be instanitated under WebGL1 if the commonly supported extension is available. Also, luma.gl treats the global vertex array as a \"default\" VertexArrayObject, so that can always be accessed.\n* `Query` objects use GPU timing extensions if available. They can always be created but obviously queries will fail if capabilities are not present.\n* `UniformBufferLayout` - this class does not create any WebGL resources, it just helps the application access memory in the layout format expected by WebGL2 uniform buffers.\n\n`VertexAttributeObject` and `Query` have a static `isSupported()` method that you can call instead of checking for WebGL2.\n\n### WebGL2 Classes that only work in WebGL2\n\nA list of luma classes that can only be instantiated under WebGL2:\n* `Texture3D` - e.g for volumetric rendering\n* `Texture2DArray` - an array of textures, e.g. a texture atlas\n* `Sampler` - holds a separate set of texture sampler parameters\n* `TransformFeedback` - holds a list of output buffers for shaders to write to.\n* `Sync` -\n\nEach of these classes has a static `isSupported()` method that you can call instead of checking for WebGL2.\n\n### WebGL2-only Features\n\nA partial list of features that are only available in WebGL2:\n\n* Non-power-of-2 textures - non-POT textures can have mipmaps in WebGL2\n* Sized texture formats -\n* Integer based texture formats and attributes -\n* Multi-Sampled renderbuffers -\n* Guaranteed texture access in vertex shaders - WebGL1 is not required to support this (although it often does)\n\n\n### GLSL 3.00\n\n* `textureSize` - query **size of texture** from within shaders\n* `texelFetch` - access textures by **pixel** coordinates (0-width, 0-height) instead of **texel** coordinates (0-1)\n* `inverse` and `transpose` Matrix operations available in GLSL\n* loop restrictions removed\n\n\n### Optional Feature Detection\n\nThe WebGL standard comes with an elaborate \"extension\" system allowing applications to check for the availability of features beyond the base WebGL1 and WebGL2 standards. These extensions tend to be rather technical, plus they have to be used differently in WebGL1 and WebGL2, so luma provides a simplified feature detection system. Following table lists all the available features, and their support under WebGL1 and WebGL2 , `NO` implies not supported, 'YES' implies supported and `*` implies supported through an extension.\n\nParameters to `hasFeatures`:\n\n| `FEATURE`                             | WebGL2  | WebGL1 | Description |\n| ---                                   | ---     | ---    | ---         |\n| **General WebGL Features**            |         |        | |\n| `FEATURES.WEBGL2`                     | **YES** | **NO** | True for WebGL2 Context |\n| `FEATURES.INSTANCED_RENDERING`        | **YES** | *      | Instanced rendering (via instanced vertex attributes) [`ANGLE_instanced_arrays`](https://developer.mozilla.org/en-US/docs/Web/API/ANGLE_instanced_arrays) |\n| `FEATURES.VERTEX_ARRAY_OBJECT`        | **YES** | *      | `VertexArrayObjects` can be created [`OES_vertex_array_object`](https://developer.mozilla.org/en-US/docs/Web/API/OES_vertex_array_object) |\n| `FEATURES.ELEMENT_INDEX_UINT32`       | **YES** | *      | 32 bit indices available for `GL.ELEMENT_ARRAY_BUFFER`s [`OES_element_index_uint`](https://developer.mozilla.org/en-US/docs/Web/API/OES_element_index_uint) |\n| `FEATURES.BLEND_MINMAX`               | **YES** | *      | `GL.MIN`, `GL.MAX` blending modes are available: [`EXT_blend_minmax`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_blend_minmax) |\n| `FEATURES.TIMER_QUERY`                | *       | *      | [`Query`](/docs/api-reference/webgl/query.md) objects support asynchronous GPU timings [`EXT_disjoint_timer_query_webgl2`](https://www.khronos.org/registry/webgl/extensions/EXT_disjoint_timer_query_webgl2/), [`EXT_disjoint_timer_query`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_disjoint_timer_query) |\n| **`Texture`s and `Framebuffer`s** |    |        | |\n| `FEATURES.TEXTURE_FLOAT`              | **YES** | *      | Floating point (`Float32Array`) textures can be created and set as samplers (Note that filtering and rendering need to be queried separately, even in WebGL2)  [`OES_texture_float`](https://developer.mozilla.org/en-US/docs/Web/API/OES_texture_float) |\n| `FEATURES.TEXTURE_HALF_FLOAT`         | **YES** |        | Half float (`Uint16Array`) textures can be created and set as samplers [`OES_texture_half_float`](https://developer.mozilla.org/en-US/docs/Web/API/OES_texture_half_float) [`WEBGL_color_buffer_float`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_color_buffer_float) |\n| `FEATURES.MULTIPLE_RENDER_TARGETS`    | **YES** | *      | `Framebuffer`s can have multiple color attachments that fragment shaders can access, see `Framebuffer.drawBuffers` [`WEBGL_draw_buffers`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_draw_buffers) |\n| `FEATURES.COLOR_ATTACHMENT_RGBA32F`   | *      | *      | Floating point `Texture`s using the `GL.RGBA32F` format are renderable and readable [`EXT_color_buffer_float`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_color_buffer_float) [`WEBGL_color_buffer_float`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_color_buffer_float) |\n| `FEATURES.COLOR_ATTACHMENT_FLOAT`     | *       | **NO** | Floating point `Texture`s are renderable and readable, i.e. can be attached to `Framebuffer`s and written to from fragment shaders, and read from with `readPixels` etc. Note that the formats include `GL.RGBA32F`. [`EXT_color_buffer_float`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_color_buffer_float) |\n| `FEATURES.COLOR_ATTACHMENT_HALF_FLOAT`| *       | **NO** | Half float format `Texture`s are renderable and readable[`EXT_color_buffer_half_float`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_color_buffer_half_float) |\n| `FEATURES.FLOAT_BLEND`| *       | *     | Blending with 32-bit floating point color buffers[`EXT_float_blend`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_float_blend) |\n| [`WEBGL_depth_texture`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_depth_texture) |\n| `FEATURES.TEXTURE_DEPTH_BUFFERS`      | **YES** | *      | Depth buffers can be stored in `Texture`s, e.g. for shadow map calculations |\n| `TEXTURE_FILTER_LINEAR_FLOAT`      | **YES** | * | Linear texture filtering for floating point textures [`OES_texture_float_linear`](https://developer.mozilla.org/en-US/docs/Web/API/OES_texture_float_linear) |\n| `FEATURES.TEXTURE_FILTER_LINEAR_HALF_FLOAT` | **Yes** | * | Linear texture filtering for half float textures [`OES_texture_half_float_linear`](https://developer.mozilla.org/en-US/docs/Web/API/OES_texture_half_float_linear) |\n| `FEATURES.TEXTURE_FILTER_ANISOTROPIC` | *       | *      | Anisotropic texture filtering [`EXT_texture_filter_anisotropic`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_texture_filter_anisotropic) |\n| `FEATURES.SRGB`                       | **YES** | *      | sRGB encoded rendering is available [`EXT_sRGB`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_sRGB) |\n| extensions**          |         |        | |\n| `FEATURES.SHADER_TEXTURE_LOD`         | `ES300` | *      | Enables shader control of LOD [`EXT_shader_texture_lod`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_shader_texture_lod) |\n| `FEATURES.FRAGMENT_SHADER_DRAW_BUFFERS` | `ES300` | *      | Fragment shader can draw to multiple render targets [`WEBGL_draw_buffers`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_draw_buffers) |\n| `FEATURES.FRAGMENT_SHADER_DEPTH`      | `ES300` | *  | Fragment shader can control fragment depth value [`EXT_frag_depth`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_frag_depth) |\n| `FEATURES.FRAGMENT_SHADER_DERIVATIVES`| `ES300` | *      | Derivative functions are available in GLSL [`OES_standard_derivatives`](https://developer.mozilla.org/en-US/docs/Web/API/OES_standard_derivatives) |\n\n## Remarks\n\n* WebGL1 only supports one color buffer format (RBG32F is deprecated)\n* WebGL2 supports multiple color buffer formats\n* Some extensions will not be enabled until they have been queries. luma always queries on startup to enable, app only needs to query again it wants to test platform.\n* The capability detection system works regardless of whether the app is running in a browser or in headless mode under Node.js.\n* Naturally, given that queries to driver and GPU are typically expensive in WebGL, the capabilities system will cache any queries.\n","slug":"docs/api-reference/webgl/context/has-features","title":"hasFeatures and hasFeature"},{"excerpt":"Upgrade Guide Upgrading from v7.2 to v7.3  has replaced  in the  class as a more robust resource manager. Use of the  with  will not affect…","rawMarkdownBody":"# Upgrade Guide\n\n## Upgrading from v7.2 to v7.3\n\n`ProgramManager` has replaced `ShaderCache` in the `Model` class as a more robust resource manager. Use of the `ShaderCache` with `Model` will not affect functionality in any way, but it is now a no-op.\n\n\n## Upgrading from v6.x to v7.0\n\nluma.gl v7.0 represents a major overhaul of the API. The majority of changes are in areas that are only infrequently used by applications, and the intention is that most applications should only require very light porting.\n\n\n## Core API Removals\n\n### Loading Functions Removed\n\nExtensive loading functionality is now provided by a new companion framework [loaders.gl](https://loaders.gl/) and because of this, most of the limited legacy luma.gl loading functions have been removed.\n\nFor the most common case (loading of images for use with textures), loading functions are no longer needed as the `data` prop in the `Texture2D` constructor now accepts url strings and `Promise` objects (this is the new Async Textures function).\n\n| Removed Function | Replacement  |\n| ---              | ---          |\n| `loadTexture(url, parameters)`  | `new Texture(gl, {data: url, parameters})` |\n| `loadFiles`      | Multiple calls to `loadFile` |\n| `loadImages`     | Multiple calls to `loadImage` |\n| `loadTextures`   | As per `loadTexture` |\n| `loadProgram`    | Manually load `fs` and `vs`, call `new Program(gl, {vs, fs})` |\n| `loadModel`      | call `loadFile` and copy `parseModel` code from examples/lesson/16|\n| `parseModel`     | call `loadFile` and copy `parseModel` code from examples/lesson/16 |\n\n### Attribute Class Removed\n\nThis experimental class has been moved to deck.gl and is now an internal class. Attribute accessor API improvements in luma.gl v7 should cover any issue.\n\n\n## WebGL API Removals\n\n### Sampler Class Removed\n\nThe `Sampler` class has been removed as its utility was limited and it added complexity to the library. It may be added back in the future if a clear use case arises.\n\n### Texture2DArray Class Removed\n\nThe `Texture2DArray` class has been removed as its utility was limited and the status of support was unclear due to limited testing. It may be added back in the future if a clear use case arises.\n\n### FenceSync Class Removed\n\nThe `FenceSync` class has been removed as its utility was limited. It may be added back in the future if a clear use case arises. If required, syncing can be done directly through the `WebGLFenceSync` object.\n\n## Framebuffer and Texture: Copy and Blit methods\n\nFollowing member function of `Framebuffer` and `Texture` classes are no longer supported, instead use the corresponding new global methods:\n\n| Removed method                  | Replacement |\n| ---                             | ---         |\n| `Framebuffer.readPixels`        | `readPixelsToArray` |\n| `Framebuffer.readPixelsToBuffer`| `readPixelsToBuffer` |\n| `Frambuffer.copyToDataUrl`      | `copyToDataUrl` |\n| `Frambuffer.copyToImage`        | `copyToImage` |\n| `Frambuffer.copyToTexture`      | `copyToTexture` |\n| `Frambuffer.blit`               | `blit` |\n| `Texture.copyFramebuffer`       | `copyToTexture` |\n\nParameters have also changed in some cases, see separate section.\n\n\n## Module Structure Changes\n\n### Debug functionality moved to separate npm module\n\nTo reduce bundle size and increase separation of concerns, debug functionality is now more cleanly separated from the core library and needs to be imported from a separate npm module:\n\nTo upgrade, install the new module\n\n```bash\nnpm install @luma.gl/debug\n```\n\nAnd replace\n\n```js\nimport \"luma.gl/debug\";\n````\nwith\n```js\nimport \"@luma.gl/debug\";\n```\n\n### Model\n\nChanges:\n* `Model` no longer extends `ScenegraphNode`. This ensures that applications that do not need scenegraph support do not need to include scenegraph related code. Use the new `ModelNode` class to inject `Models` into scenegraphs.\n\nDeletions:\n* Redraw flag handling has been removed: `Model.setNeedsRedraw()` and `Model.getNeedsRedraw()`.\n\nAdditions:\n* A new `Model.isAnimated()` method is provided, indicating that redraws are required every frame.\n\n## Geometry\n\nThe `Geometry` class has been simplified and is now a conceptually \"immutable\" class that holds typed arrays and accessor metatadata describing attributes for a geometry.\n\n| Removal                      | Replacement | Reason for Change |\n| ---                          | ---         | ---               |\n| `Geometry.drawMode` no longer accepts `String` values | `Geometry.DRAW_MODE` enum | API simplification |\n| `Geometry.setNeedsRedraw()`  | N/A | Not needed for immutable geometry |\n| `Geometry.getNeedsRedraw()`  | N/A | Not needed for immutable geometry |\n\n\n## Buffer\n\n| Removed Method               | Replacement | Reason for Change |\n| ---                          | ---         | ---               |\n| `Buffer.updateAccessor(...)` | `Buffer.setAccessor(new Accessor(buffer.accessor, ...)` | Decoupling accessors from `Buffer` |\n\n\n### Framebuffer\n\nTo maximize rendering performance, the default framebuffer is no longer preserved between frames.\n\nThe most common use case for preserving the draw buffer is capturing canvas contents into an image via `toDataURL`. This can now be done via `AnimationLoop.toDataURL` which returns a `Promise` that resolves to the canvas data URL:\n\n```js\ndataURL = await animationLoop.toDataURL();\nsnapshotImage.src = dataURL;\n```\n\nMore generally, moving code that depends on canvas contents to the end of `onRender`, after all draw operations, will ensure that canvas contents are available.\n\nPrior behaviour can re-enabled using the `glOptions` argument to the `createGLContext` or `AnimationLoop` constructors:\n\n```js\nnew AnimationLoop({\n  glOptions: {\n    preserveDrawingBuffer: true\n  }\n});\n```\n\nNote that setting `preserveDrawingBuffers` may result in a performance drop on some platforms.\n\n\n### Query\n\nUse `Query.getTimerMilliseconds` to retrieve timer results in milliseconds. `Query.getResult` now returns raw query results.\n\nTo improve performance and simplify the library, support for tracking `Query` instances with promises has changed: The `Query` constructor no longer takes `onComplete` and `onError` callbacks, and `pollGLContext` has been removed. Instead `Query.createPoll` now provides a simple, optional promise-based API.\n\n\n### Copy And Blit Parameter Unification\n\nNames of certain parameters to these methods have been unified in an effort to reduce confusion and use the same conventions across all functions implementing image read-back, copy or blit.\n\nThis table lists parameter mapping between old and new function.\n\n| `Framebuffer.readPixels` | `readPixelsToArray` |\n| ---                      | --- |\n| -                        | `source` |\n| `opts.x`                 | `opts.sourceX` |\n| `opts.y`                 | `opts.sourceY` |\n| `opts.width`             | `opts.sourceWidth` |\n| `opts.height`            | `opts.sourceHeight` |\n| `opts.format`            | `opts.sourceFormat` |\n| `opts.type`              | `opts.sourceType` |\n| `opts.attachment`        | `opts.sourceAttachment` |\n| `opts.pixelArray`        | `opts.target` |\n\n| `Framebuffer.readPixelsToBuffer` | `readPixelsToBuffer` |\n| ---               | --- |\n| -                 | `source` |\n| `opts.x`          | `opts.sourceX` |\n| `opts.y`          | `opts.sourceY` |\n| `opts.width`      | `opts.sourceWidth` |\n| `opts.height`     | `opts.sourceHeight` |\n| `opts.format`     | `opts.sourceFormat` |\n| `opts.type`       | `opts.sourceType` |\n| `opts.buffer`     | `opts.target` |\n| `opts.byteOffset` | `opts.targetByteOffset` |\n\n| `Framebuffer.copyToDataUrl` | `copyToDataUrl` |\n| ------------      | ---- |\n| -                 | `source` |\n| `opts.attachment` | `opts.sourceAttachment` |\n| `opts.maxheight`  | `opts.targetMaxHeight` |\n\n| `Framebuffer.copyToImage` | `copyToImage` |\n| ------------              | ---- |\n| -                         | `source` |\n| `opts.attachment`         | `opts.sourceAttachment` |\n| `opts.image`              | `opts.targetImage` |\n\n| `Framebuffer.copyToTexture` | `copyToTexture` |\n| ------------          | ---- |\n| -                     | `source` |\n| `opts.target`         | `target` |\n| `opts.texture`        | `target` |\n| `opts.x`              | `opts.sourceX` |\n| `opts.y`              | `opts.sourceY` |\n| `opts.xoffset`        | `opts.targetX` |\n| `opts.yoffset`        | `opts.targetY` |\n| `opts.zoffset`        | `opts.targetZ` |\n| `opts.width`          | `opts.width` |\n| `opts.height`         | `opts.height` |\n| `opts.internalFormat` | `opts.targetInternalFormat` |\n| `opts.mipmapLevel`    | `opts.targetMipmapLevel` |\n\n| `Texture.copyFramebuffer` | `copyToTexture` |\n| ------------           | ---- |\n| `opts.framebuffer` | `source` |\n| `opts.target`      | `target` |\n| `opts.x`           | `opts.sourceX` |\n| `opts.y`           | `opts.sourceY` |\n| `opts.width`       | `opts.width` |\n| `opts.height`      | `opts.height` |\n| `opts.internalFormat` | `opts.targetInternalFormat` |\n| `opts.level`       | `opts.targetMipmapLevel` |\n\n| `Framebuffer.blit` | `blit` |\n| ------------       | ---- |\n| `opts.srcFramebuffer` | `source` |\n| -                 | `target` |\n| `opts.attachment` | `opts.sourceAttachment` |\n| `opts.srcX0`      | `opts.sourceX0` |\n| `opts.srcX1`      | `opts.sourceX1` |\n| `opts.srcY0`      | `opts.sourceY0` |\n| `opts.srcY1`      | `opts.sourceY1` |\n| `opts.dstX0`      | `opts.targetX0` |\n| `opts.dstX1`      | `opts.targetX1` |\n| `opts.dstY0`      | `opts.targetY0` |\n| `opts.dstY1`      | `opts.targetY1` |\n| `opts.color`      | `opts.color` |\n| `opts.depth`      | `opts.depth` |\n| `opts.stencil`    | `opts.stencil` |\n| `opts.mask`       | `opts.mask` |\n| `opts.filter`     | `opts.filter` |\n\n\n### Geometry Scenegraph Models\n\nGeometry scenegraph models have been deprecated. Simply create a `Model` or `ModelNode` and explicitly pass a `Geometry` instance as\nan argument, e.g.:\n\n```js\n  const sphere = new Model(gl, {\n    geometry: new SphereGeometry({\n      nlat: 30,\n      nlong: 30,\n      radius: 2\n    })\n  });\n```\n\n## Upgrading from v5.3 to v6.0\n\nluma.gl v6.0 underwent a major API cleanup, resulting in a smaller, easier-to-learn API and smaller application bundles. While there are many smaller changes, the impact on most applications should be limited:\n\n* Most removed functions were in practice rarely used by applications, and the impact on typical luma.gl applications should be limited.\n* A number of API changes are related to moving attribute management from `Program` to `VertexArray`, however for higher level applications that work with the `Model` class rather than `Program` directly, there should not be much impact.\n\n\n### GL Constants Import Path\n\nThe biggest change for many apps will probably be that the static `GL` symbol (that contains all WebGL2 constants) must now be separately imported GL from 'luma.gl/constants'.\n\n\n### Experimental Exports: New Naming Convention\n\nExperimental exports are now prefixed with underscore (\\_). The `experimental` \"name space\" export has been removed.\n\n```js\n// NOW: luma.gl v6\nimport {_Attribute as Attribute} from 'luma.gl';\n\n// BEFORE: luma.gl v5.x\nimport {experimental} from 'luma.gl';\nconst {Attribute} = experimental;\n```\n\nThis change will enable tree-shaking bundlers to remove unused experimental exports, resulting in smaller final application bundles.\n\n\n### Removed symbols\n\nMath functions were moved from luma.gl to the separate math.gl module in v4.1. As of v6.0, they are no longer forwarded by luma.gl and now need to be imported directly from math.gl:\n\n```js\nimport {radians, degrees, Vector2, Vector3, Vector4, Matrix4} from 'math.gl';\n```\n\nluma.gl v6.0 removes a number of previously deprecated symbols. luma.gl will now issue an error rather than a warning if the old usage is detecated.\n\n\n### Constants\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `GL`                             | `import GL from 'luma.gl/constants'` | Bundle size reduction (by making this import optional). |\n| `glGet(name)`                    | `glGet(gl, name)`               | Bundle size reduction (Was deprecated in v5.3) |\n| `glKey(value)`                   | `glKey(gl, value)`              | Bundle size reduction (Was deprecated in v5.3) |\n| `glKeyType(value)`               | `glKeyType(gl, value)`          | Bundle size reduction (Was deprecated in v5.3) |\n\n\n### Context\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `deleteGLContest`                | `destroyGLContext`              | Naming audit (Was deprecated in v5.3) |\n| `pollContext`                    | `pollGLContext`                 | Naming audit (Was deprecated in v5.3) |\n| `trackContextCreation`           | N/A                             | Rarely used, overly specialized |\n\n\n### Global Functions\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `readPixels`                     | `Framebuffer.readPixels`        | Naming audit (was deprecated in v3.0) |\n| `FrameBufferObject`              | `FrameBuffer`                   | Naming audit (was deprecated in v3.0) |\n\n\n### AnimationLoop\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `AnimationLoop.setViewParams()`  | `AnimationLoop.setProps()`      | Naming audit  |\n\n\n### Program\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `varyingMap`                     | N/A (`configuration`)           | Program now auto discovers varyings.        |\n| `Program.setAttributes()`        | `VertexArray.setAttributes()`   | Attribute management moved to `VertexArray` |\n| `Program.setBuffers()`           | `VertexArray.setAttributes()`   | Attribute management moved to `VertexArray` |\n| `Program.setVertexArray()`       | `Program.draw({vertexArray})`   | No longer needed, just supply a `VertexArray` to `Program.draw()` |\n| `Program.unsetBuffers()`         | N/A                             | No longer needed, just supply a `VertexArray` to `Program.draw()` |\n| `Program.use()`                  | `gl.useProgram(program.handle)` | Rarely needed by apps, can use raw WebGL API |\n| `getUniformCount()`              | `getParameter(GL.ACTIVE_UNIFORMS)` | Rarely needed |\n| `getUniformInfo()`               | `gl.getActiveUniform()`         | Rarely needed by apps, can use raw WebGL API |\n| `getUniformLocation()`           | `gl.getUniformLocation()`       | Rarely needed by apps, can use raw WebGL API |\n| `getUniformValue()`              | `gl.getUniform()`               | Rarely needed by apps, can use raw WebGL API |\n| 'getVarying()'                   |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getFragDataLocation()'          |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getAttachedShaders()'           |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getAttributeCount()'            |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getAttributeLocation()'         |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getAttributeInfo()'             |                                 | Rarely needed by apps, can use raw WebGL API |\n\n\n### TransformFeedback\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `TransformFeedback.pause()`      | `gl.pauseTransformFeedback`     | Rarely needed by apps, can use raw WebGL API |\n| `TransformFeedback.resume()`     | `gl.resumeTransformFeedback`    | Rarely needed by apps, can use raw WebGL API |\n\n\n### VertexArray\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --        |\n| `VertexArray.setBuffers()`       | `VertexArray.setAttributes()`   | API Audit, setAttributes handles more cases. |\n| `VertexArray.setGeneric()`       | `VertexArray.setConstant()`     | API Audit, prefer \"constant\" instead of \"generic\" |\n| `VertexArray.filledLocations()`  | N/A                             | No longer needed. |\n| `VertexArray.clearBindings()`    | `VertexArray.reset()`           | API Audit |\n| `VertexArray.setLocations()`     | `VertexArray.constructor({program})` | Autodetected from `program` parameter |\n| `VertexArray.setGenericValues()` | `VertexArray.setConstant()`     | API Audit, prefer \"constant\" instead of \"generic\" |\n| `VertexArray.setDivisor()`       | `gl.vertexAttribDivisor()`      | Rarely needed by apps, can use raw WebGL API |\n| `VertexArray.enable()`           | `gl.enableVertexAttribArray()`  | Rarely needed by apps, can use raw WebGL API |\n| `VertexArray.disable()`          | `gl.disableVertexAttribArray()` | Rarely needed by apps, can use raw WebGL API |\n\n\n\n## Upgrading from v5.2 to v5.3\n\nv5.3 deprecates a number of symbols. It is recommended that you replace their usage in your source code.\n\n| Deprecated symbol                | Replacement                     | Reason     |\n| ---                              | ---                             | --         |\n| `GL`                             | `import GL from 'luma.gl/constants'` | Bundle size concerns |\n| `deleteGLContest`                | `destroyGLContext`              | API Audit: Naming alignment |\n| `pollContext`                    | `pollGLContext`                 | API Audit: Naming alignment |\n\n\n## Upgrading from v5.1 to v5.2\n\n### Running under Node.js\n\n[Using with Node](/docs/get-started/README.md): `\"import luma.gl/headless\"` is no longer required for luma.gl to load headless gl and the usage has been deprecated. You can now simply remove any such import statements from your code.\n\n\n### Using Debug Contexts\n\n[Debugging](/docs/developer-guide/debugging.md): The Khronos group's `WebGLDeveloperTools` are automatically installed when luma.gl is installed, but are not actually bundled into the application unless explicitly imported. This avoids impacting the size of production bundles built on luma.gl that typically do not need debug support.\n\nTo use debug support, first import the debug tools, then call `getDebugContext` to create a debug contexts from a normal WebGL context:\n\n```js\nimport \"luma.gl/debug\";\nconst gl = getDebugContext(gl);\n```\n\n\n## Upgrading from v4 to v5\n\nPlease read this documentation before upgrading your luma.gl dependency from v4 to v5. In v5 a number of previously deprecated features have been removed and a number of additional deprecations have been made at the same time.\n\nBefore upgrading to v5, it is highly recommended to run your application using latest v4 release, and check the console for any deprecated warnings, if there are any replace deprecated API with newer API as listed below.\n\n### Model Class\n\nThe `Model` constructor expects a gl context as the first argument.\n\n```js\n  // v5\n  Model(gl)\n  Model(gl, {...opts});\n  Model(gl, {program});\n```\n\nFollowing style construction was deprecated in v4 and is now removed in v5.\n\n```js\n  // NOT SUPPORTED\n  Model({gl});\n  Model({gl, ...opts});\n  Model({program});\n```\n\n### useDevicePixelRatio\n\n`useDevicePixelRatio` is used as a an argument in `AnimationLoop` class constructor and `pickModels` method. It is now deprecated in v5, but still supported with a warning message and will be removed in next major version update. It is recommended to use `useDevicePixels` instead.\n\n### Geometry\n\n`Geometry` class construction with inline attributes was deprecated in v4 and now removed in v5.\n\n```js\n// NOT SUPPORTED\nnew Geometry({\n  positions: new Float32Array([ ... ]),\n  colors: {\n    size: 4,\n    value: new Float32Array([ ... ])\n  }\n});\n```\n\nAll attributes should be grouped inside `attribute` object.\n\n```js\n// SUPPORTED\nnew Geometry({\n attributes: {\n   positions: new Float32Array([ ... ]),\n   colors: {\n     size: 4,\n     value: new Float32Array([ ... ])\n   }\n }\n});\n```\n\n### Removed Features\n\nFollowing features were deprecated in v3 and v4 are now removed in v5.\n\n* Global symbols:\n\n| Removed symbol / Usage | Replacement    | Comment |\n| ---                  | ---              | --      |\n| `withState`          | `withParameters` | State management |\n| `glContextWithState` | `withParameters` | State management |\n|`withParameters({frameBuffer})`| `withParameters({framebuffer})`| State management |\n| `MONOLITHIC_SHADERS` | `MODULAR_SHADERS` | default shaders |\n| `isWebGLContext` | `isWebGL` | WebGL context validation |\n| `isWebGL2Context` | `isWebGL2` | WebGL2 context validation |\n| `Camera`, `PerspectiveCamera`, `OrthoCamera` | `None` | |\n| `Scene` | `None` | |\n\n* Texture construction options:\n\n| Removed symbol / Usage | Replacement    |\n| ---                  | ---              |\n| `generateMipmaps` | `mipmaps` |\n| `magFilter` | `parameters[GL.TEXTURE_MAG_FILTER]` |\n| `minFilter` | `parameters[GL.TEXTURE_MIN_FILTER]` |\n| `wrapS` | `parameters[GL.TEXTURE_WRAP_S]` |\n| `wrapT` | `parameters[GL.TEXTURE_WRAP_T]` |\n\n\n## Upgrading from v3 to v4\n\nluma.gl v4 is a major release with API changes. Please read this documentation before upgrading your luma.gl's dependency from v3 to v4.\nIn addition, a number of previously deprecated features have been removed and a number of additional deprecations have been made at the same time in this version.\n\n\n## Removed Features\n\nSome previously deprecated classes and functions have been removed in luma.gl v4 and applications must be updated with the new classes and functions if they are still using these.\n\n| Symbol               | Replacement      | Comment |\n| ---                  | ---              | --- |\n| `Vec3`               | `Vector3`        | [New math library]( https://github.com/uber-web/math.gl) |\n| `Mat4`               | `Matrix4`        | [New math library]( https://github.com/uber-web/math.gl) |\n| `Quat`               | `Quaternion`     | [New math library]( https://github.com/uber-web/math.gl) |\n\n\n## Deprecated Features\n\nSome classes and functions have been deprecated in luma.gl v4. They will continue to function in v4, but a warning in the console will be generated. These functions are expected to be removed in a future major versions of luma.gl.\n\n\n| Symbol               | Replacement      | Comment |\n| ---                  | ---              | --- |\n| `withState`          | `withParameters` | [New WebGL state management](/docs/api-reference/webgl/context/with-parameters.md) |\n| `glContextWithState` | `withParameters` | [New WebGL state management](/docs/api-reference/webgl/context/with-parameters.md) |\n\n\n## API Change\n\n### Model Class\n\nThe `Model` constructor now expects a gl context as the first argument.\n\n```js\n  // v3\n  Model({gl});\n  Model({gl, ...opts});\n  Model({program});\n\n  // v4\n  Model(gl)\n  Model(gl, {...opts});\n  Model(gl, {program});\n```\n\nthe gl context used to be extracted from the supplied program or provided along side with other options, but in luma.gl v4, it is expected as a separate argument to the constructor. This change is because luma.gl v4 emphasizes sharing shaders rather than programs (often indirectly via shader caching / shader assembly), it is less common that a gl context is available.\n\n\n## Upgrading from V2 to V3\n\nV3 was a fairly minor release, a number of deprecations were made.\n\n### Deprecations\n\n| Symbol               | Replacement      | Comment |\n| ---                  | ---              | --- |\n| `Vec3`               | `Vector3`        | [New math library]( https://github.com/uber-web/math.gl) |\n| `Mat4`               | `Matrix4`        | [New math library]( https://github.com/uber-web/math.gl) |\n| `Quat`               | `Quaternion`     | [New math library]( https://github.com/uber-web/math.gl) |\n","slug":"docs/upgrade-guide","title":"Upgrade Guide"},{"excerpt":"Texture A  is a WebGL object that contains one or more images that all have the same image format. Shaders can read from textures (through a…","rawMarkdownBody":"# Texture\n\nA `Texture` is a WebGL object that contains one or more images that all have the same image format. Shaders can read from textures (through a sampler uniform) and they can be set up as render targets (by attaching them to a framebuffer).\n\nNote: This section describes the `Texture` base class that implements functionality common to all four types of WebGL:\n* [`Texture2D`](/docs/api-reference/webgl/texture-2d.md) - Contains a \"normal\" image texture\n* [`TextureCube`](/docs/api-reference/webgl/texture-cube.md) - Holds 6 textures representing sides of a cube.\n* [`Texture3D`](/docs/api-reference/webgl/texture-3d.md) (WebGL2) - Holds a \"stack\" of textures which enables 3D interpolation.\n\nFor more details see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Texture).\n\nNote that textures have a lot of optional capabilities made available by extensions, see the Limits section below.\n\n\n## Usage\n\n* For additional usage examples, `Texture` inherits from [`Resource`](/docs/api-reference/webgl/resource.md).\n\nConfiguring a Texture\n```js\nconst texture = new Texture2D(gl);\ntexture.setParameters({\n  [GL.TEXTURE_WRAP_S]: GL.CLAMP\n});\n```\n\nUsing Textures\n```js\nconst texture = new Texture2D(gl, ...);\n\n// For ease of use, the `Model` class can bind textures for a draw call\nmodel.draw({\n  uniforms({uMVMatrix: matrix, texture1: texture, texture2: texture})\n});\n\n// Alternatively, bind the textures using the `Texture` API directly\ntexture.bind(0);\ntexture.bind(1);\nmodel.draw({\n  uniforms({uMVMatrix: matrix})\n});\n```\n\n## Members\n\nA number of read only accessors are available:\n\n* `width` - width of one face of the cube map\n* `height` - height of one face of the cube map\n* `format` - internal format of the face textures\n* `border` - Always 0.\n\n* `type` - type used to create face textures\n* `dataFormat` - data format used to create face textures.\n* `offset` - offset used to create face textures. Always 0, unless specified using WebGL2 buffer constructor.\n\n* `handle` - The underlying WebGL object.\n* `id` - An identifying string that is intended to help debugging.\n\nSampler parameters can be accessed using `Texture.getParameter`, e.g:\n\n`texture.getParameter(GL.TEXTURE_MAG_FILTER);`\n\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nThe texture class cannot be constructed directly. It is a base class that provides common methods the the concrete texture classes.\n* [`Texture2D`](/docs/api-reference/webgl/texture-2d.md),\n* [`TextureCube`](/docs/api-reference/webgl/texture-cube.md) and\n* [`Texture3D`](/docs/api-reference/webgl/texture-3d.md).\n\nThe constructors for these classes should be used to create textures. They constructors all take common parameters, many of which are specified in this document.\n\n* Pixel store parameters are described in [`State Management`](/docs/api-reference/webgl/context/get-parameters.md).\n\n### resize(options : Object) : Texture2D\n\nCall to resize a texture. If size has changed, reinitializes texture with current format. Note: calling `resize` clears image and mipmaps.\n\n* `width` (GLint) - width to resize to.\n* `height` (GLint) - height to resize to.\n* `mipmaps` (bool) - turn on/off mipmapping. default `false`.\n\n### generateMipmap() : Texture2D\n\nCall to regenerate mipmaps after modifying texture(s)\n\nWebGL References [gl.generateMipmap](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/generateMipmap)\n\n\n### setImageData(options : Object) : Texture2D\n\nAllocates storage and sets image data\n\n```js\n  Texture.setImageData({\n    target = this.target,\n    pixels = null,\n    data = null,\n    width,\n    height,\n    level = 0,\n    format = GL.RGBA,\n    type,\n    dataFormat,\n    offset = 0,\n    border = 0,\n    compressed = false,\n    parameters= {}\n  });\n```\n\n* `data` (*) - Image data. Can be one of several data types see table below\n* `pixels` (*) - alternative to  `data`\n* `width` (GLint) -\n* `height` (GLint) -\n* `level` (GLint) -\n* `format` (GLenum) - format of image data.\n* `type` (GLenum)\n - format of array (autodetect from type) or\n - (WEBGL2) format of buffer\n* `offset` (Number) - (WEBGL2) offset from start of buffer\n* `border` (GLint) - must be 0.\n* `compressed` (Boolean) -\n* `parameters` (Object) - GL parameters to be temporarily applied (most of the time, pixelStorage parameters) when updating the texture.\n\nValid image data types:\n\n* `null` - create empty texture of specified format\n* Typed array - initializes from image data in typed array according to `format`\n* `Buffer`|`WebGLBuffer` - (WEBGL2) initialized from image data in WebGLBuffer accoeding to `format`.\n* `HTMLImageElement`|`Image` - Initializes with content of image. Auto deduces texture width/height from image.\n* `HTMLCanvasElement` - Inits with contents of canvas. Auto width/height.\n* `HTMLVideoElement` - Creates video texture that continuously updates. Auto width/height.\n\n\n### setSubImageData(options : Object) : Texture2D\n\nRedefines an area of an existing texture\nNote: does not allocate storage\n\n```\n  Texture.setSubImageData({\n    target = this.target,\n    pixels = null,\n    data = null,\n    x = 0,\n    y = 0,\n    width,\n    height,\n    level = 0,\n    format = GL.RGBA,\n    type,\n    dataFormat,\n    compressed = false,\n    offset = 0,\n    border = 0,\n    parameters = {}\n  });\n```\n\n* `x` (`GLint`) - xOffset from where texture to be updated\n* `y` (`GLint`) - yOffset from where texture to be updated\n* `width` (`GLint`) - width of the sub image to be updated\n* `height` (`GLint`) - height of the sub image to be updated\n* `level` (`GLint`) - mip level to be updated\n* `format` (`GLenum`) - internal format of image data.\n* `typ` (`GLenum`) - format of array (autodetect from type) or (WEBGL2) format of buffer or ArrayBufferView\n* `dataFormat` (`GLenum`) - format of image data.\n* `offset` (`Number`) - (WEBGL2) offset from start of buffer\n* `border` (`GLint`) - must be 0.\n* parameters - temporary settings to be applied, can be used to supply pixel store settings.\n\nSee also [gl.compressedTexSubImage2D](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/compressedTexSubImage2D), [gl.texSubImage2D](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texSubImage2D), [gl.bindTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindTexture), [gl.bindBuffer](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindBuffer)\n\n\n### getActiveUnit()\n\nReturns number of active textures.\n\n\n### bind()\n\nBinds itself to given textureUnit.\n\nThe following WebGL APIs are called in the function\n[gl.activeTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/activeTexture), [gl.bindTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindTexture)\n\n\n### unbind()\n\nThe following WebGL APIs are called in the function\n[gl.activeTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/activeTexture), [gl.bindTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindTexture)\n\n\n## Texture Image Data\n\nWebGL allows textures to be created from a number of different data sources.\n\n| Type                               | Description  |\n| ---------------------------------- | -----------  |\n| `null`                             | A texture will be created with the appropriate format, size and width. Bytes will be \"uninitialized\". |\n| `typed array`                      | Bytes will be interpreted according to format/type parameters and pixel store parameters. |\n| `Buffer` or `WebGLBuffer` (`WebGL2`) | Bytes will be interpreted according to format/type parameters and pixel store parameters. |\n| `Image` (`HTMLImageElement`)       | image will be used to fill the texture. width and height will be deduced. |\n| `Video` (`HTMLVideoElement`)       | video will be played, continously updating the texture. width and height will be deduced. |\n| `Canvas` (`HTMLCanvasElement`)     | canvas will be used to fill the texture. width and height will be deduced. |\n| `ImageData`                        | `canvas.getImageData()` - Used to fill the texture. width and height will be deduced. |\n\n\n\n## Texture Formats\n\n### Internal Format\n\nIf an application wants to store the texture at a certain resolution or in a certain format, it can request the resolution and format with `internalFormat`. WebGL will choose an internal representation with least the internal component sizes, and exactly the component types shown for that format, although it may not match exactly.\n\nWebGL2 adds sized internal formats which enables the application to request\nspecific components sizes and types (float and integer formats). While sized formats offer more control, unsized formats do give the GPU freedom to select the most performant internal representation.\n\n\n| Unsized Internal Format | Components | Description |\n| ----------------------- | ---------- | ----------- |\n| `GL.RGB`                | 3          | sampler reads the red, green and blue components, alpha is 1.0 |\n| `GL.RGBA`               | 4          | Red, green, blue and alpha components are sampled from the color buffer. |\n| `GL.LUMINANCE`          | 1          | Each color contains a single luminance value. When sampled, rgb are all set to this luminance, alpha is 1.0. |\n| `GL.LUMINANCE_ALPHA`    | 2          | Each component is a luminance/alpha double. When sampled, rgb are all set to luminance, alpha from component. |\n| `GL.ALPHA`              | 1          | Discards the red, green and blue components and reads the alpha component. |\n| `GL.DEPTH_COMPONENT`    | 1          | WebGL2 or `WEBGL_depth_texture` |\n| `GL.DEPTH_STENCIL`      | 2          | WebGL2 or `WEBGL_depth_texture` |\n\n| Sized Internal Format   | Comp. |   Size   | Description   |\n| ----------------------- | ----- | -------- | ------------- |\n| `GL.R8` (WebGL2)        | 1     | 8 bits   | red component |\n| `GL.R16F` (WebGL2)      | 1     | 16 bits  | half float red component |\n| `GL.R32F` (WebGL2)      | 1     | 32 bits | float red component |\n| `GL.R8UI` (WebGL2)      | 1     | 8 bits | unsigned int red component, `usampler`, no filtering |\n| `GL.RG8` (WebGL2)       | 1     | 16 bits | red and green components |\n| `GL.RG16F` (WebGL2)     | 2     | 32 bits | red and green components, half float |\n| `GL.RG32F` (WebGL2)     | 2     | 64 bits | red and green components, float |\n| `GL.RGUI` (WebGL2)      | 2     | 16 bits | red and green components, `usampler`, no filtering |\n| `GL.RGB8` (WebGL2)      | 3     | 24 bits | red, green and blue components |\n| `GL.SRGB8` (WebGL2, EXT_sRGB) |3| 24 bits | Color values are encoded to/decoded from sRGB before being written to/read from framebuffer |\n| `GL.RGB565` (WebGL2)    | 3     | 16 bits | 5 bit red, 6 bit green, 5 bit blue |\n| `GL.R11F_G11F_B10F` (WebGL2) | 3| 32 bits | [11 and 10 bit floating point colors](https://www.opengl.org/wiki/Small_Float_Formats) |\n| `GL.RGB9_E5` (WebGL2)   | 3     | 32 bits | [14 bit floating point RGB, shared exponent](https://www.opengl.org/wiki/Small_Float_Formats) |\n| `GL.RGB16F` (WebGL2)    | 3     | 48 bits | half float RGB |\n| `GL.RGB32F` (WebGL2)    | 3     | 96 bits | float RBG |\n| `GL.RGB8UI` (WebGL2)    | 3     | 24 bits | unsigned integer 8 bit RGB: use `usampler`, no filtering |\n| `GL.RGBA8` (WebGL2)     | 4     | 32 bits | 8 bit RGBA, typically what `GL.RGBA` \"resolves\" to |\n| `GL.SRGB_APLHA8` (WebGL2, EXT_sRGB) | 4 | 32 bits | Color values are encoded to/decoded from sRGB before being written to/read from framebuffer |\n| `GL.RGB5_A1` (WebGL2)   | 4     | 16 bits | 5 bit RGB, 1 bit alpha |\n| `GL.RGBA4444` (WebGL2)  | 4     | 16 bits | 4 bit RGBA |\n| `GL.RGBA16F` (WebGL2)   | 4     | 64 bits | half float RGBA |\n| `GL.RGBA32F` (WebGL2)   | 4     | 128 bits | float RGA |\n| `GL.RGBA8UI` (WebGL2)   | 4     | 32 bits | unsigned integer 8 bit RGBA, `usampler`, no filtering |\n\n\n### Texture Component Type\n\nDescribes the layout of each color component in memory.\n\n| Value                         | WebGL2 | WebGL1 | Description |\n| ---                           | ---    | ---    | --- |\n| `GL.UNSIGNED_BYTE`            | Yes    | Yes    | GLbyte 8 bits per channel for `GL.RGBA` |\n| `GL.UNSIGNED_SHORT_5_6_5`     | Yes    | Yes    | 5 red bits, 6 green bits, 5 blue bits |\n| `GL.UNSIGNED_SHORT_4_4_4_4`   | Yes    | Yes    | 4 red bits, 4 green bits, 4 blue bits, 4 alpha bits |\n| `GL.UNSIGNED_SHORT_5_5_5_1`   | Yes    | Yes    | 5 red bits, 5 green bits, 5 blue bits, 1 alpha bit |\n| `GL.BYTE`                     | Yes    | No     | |\n| `GL.UNSIGNED_SHORT`           | Yes    | `WEBGL_depth_texture` | |\n| `GL.SHORT`                    | Yes    | No     | |\n| `GL.UNSIGNED_INT`             | Yes    | `WEBGL_depth_texture` | |\n| `GL.INT`                      | Yes    | No     | |\n| `GL.HALF_FLOAT`               | Yes    | `OES_texture_half_float` | |\n| `GL.FLOAT`                    | Yes    | `OES_texture_float` |\n| `GL.UNSIGNED_INT_2_10_10_10_REV`   |Yes| No     | |\n| `GL.UNSIGNED_INT_10F_11F_11F_REV`  |Yes| No     | |\n| `GL.UNSIGNED_INT_5_9_9_9_REV`      |Yes| No     | |\n| `GL.UNSIGNED_INT_24_8`             |Yes| `WEBGL_depth_texture` | |\n| `GL.FLOAT_32_UNSIGNED_INT_24_8_REV`|Yes| No     | (pixels must be null) |\n\n\n### Texture Format Combinations\n\nThis a simplified table illustrating what combinations of internal formats\nwork with what data formats and types. Note that luma.gl deduces `dataFormat` and `type` from `format` by taking the first value from the data format and data type entries in this table.\n\nFor more details, see tables in:\n* [WebGL2 spec](https://www.khronos.org/registry/webgl/specs/latest/2.0/)\n* [OpenGL ES spec](https://www.khronos.org/opengles/sdk/docs/man3/html/glTexImage2D.xhtml)\n\n| Internal Format          | Data Format       | Data Type          |\n| ------------------------ | ----------------- | ------------------ |\n| `GL.RGB`                 | `GL.RGB`          | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_5_6_5` |\n| `GL.RGBA`                | `GL.RGBA`         | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_4_4_4_4` `GL.UNSIGNED_SHORT_5_5_5_1` |\n| `GL.LUMINANCE_ALPHA`     | `GL.LUMINANCE_ALPHA` | `GL.UNSIGNED_BYTE` |\n| `GL.LUMINANCE`           | `GL.LUMINANCE`    | `GL.UNSIGNED_BYTE` |\n| `GL.ALPHA`               | `GL.ALPHA`        | `GL.UNSIGNED_BYTE` |\n| `GL.R8`                  | `GL.RED`          | `GL.UNSIGNED_BYTE` |\n| `GL.R16F`                | `GL.RED`          | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.R32F`                | `GL.RED`          | `GL.FLOAT`         |\n| `GL.R8UI`                | `GL.RED_INTEGER`  | `GL.UNSIGNED_BYTE` |\n| `GL.RG8`                 | `GL.RG`           | `GL.UNSIGNED_BYTE` |\n| `GL.RG16F`               | `GL.RG`           | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RG32F`               | `GL.RG`           | `GL.FLOAT`         |\n| `GL.RG8UI`               | `GL.RG_INTEGER`   | `GL.UNSIGNED_BYTE` |\n| `GL.RGB8`                | `GL.RGB`          | `GL.UNSIGNED_BYTE` |\n| `GL.SRGB8`               | `GL.RGB`          | `GL.UNSIGNED_BYTE` |\n| `GL.RGB565`              | `GL.RGB`          | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_5_6_5` |\n| `GL.R11F_G11F_B10F`      | `GL.RGB`          | `GL.UNSIGNED_INT_10F_11F_11F_REV` `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RGB9_E5`             | `GL.RGB`          | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RGB16FG`             | `GL.RGB`          | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RGB32F`              | `GL.RGB`          | `GL.FLOAT`         |\n| `GL.RGB8UI`              | `GL.RGB_INTEGER`  | `GL.UNSIGNED_BYTE` |\n| `GL.RGBA8`               | `GL.RGBA`         | `GL.UNSIGNED_BYTE` |\n| `GL.SRGB8_ALPHA8`        | `GL.RGBA`         | `GL.UNSIGNED_BYTE` |\n| `GL.RGB5_A1`             | `GL.RGBA`         | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_5_5_5_1` |\n| `GL.RGBA4`               | `GL.RGBA`         | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_4_4_4_4` |\n| `GL.RGBA16F`             | `GL.RGBA`         | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RGBA32F`             | `GL.RGBA`         | `GL.FLOAT`         |\n| `GL.RGBA8UI`             | `GL.RGBA_INTEGER` | `GL.UNSIGNED_BYTE` |\n\n\n## Limits and Capabilities\n\n| Optional capabilities                                       | controlled by extensions |\n| ---                                                         | --- |\n| Create floating point textures (`GL.NEAREST` sampling only) | `TEXTURE_FLOAT` |\n| Create half-floating point textures (`GL.NEAREST` sampling) | `TEXTURE_HALF_FLOAT` |\n| Floating point textures are color-renderable and readable   | `COLOR_BUFFER_FLOAT` |\n| Half float textures are color-renderable and readable       | `COLOR_BUFFER_HALF_FLOAT` |\n| sRGB format support                                         | `SRGB` |\n| depth texture support                                       | `DEPTH_TEXTURE` |\n| anisotropic filtering                                       | `TEXTURE_FILTER_ANISOTROPIC` |\n| `GL.LINEAR_*` sampling of floating point textures           | `TEXTURE_FILTER_LINEAR_FLOAT` |\n| `GL.LINEAR_*` sampling of half-floating point textures      | `TEXTURE_FILTER_LINEAR_HALF_FLOAT` |\n\n## NPOT Textures (WebGL1)\n\n* Any texture with a `non power of two` dimension (width or height) is referred as `NPOT` texture, under WebGL1 NPOT textures have following limitations.\n\n| State              | Limitation |\n| ---                | --- |\n| Mipmapping         | Should be disabled |\n| `GL.TEXTURE_MIN_FILTER` | Must be either `GL.LINEAR` or `GL.NEAREST` |\n| `GL.TEXTURE_WRAP_S`     | Must be `GL.CLAMP_TO_EDGE` |\n| `GL.TEXTURE_WRAP_T`     | Must be `GL.CLAMP_TO_EDGE` |\n\n* 'Texture' class will perform above settings when NPOT texture resource is created. When un-supported filtering is set using `Texture.setParameters`, those will be overwritten with above supported values (`GL.TEXTURE_MIN_FILTER` will be set to `GL.LINEAR`). This only happens for NPOT textures when using WebGL1, and a warning log will be printed every time a setting is overwritten.\n\n\n## Remarks\n\n* Textures can be supplied as uniforms to shaders that can sample them using texture coordinates and color pixels accordingly.\n* Parameters that affect texture sampling can be set on textures or sampler objects.\n* Textures can be created from a number of different sources, including typed arrays, HTML Images, HTML Canvases, HTML Videos and WebGLBuffers (WebGL2).\n* The WebGL Context has global \"pixel store\" parameters that control how pixel data is laid out, including Y direction, color space etc.\n* Textures are read from supplied data and written to the specified format/type parameters and pixel store parameters.\n","slug":"docs/api-reference/webgl/texture","title":"Texture"},{"excerpt":"GLSL Reference This page is a brief reference for both the GLSL 3.00 ES and GLSL 1.00 ES syntax, with notes about what has changed between…","rawMarkdownBody":"# GLSL Reference\n\nThis page is a brief reference for both the GLSL 3.00 ES and GLSL 1.00 ES syntax, with notes about what has changed between the two versions (GLSL documentation tends to describe one version and the differences are often not emphasized).\n\nMain sources of information for this page comes the Khronos WebGL reference cards and GLSL language specs:\n* [WebGL2/GLSL 3.00 ES](https://www.khronos.org/files/webgl20-reference-guide.pdf)\n* [WebGL1/GLSL 1.00 ES](https://www.khronos.org/files/webgl/webgl-reference-card-1_0.pdf)\n* [GLSL 3.00 Spec](https://www.khronos.org/registry/OpenGL/specs/es/3.0/GLSL_ES_Specification_3.00.pdf)\n\n\n## Types\n\n### Basic Types\n\n| Type                         | GLSL 1.00 | Description     |\n| ---                          | ---       | ---             |\n| `void`                       |           | no function return value or empty parameter list |\n| `bool`                       |           | Boolean |\n| `int`                        |           | signed integer |\n| `float`                      |           | floating scalar |\n| `vec2`, `vec3`, `vec4`       |           | floating point vectors |\n| `bvec2`, `bvec3`, `bvec4`    |           | boolean vectors |\n| `ivec2`, `ivec3`, `ivec4`    |           | signed integer vectors |\n| `uvec2`, `uvec3`, `uvec4`    | N/A       | unsigned integer vectors |\n| `mat2`, `mat3`, `mat4`       |           | 2x2, 3x3, 4x4 float matrix |\n| `mat2x2`, `mat2x3`, `mat2x4` | N/A       | 2x2, 2x3, 2x4 float matrix\n| `mat3x2`, `mat3x3`, `mat3x4` | N/A       | 3x2, 3x3, 3x4 float matrix\n| `mat4x2`, `mat4x3`, `mat4x4` | N/A       | 4x2, 4x3, 4x4 float matrix\n\n\n### Floating Point Sampler Types\n\n| Type                     | GLSL 1.00 | Description |\n| ---                      | ---       | ---         |\n| `sampler2D`              |           | access a 2D (or 3D) texture |\n| `samplerCube`            |           | access cube mapped texture |\n| `sampler3D`              | N/A       | access a 2D or 3D texture |\n| `samplerCubeShadow`      | N/A       | access cube map depth texture with comparison |\n| `sampler2DShadow`        | N/A       | access 2D depth texture with comparison |\n| `sampler2DArray`         | N/A       | access 2D array texture |\n| `sampler2DArrayShadow`   | N/A       | access 2D array depth texture with comparison |\n\n\n### Signed Integer Sampler Types\n\n| Type                     | GLSL 1.00 | Description |\n| ---                      | ---       | ---         |\n| `isampler2D, isampler3D` | N/A       | access an integer 2D or 3D texture |\n| `isamplerCube`           | N/A       | access integer cube mapped texture |\n| `isampler2DArray`        | N/A       | access integer 2D array texture |\n\n\n### Unsigned Integer Sampler Types\n\n| Type                     | GLSL 1.00 | Description |\n| ---                      | ---       | ---         |\n| `usampler2D, usampler3D` | N/A       | access unsigned integer 2D or 3D texture |\n| `usamplerCube`           | N/A       | access unsigned integer cube mapped texture |\n| `usampler2DArray`        | N/A       | access unsigned integer 2D array texture |\n\n\n### Structures and Arrays\n\nStructures\n\n```\nstruct type-name {\n members\n} struct-name[]; // optional variable declaration, optionally an array\n```\n\nArrays\n\n```\nfloat foo[3];\n```\n\nNotes:\n\n* Structures and blocks can be arrays\n* Only 1-dimensional arrays supported\n* Structure members can be arrays\n\n\n## Qualifiers\nStorage Qualifiers [4.3]\nVariable declarations may be preceded by one storage qualifier.\nnone (Default) local read/write memory, or input parameter\nconst Compile-time constant, or read-only function\nparameter\nin\ncentroid in Linkage into a shader from a previous stage\nout\ncentroid out Linkage out of a shader to a subsequent stage\nuniform\nValue does not change across the primitive being processed, uniforms form the linkage between a shader, OpenGL ES, and the application\nThe following interpolation qualifiers for shader outputs and inputs may procede in, centroid in, out, or centroid out.\nsmooth Perspective correct interpolation\nflat No interpolation\n\n### Interface Blocks\n\nUniform variable declarations can be grouped into named interface blocks, for example:\n\n```\nuniform Transform {\n mat4 ModelViewProjectionMatrix;\n uniform mat3 NormalMatrix; // restatement of qualifier\n float Deformation;\n}\n```\n\n### Layout Qualifiers (GLSL 3.00)\n\n```\nlayout(layout-qualifier) block-declaration\nlayout(layout-qualifier) in/out/uniform\nlayout(layout-qualifier) in/out/uniform\n declaration\n```\n\nFor all shader stages:\n\nlocation = integer-constant\n\n\n### Uniform Block Layout Qualifiers (GLSL 3.00)\n\nLayout qualifier identifiers for uniform blocks:\n\n`shared`, `packed`, `std140`, `row_major`, `column_major`\n\n\n### Parameter Qualifiers\n\nInput values are copied in at function call time, output values are copied out at function return time.\n\n| `none` (Default) | same as in |\n| `in`             | For function parameters passed into a function |\n| `out`            | For function parameters passed back out of a function, but not initialized for use when passed in |\n| `inout`          | For function parameters passed both into and out of a function |\n\n### Precision and Precision Qualifiers\n\nAny floating point, integer, or sampler declaration can have the type preceded by one of these precision qualifiers:\n\n| `highp`   | Satisfies minimum requirements for the vertex language. |\n| `mediump` | Range and precision is between that provided by lowp and highp. |\n| `lowp`    | Range and precision can be less than mediump, but still represents all color values for any color channel. |\n\nRanges and precisions for precision qualifiers (FP=floating point):\n\n|           | FP Range       | FP Magnitude Range    | FP Precision   | Integer Range Signed   | Integer Range Unsigned |\n| ---       | ---            | ---                   | ---            | ---                    | ---                    |\n| `highp`   | (−2126 , 2127) | 0.0, (2^–126 , 2^127) | Relative 2^–24 | [−2^31, 2^31 −1]       | [0, 2^32 −1] |\n| `mediump` | (−214 , 214)   | (2^–14 , 2^14)        | Relative 2^–10 | [−2^15, 2^15 −1]       | [0, 2^16 −1] |\n| `lowp`    | (−2, 2)        | (2^–8 , 2)            | Absolute 26–8  | [−2^7, 2^7 −1]         | [0, 2^8 −1]  |\n\nA precision statement establishes a default precision qualifier for subsequent `int`, `float`, and sampler declarations, e.g.: `precision highp int;`\n\n### Invariant Qualifiers Examples\n\n| `#pragma STDGL invariant(all)`       | Force all output variables to be invariant |\n| `invariant gl_Position;`             | Qualify a previously declared variable |\n| `invariant centroid out vec3 Color;` | Qualify as part of a variable declaration |\n\n### Order of Qualification\n\nWhen multiple qualifications are present, they must follow a strict order. This order is either:\n\n* invariant, interpolation, storage, precision\n* storage, parameter, precision\n\n\n## Preprocessor\n\nPreprocessor Directives\n\nThe number sign (#) can be immediately preceded or followed in its line by spaces or horizontal tabs.\n\n`#` `#define` `#undef` `#if` `#ifdef` `#ifndef` `#else` `#elif` `#endif` `#error` `#pragma` `#extension` `#version` `#line`\n\nExamples of Preprocessor Directives\n\n* `#version 100` in a shader program specifies that the program is written in GLSL ES version 1.00. It is optional. If used, it must occur before anything else in the program other than whitespace or comments.\n* `#extension extension_name : behavior`, where behavior can be `require`, `enable`, `warn`, or `disable`; and where extension_name is an extension supported by the compiler\n* `#pragma optimize({on, off})` - enable or disable shader optimization (default on) - GLSL 3.00\n* `#pragma debug({on, off})` - enable or disable compiling shaders with debug information (default off) - GLSL 3.00\n\nPredefined Macros\n\n| Macro         | Description |\n| ---           | --- |\n| `__LINE__`    | Decimal integer constant that is one more than the number of preceding new-lines in the current\nsource string |\n| `__FILE__`    | Decimal integer constant that says which source string number is currently being processed |\n| `__VERSION__` | Decimal integer: 100 or 300 |\n| `GL_ES`       | Defined and set to integer `1` if running on an OpenGL-ES Shading Language. Always `1` in WebGL, mainly useful if sharing shader code with non-ES environments. |\n| `GL_FRAGMENT_PRECISION_HIGH` | `1` if `highp` is supported in the fragment language, else undefined |\n\n\n## Built-In Inputs, Outputs, and Constants\n\nShader programs use special variables and constants to communicate with fixed-function parts of the pipeline.\n\nNotes:\n* Output Special Variables may be read back after writing.\n* Input Special Variables are read-only.\n* All Special Variables have global scope.\n\n### Built-in Vertex Shader Variables\n\nInputs:\n\n| Variable         | Type            | Description                    | Units or coordinate system |\n| ---              | ---             | ---                            | --- |\n| `gl_VertexID`    | `int`           | integer index (GLSL 3.00 only) | |\n| `gl_InstanceID`  | `int`           | instance number (GLSL 3.00 only) | |\n\nOutputs:\n\n| Variable         | Type            | Description                 | Units or coordinate system |\n| ---              | ---             | ---                         | --- |\n| `gl_Position`    | `highp vec4`    | transformed vertex position | clip coordinates |\n| `gl_PointSize`   | `mediump float` | transformed point size (point rasterization only) | pixels |\n\n### Built-in Fragment Shader Variables\n\nInputs:\n\n| Variable         | Type            | Description                           | Units or coordinate system |\n| ---              | ---             | ---                                   | --- |\n| `gl_FragCoord`   | `mediump vec4`  | fragment position within frame buffer | window coordinates |\n| `gl_FrontFacing` | `bool`          | fragment belongs to a front-facing primitive | Boolean |\n| `gl_PointCoord`  | `mediump vec2`  | fragment position within a point (point rasterization only) | 0.0 to 1.0 for each component |\n\nOutputs (GLSL 1.00 es only):\n\n| Variable         | Type            | Description                 | Units or coordinate system |\n| ---              | ---             | ---                         | --- |\n| `gl_FragColor`   | `mediump vec4`  | fragment color              | RGBA color |\n| `gl_FragData[n]` | `mediump vec4`  | fragment color for color attachment n | RGBA color |\n\nNotes:\n* In GLSL 3.00 es there are no built-in variables for fragment shader outputs, they are declared by the shader using the `out` syntax.\n* Fragment shaders may write to `gl_FragColor` or to one or more elements of `gl_FragData[]`, but not both.\n* The size of the `gl_FragData` array is given by the built-in constant `gl_MaxDrawBuffers`.\n\n### Built-In Constants\n\n| Constant                          | Type                | WebGL1 | WebGL2 |\n| ---                               | ---                 | ---    | ---    |\n| `gl_MaxVertexAttribs`             | `const mediump int` | 8      | 16     |\n| `gl_MaxVertexUniformVectors`      | `const mediump int` | 128    | 256    |\n| `gl_MaxVaryingVectors`            | `const mediump int` | 8      | N/A    |\n| `gl_MaxVertexOutputVectors`       | `const mediump int` | N/A    | 16     |\n| `gl_MaxVertexTextureImageUnits`   | `const mediump int` | 0      | 16     |\n| `gl_MaxCombinedTextureImageUnits` | `const mediump int` | 8      | 32     |\n| `gl_MaxTextureImageUnits`         | `const mediump int` | 8      | 16     |\n| `gl_MaxFragmentInputVectors`      | `const mediump int` | N/A    | 15     |\n| `gl_MaxFragmentUniformVectors`    | `const mediump int` | 16     | 224    |\n| `gl_MaxDrawBuffers`               | `const mediump int` | 1      | 4      |\n| `gl_MinProgramTexelOffset`        | `const mediump int` | N/A    | -8     |\n| `gl_MaxProgramTexelOffset`        | `const mediump int` | N/A    | 7      |\n\n\n### Built-in Uniforms\n\n| Uniform          | Type                       | Description |\n| ---              | ---                        | ---         |\n| `gl_DepthRange`  | `gl_DepthRangeParameters`  | Specifies depth range in window coordinates. If an implementation does not support highp precision in the fragment language, and state is listed as highp, then that state will only be available as mediump in the fragment language. |\n\n```\nstruct gl_DepthRangeParameters {\n  highp float near; // n\n  highp float far; // f\n  highp float diff; // f - n\n};\n```\n\n## GLSL Built-in Functions\n\n### Common Functions\n\n`T` can be `float`, `vec2`, `vec3`, `vec4`. Component-wise operation on vectors.\n\n| `T abs(T x)`          | absolute value |\n| `T sign(T x)`         | returns -1.0, 0.0, or 1.0 |\n| `T floor(T x)`        | nearest integer <= x |\n| `T ceil(T x)`         |  |\n| `T fract(T x)`        | `x - floor(x)` |\n| `T mod(T x, T y)`     | modulus |\n| `T mod(T x, float y)` |  |\n| `T min(T x, T y)`     | minimum value |\n| `T min(T x, float y)` |  |\n| `T max(T x, T y)`     | maximum value |\n| `T max(T x, float y)` |  |\n| `T clamp(T x, T minVal, T maxVal)`         | `min(max(x, minVal), maxVal)` |\n| `T clamp(T x, float minVal, float maxVal)` | |\n| `T mix(T x, T y, T a)`     | linear blend of x and y |\n| `T mix(T x, T y, float a)` | |\n| `T step(T edge, T x)`      | 0.0 if x < edge, else 1.0 |\n| `T step(float edge, T x)`  | |\n| `T smoothstep(T edge0, T edge1, T x)` | clip and smooth |\n| `T smoothstep(float edge0, float edge1, T x)` |  |\n\n\n### Geometric Functions\n\n`T` can be `float`, `vec2`, `vec3`, `vec4`. These functions operate on vectors as vectors, not component-wise.\n\n| `float length(T x)`               | length of vector |\n| `float distance(T p0, T p1)`      | distance between points |\n| `float dot(T x, T y)`             | dot product |\n| `vec3 cross(vec3 x, vec3 y)`      | cross product |\n| `T normalize(T x)`                | normalize vector to length 1 |\n| `T faceforward(T N, T I, T Nref)` | returns N if dot(Nref, I) < 0, else -N |\n| `T reflect(T I, T N)`             | reflection direction I - 2 * dot(N,I) * N |\n| `T refract(T I, T N, float eta)`  | refraction vector |\n\n\n### Matrix Functions\n\nType mat is any matrix type.\n\n| `mat matrixCompMult(mat x, mat y)` | multiply x by y component-wise |\n\n\n### Vector Relational Functions\n\nCompare x and y component-wise. Sizes of input and return vectors for a particular call must match.\nType bvec is bvecn; vec is vecn; ivec is ivecn (where n is 2, 3, or 4). T is the union of vec and ivec.\n\n| `bvec lessThan(T x, T y)`         | x < y |\n| `bvec lessThanEqual(T x, T y)`    | x <= y |\n| `bvec greaterThan(T x, T y)`      | x > y |\n| `bvec greaterThanEqual(T x, T y)` | x >= y |\n| `bvec equal(T x, T y)`            | |\n| `bvec equal(bvec x, bvec y)`      | x == y |\n| `bvec notEqual(T x, T y)`         | |\n| `bvec notEqual(bvec x, bvec y)`   | x != y |\n| `bool any(bvec x)`                | true if any component of x is true |\n| `bool all(bvec x)`                | true if all components of x are true |\n| `bvec not(bvec x)`                | logical complement of `x` |\n\n\n### Texture Lookup Functions\n\nAvailable in vertex and fragment shaders:\n\n| `vec4 texture2D(sampler2D sampler, vec2 coord)` |\n| `vec4 texture2DProj(sampler2D sampler, vec3 coord)` |\n| `vec4 texture2DProj(sampler2D sampler, vec4 coord)` |\n| `vec4 textureCube(samplerCube sampler, vec3 coord)` |\n\nAvailable only in vertex shaders.\n\n| `vec4 texture2DLod(sampler2D sampler, vec2 coord, float lod)` |\n| `vec4 texture2DProjLod(sampler2D sampler, vec3 coord, float lod)` |\n| `vec4 texture2DProjLod(sampler2D sampler, vec4 coord, float lod)` |\n| `vec4 textureCubeLod(samplerCube sampler, vec3 coord, float lod)` |\n\nAvailable only in fragment shaders.\n\n| `vec4 texture2D(sampler2D sampler, vec2 coord, float bias)` |\n| `vec4 texture2DProj(sampler2D sampler, vec3 coord, float bias)` |\n| `vec4 texture2DProj(sampler2D sampler, vec4 coord, float bias)` |\n| `vec4 textureCube(samplerCube sampler, vec3 coord, float bias)` |\n\n\n### Texture Lookup Functions [8.8]\n\nThe function textureSize returns the dimensions of level lod for the texture bound to sampler, as described in [2.11.9] of the OpenGL ES 3.0 specification, under “Texture Size Query”. The initial “g” in a type name is a placeholder for nothing, “i”, or “u”.\n\n| `highp ivec{2,3} textureSize(gsampler{2,3}D sampler, int lod);` |\n| `highp ivec2 textureSize(gsamplerCube sampler, int lod);` |\n| `highp ivec2 textureSize(sampler2DShadow sampler, int lod);` |\n| `highp ivec2 textureSize(samplerCubeShadow sampler, int lod);` |\n| `highp ivec3 textureSize(gsampler2DArray sampler, int lod);` |\n| `highp ivec3 textureSize(sampler2DArrayShadow sampler, int lod);` |\n\nTexture lookup functions using samplers are available to vertex and fragment shaders. The initial “g” in a type name is a placeholder for nothing, “i”, or “u”.\n\n| `gvec4 texture(gsampler{2,3}D sampler, vec{2,3} P [, float bias]);` |\n| `gvec4 texture(gsamplerCube sampler, vec3 P [, float bias]);` |\n| `float texture(sampler2DShadow sampler, vec3 P [, float bias]);` |\n| `float texture(samplerCubeShadow sampler, vec4 P [, float bias]);` |\n| `gvec4 texture(gsampler2DArray sampler, vec3 P [, float bias]);` |\n| `float texture(sampler2DArrayShadow sampler, vec4 P);` |\n| `gvec4 textureProj(gsampler2D sampler, vec{3,4} P [, float bias]);` |\n| `gvec4 textureProj(gsampler3D sampler, vec4 P [, float bias]);` |\n| `float textureProj(sampler2DShadow sampler, vec4 P [, float bias]);` |\n| `gvec4 textureLod(gsampler{2,3}D sampler, vec{2,3} P, float lod);` |\n| `gvec4 textureLod(gsamplerCube sampler, vec3 P, float lod);` |\n| `float textureLod(sampler2DShadow sampler, vec3 P, float lod);` |\n| `gvec4 textureLod(gsampler2DArray sampler, vec3 P, float lod);` |\n| `gvec4 textureOffset(gsampler2D sampler, vec2 P, ivec2 offset [, float bias]);` |\n| `gvec4 textureOffset(gsampler3D sampler, vec3 P, ivec3 offset [, float bias]);` |\n| `float textureOffset(sampler2DShadow sampler, vec3 P, ivec2 offset [, float bias]);` |\n| `gvec4 textureOffset(gsampler2DArray sampler, vec3 P, ivec2 offset [, float bias]);` |\n| `gvec4 texelFetch(gsampler2D sampler, ivec2 P, int lod);` |\n| `gvec4 texelFetch(gsampler3D sampler, ivec3 P, int lod);` |\n| `gvec4 texelFetch(gsampler2DArray sampler, ivec3 P, int lod);` |\n| `gvec4 texelFetchOffset(gsampler2D sampler, ivec2 P, int lod, ivec2 offset);` |\n| `gvec4 texelFetchOffset(gsampler3D sampler, ivec3 P, int lod, ivec3 offset);` |\n| `gvec4 texelFetchOffset(gsampler2DArray sampler, ivec3 P, int lod, ivec2 offset);` |\n| `gvec4 textureProjOffset(gsampler2D sampler, vec3 P, ivec2 offset [, float bias]);` |\n| `gvec4 textureProjOffset(gsampler2D sampler, vec4 P, ivec2 offset [, float bias]);` |\n| `gvec4 textureProjOffset(gsampler3D sampler, vec4 P, ivec3 offset [, float bias]);` |\n| `float textureProjOffset(sampler2DShadow sampler, vec4 P, ivec2 offset [,float bias]);` |\n| `gvec4 textureLodOffset(gsampler2D sampler, vec2 P, float lod, ivec2 offset);` |\n| `gvec4 textureLodOffset(gsampler3D sampler, vec3 P, float lod, ivec3 offset);` |\n| `float textureLodOffset(sampler2DShadow sampler, vec3 P, float lod, ivec2 offset);` |\n| `gvec4 textureLodOffset(gsampler2DArray sampler, vec3 P, float lod, ivec2 offset);` |\n| `gvec4 textureProjLod(gsampler2D sampler, vec3 P, float lod);` |\n| `gvec4 textureProjLod(gsampler2D sampler, vec4 P, float lod);` |\n| `gvec4 textureProjLod(gsampler3D sampler, vec4 P, float lod);` |\n| `float textureProjLod(sampler2DShadow sampler, vec4 P, float lod);` |\n| `gvec4 textureProjLodOffset(gsampler2D sampler, vec3 P, float lod, ivec2 offset);` |\n| `gvec4 textureProjLodOffset(gsampler2D sampler, vec4 P, float lod, ivec2 offset);` |\n| `gvec4 textureProjLodOffset(gsampler3D sampler, vec4 P, float lod, ivec3 offset);` |\n| `float textureProjLodOffset(sampler2DShadow sampler, vec4 P, float lod, ivec2 offset);` |\n| `gvec4 textureGrad(gsampler2D sampler, vec2 P, vec2 dPdx, vec2 dPdy);` |\n| `gvec4 textureGrad(gsampler3D sampler, vec3 P, vec3 dPdx, vec3 dPdy);` |\n| `gvec4 textureGrad(gsamplerCube sampler, vec3 P, vec3 dPdx, vec3 dPdy);` |\n| `float textureGrad(sampler2DShadow sampler, vec3 P, vec2 dPdx, vec2 dPdy);` |\n| `float textureGrad(samplerCubeShadow sampler, vec4 P, vec3 dPdx, vec3 dPdy);` |\n| `gvec4 textureGrad(gsampler2DArray sampler, vec3 P, vec2 dPdx, vec2 dPdy);` |\n| `float textureGrad(sampler2DArrayShadow sampler, vec4 P, vec2 dPdx, vec2 dPdy);` |\n| `gvec4 textureGradOffset(gsampler2D sampler, vec2 P, vec2 dPdx, vec2 dPdy, ivec2 offset);` |\n| `gvec4 textureGradOffset(gsampler3D sampler, vec3 P, vec3 dPdx, vec3 dPdy, ivec3 offset);` |\n| `float textureGradOffset(sampler2DShadow sampler, vec3 P, vec2 dPdx, vec2 dPdy, ivec2 offset);` |\n| `gvec4 textureGradOffset(gsampler2DArray sampler, vec3 P, vec2 dPdx, vec2 dPdy, ivec2 offset);` |\n| `float textureGradOffset(sampler2DArrayShadow sampler, vec4 P, vec2 dPdx, vec2 dPdy, ivec2 offset);` |\n| `gvec4 textureProjGrad(gsampler2D sampler, vec3 P, vec2 dPdx, vec2 dPdy);` |\n| `gvec4 textureProjGrad(gsampler2D sampler, vec4 P, vec2 dPdx, vec2 dPdy);` |\n| `gvec4 textureProjGrad(gsampler3D sampler, vec4 P, vec3 dPdx, vec3 dPdy);` |\n| `float textureProjGrad(sampler2DShadow sampler, vec4 P, vec2 dPdx, vec2 dPdy);` |\n| `gvec4 textureProjGradOffset(gsampler2D sampler, vec3 P, vec2 dPdx, vec2 dPdy, ivec2 offset);` |\n| `gvec4 textureProjGradOffset(gsampler2D sampler, vec4 P, vec2 dPdx, vec2 dPdy, ivec2 offset);` |\n| `gvec4 textureProjGradOffset(gsampler3D sampler, vec4 P, vec3 dPdx, vec3 dPdy, ivec3 offset);` |\n| `float textureProjGradOffset(sampler2DShadow sampler, vec4 P, vec2 dPdx, vec2 dPdy, ivec2 offset);` |\n\n\n### Fragment Processing Functions [8.9]\n\nApproximated using local differencing.\n\n| `T dFdx(T p); Derivative in x` |\n| `T dFdy(T p); Derivative in y` |\n| `T fwidth(T p); abs (dFdx (p)) + abs (dFdy (p));` |\n","slug":"docs/api-reference/shadertools/glsl-reference","title":"GLSL Reference"},{"excerpt":"getParameters, getParamter, setParameters, setParameter luma.gl simplifies the usage of WebGL parameters by providing a unified API for…","rawMarkdownBody":"# getParameters, getParamter, setParameters, setParameter\n\nluma.gl simplifies the usage of WebGL parameters by providing a unified API for setting and getting values. Any GL parameter can be queried or set using `getParameters` and `setParameters` (no need to keep track of what underlying WebGL calls are required), and luma.gl also provide *setting names* that allow the normal WebGL setter functions (like `gl.blendEquation` or `gl.clearColor`) to be specified as keys in a `setParameters` call.\n\nIn addition, state queries are done towards cached values and are thus much faster than working directly with the WebGL API, where synchronous WebGL queries can be a performance bottleneck.\n\nThe following functions are provided:\n* `getParameter` - Returns the value(s) of a GL context parameter\n* `getParameters` - Returns the values of some or all GL context parameters\n* `setParameters` - Sets a the value(s) of the specified GL context parameters\n\n## Usage\n\nGet a global parameter value using a WebGL GLenum\n```js\nconst value = getParameter(gl, gl.DEPTH_TEST);\n```\n\nSet a global parameter value using a WebGL GLenum\n```js\nconst value = setParameters(gl, {\n  [gl.DEPTH_TEST]: true\n});\n```\n\nSet a global parameter value using a luma.gl setting function name\n```js\nconst value = setParameters(gl, {\n  depthTest: true\n});\n```\n\nGet all gl parameter values (values will be an object map keyed with parameter names)\n```js\nconst values = getParameters(gl);\n```\n\n## Methods\n\n### getParameter\n\nGets the value(s) of a single gl context parameter.\n\n```js\ngetParameter(gl, pname)\n```\n\n* `gl` {WebGLRenderingContext} - context\n* `pname` {GLenum}  - parameter name, a GL parameter constant\nReturns {*} - value(s) of this parameter\n\n\n### getParameters\n\nGets the values of a gl context parameter.\n\n```js\ngetParameters(gl, values)\n```\n\n* `gl` {WebGLRenderingContext} - context\n* `values`= {Object | GLenum[] | null}  - parameters, either as keys in object or elements of array. Defaults to all parameters.\nReturns {Object} - object with keys and values corresponding to supplied parameter names and the current values of those parameters.\n\n\n### setParameters\n\nSets a number of parameters.\n\n```js\nsetParameters(gl, {key: value, ...})\n```\n\n* `gl` {WebGLRenderingContext} - context\n* `key` {String} - parameter names, (, either )luma.gl setting name or a GL parameter constants\n* `value` {*} - parameter value\nReturns {*} - \"normalized\" parameter value after assignment\n\nNote:\n* If both luma.gl setting names and GL parameter constants representing the same value are submitted the results are undefined.\n* value may be \"normalized\" (in case a short form is supported). In that case the normalized value is returned.\n\n## Parameters\n\nDescribes luma.gl setting names and values\n\n### Blending\n\n| Function style        | Sets parameter(s)      |\n| --------------------- | ---------------------- |\n| [blendColor](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/blendColor)        | `GL.BLEND_COLOR`       |\n| [blendEquation](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/blendEquation)     | [`GL.BLEND_EQUATION_RGB`, `GL.BLEND_EQUATION_ALPHA`] |\n| [blendFunc](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/blendFunc)         | [`GL.BLEND_SRC_RGB`, `GL.BLEND_SRC_ALPHA`] |\n| [blendFuncSeparate](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/blendFuncSeparate) | [`GL.BLEND_SRC_RGB`, `GL.BLEND_SRC_ALPHA`, `GL.BLEND_DST_RGB`, `GL.BLEND_DST_ALPHA`] |\n\n| Parameter                 | Type            | Default         | Description |\n| ------------------------- | --------------- | --------------- | -------- |\n| `GL.BLEND`                | GLboolean       | `false`         | Blending enabled |\n| `GL.BLEND_COLOR`          | Float32Array(4) | `[0, 0, 0, 0]`  | |\n| `GL.BLEND_EQUATION_RGB`   | GLenum          | `GL.FUNC_ADD`   | |\n| `GL.BLEND_EQUATION_ALPHA` | GLenum          | `GL.FUNC_ADD`   | |\n| `GL.BLEND_SRC_RGB`        | GLenum          | `GL.ONE`        | srcRgb |\n| `GL.BLEND_SRC_ALPHA`      | GLenum          | `GL.ZERO`       | srcAlpha |\n| `GL.BLEND_DST_RGB`        | GLenum          | `GL.ONE`        | dstRgb |\n| `GL.BLEND_DST_ALPHA`      | GLenum          | `GL.ZERO`       | dstAlpha |\n\n\n### Clear Color\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [clearColor](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/clearColor) | GL.COLOR_CLEAR_VALUE |\n\n| Parameter              | Type            | Default  | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.COLOR_CLEAR_VALUE` | new Float32Array(4) | [0, 0, 0, 0] | . |\n\n\n### Color Mask\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [colorMask](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/colorMask) | GL.COLOR_WRITEMASK |\n\n| Parameter              | Type            | Default  | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.COLOR_WRITEMASK` | [GLboolean, GLboolean, GLboolean, GLboolean] | [true, true, true, true] | . |\n\n\n### Depth Test\n\n| Function style   | Sets parameters        |\n| ---------------- | ---------------------- |\n| [clearDepth](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/clearDepth)     | `GL.DEPTH_CLEAR_VALUE` |\n| [depthFunc](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/depthFunc)      | `GL.DEPTH_FUNC`        |\n| [depthRange](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/depthRange)     | `GL.DEPTH_RANGE`       |\n| [depthMask](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/depthMask)      | `GL.DEPTH_WRITEMASK`   |\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.DEPTH_TEST`        | GLboolean       | false |  |\n| `GL.DEPTH_CLEAR_VALUE` | GLfloat         | true |  |\n| `GL.DEPTH_FUNC`        | GLenum          | null |  |\n| `GL.DEPTH_RANGE`       | Float32Array(2) | [null, null] // TBD |  |\n| `GL.DEPTH_WRITEMASK`   | GLboolean       | null |  |\n\n\n### Derivative Hints (WebGL2 or extension)\n\nRequires WebGL2 or `OES_standard_derivatives`.\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.FRAGMENT_SHADER_DERIVATIVE_HINT` | GLenum     | `GL.DONT_CARE` | Accuracy of derivates in built-in GLSL functions |\n\n\n#### Hints\n\n| Value          | Description        |\n| -------------- | ---------------------- |\n| `GL.FASTEST`   | The most efficient behavior should be used |\n| `GL.NICEST`    | The most correct or the highest quality option should be used |\n| `GL.DONT_CARE` | There is no preference for this behavior |\n\n\n### Dithering\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.DITHER` | GLboolean | `true` | Enable dithering of color components before they get written to the color buffer |\n\n* Note: Dithering is driver dependent and typically has a stronger effect when the color components have a lower number of bits.\n\n\n### Face Culling\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [cullFace](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/cullFace)  | `GL.CULL_FACE_MODE` |\n| [frontFace](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/frontFace) | `GL.FRONT_FACE` |\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.CULL_FACE`         | GLboolean | `false` | Enable face culling |\n| `GL.CULL_FACE_MODE`    | GLenum    | `GL.BACK` | Which face to cull |\n| `GL.FRONT_FACE`        | GLenum    | `GL.CCW` | Which face is front |\n\n#### Cull Face Modes\n\n| Value               | Description            |\n| ------------------- | ---------------------- |\n| `GL.FRONT`          | Clock wise             |\n| `GL.BACK`           | Counter clock wise     |\n| `GL.FRONT_AND_BACK` | No polygons are drawn (but LINES and POINTS are) |\n\n#### Face orientation\n\n| Value          | Description        |\n| -------------- | ------------------ |\n| `GL.CW`        | Clock wise         |\n| `GL.CCW`       | Counter clock wise |\n\n\n### MipmapHint\n\nHint for quality of images generated with glGenerateMipmap\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.GENERATE_MIPMAP_HINT` | GLenum | `GL.DONT_CARE` | . |\n\n#### Mipmap Hints\n\n| Value          | Description            |\n| -------------- | ---------------------- |\n| `GL.FASTEST`   | The most efficient behavior should be used |\n| `GL.NICEST`    | The most correct or the highest quality option should be used |\n| `GL.DONT_CARE` | There is no preference for this behavior |\n\n\n### LineWidth\n\nLine widths are between 1 and GL.ALIASED_LINE_WIDTH_RANGE.\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [lineWidth](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/lineWidth) | `GL.LINE_WIDTH` |\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.LINE_WIDTH` | GLfloat | 1 | . |\n\nExample:\n```js\n// Set viewport to maximum supported size\nconst lineWidthRange = getLimits(gl)[GL.ALIASED_LINE_WIDTH_RANGE];\nsetState(gl, {\n  lineWidth: lineWidthRange[1]\n});\n```\n\n* Note: Line widths will be clamped to [1, `GL.ALIASED_LINE_WIDTH_RANGE`]. This is different from `gl.lineWidth` which generates errors on lineWidth 0.\n* Caution: line aliasing is driver dependent and `GL.LINES` may not give desired results.\n\n\n### PolygonOffset\n\nAdd small offset to fragment depth values (by factor × DZ + r × units)\nUseful for rendering hidden-line images, for applying decals to surfaces,\nand for rendering solids with highlighted edges.\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [polygonOffset](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/polygonOffset) | [GL.POLYGON_OFFSET_FACTOR, GL.POLYGON_OFFSET_UNITS] |\n\n| Parameter                  | Type          | Default  | Description             |\n| -------------------------- | ------------- | -------- | ----------------------- |\n| `GL.POLYGON_OFFSET_FILL`   | GLboolean     |  `false` | . |\n| `GL.POLYGON_OFFSET_FACTOR` | GLfloat       |      `0` | . |\n| `GL.POLYGON_OFFSET_UNITS`  | GLfloat       |      `0` | . |\n\n* Note: The semantics of polygon offsets are loosely specified by the WebGL standard and results can thus be driver dependent.\n\n\n### Rasterization (WebGL2)\n\nPrimitives are discarded immediately before the rasterization stage, but after the optional transform feedback stage. `gl.clear()` commands are ignored.\n\n| Parameter                           | Type          | Default  | Description             |\n| ----------------------------------- | ------------- | -------- | ----------------------- |\n| `GL.RASTERIZER_DISCARD`             | GLboolean     | `false`  | Disable rasterization |\n\n\n### Sampling\n\nSpecify multisample coverage parameters\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [sampleCoverage](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/sampleCoverage) | [`GL.SAMPLE_COVERAGE_VALUE`, `GL.SAMPLE_COVERAGE_INVERT`] |\n\n| Parameter                          | Type          | Default  | Description             |\n| ---------------------------------- | ------------- | -------- | ----------------------- |\n| `GL_SAMPLE_COVERAGE`               | GLboolean | `false` | Activates the computation of a temporary coverage value determined by the alpha value. |\n| `GL_SAMPLE_ALPHA_TO_COVERAGE`      | GLboolean | `false` | Activates ANDing the fragment's coverage with the temporary coverage value |\n| `GL.SAMPLE_COVERAGE_VALUE`         | GLfloat   | 1.0     |  |\n| `GL.SAMPLE_COVERAGE_INVERT`        | GLboolean | `false` |  |\n\n\n### Scissor Test\n\nSettings for scissor test and scissor box.\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [scissor](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/scissor) | `GL.SCISSOR_BOX`                   |\n| scissorTest | GL.SCISSOR_TEST |\n\n| Parameter                          | Type          | Default  | Description             |\n| ---------------------------------- | ------------- | -------- | ----------------------- |\n| `GL.SCISSOR_TEST`                  | GLboolean     | `false`  |\n| `GL.SCISSOR_BOX`                   | Int32Array(4) | [null, null, null, null]), // TBD |\n\n\n### Stencil Test\n\nSetting any value will enable stencil testing (i.e. enable `GL.STENCIL_TEST`).\n\n| Function | Parameters Set |\n| -------- | -------------- |\n| [clearStencil](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/clearStencil) | `GL.STENCIL_CLEAR_VALUE` |\n| [stencilMask](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilMask) | [`GL.STENCIL_WRITEMASK`] |\n| [stencilMaskSeparate](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilMaskSeparate) | [`GL.STENCIL_WRITEMASK`, `GL.STENCIL_BACK_WRITEMASK`] |\n| [stencilFunc](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilFunc) | [`GL.STENCIL_FUNC`, `GL.STENCIL_REF`, `GL.STENCIL_VALUE_MASK`] |\n| [stencilFuncSeparate](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilFuncSeparate) | [`GL.STENCIL_FUNC`, `GL.STENCIL_REF`, `GL.STENCIL_VALUE_MASK`, `GL.STENCIL_BACK_FUNC`, `GL.STENCIL_BACK_REF`, `GL.STENCIL_BACK_VALUE_MASK` ]\n| [stencilOp](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilOp) | [`GL.STENCIL_FAIL`, `GL.STENCIL_FAIL_DEPTH_FAIL`, `GL.STENCIL_FAIL_DEPTH_PASS`]|\n| [stencilOpSeparate](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilOpSeparate) | [`GL.STENCIL_FAIL`, `GL.STENCIL_FAIL_DEPTH_FAIL`, `GL.STENCIL_FAIL_DEPTH_PASS`, `GL.STENCIL_BACK_FAIL`, `GL.STENCIL_BACK_FAIL_DEPTH_FAIL`, `GL.STENCIL_BACK_FAIL_DEPTH_PASS`]|\n\n| Parameter                         | Type      | Default      | Description             |\n| --------------------------------- | --------- | ------------ | ----------------------- |\n| `GL.STENCIL_TEST`                 | GLboolean | `false`      | Enables stencil testing |\n| `GL.STENCIL_CLEAR_VALUE`          | GLint     | `0`          | Sets index used when stencil buffer is cleared. |\n| `GL.STENCIL_WRITEMASK`            | GLuint    | `0xFFFFFFFF` | Sets bit mask enabling writing of individual bits in the stencil planes |\n| `GL.STENCIL_BACK_WRITEMASK`       | GLuint    | `0xFFFFFFFF` | Sets bit mask enabling writing of individual bits in the stencil planes |\n| `GL.STENCIL_FUNC`                 | GLenum    | `GL.ALWAYS`  | |\n| `GL.STENCIL_REF`                  | GLint     | `0`          | |\n| `GL.STENCIL_VALUE_MASK`           | GLuint    | `0xFFFFFFFF` | Sets bit mask |\n| `GL.STENCIL_BACK_FUNC`            | GLenum    | `GL.ALWAYS`  | |\n| `GL.STENCIL_BACK_REF`             | GLint     | `0`          | |\n| `GL.STENCIL_BACK_VALUE_MASK`      | GLuint    | `0xFFFFFFFF` | Sets bit mask enabling writing of individual bits in the stencil planes |\n| `GL.STENCIL_FAIL`                 | GLenum    | `GL.KEEP`    | stencil test fail action |\n| `GL.STENCIL_PASS_DEPTH_FAIL`      | GLenum    | `GL.KEEP`    | depth test fail action |\n| `GL.STENCIL_PASS_DEPTH_PASS`      | GLenum    | `GL.KEEP`    | depth test pass action |\n| `GL.STENCIL_BACK_FAIL`            | GLenum    | `GL.KEEP`    | stencil test fail action, back |\n| `GL.STENCIL_BACK_PASS_DEPTH_FAIL` | GLenum    | `GL.KEEP`    | depth test fail action, back |\n| `GL.STENCIL_BACK_PASS_DEPTH_PASS` | GLenum    | `GL.KEEP`    | depth test pass action, back |\n\n#### Stencil Test Functions\n\nValues for `GL.STENCIL_TEST`\n\n| Value          | Description            |\n| -------------- | ---------------------- |\n| `GL.NEVER`     | Never pass |\n| `GL.LESS`      | Pass if (ref & mask) <  (stencil & mask) |\n| `GL.EQUAL`     | Pass if (ref & mask) =  (stencil & mask) |\n| `GL.LEQUAL`    | Pass if (ref & mask) <= (stencil & mask) |\n| `GL.GREATER`   | Pass if (ref & mask) >  (stencil & mask) |\n| `GL.NOTEQUAL`  | Pass if (ref & mask) != (stencil & mask) |\n| `GL.GEQUAL`    | Pass if (ref & mask) >= (stencil & mask) |\n| `GL.ALWAYS`    | Always pass |\n\n#### Stencil Operations\n\n| Value          | Description            |\n| -------------- | ---------------------- |\n| `GL.KEEP`      | Keeps the current value |\n| `GL.ZERO`      | Sets the stencil buffer value to 0 |\n| `GL.REPLACE`   | Sets the stencil buffer value to the reference value as specified by `stencilFunc` |\n| `GL.INCR`      | Increments the current stencil buffer value. Clamps to the maximum representable unsigned value |\n| `GL.INCR_WRAP` | Increments the current stencil buffer value. Wraps to zero when incrementing the maximum representable unsigned value |\n| `GL.DECR`      | Decrements current stencil buffer value. Clamps to 0 |\n| `GL.DECR_WRAP` | Decrements  current stencil buffer value, wraps to maximum unsigned value when decrementing 0 |\n| `GL.INVERT`    | Inverts the current stencil buffer value bitwise |\n\nAction when the stencil test fails, front and back.\n* stencil test fail action,\n* depth test fail action,\n* pass action\n\n\n## Viewport\n\nSpecifies the transformation from normalized device coordinates to\nwindow/framebuffer coordinates. The maximum supported value, is defined by the\n`GL.MAX_VIEWPORT_DIMS` limit.\n\n| Function     | Parameters     |\n| ------------ | -------------- |\n| [viewport](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/viewport) | `GL.VIEWPORT`  |\n\n| Parameter                          | Type          | Default   | Description             |\n| ---------------------------------- | ------------- | --------- | ----------------------- |\n| `GL.VIEWPORT`                      | Int32Array(4) | [...] TBD | Viewport                |\n\nExample:\n```js\n// Set viewport to maximum supported size\nconst maxViewport = getLimits(gl)[GL.MAX_VIEWPORT_DIMS];\nsetState(gl, {\n  viewport: [0, 0, maxViewport[0], maxViewport[1]]\n});\n```\n\n## Pixel Pack/Unpack Modes\n\nSpecifies how bitmaps are written to and read from memory\n\n| Parameter                             | Type          | Default  | Description             |\n| ------------------------------------- | ------------- | -------- | ----------------------- |\n| `GL.PACK_ALIGNMENT`                   | GLint         |        4 | Byte alignment of pixel row data in memory (1,2,4,8 bytes) when storing data |\n| `GL.UNPACK_ALIGNMENT`                 | GLint         |        4 | Byte alignment of pixel row data in memory (1,2,4,8 bytes) when reading data |\n| `GL.UNPACK_FLIP_Y_WEBGL`              | GLboolean     |  `false` | Flip source data along its vertical axis |\n| `GL.UNPACK_PREMULTIPLY_ALPHA_WEBGL`   | GLboolean     |  `false` | Multiplies the alpha channel into the other color channels |\n| `GL.UNPACK_COLORSPACE_CONVERSION_WEBGL` | GLenum      | `GL.BROWSER_DEFAULT_WEBGL` | Use default or no color space conversion. |\n\n\n## Pixel Pack/Unpack Modes **WebGL2**\n\nSpecifies how bitmaps are written to and read from memory\n\n| Parameter                          | Type          | Default  | Description               |\n| ---------------------------------- | ------------- | -------- | ------------------------- |\n| `GL.PACK_ROW_LENGTH`               | GLint         |      `0` | Number of pixels in a row |\n| `GL.PACK_SKIP_PIXELS`              | GLint         |      `0` | Number of pixels skipped before the first pixel is written into memory |\n| `GL.PACK_SKIP_ROWS`                | GLint         |      `0` | Number of rows of pixels skipped before first pixel is written to memory |\n| `GL.UNPACK_ROW_LENGTH`             | GLint         |      `0` | Number of pixels in a row. |\n| `GL.UNPACK_IMAGE_HEIGHT`           | GLint         |      `0` | Image height used for reading pixel data from memory |\n| `GL.UNPACK_SKIP_PIXELS`            | GLint         |      `0` | Number of pixel images skipped before first pixel is read from memory |\n| `GL.UNPACK_SKIP_ROWS`              | GLint         |      `0` | Number of rows of pixels skipped before first pixel is read from memory |\n| `GL.UNPACK_SKIP_IMAGES`            | GLint         |      `0` | Number of pixel images skipped before first pixel is read from memory |\n\n\n## Remarks\n\nWebGL State Management can be quite complicated.\n* A large part of the WebGL API is devoted to parameters. When reading, querying individual values using GL constants is the norm, and when writing, special purpose functions are provided for most parameters. luma.gl supports both forms for both reading and writing parameters.\n* Reading values from WebGL can be very slow if it requires a GPU roundtrip. To get around this, luma.gl reads values once, caches them and tracks them as they are changed through luma functions. The cached values can get out of sync if the context is shared outside of luma.gl.\n* luma.gl's state management enables \"conflict-free\" programming, so that even when setting global state, one part of the code does not need to worry about whether other parts are changing the global state.\n* Note that to fully support the conflict-free model and detect changes done e.g. in other WebGL libraries, luma.gl needs to hook into the WebGL context to track state changes.\n","slug":"docs/api-reference/webgl/context/get-parameters","title":"getParameters, getParamter, setParameters, setParameter"},{"excerpt":"What's New Version 7.3 Date: September 19, 2019 Program Management luma.gl introduces the ProgramManager class to manage caching and re-use…","rawMarkdownBody":"# What's New\n\n## Version 7.3\n\nDate: September 19, 2019\n\n### Program Management\n\nluma.gl introduces the [ProgramManager](/docs/api-reference/core/resource-management/program-manager.md) class to manage caching and re-use of `Program` objects, providing powerful load and runtime optimizations:\n- Redundant shader compilation and linking is avoided.\n- Redundant program switching (among the [most expensive](https://computergraphics.stackexchange.com/a/46) GPU state changes) while rendering is avoided.\n\nThe `Model` class has been updated to take advantage of these new capabilities, automatically caching and re-using `Program`s where possible.\n\nThe table below shows the effect of program sharing in deck.gl. The test renders 1000 [ScatterplotLayers](https://deck.gl/#/examples/core-layers/scatterplot-layer), each of which draws 100 intanced geometries, for a total of 1000 draw calls and 100,000 instances. Timings are milliseconds spent on the CPU and GPU to render a single frame on the following two machines:\n\n- Macbook Pro 2018, OSX, 2.6 GHz Intel Core i7, Radeon Pro 560X 4 GB\n- Razer Blade, Windows 10, Intel i7-8750H 6 Core, Intel UHD Graphics 630\n\n||  No Program Sharing |Program Sharing | Improvement |\n| --- | --- | --- | --- |\n| Macbook Pro CPU | 113ms | 93ms | 17% |\n| Macbook Pro GPU | 43ms   | 34ms  | 20% |\n| Razer Blade CPU | 145ms | 125ms | 13% |\n| Razer Blade GPU | 137ms | 115ms | 16% |\n\n\n\n### Custom Device Pixels (Experimental)\n\nluma.gl now provides experimental support for specifying the pixel ratio mapping between canvas size and the GL drawing buffer. luma.gl has always provided support for matching the native device pixel ratio on high-resolution screens, but custom ratios allow applications to, for example, use SSAO for improved fidelity or reduced drawing resolution to improve performance.\n\n\n## Version 7.2\n\nDate: July 9, 2019\n\n### FXAA Shader Module\n\nluma.gl now supports FXAA (Fast Approximate Antialiasing) as a post processing effect. This allows for antialiasing on offscreen framebuffers.\n\n### ImageBitmap Textures\n\nThe `Texture` class now supports `ImageBitmap` input data.\n\n\n## Version 7.1\n\nDate: June 4, 2019\n\n### Enhanced Shader Injection System\n\nluma.gl now supports a much more robust system for injecting code into shaders. In addition to the pre-defined shader hooks such as `vs:#main-start`,\nthe shader injection system now supports:\n- Definition of arbitrary shader hook functions that can be called anywhere in a shader\n- Injection of arbitrary code into shader hook functions to modify their behavior\n- Automatic injection by shader modules into hook functions or pre-defined shader hooks\n\nThe combination of these features allows the behavior of the same shader code to be modified depending on included shader modules or other\nrequirements of the application. See [assembleShaders](/docs/api-reference/shadertools/assemble-shaders.md) documentation for more details.\n\n### Animation Support\n\nMore robust animations are now supported via the `Timeline` and `KeyFrames` classes.\n\nThe  `Timeline` class supports easily managing a timeline with multiple channels elapsing at different rates, as well as orchestrating playing, pausing, and rewinding behavior between them. A timeline can be attached to an `AnimationLoop` and then queried for time values, which can be used in animations. See [Timeline](/docs/api-reference/addons/animation/timeline.md) documentation for more details.\n\nThe `KeyFrames` class allows arbitrary data to be associated with time points. The time value of the key frames can be set and the current key frames and interpolation factor can be queried and used in calculating animated values. See [KeyFrames](/docs/api-reference/addons/animation/key-frames.md) documentation for more details.\n\n## Version 7.0\n\nDate: April 19, 2019\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=200 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/gltf-city.gif\" />\n        <p><i>glTF Support</i></p>\n      </td>\n      <td>\n        <img height=200 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/gltf-pbr.gif\" />\n        <p><i>PBR (Physically Based Rendering)</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### glTF Support\n\n<img height=100 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/gltf.png\" />\n\nluma.gl can now load 3D models and scenegraphs in the popular [glTF™](https://www.khronos.org/gltf/) asset format (with the help of the loaders.gl [GLTFLoader](https://github.com/uber-web/loaders.gl/blob/master/website/docs/api-reference/gltf-loaders/gltf-loader.md). All variants of glTF 2.0 are supported, including binary `.glb` files as well as JSON `.gltf` files with binary assets in base64 encoding or in separate files. The Draco Mesh compression extension is also supported.\n\n- **Physically-based Material Support**: Ensures that PBR models display as intended.\n- **Scenegraph Improvements**: The Scenegraph classes have been refactored to ensure support for glTF objects.\n- **Geometry glTF Support**: The `Geometry` class and scene graph support has been overhauled to conform to glTF conventions, simplifying loading and manipulation of glTF formatted data.\n\n\n### loaders.gl Integration\n\n[loaders.gl](https://uber-web.github.io/loaders.gl/) is a major new companion framework to luma.gl that provides a suite of 3D file format loaders (with an emphasizis on point cloud formats), including:\n\n* Draco\n* PLY\n* PCD\n* LAS/LAZ\n* OBJ\n\nloaders.gl output can now be passed directly into luma.gl classes like `Geometry` and `Model` making it straightforward to use luma.gl with a wide variety of file formats.\n\n\n### Asynchronous Textures\n\nImage data for `Texture` classes can now be supplied using URLs or `Promise`s, making it unnecessary for applications to handle image loading themselves.\n\n```js\nnew Texture2D(gl, 'path/to/my/image.png'); // Texture2D will load the image and becomes 'renderable' once it loads\n// or\nnew Texture2D(gl, loadImage('path/to/my/image.png')); // loadImage returns a promise\n```\n\n### Lighting\n\nA standardized set of light classes are now supported by multiple material models (Phong, Goraud and PBR) enabling various models to be mixed and properly lit in the same scene.\n\n\n### Modularization Improvements\n\n- luma.gl has been restructured to make it easier for applications to select and import only parts of the library that they use.\n\n* ` @luma.gl/gpgpu` **<sup>New</sup>** - A new experimental submodule with GPGPU Algorithms and Utilities has been added, containing a growing collection of GPU accelerated algorithms and utility methods.\n\n\n### Performance Instrumentation\n\nExtensive metrics about frame CPU and GPU times, resource counts, and GPU memory usage are being collected. The data is exposed as a [probe.gl](https://uber-web.github.io/probe.gl/#/) [`Stats`](https://uber-web.github.io/probe.gl/#/documentation/api-reference-logging/stats) object. The new probe.gl [StatsWidget](https://uber-web.github.io/probe.gl/#/documentation/api-reference-widgets/statswidget) can be used to present data in applications.\n\n\n### Interleaved Attributes\n\nTo improve support for interleaved attributes and glTF model loading, accessor objecs and the `Accessor` class now support a `buffer` field. In addition, attribute setting functions now accept accessor objects with the `buffer` field set. This allows multiple accessor objects referencing the same buffer:\n\n```\nconst buffer = // \"interleaved\" vertex attributes: 3 floats for position followed by 4 bytes for RGBA\nmodel.setAttributes({\n  positions: {buffer, stride: 16, offset: 0, ...}}),\n  colors: {buffer, stride: 16, offset: 12, ...}})\n}\n```\n\n### Unified functions for Framebuffers and Textures (Read/Copy/Blit)\n\nA set of global methods that perform copying data to and from `Framebuffer` objects. All functions that read from or write to a `Framebuffer` object now also accept a `Texture` object (no need to create and configure a `Framebuffer` just to do a simple operation on a `Texture`).\n\n\n## Experimental Features\n\n### WebVR Support (experimental)\n\nJust replace your `AnimationLoop` with `VRAnimationLoop` from ` @luma.gl/addons`. Works with [Firefox Reality](https://mixedreality.mozilla.org/firefox-reality/).\n\n\n\n## Version 6.4\n\nDate: January 29, 2018\n\n### PBR (Physically Based) Rendering and Material\n\nPhysically-Based Rendering is now supported and the new `PBRMaterial` class can be used to set up parameters. Material can be selected per model.\n\n\n### Copy and Blit methods\n\nSeveral member function of `Framebuffer` and `Texture` classes are now replaced by global methods that peform copying data to and from `Framebuffer` objects. All methods that read from or write to a `Framebuffer` object, can now also accept a `Texture` object.\n\n\n## Version 6.3\n\nDate: November 16, 2018\n\n### Uniform Caching\n\nUniforms are now cached at `Program` object, which improves performance by eliminating uniform setter calls when uniform values are not changed.\n\n### New submodules\n\n* `@luma.gl/debug` - an experimental module for debugging WebGL shaders on CPU\n* `@luma.gl/glfx` - shader modules for image processing\n\n### Offscreen Rendering (Experimental)\n\nA new experimental class `AnimationLoopProxy` supports running an `AnimationLoop` on a worker thread using the `OffscreenCanvas` API made official in Chrome 70. For more detatils, see [API documentation](/docs/api-reference/core/animation-loop-proxy.md) and [example app](https://github.com/uber/luma.gl/tree/7.2-release/test/apps/wip/worker).\n\n\n## Version 6.2\n\nDate: September 12, 2018\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/render-pass.gif\" />\n        <p><i>glfx port using ShaderModulePass</i></p>\n      </td>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/transform-texture.gif\" />\n        <p><i>Transform: edge detection</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### ShaderModulePass (Experimental)\n\nShader modules that expose \"standard\" filtering and sampling functions can be given extra metadata (the `passes` field) enabling easy construction of a `ShaderModulePass`. Look for `ShaderPass` badges in the documentation of shader modules.\n\n### Transform Texture support (Experimental)\n\n`Transform` class was introduced in 6.0 provides easy API to perform WebGL's complicated `TransformFeedback`. We are now extending this class to provide same easy API to read and write into textures. Running image filters, performing offline rendering and custom texture mip-map generation are some of the use-cases. Moreover, texture and buffer access can be combined, i.e. using single `Transform` instance buffers can be captured using `TransformFeedback` and data can be propagated beyond vertex shader to generate a texture.\n\n\n## Version 6.1\n\nDate: Target August 31, 2018\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/luma61-ssao-pass-thumb.gif\" />\n        <p><i>Ambient Occlusion Render Pass</i></p>\n      </td>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/luma61-edge-pass-thumb.gif\" />\n        <p><i>Edge Detection Render Pass</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nluma.gl 6.1 is a minor release that introduces a number of new experimental capabilities that are expected to be built out and become official over the next few releases.\n\n\n### New Multipass Rendering System (Experimental)\n\nluma.gl now provides a composable multipass rendering framework, based on a `MultiPassRenderer` class that accepts a list of render passes.\n\n\n### Post-Processing Effects (Experimental)\n\nA number of classic WebGL/OpenGL post processing effects have been ported to luma.gl and packaged as composable render passes. For maxiumum flexibility, many of the underlying shaders have also been exposed as shader modules, allowing filtering features to be used either directly in existing shaders or applied as a post-processing filter.\n\n\n### New loaders.gl Submodule (Experimental)\n\nA selection of open source 3D loaders have been ported to a new submodule `loaders.gl`. Initial focus is on point cloud loaders (PLY, LAZ, PCD), although a geospatial loader (KML) is also included. In addition it contains both read and write support for GLB (the glTF binary container format).\n\n\n### Transform Class now supports Shader Modules\n\nThe `Transform` class now accepts shader module parameters (such as `modules`, `dependencies` and `inject`, see [assembleShaders](/docs/api-reference/shadertools/assemble-shaders.md)), enabling the use of shader modules in transform feedback operations.\n\n\n### Documentation Search\n\nluma.gl is now using the [ocular](https://github.com/uber-web/ocular) document generator to build its website, which among other things enables search.\n\n\n## Version 6.0\n\nDate: July 18, 2018\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/webgl2.jpg\" />\n        <p><i>WebGL Improvements</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nA major release that as always focuses on WebGL performance and code size optimizations, better support for shader/GLSL programming, improved documentation and API cleanup.\n\n\n## WebGL Improvements\n\n### Attribute Management Optimizations\n\n`VertexArray` objects are now used for all attribute management in luma.gl, resulting in improved performance and a simpler, more consistent API. The `Program` and `Model` class APIs have been updated to use `VertexArray`.\n\n### Buffer Memory Optimizations\n\nThe `Buffer` class no longer holds on to the complete JavaScript typed arrays used during initialization. This can lead to significant memory savings in apps that use multiple large GPU buffers initialized from typed arrays. Also for convenience a new method `getElementCount` is added that returns number elements based on its size and type.\n\n### Transform Feedback Improvements\n\nA new method `Model.transform` makes it easier to run basic transform feedback operations, when the full power of the new `Transform` class (see below) is not needed.\n\n\n### Transform class (WebGL2)\n\n[`Transform`](/docs/api-reference/core/transform.md) is now an officially supported luma.gl class. This new class provides an easy-to-use interface to Transform Feedback. This class hides complexity by internally creating and managing the supporing WebGL objects that are necessary to perform Transform Feedback operations.\n\n\n## Shader Module System Improvements\n\n### GLSL Transpilation\n\nThe shader assembler now transforms shader code to the GLSL version specified by the top-level shader. GLSL 3.00 ES shader code is transparently transformed into GLSL 1.00 ES compatible code when needed, and vice versa. This allows application to write shader code in the modern GLSL version available (3.00 ES) and still run it under WebGL1 - Shader \"transpilation\" will automatically convert shader module source code syntax to the target version (assuming that no WebGL2 only features were used).\n\n\n### Shader Code Injection\n\nA new shader injection system allows applications to inject additional code into existing shaders. In many cases, this can avoid the need to copy (or \"fork\") large and complicated existing shaders just to add a few lines of code.\n\nShader injection can be used to \"inject\" new shader modules into an existing shader. Adding a shader module to the modules list automatically \"prepends\" the shader module functions to the beginning of your main shader code, but using a shader module still typically requires adding one or two lines of code each to the main functions in the vertex and fragment shaders. In many cases, the new shader injection feature allows this be done without copying the original shaders.\n\n\n### Shader Modules now support GLSL 3.00 ES\n\nAll shader modules are now written in GLSL 3.00 syntax, and leverage the new GLSL transpilation feature to be compatible with both GLSL 3.00 ES and GLSL 1.00 ES main shaders. Care is taken to avoid using GLSL 3.00 specific features whenever possible, and exceptions will be clearly documented.\n\n\n## Documentation\n\n### Developer's Guide\n\nluma.gl now has a more extensive Developer's Guide covering more areas of the API, including a new developer guide for shader programming, with sections about writing shaders and the shader module system. Content includes:\n\n- Guidelines for writing shaders that work in both GLSL 3.00 ES and GLSL 1.00 ES\n- A new GLSL language reference page describing both GLSL 3.00 ES and GLSL 1.00 ES (as well as what has changed between them) in a single place.\n\n\n## API Cleanup\n\nBeing a major release, in v6.0 we took the opportunity to clean up the luma.gl API.\n\n\n### Removal of Deprecated/Unused Methods\n\nTo keep reducing application bundle size, a number of methods have been removed from the luma.gl API. Methods that were deprecated in previous releases have now been removed, and in additional a number of rarely used methods have also been dropped (in most cases, the dropped functionality is still accessible using raw WebGL calls).\n\n### Renamed Methods\n\nIn a few cases, methods have been renamed after API Audits, usually to improve API consistency. The details are listed in the Upgrade Guide. In most cases, running your pre-v6 application on v6 should generate messages in the console when old method calls are encountered, and you should be able to quickly address any changes one-by-one by referring to the Upgrade Guide.\n\n\n\n## Version 5.3\n\nDate: June 1, 2018\n\nA minor release with bug fixes and internal improvements.\n\n\n## Version 5.2\n\nDate: Apr 24, 2018\n\n## Transform class (WebGL2, Experimental)\n\nThe new experimental [`Transform`](/docs/api-reference/core/transform.md) class provides an easy-to-use interface to perform Transform Feedback operations.\n\n\n## Framebuffer Class\n\n**Pixel Readback to GPU Buffers** (WebGL2) - A new method [`Framebuffer.readPixelsToBuffer`](/docs/api-reference/webgl/framebuffer.md) is added to asynchronously read pixel data into a `Buffer` object. This allows  applications to reduce the CPU-GPU sync time by postponing transfer of data or to completely avoid GPU-CPU sync by using the pixel data in the GPU `Buffer` object directly as data source for another GPU draw or transform feedback operation.\n\n\n## Bundle Size Reduction\n\nThe impact of importing luma.gl on production application bundle sizes has been reduced, in particular when using webpack 4 with appropriate configuration. A new article about [bundling and tree shaking](/docs/developer-guide/building-apps.md) has been added to the Developer Guide, providing in-depth information and guidance on what numbers to expect.\n\n\n## Running luma.gl in Node.js\n\nRunning of luma.gl under Node.js is now easier than ever. luma.gl v5.2 automatically loads headless-gl if installed on the system, avoiding the need for the app to import special files or add other conditional logic. See [Using with Node](/docs/get-started/README.md) and the Upgrade Guide.\n\n\n## Debug Mode Changes\n\nTo further reduce production application bundle sizes, luma.gl no longer support WebGL debug contexts by default, as this requires including the Khronos [WebGLDeveloperTools](https://github.com/KhronosGroup/WebGLDeveloperTools) into the bundle. WebGL debug contexts are still available, but needs to be explicitly enabled. To understand how to use WebGL debug contexts in v5.2, please refer to the article on [Debugging](/docs/developer-guide/debugging.md) and the Upgrade Guide.\n\n\n## Examples\n\nAll examples have been updated to use webpack 4\n\n\n## Version 5.1\n\nA smaller release with improvements to `TransformFeedback` support.\n\nDate: Feb 15, 2018\n\n## TransformFeedback Class\n\nTwo improvements Performing Transform Feedback operations has gotten easier, mainly in the following two ways:\n\n`TransformFeedback` instances can now be supplied directly to `Model.draw` and feedback will begin and end during that draw call. Thus it is no longer necessary to work directly with the `Program` class to use transform feedback.\n\n`Program` now build a `varyingMap` on creation depending on `varyings` array and `drawMode`. This `varyingMap` can be passed to `TransformFeedback.bindBuffers()` enabling buffers to be indexed by the name of the \"varying\" instead of using an index.\n\nFor more details check [`TransformFeedback`](/docs/api-reference/webgl/transform-feedback.md) and [`Model`](/docs/api-reference/core/model.md) documentation.\n\n\n## Version 5.0\n\nDate: Dec 22, 2017\n\nA smaller release with several new examples and some under the hood changes to improve performance.\n\n\n### Examples\n\nAdditional examples have been ported to the luma.gl v5 API.\n\n* [Lesson 10](http://uber.github.io/luma.gl/#/examples/webgl-lessons/lesson-10-3d-world)\n* [Lesson 11](http://uber.github.io/luma.gl/#/examples/webgl-lessons/lesson-11-sphere)\n* [Lesson 12](http://uber.github.io/luma.gl/#/examples/webgl-lessons/lesson-12-point-lighting)\n* [Lesson 13](http://uber.github.io/luma.gl/#/examples/webgl-lessons/lesson-13-per-fragment-lighting)\n\n\n### Model Class\n\n* `Model.draw` now supports a `moduleSettings` parameters to update shader module settings.\n* `Model.render` now supports `attributes` and `samplers` arguments to be used for drawing.\n\n\n### Framebuffer Binding Management\n\nIn v4 we added WebGL state management which automatically tracks all WebGL state settings. In this release we extended this feature to support framebuffer bindings. When restoring context settings, the previous framebuffer binding will also be restored.\n\n\n### WebGL2 Improvements\n\nImprovements in particular to the `Buffer`, `TransformFeedback` and `Framebuffer` classes based on use in applications.\n\n\n### Shader Modules\n\n* `fp64` - fp64 module works under more platforms/GPUs/drivers\n* [`picking`](/docs/api-reference/shadertools/shader-module-picking.md) shader module is moved from deck.gl to luma.gl and has been enhanced to also support object highlighting.\n\n\n\n## Version 4.0\n\nRelease date: July 27th, 2017\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/webgl2.jpg\" />\n        <p><i>WebGL 2</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nA major release that brings full WebGL2 support to luma.gl, as well as adding support for GL state management and a new shader module system.\n\n\n### Full WebGL2 Support\n\nluma.gl now exposes the complete WebGL2 APIs:\n\n* New classes expose all the new WebGL2 objects ([`Query`](/docs/api-reference/webgl/query.md), [`Texture3D`](/docs/api-reference/webgl/texture-3d.md), and [`TransformFeedback`](/docs/api-reference/webgl/transform-feedback.md)), together with a new [`UniformBufferLayout`](/docs/api-reference/webgl/uniform-buffer-layout.md) helper class to make uniform buffers easy to use.\n* Other existing WebGL classes with new functionalites under WebGL2 have been updated.\n* Add new WebGL2 texture formats and types support, including floating point textures, and multiple render targets.\n\n\n### WebGL Capability Management\n\nluma.gl provides a single unified WebGL2-style API across WebGL2, WebGL1 and WebGL extensions, and provides a simple mechanisms for querying what capabilities are available. This simplifies building apps that run on both WebGL1 and WebGL2, seamlessly allowing applications to leverage WebGL extensions when available.\n\n\n### WebGL State Management\n\nIn this version, a new WebGL state management is implemented to help address one of the weak spots of the stateful WebGL API:\n\n* luma.gl can track certain WebGL context state changes so the app could easily set and reset WebGL states for certain operations.\n* luma.gl also has a host-side WebGL state caching system that records certain WebGL states so that expansive queries into the GPU or underlying OpenGL driver won't be necessary.\n\n\n### shadertools - A New Shader Module System\n\n* The new, optional, shadertools module with the `assembleShaders` function system allows shader code to be broken into composable pieces.\n\n* A new `ShaderCache` class is provided to ensure that identical shaders are only compiled once and no unnecessary examination and/or checks are done on already compiled WebGL shader and program objects, which significantly accelerates app start up under some occasions.\n\n\n### Documentation Improvements\n\nComplete rewrite of luma.gl's documentation. New structure and contents for every classes provided, featured on a new website with links to other frameworks in Uber's visualization framework suite, such as deck.gl and react-map-gl.\n\n\n### Code Size Improvements\n\nSignificant reduction in the size of distributed luma.gl library\n\n* Code Size - luma.gl is continuously being tuned for code size.\n* Deprecated Code Removed - Removal of deprecated features to help reduce library size.\n* Tree Shaking support - special care have been taken to avoid so called \"side effects\" that defeat dependency analysis during tree shaking).\n\n\n## v3.0\n\nRelease Date: March 15, 2017\n\nA smaller release mainly intended to align the luma.gl code base with the big deck.gl v4 release.\n\n## Major News\n\n### Examples\n\n* Examples converted to ES6 to better showcase the luma.gl API.\n\n\n## Debug Support\n\n* Now uses `WEBGL_debug_shaders` extension when available to log translated shader source code.\n* Performance queries, using `EXT_disjoint_timer_query` and `EXT_disjoint_timer_query_webgl2` to provide timings.\n\n\n## New `AnimationFrame` class\n\n* Wraps requestAnimationFrame on browser and Node.js\n* Supports initialization promises (wait for HTML body (canvas) to load, wait for texture images to load, etc).\n* Supplies common uniforms to the frame render function: `width`, `height`, `aspect`, `tick`, `time` etc.\n\n\n## Smaller changes\n\n* Fix glTypeToArray to use `Uint8ClampedArrays` by default\n* Add CORS setting to allow loading image from a different domain\n\n## New `gl-matrix` based math library\n\n* Optional library: All math operations directly accept JavaScript arrays\n* Math classes are subclasses of JavaScript arrays (i.e. not {x,y,z} objects)\n  and can thus be used interchangeably with arrays.\n* Relies on `gl-matrix` for computations.\n* Adds optional error checking.\n* Offers more control over details like printing precision etc.\n\n### Library Size\n\n* Reorganized to only export a minimal surface of functions/classes.\n* Tree-shaking support (package.json module keyword and dist-es6 distribution)\n* Significant reduction of module dependencies.\n\n### Experimental APIs\n\n* `shader-modules`, `shader-tools`, `shaders` shader module system added to `/experimental`\n* `probe` moved to `/experimental`\n\n### Deprecations/Deletions\n\n* Old math lib deprecated.\n* `FBO` class deprecated (use `Framebuffer` directly).\n* `Camera` class deprecated, use math library directly.\n* `Scene` class deprecated, for effects use - TBD\n\n### Internal improvements\n\n* Replace wildcard exports with named exports in index.js\n* ES6 Conformant code base: stage-2 extensions removed\n* Webpack based build\n* Multiple examples now work standalone\n* Experimental tree-shaking support: dist and dist-es6 directories\n* Dependency removal, including removal of `autobind-decorator` dependency\n* Changed precommit hook from `husky` to `pre-commit`\n* `webgl` folder now contains both webgl1 and webgl2 classes\n\n### Breaking Changes\n\n* BREAKING CHANGE: Move node IO (loadImage etc) out of main src tree and into `packages`. This allows luma.gl to drop a number of big dependencies. The node IO code may be published as a separate module later.\n\n\n## v2.0\n\nRelease Date: July 05, 2016 (evolved through a number of minor releases)\n\nTheme: A bigger official release, a major API refactoring that introduced the WebGL classes that are now a characteristic aspect of the luma.gl API.\n\n## Major Features\n\n* CHANGE: Removes glslify as a dependency, apps that depend on glslify must add it to their own package.json.\n\n### TimerQuery\n\n* Support EXT_disjoint_timer_query.\n\n## Debug Support\n\n* Built-in attribute/uniform logging\n* GLSL shader compiler error handling\n\n### Linux support\n\n* Add missing call to getAttribLocation.\n\n### New gl-matrix based math classes\n\n* Move old math lib to deprecated folder.\n* Move FBO to deprecated folder.\n* Examples converted to ES6. AnimationFrame class updates.\n* Add back persistence example\n* WebGL type and constant cleanup\n* Fix glTypeToArray and use clamped arrays by default\n\n### TimerQuery, WebGL Extension doc, fix crash on Travis CI\n\n* Support EXT_disjoint_timer_query\n* Document luma.gl use of WebGL extensions.\n* Fix: context creation crash when WEBGL_debug_info extension was undefined\n\n### Debug log improvements, import fix\n\n* Debug logs now print unused attributes more compactly, number formatting improved.\n\n### Add ability to import luma without io\n\n* import \"luma.gl/luma\" will import luma without io functions\n* import \"luma.gl/io\" will import luma io functions only\n* omitting io functions significantly reduces dependencies\n* Makes the luma object available in console for debugging.\n* Some polish on luma's built-in attribute/uniform logging\n\n### Node.js/AttributeManager/Renderer/Program.render()/Examples\n\n* Ensure luma.gl does not fail under node until createGLContext is called.\n* Program.render() now takes a map of uniforms, reducing need to \"set\" uniforms before render.\n* New experimental Renderer class - `requestAnimationFrame` replacement.\n* Improvement/fixes to examples\n\n### Node.js support\n\n* Ensure luma.gl does not fail under node until createGLContext is called.\n\n### luma global initialization\n\n* Makes the luma object available in console for debugging.\n* Makes optional headless support more reliable.\n\n### Headless support\n\n* Removed `gl` (headless-gl) dependency, to simplify build and setup for applications that don't use headless-gl.\n* `import 'luma.gl/headless'` and `npm install gl` to get headless integration.\n\n### Improve change detection\n\n* Redraw flag management improvements\n\n### Decoupled headless-gl dependency\n\n* It is now necessary to import luma.gl through `luma.gl/headless` to get headless integration. When using the basic `luma.gl` import, the app no longer needs to have `gl` as a dependency. This should simplify build and setup for applications that don't use headless-gl.\n\n### Improve change detection\n\n* Redraw flag management improvements\n* New experimental Renderer class - `requestAnimationFrame` replacement.\n\n\n## v1.0\n\nRelease Date: 2016\n\nTheme: A smaller, mostly internal version that was the starting point for luma.gl development.\n\n### Major Features\n\n* Initial ES6 Port from PhiloGL\n","slug":"docs/whats-new","title":"What's New"}]}}}