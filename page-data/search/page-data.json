{"componentChunkName":"component---node-modules-gatsby-theme-ocular-src-templates-search-jsx","path":"/search","result":{"pageContext":{"isCreatedByStatefulCreatePages":false,"data":[{"excerpt":"Accessors \"Buffer accessor objects\" (or \"accessor objects\", or just \"accessors\" for short) are used to describe the structure of data…","rawMarkdownBody":"# Accessors\n\n\"Buffer accessor objects\" (or \"accessor objects\", or just \"accessors\" for short) are used to describe the structure of data contained in WebGL buffers (for more information see [`Buffers`](/docs/api-reference/webgl/buffer)).\n\nWhen using `Buffer`s as input to shader programs, applications must tell WebGL how the data in the buffer is formatted, so that the GPU knows how to access buffers' memory. To enable applications to specify how the buffer memory should be accessed, luma.gl APIs that set attribute buffers accept buffer \"accessor objects\".\n\n## Accessor Object Fields\n\nThis is an overview of the object accessor fields that are available to applications to define format descriptions. These objects can contain the following fields, this is an excerpt from [`Accessor`](/docs/api-reference/webgl/accessor).\n\n| Property    | Auto Deduced | Default    | Comment |\n| ---         | ---          | ---        | ---        | ---     |\n| `buffer`    | No           | An accessor can optionally reference a specific buffer. Multiple accessors can point to the same buffer, providing different views or \"slices\" of the buffer's memory. |\n| `offset`    | No           | `0`        | Byte offset to start of data in buffer |\n| `stride`    | No           | `0`        | Extra bytes between each successive data element |\n| `type`      | Yes          | `GL.FLOAT` | Low level data type (`GL.BYTE`, `GL.SHORT`, ...) |\n| `size`      | Yes          | `1`        | Components per element (`1`-`4`) |\n| `divisor`   | Yes          | `0`        | Enables/disables instancing |\n| `normalize` | N/A          | `false`    | Normalize integers to [-1,1], or [0,1] if unsigned |\n| `integer`   | N/A          | `false`    | Disable conversion of integer values to floats **WebGL 2** |\n\n\n## Combining Accessors with Buffers\n\nWhen setting attributes (e.g. using `Model.setProps({attributes: {attributeName: value, ...}}))`, each attribute value needs to contain both a buffer (a handle to the raw data uploaded to the GPU) and an accessor (describing how that data should be accessed).\n\nluma.gl provides three methods to specify attribute values so that both a buffer and an accessor are provided:\n* As a two-element array: `[buffer, accessor]`.\n* As an accessor, in which case the accessor object's `buffer` field should be set to the matching `Buffer`.\n* As a `Buffer`, in which case the `Buffer` objects `accessor` field should be set to the mathing `Accessor`.\n\nAll three methods have their uses: the first option gives the applications full freedom to dynamically select combinations of buffers and accessors, the second option is often the natural choice when working with interleaved buffers (see below), and the last choice is often the most convenient when just setting up an ad-hoc buffer for immediate use, as the accessor can be stored directly on the buffer, avoiding the need to manage separate objects.\n\n\n## Accessor Class vs Accessor Objects\n\nluma.gl provides the [`Accessor`](/docs/api-reference/webgl/accessor) helper class to help you work with accessor objects. For instance, the `Accessor` class supports merging of partial accessor objects, see below.\n\nNote that it is not necessary to use the `Accessor` class, as plain old JavaScript objects with the appropriate fields are also accepted by the various APIs that accept accessors. Use the style that works best for your application.\n\n\n### \"Partial\" Accessors\n\nluma.gl allows \"partial\" accessors to be created, and later combined. Usually many accessor fields can be left undefined (e.g. because defaults are sufficient, or because accessor auto-deduction has already deduced the information, see below).\n\nPartial accessors will be created automatically by `Program` when shaders are compiled and linked, and also by `Buffer` objects when they are created. Any application supplied accessors fields will then be merged in (override) these auto-deduceted fields, that can add any fine-tuning or override of parameters.\n\n\n### Accessor Auto Deduction\n\nluma.gl attempts to \"auto deduce\" as much accessor information as it can, for instance luma.gl can extract fields like `type` and `size` after shaders have been compiled.\n\nThis relieves applications from having to respecify the same thing multiple times. For instance if the application has already declared an attribute as `in vec2 size` in the vertex shader, it does not need to specify `size:2, type: GL.FLOAT` again in the accessor, when it sets the buffer in JavaScript, since this information will have been auto-deduced.\n\nIn many cases, when buffers are not shared between attributes (i.e. interleaved) and default behavior is desired, luma.gl applications often do not need to specify any `Accessor` at all.\n\n\n### Merging (Resolving) Accessors\n\nThe `Accessor` API allows for accessors to be merged (or \"resolved\") into a new `Accessor`. Accessor mmerging is mainly used internally in luma.gl to implement support for partial accessors and accessor auto deduction, but can be used by applications if necessary.\n\n\n### Data Interleaving\n\nUsing the`stride` and `offset` fields in accessor objects, it is possible to interleave two arrays so that the first two elements of one array are next to each other, then the next two elements etc.\n\n```\nconst interleavedBuffer = new Buffer(gl, accessor: {stride: 12 + 4}}); // Creates a partial accessor with `stride` in buffer.\n\nvertexArray.setAttributes({\n  // These accessors are merged with the `interleavedBuffer` accessor and any\n  // auto-deduced accessors\n  POSITIONS: new Accessor({offset: 0, buffer: interleavedBuffer})\n  COLORS: new Accessor({offset: 12, buffer: interleavedBuffer})\n})\n```\n\nFor more information see the article about attributes.\n\n\n### Using Different Size in Buffers and Shaders\n\nIt is possible to use different size memory attributes than specified by the GLSL shader code, by specifying a different size in the accessor compared to the GLSL shader variable declaration. Extra components in the Buffer memory will be ignored, missing components will be filled in from `(0.0, 0.0, 0.0, 1.0)`\n\n> Be aware that the headless gl integration does not support this feature due to limitations in headless gl.\n\n\n### glTF Format Accessors\n\n[glTF formatted files](https://www.khronos.org/gltf/). glTF files contain two JSON object arrays (\"bufferViews\" and \"accessors\") that describe how raw memory buffers are organized and should be interpreted.\n\nThe `Accessor` and `Buffer` class APIs have intentionally been designed to be a close representation when converting \"accessors\" and \"bufferViews\" stored in glTF files. Each glTF `accessor` can be mapped to a luma.gl `Accessor` and each glTF `bufferView` can be mapped to a luma.gl `Buffer`. For more details see [glTF mapping]().\n","slug":"docs/developer-guide/accessors","title":"Accessors"},{"excerpt":"What's New Version 8.0 Date: December 16, 2019 Performance The key focus of luma.gl v8.0 was optimizing performance. Compared to v7.3, the…","rawMarkdownBody":"# What's New\n\n## Version 8.0\n\nDate: December 16, 2019\n\n### Performance\n\nThe key focus of luma.gl v8.0 was optimizing performance. Compared to v7.3, the latest release shows a **2x** improvement in render time on the luma.gl stress test (1 million textured cubes), as detailed below:\n\n|        |  7.3  |8.0   |Improvement|\n|--------|-------|------|-----------|\n|CPU Time| 30ms  | 16ms | 14ms (47%)|\n|GPU Time| 26ms  | 21ms | 5ms  (19%)|\n\nluma.gl's optimizations also contributed significantly to deck.gl's performance gains in v8.0, leading to a **3x** improvement over its prior release on the deck.gl stress test (rendering 100,000 `ScatterplotLayer` instances):\n\n|        |  7.3  |8.0   |Improvement|\n|--------|-------|------|-----------|\n|CPU Time| 76ms  | 26ms | 50ms (66%)|\n|GPU Time| 17ms  | 10ms | 7ms  (41%)|\n\nStress tests were run on a Macbook Pro 2018, OSX, 2.6 GHz Intel Core i7, Radeon Pro 560X 4 GB.\n\n### Streamlined API\n\nluma.gl v8.0 also brings with it a major simplification of the API and streamlining of architecture. The number of modules as been reduced from 14 to 9, each with a clearly defined purpose and relationship to other modules:\n\n- Low-level\n  - **constants**: WebGL 1 and 2 enums.\n  - **gltools**: Tools for polyfilling, intrumenting and tracking state for WebGL contexts.\n  - **shadertools**: Tools for creating and composing re-usable GLSL shader modules.\n- Mid-level\n  - **webgl**: WebGL 1 and 2 wrapper classes.\n- High-level\n  - **engine**: Higher-level 3D graphics abstractions and resource management.\n- Utilities\n  - **debug**: Debug instrumentation for WebGL contexts and luma.gl classes.\n  - **test-utils**: Testing utilities.\n  - **core**: Selected re-exports from other modules.\n  - **experimental**: Unfinished and unsupported features.\n\n## Version 7.3\n\nDate: September 19, 2019\n\n### Program Management\n\nluma.gl introduces the [ProgramManager](/docs/api-reference/engine/program-manager) class to manage caching and re-use of `Program` objects, providing powerful load and runtime optimizations:\n- Redundant shader compilation and linking is avoided.\n- Redundant program switching (among the [most expensive](https://computergraphics.stackexchange.com/a/46) GPU state changes) while rendering is avoided.\n\nThe `Model` class has been updated to take advantage of these new capabilities, automatically caching and re-using `Program`s where possible.\n\nThe table below shows the effect of program sharing in deck.gl. The test renders 1000 [ScatterplotLayers](https://deck.gl/#/examples/core-layers/scatterplot-layer), each of which draws 100 intanced geometries, for a total of 1000 draw calls and 100,000 instances. Timings are milliseconds spent on the CPU and GPU to render a single frame on the following two machines:\n\n- Macbook Pro 2018, OSX, 2.6 GHz Intel Core i7, Radeon Pro 560X 4 GB\n- Razer Blade, Windows 10, Intel i7-8750H 6 Core, Intel UHD Graphics 630\n\n||  No Program Sharing |Program Sharing | Improvement |\n| --- | --- | --- | --- |\n| Macbook Pro CPU | 113ms | 93ms | 17% |\n| Macbook Pro GPU | 43ms   | 34ms  | 20% |\n| Razer Blade CPU | 145ms | 125ms | 13% |\n| Razer Blade GPU | 137ms | 115ms | 16% |\n\n\n\n### Custom Device Pixels (Experimental)\n\nluma.gl now provides experimental support for specifying the pixel ratio mapping between canvas size and the GL drawing buffer. luma.gl has always provided support for matching the native device pixel ratio on high-resolution screens, but custom ratios allow applications to, for example, use SSAA for improved fidelity or reduced drawing resolution to improve performance.\n\n\n## Version 7.2\n\nDate: July 9, 2019\n\n### FXAA Shader Module\n\nluma.gl now supports FXAA (Fast Approximate Antialiasing) as a post processing effect. This allows for antialiasing on offscreen framebuffers.\n\n### ImageBitmap Textures\n\nThe `Texture` class now supports `ImageBitmap` input data.\n\n\n## Version 7.1\n\nDate: June 4, 2019\n\n### Enhanced Shader Injection System\n\nluma.gl now supports a much more robust system for injecting code into shaders. In addition to the pre-defined shader hooks such as `vs:#main-start`,\nthe shader injection system now supports:\n- Definition of arbitrary shader hook functions that can be called anywhere in a shader\n- Injection of arbitrary code into shader hook functions to modify their behavior\n- Automatic injection by shader modules into hook functions or pre-defined shader hooks\n\nThe combination of these features allows the behavior of the same shader code to be modified depending on included shader modules or other\nrequirements of the application. See [assembleShaders](/docs/api-reference/shadertools/assemble-shaders.md) documentation for more details.\n\n### Animation Support\n\nMore robust animations are now supported via the `Timeline` and `KeyFrames` classes.\n\nThe  `Timeline` class supports easily managing a timeline with multiple channels elapsing at different rates, as well as orchestrating playing, pausing, and rewinding behavior between them. A timeline can be attached to an `AnimationLoop` and then queried for time values, which can be used in animations. See [Timeline](/docs/api-reference/addons/animation/timeline.md) documentation for more details.\n\nThe `KeyFrames` class allows arbitrary data to be associated with time points. The time value of the key frames can be set and the current key frames and interpolation factor can be queried and used in calculating animated values. See [KeyFrames](/docs/api-reference/addons/animation/key-frames.md) documentation for more details.\n\n## Version 7.0\n\nDate: April 19, 2019\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=200 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/gltf-city.gif\" />\n        <p><i>glTF Support</i></p>\n      </td>\n      <td>\n        <img height=200 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/gltf-pbr.gif\" />\n        <p><i>PBR (Physically Based Rendering)</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### glTF Support\n\n<img height=100 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/gltf.png\" />\n\nluma.gl can now load 3D models and scenegraphs in the popular [glTF™](https://www.khronos.org/gltf/) asset format (with the help of the loaders.gl [GLTFLoader](https://github.com/uber-web/loaders.gl/blob/master/website/docs/api-reference/gltf-loaders/gltf-loader.md). All variants of glTF 2.0 are supported, including binary `.glb` files as well as JSON `.gltf` files with binary assets in base64 encoding or in separate files. The Draco Mesh compression extension is also supported.\n\n- **Physically-based Material Support**: Ensures that PBR models display as intended.\n- **Scenegraph Improvements**: The Scenegraph classes have been refactored to ensure support for glTF objects.\n- **Geometry glTF Support**: The `Geometry` class and scene graph support has been overhauled to conform to glTF conventions, simplifying loading and manipulation of glTF formatted data.\n\n\n### loaders.gl Integration\n\n[loaders.gl](https://uber-web.github.io/loaders.gl/) is a major new companion framework to luma.gl that provides a suite of 3D file format loaders (with an emphasizis on point cloud formats), including:\n\n* Draco\n* PLY\n* PCD\n* LAS/LAZ\n* OBJ\n\nloaders.gl output can now be passed directly into luma.gl classes like `Geometry` and `Model` making it straightforward to use luma.gl with a wide variety of file formats.\n\n\n### Asynchronous Textures\n\nImage data for `Texture` classes can now be supplied using URLs or `Promise`s, making it unnecessary for applications to handle image loading themselves.\n\n```js\nnew Texture2D(gl, 'path/to/my/image.png'); // Texture2D will load the image and becomes 'renderable' once it loads\n// or\nnew Texture2D(gl, loadImage('path/to/my/image.png')); // loadImage returns a promise\n```\n\n### Lighting\n\nA standardized set of light classes are now supported by multiple material models (Phong, Goraud and PBR) enabling various models to be mixed and properly lit in the same scene.\n\n\n### Modularization Improvements\n\n- luma.gl has been restructured to make it easier for applications to select and import only parts of the library that they use.\n\n* ` @luma.gl/gpgpu` **<sup>New</sup>** - A new experimental submodule with GPGPU Algorithms and Utilities has been added, containing a growing collection of GPU accelerated algorithms and utility methods.\n\n\n### Performance Instrumentation\n\nExtensive metrics about frame CPU and GPU times, resource counts, and GPU memory usage are being collected. The data is exposed as a [probe.gl](https://uber-web.github.io/probe.gl/#/) [`Stats`](https://uber-web.github.io/probe.gl/#/documentation/api-reference-logging/stats) object. The new probe.gl [StatsWidget](https://uber-web.github.io/probe.gl/#/documentation/api-reference-widgets/statswidget) can be used to present data in applications.\n\n\n### Interleaved Attributes\n\nTo improve support for interleaved attributes and glTF model loading, accessor objecs and the `Accessor` class now support a `buffer` field. In addition, attribute setting functions now accept accessor objects with the `buffer` field set. This allows multiple accessor objects referencing the same buffer:\n\n```\nconst buffer = // \"interleaved\" vertex attributes: 3 floats for position followed by 4 bytes for RGBA\nmodel.setAttributes({\n  positions: {buffer, stride: 16, offset: 0, ...}}),\n  colors: {buffer, stride: 16, offset: 12, ...}})\n}\n```\n\n### Unified functions for Framebuffers and Textures (Read/Copy/Blit)\n\nA set of global methods that perform copying data to and from `Framebuffer` objects. All functions that read from or write to a `Framebuffer` object now also accept a `Texture` object (no need to create and configure a `Framebuffer` just to do a simple operation on a `Texture`).\n\n\n## Experimental Features\n\n### WebVR Support (experimental)\n\nJust replace your `AnimationLoop` with `VRAnimationLoop` from ` @luma.gl/addons`. Works with [Firefox Reality](https://mixedreality.mozilla.org/firefox-reality/).\n\n\n\n## Version 6.4\n\nDate: January 29, 2018\n\n### PBR (Physically Based) Rendering and Material\n\nPhysically-Based Rendering is now supported and the new `PBRMaterial` class can be used to set up parameters. Material can be selected per model.\n\n\n### Copy and Blit methods\n\nSeveral member function of `Framebuffer` and `Texture` classes are now replaced by global methods that peform copying data to and from `Framebuffer` objects. All methods that read from or write to a `Framebuffer` object, can now also accept a `Texture` object.\n\n\n## Version 6.3\n\nDate: November 16, 2018\n\n### Uniform Caching\n\nUniforms are now cached at `Program` object, which improves performance by eliminating uniform setter calls when uniform values are not changed.\n\n### New submodules\n\n* `@luma.gl/debug` - an experimental module for debugging WebGL shaders on CPU\n* `@luma.gl/glfx` - shader modules for image processing\n\n### Offscreen Rendering (Experimental)\n\nA new experimental class `AnimationLoopProxy` supports running an `AnimationLoop` on a worker thread using the `OffscreenCanvas` API made official in Chrome 70. For more detatils, see [API documentation](/docs/api-reference/core/animation-loop-proxy.md) and [example app](https://github.com/uber/luma.gl/tree/7.3-release/test/apps/wip/worker).\n\n\n## Version 6.2\n\nDate: September 12, 2018\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/render-pass.gif\" />\n        <p><i>glfx port using ShaderModulePass</i></p>\n      </td>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/transform-texture.gif\" />\n        <p><i>Transform: edge detection</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### ShaderModulePass (Experimental)\n\nShader modules that expose \"standard\" filtering and sampling functions can be given extra metadata (the `passes` field) enabling easy construction of a `ShaderModulePass`. Look for `ShaderPass` badges in the documentation of shader modules.\n\n### Transform Texture support (Experimental)\n\n`Transform` class was introduced in 6.0 provides easy API to perform WebGL's complicated `TransformFeedback`. We are now extending this class to provide same easy API to read and write into textures. Running image filters, performing offline rendering and custom texture mip-map generation are some of the use-cases. Moreover, texture and buffer access can be combined, i.e. using single `Transform` instance buffers can be captured using `TransformFeedback` and data can be propagated beyond vertex shader to generate a texture.\n\n\n## Version 6.1\n\nDate: Target August 31, 2018\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/luma61-ssao-pass-thumb.gif\" />\n        <p><i>Ambient Occlusion Render Pass</i></p>\n      </td>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/luma61-edge-pass-thumb.gif\" />\n        <p><i>Edge Detection Render Pass</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nluma.gl 6.1 is a minor release that introduces a number of new experimental capabilities that are expected to be built out and become official over the next few releases.\n\n\n### New Multipass Rendering System (Experimental)\n\nluma.gl now provides a composable multipass rendering framework, based on a `MultiPassRenderer` class that accepts a list of render passes.\n\n\n### Post-Processing Effects (Experimental)\n\nA number of classic WebGL/OpenGL post processing effects have been ported to luma.gl and packaged as composable render passes. For maxiumum flexibility, many of the underlying shaders have also been exposed as shader modules, allowing filtering features to be used either directly in existing shaders or applied as a post-processing filter.\n\n\n### New loaders.gl Submodule (Experimental)\n\nA selection of open source 3D loaders have been ported to a new submodule `loaders.gl`. Initial focus is on point cloud loaders (PLY, LAZ, PCD), although a geospatial loader (KML) is also included. In addition it contains both read and write support for GLB (the glTF binary container format).\n\n\n### Transform Class now supports Shader Modules\n\nThe `Transform` class now accepts shader module parameters (such as `modules`, `dependencies` and `inject`, see [assembleShaders](/docs/api-reference/shadertools/assemble-shaders.md)), enabling the use of shader modules in transform feedback operations.\n\n\n### Documentation Search\n\nluma.gl is now using the [ocular](https://github.com/uber-web/ocular) document generator to build its website, which among other things enables search.\n\n\n## Version 6.0\n\nDate: July 18, 2018\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/webgl2.jpg\" />\n        <p><i>WebGL Improvements</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nA major release that as always focuses on WebGL performance and code size optimizations, better support for shader/GLSL programming, improved documentation and API cleanup.\n\n\n## WebGL Improvements\n\n### Attribute Management Optimizations\n\n`VertexArray` objects are now used for all attribute management in luma.gl, resulting in improved performance and a simpler, more consistent API. The `Program` and `Model` class APIs have been updated to use `VertexArray`.\n\n### Buffer Memory Optimizations\n\nThe `Buffer` class no longer holds on to the complete JavaScript typed arrays used during initialization. This can lead to significant memory savings in apps that use multiple large GPU buffers initialized from typed arrays. Also for convenience a new method `getElementCount` is added that returns number elements based on its size and type.\n\n### Transform Feedback Improvements\n\nA new method `Model.transform` makes it easier to run basic transform feedback operations, when the full power of the new `Transform` class (see below) is not needed.\n\n\n### Transform class (WebGL 2)\n\n[`Transform`](/docs/api-reference/core/transform.md) is now an officially supported luma.gl class. This new class provides an easy-to-use interface to Transform Feedback. This class hides complexity by internally creating and managing the supporing WebGL objects that are necessary to perform Transform Feedback operations.\n\n\n## Shader Module System Improvements\n\n### GLSL Transpilation\n\nThe shader assembler now transforms shader code to the GLSL version specified by the top-level shader. GLSL 3.00 ES shader code is transparently transformed into GLSL 1.00 ES compatible code when needed, and vice versa. This allows application to write shader code in the modern GLSL version available (3.00 ES) and still run it under WebGL 1 - Shader \"transpilation\" will automatically convert shader module source code syntax to the target version (assuming that no WebGL 2 only features were used).\n\n\n### Shader Code Injection\n\nA new shader injection system allows applications to inject additional code into existing shaders. In many cases, this can avoid the need to copy (or \"fork\") large and complicated existing shaders just to add a few lines of code.\n\nShader injection can be used to \"inject\" new shader modules into an existing shader. Adding a shader module to the modules list automatically \"prepends\" the shader module functions to the beginning of your main shader code, but using a shader module still typically requires adding one or two lines of code each to the main functions in the vertex and fragment shaders. In many cases, the new shader injection feature allows this be done without copying the original shaders.\n\n\n### Shader Modules now support GLSL 3.00 ES\n\nAll shader modules are now written in GLSL 3.00 syntax, and leverage the new GLSL transpilation feature to be compatible with both GLSL 3.00 ES and GLSL 1.00 ES main shaders. Care is taken to avoid using GLSL 3.00 specific features whenever possible, and exceptions will be clearly documented.\n\n\n## Documentation\n\n### Developer's Guide\n\nluma.gl now has a more extensive Developer's Guide covering more areas of the API, including a new developer guide for shader programming, with sections about writing shaders and the shader module system. Content includes:\n\n- Guidelines for writing shaders that work in both GLSL 3.00 ES and GLSL 1.00 ES\n- A new GLSL language reference page describing both GLSL 3.00 ES and GLSL 1.00 ES (as well as what has changed between them) in a single place.\n\n\n## API Cleanup\n\nBeing a major release, in v6.0 we took the opportunity to clean up the luma.gl API.\n\n\n### Removal of Deprecated/Unused Methods\n\nTo keep reducing application bundle size, a number of methods have been removed from the luma.gl API. Methods that were deprecated in previous releases have now been removed, and in additional a number of rarely used methods have also been dropped (in most cases, the dropped functionality is still accessible using raw WebGL calls).\n\n### Renamed Methods\n\nIn a few cases, methods have been renamed after API Audits, usually to improve API consistency. The details are listed in the Upgrade Guide. In most cases, running your pre-v6 application on v6 should generate messages in the console when old method calls are encountered, and you should be able to quickly address any changes one-by-one by referring to the Upgrade Guide.\n\n\n\n## Version 5.3\n\nDate: June 1, 2018\n\nA minor release with bug fixes and internal improvements.\n\n\n## Version 5.2\n\nDate: Apr 24, 2018\n\n## Transform class (WebGL 2, Experimental)\n\nThe new experimental [`Transform`](/docs/api-reference/core/transform.md) class provides an easy-to-use interface to perform Transform Feedback operations.\n\n\n## Framebuffer Class\n\n**Pixel Readback to GPU Buffers** (WebGL 2) - A new method [`Framebuffer.readPixelsToBuffer`](/docs/api-reference/webgl/framebuffer.md) is added to asynchronously read pixel data into a `Buffer` object. This allows  applications to reduce the CPU-GPU sync time by postponing transfer of data or to completely avoid GPU-CPU sync by using the pixel data in the GPU `Buffer` object directly as data source for another GPU draw or transform feedback operation.\n\n\n## Bundle Size Reduction\n\nThe impact of importing luma.gl on production application bundle sizes has been reduced, in particular when using webpack 4 with appropriate configuration. A new article about [bundling and tree shaking](/docs/developer-guide/building-apps.md) has been added to the Developer Guide, providing in-depth information and guidance on what numbers to expect.\n\n\n## Running luma.gl in Node.js\n\nRunning of luma.gl under Node.js is now easier than ever. luma.gl v5.2 automatically loads headless-gl if installed on the system, avoiding the need for the app to import special files or add other conditional logic. See [Using with Node](/docs/get-started/README.md) and the Upgrade Guide.\n\n\n## Debug Mode Changes\n\nTo further reduce production application bundle sizes, luma.gl no longer support WebGL debug contexts by default, as this requires including the Khronos [WebGLDeveloperTools](https://github.com/KhronosGroup/WebGLDeveloperTools) into the bundle. WebGL debug contexts are still available, but needs to be explicitly enabled. To understand how to use WebGL debug contexts in v5.2, please refer to the article on [Debugging](/docs/developer-guide/debugging.md) and the Upgrade Guide.\n\n\n## Examples\n\nAll examples have been updated to use webpack 4\n\n\n## Version 5.1\n\nA smaller release with improvements to `TransformFeedback` support.\n\nDate: Feb 15, 2018\n\n## TransformFeedback Class\n\nTwo improvements Performing Transform Feedback operations has gotten easier, mainly in the following two ways:\n\n`TransformFeedback` instances can now be supplied directly to `Model.draw` and feedback will begin and end during that draw call. Thus it is no longer necessary to work directly with the `Program` class to use transform feedback.\n\n`Program` now build a `varyingMap` on creation depending on `varyings` array and `drawMode`. This `varyingMap` can be passed to `TransformFeedback.bindBuffers()` enabling buffers to be indexed by the name of the \"varying\" instead of using an index.\n\nFor more details check [`TransformFeedback`](/docs/api-reference/webgl/transform-feedback.md) and [`Model`](/docs/api-reference/core/model.md) documentation.\n\n\n## Version 5.0\n\nDate: Dec 22, 2017\n\nA smaller release with several new examples and some under the hood changes to improve performance.\n\n\n### Examples\n\nAdditional examples have been ported to the luma.gl v5 API.\n\n* [Lesson 10](http://uber.github.io/luma.gl/#/examples/webgl-lessons/lesson-10-3d-world)\n* [Lesson 11](http://uber.github.io/luma.gl/#/examples/webgl-lessons/lesson-11-sphere)\n* [Lesson 12](http://uber.github.io/luma.gl/#/examples/webgl-lessons/lesson-12-point-lighting)\n* [Lesson 13](http://uber.github.io/luma.gl/#/examples/webgl-lessons/lesson-13-per-fragment-lighting)\n\n\n### Model Class\n\n* `Model.draw` now supports a `moduleSettings` parameters to update shader module settings.\n* `Model.render` now supports `attributes` and `samplers` arguments to be used for drawing.\n\n\n### Framebuffer Binding Management\n\nIn v4 we added WebGL state management which automatically tracks all WebGL state settings. In this release we extended this feature to support framebuffer bindings. When restoring context settings, the previous framebuffer binding will also be restored.\n\n\n### WebGL 2 Improvements\n\nImprovements in particular to the `Buffer`, `TransformFeedback` and `Framebuffer` classes based on use in applications.\n\n\n### Shader Modules\n\n* `fp64` - fp64 module works under more platforms/GPUs/drivers\n* [`picking`](/docs/api-reference/shadertools/shader-module-picking.md) shader module is moved from deck.gl to luma.gl and has been enhanced to also support object highlighting.\n\n\n\n## Version 4.0\n\nRelease date: July 27th, 2017\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td>\n        <img height=150 src=\"https://raw.github.com/uber-common/deck.gl-data/master/images/whats-new/webgl2.jpg\" />\n        <p><i>WebGL 2</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\nA major release that brings full WebGL 2 support to luma.gl, as well as adding support for GL state management and a new shader module system.\n\n\n### Full WebGL 2 Support\n\nluma.gl now exposes the complete WebGL 2 APIs:\n\n* New classes expose all the new WebGL 2 objects ([`Query`](/docs/api-reference/webgl/query.md), [`Texture3D`](/docs/api-reference/webgl/texture-3d.md), and [`TransformFeedback`](/docs/api-reference/webgl/transform-feedback.md)), together with a new [`UniformBufferLayout`](/docs/api-reference/webgl/uniform-buffer-layout.md) helper class to make uniform buffers easy to use.\n* Other existing WebGL classes with new functionalites under WebGL 2 have been updated.\n* Add new WebGL 2 texture formats and types support, including floating point textures, and multiple render targets.\n\n\n### WebGL Capability Management\n\nluma.gl provides a single unified WebGL 2-style API across WebGL 2, WebGL 1 and WebGL extensions, and provides a simple mechanisms for querying what capabilities are available. This simplifies building apps that run on both WebGL 1 and WebGL 2, seamlessly allowing applications to leverage WebGL extensions when available.\n\n\n### WebGL State Management\n\nIn this version, a new WebGL state management is implemented to help address one of the weak spots of the stateful WebGL API:\n\n* luma.gl can track certain WebGL context state changes so the app could easily set and reset WebGL states for certain operations.\n* luma.gl also has a host-side WebGL state caching system that records certain WebGL states so that expansive queries into the GPU or underlying OpenGL driver won't be necessary.\n\n\n### shadertools - A New Shader Module System\n\n* The new, optional, shadertools module with the `assembleShaders` function system allows shader code to be broken into composable pieces.\n\n* A new `ShaderCache` class is provided to ensure that identical shaders are only compiled once and no unnecessary examination and/or checks are done on already compiled WebGL shader and program objects, which significantly accelerates app start up under some occasions.\n\n\n### Documentation Improvements\n\nComplete rewrite of luma.gl's documentation. New structure and contents for every classes provided, featured on a new website with links to other frameworks in Uber's visualization framework suite, such as deck.gl and react-map-gl.\n\n\n### Code Size Improvements\n\nSignificant reduction in the size of distributed luma.gl library\n\n* Code Size - luma.gl is continuously being tuned for code size.\n* Deprecated Code Removed - Removal of deprecated features to help reduce library size.\n* Tree Shaking support - special care have been taken to avoid so called \"side effects\" that defeat dependency analysis during tree shaking).\n\n\n## v3.0\n\nRelease Date: March 15, 2017\n\nA smaller release mainly intended to align the luma.gl code base with the big deck.gl v4 release.\n\n## Major News\n\n### Examples\n\n* Examples converted to ES6 to better showcase the luma.gl API.\n\n\n## Debug Support\n\n* Now uses `WEBGL_debug_shaders` extension when available to log translated shader source code.\n* Performance queries, using `EXT_disjoint_timer_query` and `EXT_disjoint_timer_query_webgl2` to provide timings.\n\n\n## New `AnimationFrame` class\n\n* Wraps requestAnimationFrame on browser and Node.js\n* Supports initialization promises (wait for HTML body (canvas) to load, wait for texture images to load, etc).\n* Supplies common uniforms to the frame render function: `width`, `height`, `aspect`, `tick`, `time` etc.\n\n\n## Smaller changes\n\n* Fix glTypeToArray to use `Uint8ClampedArrays` by default\n* Add CORS setting to allow loading image from a different domain\n\n## New `gl-matrix` based math library\n\n* Optional library: All math operations directly accept JavaScript arrays\n* Math classes are subclasses of JavaScript arrays (i.e. not {x,y,z} objects)\n  and can thus be used interchangeably with arrays.\n* Relies on `gl-matrix` for computations.\n* Adds optional error checking.\n* Offers more control over details like printing precision etc.\n\n### Library Size\n\n* Reorganized to only export a minimal surface of functions/classes.\n* Tree-shaking support (package.json module keyword and dist-es6 distribution)\n* Significant reduction of module dependencies.\n\n### Experimental APIs\n\n* `shader-modules`, `shader-tools`, `shaders` shader module system added to `/experimental`\n* `probe` moved to `/experimental`\n\n### Deprecations/Deletions\n\n* Old math lib deprecated.\n* `FBO` class deprecated (use `Framebuffer` directly).\n* `Camera` class deprecated, use math library directly.\n* `Scene` class deprecated, for effects use - TBD\n\n### Internal improvements\n\n* Replace wildcard exports with named exports in index.js\n* ES6 Conformant code base: stage-2 extensions removed\n* Webpack based build\n* Multiple examples now work standalone\n* Experimental tree-shaking support: dist and dist-es6 directories\n* Dependency removal, including removal of `autobind-decorator` dependency\n* Changed precommit hook from `husky` to `pre-commit`\n* `webgl` folder now contains both webgl1 and webgl2 classes\n\n### Breaking Changes\n\n* BREAKING CHANGE: Move node IO (loadImage etc) out of main src tree and into `packages`. This allows luma.gl to drop a number of big dependencies. The node IO code may be published as a separate module later.\n\n\n## v2.0\n\nRelease Date: July 05, 2016 (evolved through a number of minor releases)\n\nTheme: A bigger official release, a major API refactoring that introduced the WebGL classes that are now a characteristic aspect of the luma.gl API.\n\n## Major Features\n\n* CHANGE: Removes glslify as a dependency, apps that depend on glslify must add it to their own package.json.\n\n### TimerQuery\n\n* Support EXT_disjoint_timer_query.\n\n## Debug Support\n\n* Built-in attribute/uniform logging\n* GLSL shader compiler error handling\n\n### Linux support\n\n* Add missing call to getAttribLocation.\n\n### New gl-matrix based math classes\n\n* Move old math lib to deprecated folder.\n* Move FBO to deprecated folder.\n* Examples converted to ES6. AnimationFrame class updates.\n* Add back persistence example\n* WebGL type and constant cleanup\n* Fix glTypeToArray and use clamped arrays by default\n\n### TimerQuery, WebGL Extension doc, fix crash on Travis CI\n\n* Support EXT_disjoint_timer_query\n* Document luma.gl use of WebGL extensions.\n* Fix: context creation crash when WEBGL_debug_info extension was undefined\n\n### Debug log improvements, import fix\n\n* Debug logs now print unused attributes more compactly, number formatting improved.\n\n### Add ability to import luma without io\n\n* import \"luma.gl/luma\" will import luma without io functions\n* import \"luma.gl/io\" will import luma io functions only\n* omitting io functions significantly reduces dependencies\n* Makes the luma object available in console for debugging.\n* Some polish on luma's built-in attribute/uniform logging\n\n### Node.js/AttributeManager/Renderer/Program.render()/Examples\n\n* Ensure luma.gl does not fail under node until createGLContext is called.\n* Program.render() now takes a map of uniforms, reducing need to \"set\" uniforms before render.\n* New experimental Renderer class - `requestAnimationFrame` replacement.\n* Improvement/fixes to examples\n\n### Node.js support\n\n* Ensure luma.gl does not fail under node until createGLContext is called.\n\n### luma global initialization\n\n* Makes the luma object available in console for debugging.\n* Makes optional headless support more reliable.\n\n### Headless support\n\n* Removed `gl` (headless-gl) dependency, to simplify build and setup for applications that don't use headless-gl.\n* `import 'luma.gl/headless'` and `npm install gl` to get headless integration.\n\n### Improve change detection\n\n* Redraw flag management improvements\n\n### Decoupled headless-gl dependency\n\n* It is now necessary to import luma.gl through `luma.gl/headless` to get headless integration. When using the basic `luma.gl` import, the app no longer needs to have `gl` as a dependency. This should simplify build and setup for applications that don't use headless-gl.\n\n### Improve change detection\n\n* Redraw flag management improvements\n* New experimental Renderer class - `requestAnimationFrame` replacement.\n\n\n## v1.0\n\nRelease Date: 2016\n\nTheme: A smaller, mostly internal version that was the starting point for luma.gl development.\n\n### Major Features\n\n* Initial ES6 Port from PhiloGL\n","slug":"docs/whats-new","title":"What's New"},{"excerpt":"Overview luma.gl is a high-performance toolkit for WebGL-based data visualization. luma.gl is the core 3D rendering library in the vis.gl…","rawMarkdownBody":"# Overview\n\nluma.gl is a high-performance toolkit for WebGL-based data visualization. luma.gl is the core 3D rendering library in the [vis.gl](http://vis.gl/) framework suite.\n\n\n## Versions\n\nThese docs are for\n<a href=\"https://github.com/uber/luma.gl/blob/8.0-release/docs\">\n  <img style=\"margin-bottom: -4px\" src=\"https://img.shields.io/badge/luma.gl-v8.0-brightgreen.svg?style=flat-square\" />\n</a> Looking for an older version?\n\n<a href=\"https://github.com/uber/luma.gl/blob/7.3-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-7.3-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/7.2-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-7.2-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/7.1-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-7.1-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/7.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-7.0-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/6.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-6.0-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/5.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-5.0-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/blob/4.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-4.0-green.svg?style=flat-square\" />\n</a>\n<a href=\"https://github.com/uber/luma.gl/tree/3.0-release/docs\">\n  <img src=\"https://img.shields.io/badge/v-3.0-green.svg?style=flat-square\" />\n</a>\n\n<BR>\n<BR>\n\nluma.gl aims to provide tools for WebGL developers wether they wish to do high or low-level GPU programming. Polyfilling and shader composition utilities, for example, can be used while programming directly with the WebGL API, while resource management utilities provide higher-level 3D engine functionality.\n\nThe core use case for luma.gl is visualization of large datasets, but its design is generic enough for more general usage. Key strengths of luma.gl include:\n\n- **A WebGL 2-first API** - luma.gl polyfills WebGL 1 contexts insofar as possible to support the WebGL 2 API. This allows applications to code using the latest WebGL 2 APIs while transparently keeping the application backwards compatible with WebGL 1 (using WebGL extensions, shader transpilation and other techniques).\n- **Modular, Composable Tools** - It is left to the develop to decide what parts of luma.gl suit their application. Program at a higher level using WebGL wrapper classes or a `Model`, or simply polyfill the context and program using the WebGL 2 API.\n- **High-performance Data Visualization** - luma.gl focuses on simplifying access to APIs that are particularly useful when visualizing large data sets, such as instanced drawing and transform feedback.\n\nFor some powerful examples of what can be achieved with luma.gl, take a look at [deck.gl](http://deck.gl/#/), [kepler.gl](https://kepler.gl/) and [avs.auto](https://avs.auto/#/).\n\n## Future\n\nWe share information about the direction of luma.gl in the following ways:\n\n* **[RFCs](https://github.com/uber/luma.gl/tree/7.3-release/dev-docs/RFCs)** - RFCs are technical writeups that describe proposed features in upcoming releases.\n* **[Roadmap Document](https://luma.gl/#/documentation/overview/roadmap)** - (this document) A high-level summary of our current direction for future releases.\n* **[Blog](https://medium.com/@vis.gl)** - We use the vis.gl blog to share information about what we are doing.\n* **[Github Issues](https://github.com/uber/luma.gl/issues)** - The traditional way to start or join a discussion.\n","slug":"docs","title":"Overview"},{"excerpt":"Debugging luma.gl has a number of provisions for debugging designed to help you save time during development. id strings Most classes in…","rawMarkdownBody":"# Debugging\n\nluma.gl has a number of provisions for debugging designed to help you save time during development.\n\n## id strings\n\nMost classes in luma.gl allow you to supply and optional `id` string to their constructors. This allows you to later easily check in the debugger which object (which specific instance of that class) is involved in a stack trace.\n\n```js\nconst program = new Program(gl, {id: 'cube-program', ...});\nconst program = new Program(gl, {id: 'pyramid-program', ...});\n```\n\n`id`s that you provide are also used by the built-in logging.\n\n\n## Logging\n\nluma.gl has a logging mechanism. Set the global variable luma.log.level to 3 (can be done in the browser console at any time) and luma will print tables for uniforms and attributes providing information about their values and types before each render call. This can be extremely helpful for checking that shaders are getting valid inputs.\n\n\n## Shader compilation errors\n\nluma.gl takes care to extract as much information as possible about shader compiler errors etc, and will throw exceptions with very detailed error strings when shaders fail to compile. luma.gl also injects and parses `glslify` \"shader names\", making it possible to name shaders inside the shader code, making it easier to identify which shader is involved when e.g shader parsing errors occur.\n\n\n## Parameter Validation\n\nluma.gl runs checks on attributes and buffers when they are being set, catching many trivial errors such as setting uniforms to `undefined` or wrong type (scalar vs array etc).\n\nBuffers will also have their first values checked to ensure that they are not NaN. As an example, setting uniforms to illegal values now throws an exception containing a helpful error message including the name of the problematic uniform.\n\n\n## Debug Module\n\nImporting `@luma.gl/debug` will enable creation of debug contexts for several **luma.gl** functions. See [@luma.gl/debug](/docs/api-reference/debug) for more information.\n\n```js\nimport {createGLContext} from '@luma.gl/gltools';\nimport '@luma.gl/debug';\nconst gl = createGLContext(gl, {debug: true});\n```\n\n\n\n\n","slug":"docs/developer-guide/debugging","title":"Debugging"},{"excerpt":"Upgrade Guide Upgrading from v7.3 to v8.0 The key goals of luma.gl v8.0 were to simplify the core architecture and significantly improve…","rawMarkdownBody":"# Upgrade Guide\n\n## Upgrading from v7.3 to v8.0\n\nThe key goals of luma.gl v8.0 were to simplify the core architecture and significantly improve performance. The number of modules has been reduced from 14 to 9, and they are now structured around layers of abstraction (high-level to low-level) to clarify the relationship between them. Unfinished and rarely-used components have been removed, reducing the complexity of the API and leading to significant performance gains (see [What's New](/docs/whats-new)) for details).\n\n### Module Restructure\n\nThe module structure has been significantly changed for v8.0 with the intention of clarifying the purpose of each module and the relationships between them.\n\n| New Module | Purpose | Components from v7 |\n| ---------- | ------- |---------- |\n| constants | WebGL enum values | Same as before |\n| shadertools| Tools for manipulating and composing shader text | shadertools and effects (formerly glfx) |\n| gltools    | Creation, tooling and polyfilling for the WebGL context| webgl2-polyfill and webgl-state-tracker|\n| webgl      | Wrapper classes for WebGL | Same as before |\n| core       | Single module re-exporting key parts of engine, webgl, gltools, shadertools | Changes described below |\n| engine     | High-level drawing APIs | core/model, core/animation-loop, core/resource-management, addons/animation, core/geometry, core/transform|\n| debug      | Debug tooling for the other modules | Same as before |\n| test-utils | Test tooling for the other modules | Same as before |\n| experimental| Experimental, unsupported APIs | core/scenegraph, gpgpu, addons/gltf, addons/webvr|\n\n### Breaking changes\n\n- `Texture2D`'s `unpackFlipY` option is removed. This change ensures that all data sources (Image, ImageBitmap, typed array) are treated consistently. As a result, textures created from Image objects and URL strings are now y-flipped from the v7.3 default. To get the old behavior, specify the `pixelStore` option:\n\n```js\nnew Texture2D({\n  data,\n  pixelStore: {\n    [GL.UNPACK_FLIP_Y_WEBGL]: true\n  }\n});\n```\n- `createGLContext` will no longer attempt to create a headlessgl context under node.js. One can either create headless context externally and use `instrumentGLContext` to prepare it for use with luma.gl or use `createHeadlessContext` from `@luma.gl/test-utils` to create a headlessgl context.\n- `registerShaderModules` has been removed. Modules can be imported and used directly where necessary.\n- `createShaderHook` and `createModuleInjection` have been removed. Use `ProgramManager.getDefaultProgramManger(gl).addShaderHook` && the shader module [inject field](/docs/developer-guide/shader-modules.md) instead.\n- `ProgramManager.getDefaultProgramManger(gl).addModuleInjection` been removed. Use the shader module [inject field](/docs/developer-guide/shader-modules.md) instead.\n- `getParameter` and `setParameter` have been removed. Use `getParameters` and `setParameters` instead.\n- The following are no longer exported by @luma.gl/core, but can still be imported from the modules indicated:\n\n| |Available in|\n|-|------------|\n|Query, VertexArrayObject, VertexArray, UniformBufferLayout, Shader, VertexShader, FragmentShader, clearBuffer, clearBuffer, copyToDataUrl, copyToImage, blit, setPathPrefix, loadFile, loadImage|@luma.gl/webgl|\n|resizeGLContext|@luma.gl/gltools|\n|combineInjects, lights, getQualifierDetails, getPassthroughFS, typeToChannelSuffix, typeToChannelCount, convertToVec4|@luma.gl/shadertools|\n\n\n### Smaller changes\n\n- Functions are no longer accepted as uniform values to the `Model` class. The same effect can be achieved by updating the uniform values each frame prior to drawing.\n- `BaseModel` and `Model` have been consolidated in `Model`. `Model` can be used as a substitute for `BaseModel` where necessary.\n- `AmbientLight`, `DirectionalLight`, `PointLight`, `PhongMaterial`, `PBRMaterial`, `CameraNode` have been removed from @luma.gl/core. These were either empty classes or simple data objects and so can be replaced by plain JavaScript objects in most cases.\n- `ShaderCache` has been removed and superseded by `ProgramManager`.\n- `VertexArray.getDrawParams` no longer takes overrides as an argument. The calling function can manually override values as needed.\n- @luma.gl/main has been removed. Use individual modules instead.\n- `Multipass` classes have been removed.\n- Seer support has been removed.\n- Timeline and Keyframes have been moved from @luma.gl/addons to @luma.gl/engine.\n\n\n## Upgrading from v7.2 to v7.3\n\n`ProgramManager` has replaced `ShaderCache` in the `Model` class as a more robust resource manager. Use of the `ShaderCache` with `Model` will not affect functionality in any way, but it is now a no-op.\n\n\n## Upgrading from v6.x to v7.0\n\nluma.gl v7.0 represents a major overhaul of the API. The majority of changes are in areas that are only infrequently used by applications, and the intention is that most applications should only require very light porting.\n\n\n## Core API Removals\n\n### Loading Functions Removed\n\nExtensive loading functionality is now provided by a new companion framework [loaders.gl](https://loaders.gl/) and because of this, most of the limited legacy luma.gl loading functions have been removed.\n\nFor the most common case (loading of images for use with textures), loading functions are no longer needed as the `data` prop in the `Texture2D` constructor now accepts url strings and `Promise` objects (this is the new Async Textures function).\n\n| Removed Function | Replacement  |\n| ---              | ---          |\n| `loadTexture(url, parameters)`  | `new Texture(gl, {data: url, parameters})` |\n| `loadFiles`      | Multiple calls to `loadFile` |\n| `loadImages`     | Multiple calls to `loadImage` |\n| `loadTextures`   | As per `loadTexture` |\n| `loadProgram`    | Manually load `fs` and `vs`, call `new Program(gl, {vs, fs})` |\n| `loadModel`      | call `loadFile` and copy `parseModel` code from examples/lesson/16|\n| `parseModel`     | call `loadFile` and copy `parseModel` code from examples/lesson/16 |\n\n### Attribute Class Removed\n\nThis experimental class has been moved to deck.gl and is now an internal class. Attribute accessor API improvements in luma.gl v7 should cover any issue.\n\n\n## WebGL API Removals\n\n### Sampler Class Removed\n\nThe `Sampler` class has been removed as its utility was limited and it added complexity to the library. It may be added back in the future if a clear use case arises.\n\n### Texture2DArray Class Removed\n\nThe `Texture2DArray` class has been removed as its utility was limited and the status of support was unclear due to limited testing. It may be added back in the future if a clear use case arises.\n\n### FenceSync Class Removed\n\nThe `FenceSync` class has been removed as its utility was limited. It may be added back in the future if a clear use case arises. If required, syncing can be done directly through the `WebGLFenceSync` object.\n\n## Framebuffer and Texture: Copy and Blit methods\n\nFollowing member function of `Framebuffer` and `Texture` classes are no longer supported, instead use the corresponding new global methods:\n\n| Removed method                  | Replacement |\n| ---                             | ---         |\n| `Framebuffer.readPixels`        | `readPixelsToArray` |\n| `Framebuffer.readPixelsToBuffer`| `readPixelsToBuffer` |\n| `Frambuffer.copyToDataUrl`      | `copyToDataUrl` |\n| `Frambuffer.copyToImage`        | `copyToImage` |\n| `Frambuffer.copyToTexture`      | `copyToTexture` |\n| `Frambuffer.blit`               | `blit` |\n| `Texture.copyFramebuffer`       | `copyToTexture` |\n\nParameters have also changed in some cases, see separate section.\n\n\n## Module Structure Changes\n\n### Debug functionality moved to separate npm module\n\nTo reduce bundle size and increase separation of concerns, debug functionality is now more cleanly separated from the core library and needs to be imported from a separate npm module:\n\nTo upgrade, install the new module\n\n```bash\nnpm install @luma.gl/debug\n```\n\nAnd replace\n\n```js\nimport \"luma.gl/debug\";\n````\nwith\n```js\nimport \"@luma.gl/debug\";\n```\n\n### Model\n\nChanges:\n* `Model` no longer extends `ScenegraphNode`. This ensures that applications that do not need scenegraph support do not need to include scenegraph related code. Use the new `ModelNode` class to inject `Models` into scenegraphs.\n\nDeletions:\n* Redraw flag handling has been removed: `Model.setNeedsRedraw()` and `Model.getNeedsRedraw()`.\n\nAdditions:\n* A new `Model.isAnimated()` method is provided, indicating that redraws are required every frame.\n\n## Geometry\n\nThe `Geometry` class has been simplified and is now a conceptually \"immutable\" class that holds typed arrays and accessor metatadata describing attributes for a geometry.\n\n| Removal                      | Replacement | Reason for Change |\n| ---                          | ---         | ---               |\n| `Geometry.drawMode` no longer accepts `String` values | `Geometry.DRAW_MODE` enum | API simplification |\n| `Geometry.setNeedsRedraw()`  | N/A | Not needed for immutable geometry |\n| `Geometry.getNeedsRedraw()`  | N/A | Not needed for immutable geometry |\n\n\n## Buffer\n\n| Removed Method               | Replacement | Reason for Change |\n| ---                          | ---         | ---               |\n| `Buffer.updateAccessor(...)` | `Buffer.setAccessor(new Accessor(buffer.accessor, ...)` | Decoupling accessors from `Buffer` |\n\n\n### Framebuffer\n\nTo maximize rendering performance, the default framebuffer is no longer preserved between frames.\n\nThe most common use case for preserving the draw buffer is capturing canvas contents into an image via `toDataURL`. This can now be done via `AnimationLoop.toDataURL` which returns a `Promise` that resolves to the canvas data URL:\n\n```js\ndataURL = await animationLoop.toDataURL();\nsnapshotImage.src = dataURL;\n```\n\nMore generally, moving code that depends on canvas contents to the end of `onRender`, after all draw operations, will ensure that canvas contents are available.\n\nPrior behaviour can re-enabled using the `glOptions` argument to the `createGLContext` or `AnimationLoop` constructors:\n\n```js\nnew AnimationLoop({\n  glOptions: {\n    preserveDrawingBuffer: true\n  }\n});\n```\n\nNote that setting `preserveDrawingBuffers` may result in a performance drop on some platforms.\n\n\n### Query\n\nUse `Query.getTimerMilliseconds` to retrieve timer results in milliseconds. `Query.getResult` now returns raw query results.\n\nTo improve performance and simplify the library, support for tracking `Query` instances with promises has changed: The `Query` constructor no longer takes `onComplete` and `onError` callbacks, and `pollGLContext` has been removed. Instead `Query.createPoll` now provides a simple, optional promise-based API.\n\n\n### Copy And Blit Parameter Unification\n\nNames of certain parameters to these methods have been unified in an effort to reduce confusion and use the same conventions across all functions implementing image read-back, copy or blit.\n\nThis table lists parameter mapping between old and new function.\n\n| `Framebuffer.readPixels` | `readPixelsToArray` |\n| ---                      | --- |\n| -                        | `source` |\n| `opts.x`                 | `opts.sourceX` |\n| `opts.y`                 | `opts.sourceY` |\n| `opts.width`             | `opts.sourceWidth` |\n| `opts.height`            | `opts.sourceHeight` |\n| `opts.format`            | `opts.sourceFormat` |\n| `opts.type`              | `opts.sourceType` |\n| `opts.attachment`        | `opts.sourceAttachment` |\n| `opts.pixelArray`        | `opts.target` |\n\n| `Framebuffer.readPixelsToBuffer` | `readPixelsToBuffer` |\n| ---               | --- |\n| -                 | `source` |\n| `opts.x`          | `opts.sourceX` |\n| `opts.y`          | `opts.sourceY` |\n| `opts.width`      | `opts.sourceWidth` |\n| `opts.height`     | `opts.sourceHeight` |\n| `opts.format`     | `opts.sourceFormat` |\n| `opts.type`       | `opts.sourceType` |\n| `opts.buffer`     | `opts.target` |\n| `opts.byteOffset` | `opts.targetByteOffset` |\n\n| `Framebuffer.copyToDataUrl` | `copyToDataUrl` |\n| ------------      | ---- |\n| -                 | `source` |\n| `opts.attachment` | `opts.sourceAttachment` |\n| `opts.maxheight`  | `opts.targetMaxHeight` |\n\n| `Framebuffer.copyToImage` | `copyToImage` |\n| ------------              | ---- |\n| -                         | `source` |\n| `opts.attachment`         | `opts.sourceAttachment` |\n| `opts.image`              | `opts.targetImage` |\n\n| `Framebuffer.copyToTexture` | `copyToTexture` |\n| ------------          | ---- |\n| -                     | `source` |\n| `opts.target`         | `target` |\n| `opts.texture`        | `target` |\n| `opts.x`              | `opts.sourceX` |\n| `opts.y`              | `opts.sourceY` |\n| `opts.xoffset`        | `opts.targetX` |\n| `opts.yoffset`        | `opts.targetY` |\n| `opts.zoffset`        | `opts.targetZ` |\n| `opts.width`          | `opts.width` |\n| `opts.height`         | `opts.height` |\n| `opts.internalFormat` | `opts.targetInternalFormat` |\n| `opts.mipmapLevel`    | `opts.targetMipmapLevel` |\n\n| `Texture.copyFramebuffer` | `copyToTexture` |\n| ------------           | ---- |\n| `opts.framebuffer` | `source` |\n| `opts.target`      | `target` |\n| `opts.x`           | `opts.sourceX` |\n| `opts.y`           | `opts.sourceY` |\n| `opts.width`       | `opts.width` |\n| `opts.height`      | `opts.height` |\n| `opts.internalFormat` | `opts.targetInternalFormat` |\n| `opts.level`       | `opts.targetMipmapLevel` |\n\n| `Framebuffer.blit` | `blit` |\n| ------------       | ---- |\n| `opts.srcFramebuffer` | `source` |\n| -                 | `target` |\n| `opts.attachment` | `opts.sourceAttachment` |\n| `opts.srcX0`      | `opts.sourceX0` |\n| `opts.srcX1`      | `opts.sourceX1` |\n| `opts.srcY0`      | `opts.sourceY0` |\n| `opts.srcY1`      | `opts.sourceY1` |\n| `opts.dstX0`      | `opts.targetX0` |\n| `opts.dstX1`      | `opts.targetX1` |\n| `opts.dstY0`      | `opts.targetY0` |\n| `opts.dstY1`      | `opts.targetY1` |\n| `opts.color`      | `opts.color` |\n| `opts.depth`      | `opts.depth` |\n| `opts.stencil`    | `opts.stencil` |\n| `opts.mask`       | `opts.mask` |\n| `opts.filter`     | `opts.filter` |\n\n\n### Geometry Scenegraph Models\n\nGeometry scenegraph models have been deprecated. Simply create a `Model` or `ModelNode` and explicitly pass a `Geometry` instance as\nan argument, e.g.:\n\n```js\n  const sphere = new Model(gl, {\n    geometry: new SphereGeometry({\n      nlat: 30,\n      nlong: 30,\n      radius: 2\n    })\n  });\n```\n\n## Upgrading from v5.3 to v6.0\n\nluma.gl v6.0 underwent a major API cleanup, resulting in a smaller, easier-to-learn API and smaller application bundles. While there are many smaller changes, the impact on most applications should be limited:\n\n* Most removed functions were in practice rarely used by applications, and the impact on typical luma.gl applications should be limited.\n* A number of API changes are related to moving attribute management from `Program` to `VertexArray`, however for higher level applications that work with the `Model` class rather than `Program` directly, there should not be much impact.\n\n\n### GL Constants Import Path\n\nThe biggest change for many apps will probably be that the static `GL` symbol (that contains all WebGL 2 constants) must now be separately imported GL from 'luma.gl/constants'.\n\n\n### Experimental Exports: New Naming Convention\n\nExperimental exports are now prefixed with underscore (\\_). The `experimental` \"name space\" export has been removed.\n\n```js\n// NOW: luma.gl v6\nimport {_Attribute as Attribute} from 'luma.gl';\n\n// BEFORE: luma.gl v5.x\nimport {experimental} from 'luma.gl';\nconst {Attribute} = experimental;\n```\n\nThis change will enable tree-shaking bundlers to remove unused experimental exports, resulting in smaller final application bundles.\n\n\n### Removed symbols\n\nMath functions were moved from luma.gl to the separate math.gl module in v4.1. As of v6.0, they are no longer forwarded by luma.gl and now need to be imported directly from math.gl:\n\n```js\nimport {radians, degrees, Vector2, Vector3, Vector4, Matrix4} from 'math.gl';\n```\n\nluma.gl v6.0 removes a number of previously deprecated symbols. luma.gl will now issue an error rather than a warning if the old usage is detecated.\n\n\n### Constants\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `GL`                             | `import GL from 'luma.gl/constants'` | Bundle size reduction (by making this import optional). |\n| `glGet(name)`                    | `glGet(gl, name)`               | Bundle size reduction (Was deprecated in v5.3) |\n| `glKey(value)`                   | `glKey(gl, value)`              | Bundle size reduction (Was deprecated in v5.3) |\n| `glKeyType(value)`               | `glKeyType(gl, value)`          | Bundle size reduction (Was deprecated in v5.3) |\n\n\n### Context\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `deleteGLContest`                | `destroyGLContext`              | Naming audit (Was deprecated in v5.3) |\n| `pollContext`                    | `pollGLContext`                 | Naming audit (Was deprecated in v5.3) |\n| `trackContextCreation`           | N/A                             | Rarely used, overly specialized |\n\n\n### Global Functions\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `readPixels`                     | `Framebuffer.readPixels`        | Naming audit (was deprecated in v3.0) |\n| `FrameBufferObject`              | `FrameBuffer`                   | Naming audit (was deprecated in v3.0) |\n\n\n### AnimationLoop\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `AnimationLoop.setViewParams()`  | `AnimationLoop.setProps()`      | Naming audit  |\n\n\n### Program\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `varyingMap`                     | N/A (`configuration`)           | Program now auto discovers varyings.        |\n| `Program.setAttributes()`        | `VertexArray.setAttributes()`   | Attribute management moved to `VertexArray` |\n| `Program.setBuffers()`           | `VertexArray.setAttributes()`   | Attribute management moved to `VertexArray` |\n| `Program.setVertexArray()`       | `Program.draw({vertexArray})`   | No longer needed, just supply a `VertexArray` to `Program.draw()` |\n| `Program.unsetBuffers()`         | N/A                             | No longer needed, just supply a `VertexArray` to `Program.draw()` |\n| `Program.use()`                  | `gl.useProgram(program.handle)` | Rarely needed by apps, can use raw WebGL API |\n| `getUniformCount()`              | `getParameter(GL.ACTIVE_UNIFORMS)` | Rarely needed |\n| `getUniformInfo()`               | `gl.getActiveUniform()`         | Rarely needed by apps, can use raw WebGL API |\n| `getUniformLocation()`           | `gl.getUniformLocation()`       | Rarely needed by apps, can use raw WebGL API |\n| `getUniformValue()`              | `gl.getUniform()`               | Rarely needed by apps, can use raw WebGL API |\n| 'getVarying()'                   |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getFragDataLocation()'          |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getAttachedShaders()'           |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getAttributeCount()'            |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getAttributeLocation()'         |                                 | Rarely needed by apps, can use raw WebGL API |\n| 'getAttributeInfo()'             |                                 | Rarely needed by apps, can use raw WebGL API |\n\n\n### TransformFeedback\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --          |\n| `TransformFeedback.pause()`      | `gl.pauseTransformFeedback`     | Rarely needed by apps, can use raw WebGL API |\n| `TransformFeedback.resume()`     | `gl.resumeTransformFeedback`    | Rarely needed by apps, can use raw WebGL API |\n\n\n### VertexArray\n\n| Removed symbol                   | Replacement                     | Reason for change     |\n| ---                              | ---                             | --        |\n| `VertexArray.setBuffers()`       | `VertexArray.setAttributes()`   | API Audit, setAttributes handles more cases. |\n| `VertexArray.setGeneric()`       | `VertexArray.setConstant()`     | API Audit, prefer \"constant\" instead of \"generic\" |\n| `VertexArray.filledLocations()`  | N/A                             | No longer needed. |\n| `VertexArray.clearBindings()`    | `VertexArray.reset()`           | API Audit |\n| `VertexArray.setLocations()`     | `VertexArray.constructor({program})` | Autodetected from `program` parameter |\n| `VertexArray.setGenericValues()` | `VertexArray.setConstant()`     | API Audit, prefer \"constant\" instead of \"generic\" |\n| `VertexArray.setDivisor()`       | `gl.vertexAttribDivisor()`      | Rarely needed by apps, can use raw WebGL API |\n| `VertexArray.enable()`           | `gl.enableVertexAttribArray()`  | Rarely needed by apps, can use raw WebGL API |\n| `VertexArray.disable()`          | `gl.disableVertexAttribArray()` | Rarely needed by apps, can use raw WebGL API |\n\n\n\n## Upgrading from v5.2 to v5.3\n\nv5.3 deprecates a number of symbols. It is recommended that you replace their usage in your source code.\n\n| Deprecated symbol                | Replacement                     | Reason     |\n| ---                              | ---                             | --         |\n| `GL`                             | `import GL from 'luma.gl/constants'` | Bundle size concerns |\n| `deleteGLContest`                | `destroyGLContext`              | API Audit: Naming alignment |\n| `pollContext`                    | `pollGLContext`                 | API Audit: Naming alignment |\n\n\n## Upgrading from v5.1 to v5.2\n\n### Running under Node.js\n\n[Using with Node](/docs/get-started/README.md): `\"import luma.gl/headless\"` is no longer required for luma.gl to load headless gl and the usage has been deprecated. You can now simply remove any such import statements from your code.\n\n\n### Using Debug Contexts\n\n[Debugging](/docs/developer-guide/debugging.md): The Khronos group's `WebGLDeveloperTools` are automatically installed when luma.gl is installed, but are not actually bundled into the application unless explicitly imported. This avoids impacting the size of production bundles built on luma.gl that typically do not need debug support.\n\nTo use debug support, first import the debug tools, then call `getDebugContext` to create a debug contexts from a normal WebGL context:\n\n```js\nimport \"luma.gl/debug\";\nconst gl = getDebugContext(gl);\n```\n\n\n## Upgrading from v4 to v5\n\nPlease read this documentation before upgrading your luma.gl dependency from v4 to v5. In v5 a number of previously deprecated features have been removed and a number of additional deprecations have been made at the same time.\n\nBefore upgrading to v5, it is highly recommended to run your application using latest v4 release, and check the console for any deprecated warnings, if there are any replace deprecated API with newer API as listed below.\n\n### Model Class\n\nThe `Model` constructor expects a gl context as the first argument.\n\n```js\n  // v5\n  Model(gl)\n  Model(gl, {...opts});\n  Model(gl, {program});\n```\n\nFollowing style construction was deprecated in v4 and is now removed in v5.\n\n```js\n  // NOT SUPPORTED\n  Model({gl});\n  Model({gl, ...opts});\n  Model({program});\n```\n\n### useDevicePixelRatio\n\n`useDevicePixelRatio` is used as a an argument in `AnimationLoop` class constructor and `pickModels` method. It is now deprecated in v5, but still supported with a warning message and will be removed in next major version update. It is recommended to use `useDevicePixels` instead.\n\n### Geometry\n\n`Geometry` class construction with inline attributes was deprecated in v4 and now removed in v5.\n\n```js\n// NOT SUPPORTED\nnew Geometry({\n  positions: new Float32Array([ ... ]),\n  colors: {\n    size: 4,\n    value: new Float32Array([ ... ])\n  }\n});\n```\n\nAll attributes should be grouped inside `attribute` object.\n\n```js\n// SUPPORTED\nnew Geometry({\n attributes: {\n   positions: new Float32Array([ ... ]),\n   colors: {\n     size: 4,\n     value: new Float32Array([ ... ])\n   }\n }\n});\n```\n\n### Removed Features\n\nFollowing features were deprecated in v3 and v4 are now removed in v5.\n\n* Global symbols:\n\n| Removed symbol / Usage | Replacement    | Comment |\n| ---                  | ---              | --      |\n| `withState`          | `withParameters` | State management |\n| `glContextWithState` | `withParameters` | State management |\n|`withParameters({frameBuffer})`| `withParameters({framebuffer})`| State management |\n| `MONOLITHIC_SHADERS` | `MODULAR_SHADERS` | default shaders |\n| `isWebGLContext` | `isWebGL` | WebGL context validation |\n| `isWebGL2Context` | `isWebGL2` | WebGL 2 context validation |\n| `Camera`, `PerspectiveCamera`, `OrthoCamera` | `None` | |\n| `Scene` | `None` | |\n\n* Texture construction options:\n\n| Removed symbol / Usage | Replacement    |\n| ---                  | ---              |\n| `generateMipmaps` | `mipmaps` |\n| `magFilter` | `parameters[GL.TEXTURE_MAG_FILTER]` |\n| `minFilter` | `parameters[GL.TEXTURE_MIN_FILTER]` |\n| `wrapS` | `parameters[GL.TEXTURE_WRAP_S]` |\n| `wrapT` | `parameters[GL.TEXTURE_WRAP_T]` |\n\n\n## Upgrading from v3 to v4\n\nluma.gl v4 is a major release with API changes. Please read this documentation before upgrading your luma.gl's dependency from v3 to v4.\nIn addition, a number of previously deprecated features have been removed and a number of additional deprecations have been made at the same time in this version.\n\n\n## Removed Features\n\nSome previously deprecated classes and functions have been removed in luma.gl v4 and applications must be updated with the new classes and functions if they are still using these.\n\n| Symbol               | Replacement      | Comment |\n| ---                  | ---              | --- |\n| `Vec3`               | `Vector3`        | [New math library]( https://github.com/uber-web/math.gl) |\n| `Mat4`               | `Matrix4`        | [New math library]( https://github.com/uber-web/math.gl) |\n| `Quat`               | `Quaternion`     | [New math library]( https://github.com/uber-web/math.gl) |\n\n\n## Deprecated Features\n\nSome classes and functions have been deprecated in luma.gl v4. They will continue to function in v4, but a warning in the console will be generated. These functions are expected to be removed in a future major versions of luma.gl.\n\n\n| Symbol               | Replacement      | Comment |\n| ---                  | ---              | --- |\n| `withState`          | `withParameters` | [New WebGL state management](/docs/api-reference/webgl/context/with-parameters.md) |\n| `glContextWithState` | `withParameters` | [New WebGL state management](/docs/api-reference/webgl/context/with-parameters.md) |\n\n\n## API Change\n\n### Model Class\n\nThe `Model` constructor now expects a gl context as the first argument.\n\n```js\n  // v3\n  Model({gl});\n  Model({gl, ...opts});\n  Model({program});\n\n  // v4\n  Model(gl)\n  Model(gl, {...opts});\n  Model(gl, {program});\n```\n\nthe gl context used to be extracted from the supplied program or provided along side with other options, but in luma.gl v4, it is expected as a separate argument to the constructor. This change is because luma.gl v4 emphasizes sharing shaders rather than programs (often indirectly via shader caching / shader assembly), it is less common that a gl context is available.\n\n\n## Upgrading from V2 to V3\n\nV3 was a fairly minor release, a number of deprecations were made.\n\n### Deprecations\n\n| Symbol               | Replacement      | Comment |\n| ---                  | ---              | --- |\n| `Vec3`               | `Vector3`        | [New math library]( https://github.com/uber-web/math.gl) |\n| `Mat4`               | `Matrix4`        | [New math library]( https://github.com/uber-web/math.gl) |\n| `Quat`               | `Quaternion`     | [New math library]( https://github.com/uber-web/math.gl) |\n","slug":"docs/upgrade-guide","title":"Upgrade Guide"},{"excerpt":"Shader Modules Overview shadertools is a GLSL shader module system built around a GLSL \"assembler\" that allows you build modular shaders. It…","rawMarkdownBody":"# Shader Modules\n\n## Overview\n\nshadertools is a GLSL shader module system built around a GLSL \"assembler\" that allows you build modular shaders. It addresses the lack of a module/import system in the GLSL language and allows you to import chunks of reusable shader code from modules into your shader source code, and organize your shader code in reusable modules.\n\n* Enables you to import and \"inject\" prepackaged modules of shader code into your shaders.\n* Allows you to package up reusable GLSL code as shader modules.\n* Adds GPU detection and a measure of portability your shaders.\n\n\n## Usage\n\nTo add/inject existing modules into your shaders, just add the modules parameter to your `assembleShaders` call:\n\n```js\nimport {shaderModule} from 'library-of-shader-modules';\nconst {vs, fs, getUniforms, moduleMap} = assembleShaders(gl, {\n  fs: '...',\n  vs: '...',\n  modules: [shaderModule],\n  ...\n})\n```\n\nTo create a new shader module, you need to create a descriptor object.\n\n```js\nconst MY_SHADER_MODULE = {\n  name: 'my-shader-module',\n  vs: ....\n  fs: null,\n  inject: {},\n  dependencies: [],\n  deprecations: [],\n  getUniforms\n};\n```\n\nThis object can be used as shader module directly:\n\n```js\nassembleShaders(gl, {..., modules: [MY_SHADER_MODULE]});\n```\n\n## Structure of a Shader Module\n\n### Shader Module Type\n\nA shader module is either:\n\n* **Generic** - a set of generic GLSL functions that can be included either in a fragment shader or a vertex shader (or both). The `fp64` module is a good example of this type of module.\n* **Functional** - Contains specific vertex and/or fragment shader \"chunks\", often set up so that the vertex shader part sets up a `varying` used by the fragment shader part.\n\n\n### Shader Module Descriptor\n\nTo define a new shader module, you create a descriptor object that brings together all the necessary pieces:\n\n```js\nexport const MY_SHADER_MODULE = {\n  name: 'my-shader-module',\n  vs: '...',\n  fs: '...',\n  inject: {},\n  dependencies: [],\n  deprecations: [],\n  getUniforms\n};\n```\n\nDescriptor objects can define the following fields:\n\n* `name` (*String*, Required) - The name of the shader module.\n* `vs` - (String | null)\n* `fs` - (String | null)\n* `getUniforms` JavaScript function that maps JavaScript parameter keys to uniforms used by this module\n* `uniforms` (*Object*) - a light alternative to `getUniforms`, see below\n* `inject` (*Object*) - injections the module will make into shader hooks, see below\n* `dependencies` (*Array*) - a list of other shader modules that this module is dependent on\n* `deprecations` (*Array*) - a list of deprecated APIs.\n\nIf `deprecations` is supplied, `assembleShaders` will scan GLSL source code for the deprecated constructs and issue a console warning if found. Each API is described in the following format:\n  - `type`: `uniform <type>` or `function`\n  - `old`: name of the deprecated uniform/function\n  - `new`: name of the new uniform/function\n  - `deprecated`: whether the old API is still supported.\n\n\n### GLSL Code\n\nThe GLSL code for a shader module typically contains:\n\n* a mix of uniform and varying declarations\n* one or more GLSL function definitions\n\n\n### getUniforms\n\nEach shader module provides a method to get a map of uniforms for the shader. This function will be called with two arguments:\n\n* `opts` - the module settings to update. This argument may not be provided when `getUniforms` is called to generate a set of default uniform values.\n* `context` - the uniforms generated by this module's dependencies.\n\nThe function should return a JavaScript object with keys representing uniform names and values representing uniform values.\n\nThe function should expect the shape of the dependency uniforms to vary based on what's passed in `opts`. This behavior is intended because we only want to recalculate a uniform if the uniforms that it depends on are changed. An example is the `project` and `project64` modules in deck.gl. When `opts.viewport` is provided, `project64` will receive the updated projection matrix generated by the `project` module. If `opts.viewport` is empty, then the `project` module generates nothing and so should `project64`.\n\n\n### uniforms\n\nIf the uniforms of this module can be directly pulled from user settings, they may declaratively defined by a `uniforms` object:\n\n```js\n{\n  name: 'my-shader-module',\n  uniforms: {\n    strength: {type: 'number', value: 1, min: 0, max: 1},\n    center: [0.5, 0.5]\n  }\n}\n```\n\nAt runtime, this map will be used to generate the uniforms needed by the shaders. If either `strength` or `center` is present in the user's module settings, then the user's value will be used; otherwise, the default value in the original definition will be used.\n\nEach uniform definition may contain the following fields:\n\n* `type` (*String*) - one of `number`, `boolean`, `array` or `object`\n* `value` - the default value of this uniform\n\nWith `type: 'number'`, the following additional fields may be added for validation:\n\n* `min` (*Number*)\n* `max` (*Number*)\n\nNote: `uniforms` is ignored if `getUniforms` is provided.\n\n## inject\n\nA map of hook function signatures to either the injection code string, or an object containing the injection code and an `order` option indicating ordering within the hook function. See [assembleShaders](/docs/api-reference/shadertools/assemble-shaders) documentation for more information on shader hooks.\n\nFor example:\n\n```js\n{\n  picking: {\n    'vs:VERTEX_HOOK_FUNCTION': 'picking_setPickingColor(color.rgb);',\n    'fs:FRAGMENT_HOOK_FUNCTION': {\n      injection: 'color = picking_filterColor(color);',\n      order: Number.POSITIVE_INFINITY\n    },\n    'fs:#main-end': 'gl_FragColor = picking_filterColor(gl_FragColor);'\n  }\n}\n```\n\n## GLSL Syntax Conversion Reference\n\nWhere possible, the shader assembler replaces keywords based on the version of the shader into which a module is inserted. While not all GLSL ES 3.0 features can be emulated, this allows many modules to be used across versions.\n\nSyntax replacement tables are provided below:\n\nVertex Shaders\n\n| 3.00 ES         | 1.00 ES     | Comment         |\n| ---             | ---         | ---             |\n| `in`            | `attribute` |                 |\n| `out`           | `varying`   |                 |\n\nFragment Shaders\n\n| 3.00 ES         | 1.00 ES        | Comment |\n| ---             | ---            | ---     |\n| `in`            | `varying`      |         |\n| `out`           | `gl_FragColor` |         |\n| `out`           | `gl_FragData`  |         |\n| `texture`       | `texture2D`    | `texture` will be replaced with `texture2D` to ensure 1.00 code is correct. See note on `textureCube` below. |\n| `textureCube` * | `textureCube`  | `textureCube` is not valid 3.00 syntax, but must be used to ensure 1.00 code is correct, because `texture` will be substituted with `texture2D` when transpiled to 100. Also `textureCube` will be replaced with correct `texture` syntax when transpiled to 300. |\n| `gl_FragDepth`  | `gl_FragDepthEXT` | WebGL 1: **EXT_frag_depth** |\n\n\n| 3.00 ES             | 1.00 ES                | Comment |\n| ---                 | ---                    | --- |\n| `texture2DLod`      | `texture2DLodEXT`      | WebGL 1: **EXT_shader_texture_lod** |\n| `texture2DProjLod`  | `texture2DProjLodEXT`  | WebGL 1: **EXT_shader_texture_lod** |\n| `texture2DProjLod`  | `texture2DProjLodEXT`  | WebGL 1: **EXT_shader_texture_lod** |\n| `textureCubeLod`    | `textureCubeLodEXT`    | WebGL 1: **EXT_shader_texture_lod** |\n| `texture2DGrad`     | `texture2DGradEXT`     | WebGL 1: **EXT_shader_texture_lod** |\n| `texture2DProjGrad` | `texture2DProjGradEXT` | WebGL 1: **EXT_shader_texture_lod** |\n| `texture2DProjGrad` | `texture2DProjGradEXT` | WebGL 1: **EXT_shader_texture_lod** |\n| `textureCubeGrad`   | `textureCubeGradEXT`   | WebGL 1: **EXT_shader_texture_lod** |\n","slug":"docs/developer-guide/shader-modules","title":"Shader Modules"},{"excerpt":"Transform Feedback (WebGL 2) Transform Feedback operations represent a GPGPU/GPU compute technique where GPU draw calls are configured so…","rawMarkdownBody":"# Transform Feedback (WebGL 2)\n\nTransform Feedback operations represent a GPGPU/GPU compute technique where GPU draw calls are configured so that they write some specified outputs from the vertex shaders to (one or more) GPU memory buffers that have been provided by the application. Applications use transform feedback to data processing from CPU to GPU, where multiple parallel execution units will be used for processing. Data is handled in form of `Buffer` objects, i.e. data resides in the GPU memory.\n\nTransform Feedback operations write their output into `Buffer` instances. These buffers can then be directly set as attributes on `Model` or `VertexArray` for regular rendering operations.\n\nBuffers can be read back to the CPU, but this has a high performance penaltyh. Ideally, the application's logic can be designed so that CPU access is not required which avoids expensive CPU and GPU sync.\n\nTo run a single transform feedback operation:\n\n* Create a `Program` or a `Model` with varyings (`out` variables) declared in the vertex shader's GLSL code, and provide the names of these varyings to the `Program` constructor.\n* Use `Program.draw()` or `Model.draw()` with a `transformFeedback` parameter.\n* `Model.transform()` is equivalent to `Model.draw()` but automatically turns off the fragment shader stage.\n\nAlternatively, the more powerful `Transform` class is preferable if you don't want to deal with setting up `Program` and `TransformFeedback` instances, or if intend to run a repeating, double buffered transform feedback loop.\n\n\n## Usage\n\n```js\nimport {Transform} from '@luma.gl/core';\n```\n\n### Use case : Specify source and destination buffers.\n\nCreate a `Transform` object by passing, vs (vertex shader), source buffer(s), varyings (output variable names in vertex shader) and destination buffers. Then call `run` to perform one transform feedback iteration.\n\n```js\nconst VS = `\\\n#version 300 es\nattribute float inValue;\nvarying float outValue;\n\nvoid main()\n{\n  outValue = 2.0 * inValue;\n}\n`;\n\nconst sourceData = new Float32Array([10, 20, 31, 0, -57]);\nconst sourceBuffer = new Buffer(gl, {data: sourceData});\n\n// Default values applied for size (1) and type (gl.FLOAT)\nconst feedbackBuffer = new Buffer(gl, {byteLength: sourceData.length * 4});\n\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inValue: sourceBuffer\n  },\n  feedbackBuffers: {\n    outValue: feedbackBuffer\n  },\n  vs: VS,\n  varyings: ['outValue'],\n  elementCount: 5\n});\n\n// Perform one transform feedback iteration\ntransform.run();\n```\n\n### Use case : Create destination buffers automatically.\n\n`Transform` can internally create destination buffers (i.e. feedback buffers), when `feedbackMap` is provided. Each destination buffer is created with same settings and layout as corresponding source buffer as per `feedbackMap`.\n\n```js\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inValue: sourceBuffer\n  },\n  feedbackMap: {\n    inValue: 'outValue'\n  },\n  vs: VS,\n  varyings: ['outValue'],\n  elementCount: 5\n});\n\n```\n### Use case : Multiple iterations using swap().\n\nWhen `feedbackMap` is specified buffers can be swapped using a single call to `swap()`, this is useful for cases like particle simulation, where output of one transform feedback iteration is piped as input to the next iteration.\n\n```js\n\n// Setup Transform with `souceDestinationMap` as above\n\ntransform.run();\n\nlet bufferWithNewValues = transform.getBuffer('outValue');\n...\n// Render using 'bufferWithNewValues'\n...\n\n//swap buffers\ntransform.swap();\ntransform.run();\nbufferWithNewValues = transform.getBuffer('outValue');\n...\n// Render using 'bufferWithNewValues'\n...\n```\n\n### Use case : Update one or more buffers using update() method..\n\nOnce `Transform` object is constructed and used, one or more source or destination buffers can be updated using `update`.\n\n```js\n// transform is set up as above\n...\n\n// update buffer binding for 'inValue' attribute\nconst newSourceBuffer = new Buffer(gl, {data: newSourceData});\ntransform.update({\n  sourceBuffers: {\n    inValue: newSourceBuffer\n  }\n});\n\n// now data is provided from newly bound buffer.\ntransform.run();\n```\n","slug":"docs/developer-guide/transform-feedback","title":"Transform Feedback (WebGL 2)"},{"excerpt":"Bundling Optimizing for Bundle Size luma.gl and luma.gl provide a lot of functionality and the amount of code these libraries contain will…","rawMarkdownBody":"# Bundling\n\n## Optimizing for Bundle Size\n\nluma.gl and luma.gl provide a lot of functionality and the amount of code these libraries contain will of course impact the size of your application bundle and your startup load time.\n\nThere are multiple techniques used in JavaScript.\n\n\n### Choosing a dist folder\n\nWhen installed from npm, luma.gl and related libraries come with three separate `dist` sub folders.\n\n| Folder     | `mainField` | Description   |\n| ---        | ---         | --- |\n| `dist/es6` | `esnext`    | The most compact distribution is with very few exceptions essentially untranspiled ES6/ES2015 code (via `babel-preset-env`). This is the smallest distribution, and is the best choice if you are only targeting modern \"evergreen\" browsers (e.g. not IE11 or older mobile devices). |\n| `dist/esm` | `module`    | Same as `dist/es5`, except `export` and `import` statements are left untranspiled to enable tree shaking. The main reason to use this distribution is if your are targeting older browsers (e.g. IE11 or older mobile devices). |\n| `dist/es5` | `main`      | All code is transpiled into ES5 and exports/imports are transpiled into `commonjs` requires. The main reason to use this distribution is if your bundler does not support tree-shaking using `import`/`export` syntax. |\n\nYou will have to check the documentation of your particular bundler to see what configuration options are available:\n\n* Webpack 2 and later will pick the `esm` distribution by default (the `module` main field)\n* Webpack 4 allows you to choose the `esnext` distribution by specifying a new `resolve.mainFields` array in your application's webpack config.\n* For other bundlers, please refer to the respective documentation to see if you can control which distribution to use. If not, expect the `es5` distribution to be used.\n\n\n### About Tree-Shaking\n\nluma.gl is designed to fully leverage tree-shaking. Tree-shaking should be possible with any supporting browser but development has currentle focusing on enabling the webpack 4 + babel 7 combination which provides excellent results.\n\nSome things to be aware of when working with tree-shaking:\n\n* At least in Webpack, tree shaking is done by the uglifier, which is typically only run as the very last step on production builds. This means that it is typically not possible to assess the benefits of tree shaking during development.\n* The lack of tree-shaking during development makes it hard to make statements about bundle size impact of a library just from looking at bundle sizes of development builds or the size of the library's npm module. Our recommendation is to always measure impact on your actual production builds.\n\n\n### Pay for What you Use\n\nNaturally, an application that uses all the functionality offered by a framework will benefit little from tree shaking, whereas a small app that only uses a few selected components should expect big savings.\n\nWhen we modularize luma.gl, we are less focused on the size of the entire library, and more on making sure that applications only pay for the features they actually use. Also we try to make the core set of functionality small.\n\n\n### Bundle Size Numbers\n\nSo, what kind of impact on bundle sizes should you expect when using luma.gl? When do you know if you have set up your bundler optimally. To help answer these questions, we provide some numbers you can compare against. luma.gl has scripts that measure the size of a minified bundle after each build, which allows us to provide comparison numbers between releases. This bundle imports the `Module` and `AnimationLoop` classes, which are the basic building blocks of most apps.\n\n| es6-production  | 6.1 Bundle/Zip | 6.0 Bundle/Zip |\n| ---             | ---            | ---            |\n| es6-production  | 144KB  / 42KB  | 181KB  / 51KB  |\n| esm-production  | 209KB  / 49KB  | 281KB  / 66KB  |\n| es5-production  | 408KB  / 88KB  | 422KB  / 93KB  |\n| es6-development | 787KB  / 123KB | 926KB  / 165KB |\n| esm-development | 1048KB / 150KB | 1167KB / 192KB |\n| es5-development | 961KB  / 142KB | 1052KB / 182KB |\n\n\n* Numbers represent the minified bundle size of a minimal application, bundled with Webpack 4, which means that the `ES6` and ESM numbers benefit from tree shaking.\n* The number in parenthesis are the compressed bundle sizes. This is an indication of the how much extra size will be added to your compressed app bundle if you import luma.gl.\n* For the ES6 and ESM dists, apps that use more luma.gl classes and features will see an increase in bundle size.\n\n\n### Future Work\n\nThis is not the final word on luma.gl bundle size. More work is being done to reduce the size of luma.gl and we are confident that even as fture releases will have more functionality, we will be able to keep the library code from growing and, more importantly, make luma.gl even more \"tree shakeable\", with the intention that apps should only \"pay for what they use\".\n\n\n## Remarks\n\n* **Optimizing for minified code** - Due to inclusion of sourcemaps etc, the bundle size impact of luma.gl tends to look more significant in development builds than in the final production builds. While reducing the size of the development libraries is also desirable, the current goal is to ensure the impact of adding luma.gl on the final, minified/uglified application bundle is as small as possible.\n* Compressed bundle sizes are calculated using `gzip -9`. Consider using slower `brotli` compression for static assests, it typically provides an additional 20% reduction.\n","slug":"docs/developer-guide/bundling","title":"Bundling"},{"excerpt":"Hello Instancing (High-level) In this tutorial, we'll work through how to do instanced drawing with luma.gl's high-level APIs. We'll also…","rawMarkdownBody":"# Hello Instancing (High-level)\n\nIn this tutorial, we'll work through how to do instanced drawing with luma.gl's high-level APIs. We'll also take this opportunity to introduce luma.gl shader modules. We'll begin with our [hello triangle](/docs/getting-started/hello-triangle) app and make some modifications. First let's create a shader module:\n```js\nimport {AnimationLoop, Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n\nconst colorShaderModule = {\n  name: 'color',\n  vs: `\n    varying vec3 color_vColor;\n\n    void color_setColor(vec3 color) {\n      color_vColor = color;\n    }\n  `,\n  fs: `\n    varying vec3 color_vColor;\n\n    vec3 color_getColor() {\n      return color_vColor;\n    }\n  `\n};\n```\n\nA shader module is essentially just some GLSL code that will be inserted into our vertex and fragment shaders. They're usually used to define functions that implement generic functionality that can be reused in different programs. In this case, we're defining one to simply pass a color from the vertex shader to the fragment shader in a varying. This module also demonstrates a common convention in luma.gl to prefix function and variable names in a shader module with the name of the module to avoid name collisions.\n\nNow let's update our vertex and fragment shaders to use the module functions:\n```js\nconst vs = `\n  attribute vec2 position;\n  attribute vec3 color;\n\n  void main() {\n    color_setColor(color);\n    gl_Position = vec4(position, 0.0, 1.0);\n  }\n`;\n\nconst fs = `\n  void main() {\n    gl_FragColor = vec4(color_getColor(), 1.0);\n  }\n`;\n```\n\nNow we update the `Model` to use the module:\n```js\nconst model = new Model(gl, {\n  vs,\n  fs,\n  modules: [colorShaderModule],\n  attributes: {\n    position: positionBuffer,\n    color: colorBuffer\n  },\n  vertexCount: 3\n});\n```\n\nIf you rerun the app, it should render as it did before.\n\nNow let's add some instancing to this scene! First we'll modify the position and color buffers we created before, and add an offset buffer to set the position of each instance:\n```js\nconst positionBuffer = new Buffer(gl, new Float32Array([\n  -0.2, -0.2,\n  0.2, -0.2,\n  0.0, 0.2\n]));\n\nconst colorBuffer = new Buffer(gl, new Float32Array([\n  1.0, 0.0, 0.0,\n  0.0, 1.0, 0.0,\n  0.0, 0.0, 1.0,\n  1.0, 1.0, 0.0\n]));\n\nconst offsetBuffer = new Buffer(gl, new Float32Array([\n  0.5, 0.5,\n  -0.5, 0.5,\n  0.5,  -0.5,\n  -0.5, -0.5\n]));\n```\nFor this scene, the positions are vertex attributes, while the colors and offsets are instance attributes.\n\nNow add the offsets to the vertex shader:\n```js\nconst vs = `\n  attribute vec2 position;\n  attribute vec3 color;\n  attribute vec2 offset;\n\n  void main() {\n    color_setColor(color);\n    gl_Position = vec4(position + offset, 0.0, 1.0);\n  }\n`;\n```\n\nFinally, we need to add the new buffer to the `Model`, and describe the parameters of the instanced draw:\n```js\nconst model = new Model(gl, {\n  vs,\n  fs,\n  modules: [colorShaderModule],\n  attributes: {\n    position: positionBuffer,\n    color: [colorBuffer, {divisor: 1}],\n    offset: [offsetBuffer, {divisor: 1}]\n  },\n  vertexCount: 3,\n  instanceCount: 4\n});\n```\nNote the new syntax used for the attributes. The second element in each array is an `accessor` that describes how the buffer should be traversed during a draw. luma.gl will try to infer these parameters from the data or the shader when possible, but when it can't (or when we want to override the inferred values), we have to provide an explicit accessor. We also provide the model with the number of instances we want to draw.\n\nIf all went well, running the app now should draw four triangles, each a different color. See the live demo [here](/examples/getting-started/hello-instancing-mid).\n\nFor reference the complete code is provided below:\n```js\nimport {AnimationLoop, Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n\nconst colorShaderModule = {\n  name: 'color',\n  vs: `\n    varying vec3 color_vColor;\n\n    void color_setColor(vec3 color) {\n      color_vColor = color;\n    }\n  `,\n  fs: `\n    varying vec3 color_vColor;\n\n    vec3 color_getColor() {\n      return color_vColor;\n    }\n  `\n};\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.2, -0.2,\n      0.2, -0.2,\n      0.0, 0.2\n    ]));\n\n    const colorBuffer = new Buffer(gl, new Float32Array([\n      1.0, 0.0, 0.0,\n      0.0, 1.0, 0.0,\n      0.0, 0.0, 1.0,\n      1.0, 1.0, 0.0\n    ]));\n\n    const offsetBuffer = new Buffer(gl, new Float32Array([\n      0.5, 0.5,\n      -0.5, 0.5,\n      0.5,  -0.5,\n      -0.5, -0.5\n    ]));\n\n    const model = new Model(gl, {\n      vs: `\n        attribute vec2 position;\n        attribute vec3 color;\n        attribute vec2 offset;\n\n        void main() {\n          color_setColor(color);\n          gl_Position = vec4(position + offset, 0.0, 1.0);\n        }\n      `,\n      fs: `\n        void main() {\n          gl_FragColor = vec4(color_getColor(), 1.0);\n        }\n      `,\n      modules: [colorShaderModule],\n      attributes: {\n        position: positionBuffer,\n        color: [colorBuffer, {divisor: 1}],\n        offset: [offsetBuffer, {divisor: 1}]\n      },\n      vertexCount: 3,\n      instanceCount: 4,\n      instanced: true\n    });\n\n    return {model};\n  },\n\n  onRender({gl, model}) {\n    clear(gl, {color: [0, 0, 0, 1]});\n    model.draw();\n  }\n});\n\nloop.start();\n\n```\n","slug":"docs/getting-started/hello-instancing-high","title":"Hello Instancing (High-level)"},{"excerpt":"Getting Started This tutorial will walk you through setting up a basic development environment for luma.gl applications using webpack. Later…","rawMarkdownBody":"# Getting Started\n\nThis tutorial will walk you through setting up a basic development environment for luma.gl applications using [webpack](https://webpack.js.org). Later tutorials will build on this one, so we recommend going through it first.\n\n**Note:** It is assumed for these tutorials that you have some knowledge of the WebGL API. If you are unfamiliar with how to draw with WebGL, we highly recommend the excellent [WebGL 2 Fundamentals](https://webgl2fundamentals.org/).\n\nFrom the command line, first run\n```bash\nmkdir luma-demo\ncd luma-demo\nnpm init -y\n```\nto set up our project directory and initialize npm.\n\n\nNext run\n```bash\nnpm i @luma.gl/engine @luma.gl/webgl\nnpm i -D webpack webpack-cli webpack-dev-server html-webpack-plugin\n```\nto install our dependencies.\n\nOpen the file `package.json` (created when we initialized npm), and add the following to the `scripts` block:\n```json\n\"start\": \"webpack-dev-server --open\"\n```\n\nThe full contents of the `package.json` should be the following (dependency version numbers might differ):\n\n```json\n{\n  \"name\": \"luma-demo\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"start\": \"webpack-dev-server --open\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"@luma.gl/core\": \"^8.0.0\"\n  },\n  \"devDependencies\": {\n    \"html-webpack-plugin\": \"^3.2.0\",\n    \"webpack\": \"^4.41.2\",\n    \"webpack-cli\": \"^3.3.9\",\n    \"webpack-dev-server\": \"^3.9.0\"\n  }\n}\n```\n\nCreate a file `webpack.config.js` in the project root and add the following to it:\n```js\nconst path = require('path');\nconst HtmlWebpackPlugin = require('html-webpack-plugin');\n\nmodule.exports = {\n  mode: 'development',\n  entry: './index.js',\n  plugins: [\n    new HtmlWebpackPlugin({\n      title: 'luma.gl Demo',\n    }),\n  ],\n  output: {\n    filename: 'bundle.js'\n  },\n};\n```\n(For more information on Webpack, visit their [excellent documentation](https://webpack.js.org/guides/getting-started/)).\n\nNow create a file `index.js` in the project root and add the following to it:\n```js\nimport {AnimationLoop} from '@luma.gl/engine';\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    // Setup logic goes here\n  },\n\n  onRender({gl}) {\n    // Drawing logic goes here\n  }\n});\n\nloop.start();\n\n```\n\nThis will be the basic structure of most luma.gl applications. To make sure everything works, let's add a draw command:\n```js\nimport {AnimationLoop} from '@luma.gl/engine';\nimport {clear} from '@luma.gl/webgl';\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    // Setup logic goes here\n  },\n\n  onRender({gl}) {\n    // Drawing logic goes here\n    clear(gl, {color: [0, 0, 0, 1]});\n  }\n});\n\nloop.start();\n```\nand run\n```bash\nnpm start\n```\nfrom the command line. If all went well, a tab should open in your default browser, and you should see a black rectangle at the top left of your screen.\n","slug":"docs/getting-started","title":"Getting Started"},{"excerpt":"External Contexts This tutorial will be a simple demonstration of how to use an externally created WebGL context with luma.gl's higher-level…","rawMarkdownBody":"# External Contexts\n\nThis tutorial will be a simple demonstration of how to use an externally created WebGL context with luma.gl's higher-level APIs. So far, we have either created a WebGL context ourselves to use with low-level APIs, or allowed the the `AnimationLoop` class to create a WebGL context for us. luma.gl's higher-level APIs expect some instrumentation on the WebGL context, so we can't just use a context we create ourselves with classes like `Model` and `Buffer`. The `AnimationLoop` class performs this instrumentation for us using the `instrumentGLContext` function from **@luma.gl/gltools**, and we can use this function directly if we want to control creation of the context or use a context passed to us by another framework (e.g. the [GeoSpatial](/examples/showcase/geospatial) example uses this technique with a WebGL context created by [MapboxGL](https://docs.mapbox.com/mapbox-gl-js/api/)).\n\nWe'll create a modified version of the [Hello Triangle](/docs/getting-started/hello-triangle) tutorial that creates a WebGL context manually rather than using the `AnimationLoop` class. To start with, we'll modify our imports:\n\n```js\nimport {Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\nimport {instrumentGLContext} from '@luma.gl/gltools';\n```\n\nWe then create our context and pass it to `instrumentGLContext`:\n\n```js\nconst canvas = document.createElement('canvas');\ncanvas.width = 800;\ncanvas.height = 600;\ndocument.body.appendChild(canvas);\n\nconst gl = instrumentGLContext(canvas.getContext('webgl'));\n```\nThis performs some polyfilling (done by `polyfillContext`, which we saw in the [Hello Instancing Low-level tutorial](/docs/getting-started/hello-instancing-low)) and tracks some additional metadata on the context, ensuring it will work properly with the rest of luma.gl. With that done, we simply create our luma.gl objects and draw as we did in the original example, with the sole difference being we create our own render loop using `requestAnimationFrame` rather than using the `AnimationLoop` callbacks.\n\n```js\nconst gl = instrumentGLContext(canvas.getContext('webgl'));\ngl.clearColor(0, 0, 0, 1);\n\nconst positionBuffer = new Buffer(gl, new Float32Array([\n  -0.5, -0.5,\n  0.5, -0.5,\n  0.0, 0.5\n]));\n\nconst colorBuffer = new Buffer(gl, new Float32Array([\n  1.0, 0.0, 0.0,\n  0.0, 1.0, 0.0,\n  0.0, 0.0, 1.0\n]));\n\n// ...\n\nconst model = new Model(gl, {\n  vs,\n  fs,\n  attributes: {\n    position: positionBuffer,\n    color: colorBuffer\n  },\n  vertexCount: 3\n});\n\nrequestAnimationFrame(function draw() {\n  requestAnimationFrame(draw);\n\n  clear(gl, {color: [0, 0, 0, 1]});\n  model.draw();\n});\n```\n\nIf all went well, a tri-color triangle should render as it did in the **Hello Triangle** example. A live version is available [here](/examples/getting-started/external-context), and the full source code is listed below for reference:\n\n```js\nimport {Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\nimport {instrumentGLContext} from '@luma.gl/gltools';\n\nconst canvas = document.createElement('canvas');\ncanvas.width = 800;\ncanvas.height = 600;\ndocument.body.appendChild(canvas);\n\nconst gl = instrumentGLContext(canvas.getContext('webgl'));\ngl.clearColor(0, 0, 0, 1);\n\nconst positionBuffer = new Buffer(gl, new Float32Array([\n  -0.5, -0.5,\n  0.5, -0.5,\n  0.0, 0.5\n]));\n\nconst colorBuffer = new Buffer(gl, new Float32Array([\n  1.0, 0.0, 0.0,\n  0.0, 1.0, 0.0,\n  0.0, 0.0, 1.0\n]));\n\nconst vs = `\n attribute vec2 position;\n attribute vec3 color;\n\n varying vec3 vColor;\n\n void main() {\n   vColor = color;\n   gl_Position = vec4(position, 0.0, 1.0);\n }\n`;\n\nconst fs = `\n varying vec3 vColor;\n\n void main() {\n   gl_FragColor = vec4(vColor, 1.0);\n }\n`;\n\nconst model = new Model(gl, {\n  vs,\n  fs,\n  attributes: {\n    position: positionBuffer,\n    color: colorBuffer\n  },\n  vertexCount: 3\n});\n\nrequestAnimationFrame(function draw() {\n  requestAnimationFrame(draw);\n\n  clear(gl, {color: [0, 0, 0, 1]});\n  model.draw();\n});\n```\n","slug":"docs/getting-started/external-context","title":"External Contexts"},{"excerpt":"Hello Instancing (Mid-level) In this tutorial, we'll work through how to do instanced drawing with luma.gl's mid-level APIs. This will…","rawMarkdownBody":"# Hello Instancing (Mid-level)\n\nIn this tutorial, we'll work through how to do instanced drawing with luma.gl's mid-level APIs. This will involve using luma.gl's WebGL wrappers to do the drawing instead of the higher-level `Model`. We'll start from the [high-level app](/docs/getting-started/hello-instancing-high) we created. First we need to install the `shadertools` module so we can compose shaders without the `Model` class:\n```bash\nnpm i @luma.gl/shadertools\n```\n\nNow we can update the imports:\n```js\nimport {AnimationLoop} from '@luma.gl/engine';\nimport {Program, VertexArray, Buffer, clear} from '@luma.gl/webgl';\nimport {assembleShaders} from '@luma.gl/shadertools';\n```\nMost of the initialization is similar, but we'll replace the creation of `Model` with its individual parts: shader composition, a vertex array, and a program. Shader composition is handled by `assembleShaders`\n```js\nconst assembled = assembleShaders(gl, {\n  vs,\n  fs,\n  modules: [colorShaderModule]\n});\n```\n\nWe can then use the assembled shaders to create a `Program`:\n```js\nconst program = new Program(gl, assembled);\n```\n\nThe attributes for the draw are managed by a `VertexArray`:\n```js\nconst vertexArray = new VertexArray(gl, {\n  program,\n  attributes: {\n    position: positionBuffer,\n    color: [colorBuffer, {divisor: 1}],\n    offset: [offsetBuffer, {divisor: 1}]\n  }\n});\n```\nThe `VertexArray` takes the `program` as an argument to infer attribute parameters.\n\nThe `vertexArray` and `program` are required for drawing, so we'll return them from `onInitialize`, and then use them in `onRender`:\n```js\nonInitialize({gl}) {\n  // Setup...\n\n  return {program, vertexArray};\n}\n\nonRender({gl, program, vertexArray}) {\n  clear(gl, {color: [0, 0, 0, 1]});\n  program.draw({\n    vertexArray,\n    vertexCount: 3,\n    instanceCount: 4\n  });\n}\n```\n\nThe scene should be identical to the one draw with the high-level API. See the live demo [here](/examples/getting-started/hello-instancing-mid).\n\nThe complete app is as follows:\n```js\nimport {AnimationLoop} from '@luma.gl/engine';\nimport {Program, VertexArray, Buffer, clear} from '@luma.gl/webgl';\nimport {assembleShaders} from '@luma.gl/shadertools';\n\nconst colorShaderModule = {\n  name: 'color',\n  vs: `\n    varying vec3 color_vColor;\n\n    void color_setColor(vec3 color) {\n      color_vColor = color;\n    }\n  `,\n  fs: `\n    varying vec3 color_vColor;\n\n    vec3 color_getColor() {\n      return color_vColor;\n    }\n  `\n};\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.2, -0.2,\n      0.2, -0.2,\n      0.0, 0.2\n    ]));\n\n    const colorBuffer = new Buffer(gl, new Float32Array([\n      1.0, 0.0, 0.0,\n      0.0, 1.0, 0.0,\n      0.0, 0.0, 1.0,\n      1.0, 1.0, 0.0\n    ]));\n\n    const offsetBuffer = new Buffer(gl, new Float32Array([\n      0.5, 0.5,\n      -0.5, 0.5,\n      0.5,  -0.5,\n      -0.5, -0.5\n    ]));\n\n    const vs = `\n      attribute vec2 position;\n      attribute vec3 color;\n      attribute vec2 offset;\n\n      void main() {\n        color_setColor(color);\n        gl_Position = vec4(position + offset, 0.0, 1.0);\n      }\n    `;\n    const fs = `\n      void main() {\n        gl_FragColor = vec4(color_getColor(), 1.0);\n      }\n    `;\n\n    const assembled = assembleShaders(gl, {\n      vs,\n      fs,\n      modules: [colorShaderModule]\n    });\n\n    const program = new Program(gl, assembled);\n\n    const vertexArray = new VertexArray(gl, {\n      program,\n      attributes: {\n        position: positionBuffer,\n        color: [colorBuffer, {divisor: 1}],\n        offset: [offsetBuffer, {divisor: 1}]\n      }\n    });\n\n    return {program, vertexArray};\n  },\n\n  onRender({gl, program, vertexArray}) {\n    clear(gl, {color: [0, 0, 0, 1]});\n    program.draw({\n      vertexArray,\n      vertexCount: 3,\n      instanceCount: 4\n    });\n  }\n});\n\nloop.start();\n\n```\n","slug":"docs/getting-started/hello-instancing-mid","title":"Hello Instancing (Mid-level)"},{"excerpt":"Hello Triangle This tutorial will demonstrate how to draw a triangle using luma.gl's high-level APIs. It is assumed you've set up your…","rawMarkdownBody":"# Hello Triangle\n\nThis tutorial will demonstrate how to draw a triangle using luma.gl's high-level APIs. It is assumed you've set up your development environment as described in [Getting Started](/docs/getting-started). Your `index.js` file should look like the following:\n\n```js\nimport {AnimationLoop} from '@luma.gl/engine';\nimport {clear} from '@luma.gl/webgl';\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    // Setup logic goes here\n  },\n\n  onRender({gl}) {\n    // Drawing logic goes here\n    clear(gl, {color: [0, 0, 0, 1]});\n  }\n});\n\nloop.start();\n```\n\nFirst, we'll need to update our imports with the classes we'll be using, `Buffer` and `Model`:\n```js\nimport {AnimationLoop, Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n```\n\nNow let's create some buffers in the `onInitialize` method to hold our attribute data:\n```js\n  onInitialize({gl}) {\n    // Setup logic goes here\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.5, -0.5,\n      0.5, -0.5,\n      0.0, 0.5\n    ]));\n\n    const colorBuffer = new Buffer(gl, new Float32Array([\n      1.0, 0.0, 0.0,\n      0.0, 1.0, 0.0,\n      0.0, 0.0, 1.0\n    ]));\n  }\n```\nNext let's add the vertex and fragment shader code we'll be using to draw:\n```js\n  onInitialize({gl}) {\n    // Setup logic goes here\n\n    // Buffers...\n\n    const vs = `\n      attribute vec2 position;\n      attribute vec3 color;\n\n      varying vec3 vColor;\n\n      void main() {\n        vColor = color;\n        gl_Position = vec4(position, 0.0, 1.0);\n      }\n    `;\n\n    const fs = `\n      varying vec3 vColor;\n\n      void main() {\n        gl_FragColor = vec4(vColor, 1.0);\n      }\n    `;\n\n  }\n```\n\nAs a final step in our initialization, we'll create a `Model` and return it from `onInitialize`:\n\n```js\n  onInitialize({gl}) {\n    // Setup logic goes here\n\n    // Buffers...\n\n    // Shaders...\n\n    const model = new Model(gl, {\n      vs,\n      fs,\n      attributes: {\n        position: positionBuffer,\n        color: colorBuffer\n      },\n      vertexCount: 3\n    });\n\n    return {model};\n  }\n```\nA `Model` can be thought of as gathering all the WebGL pieces necessary for a single draw call: programs, attributes, uniforms. Also note that we return the `Model` instance we created. This will make it available to the `onRender` method.\n\nOur `onRender` method is comparitavely much simpler:\n```js\n  onRender({gl, model}) {\n    clear(gl, {color: [0, 0, 0, 1]});\n    model.draw();\n  }\n```\nThis clears the canvas and draws the `Model`. If all went well, you should see a tri-color triangle on a black background. See the live demo [here](../../../examples/getting-started/hello-triangle).\n\nThe entire application should look like the following:\n```js\nimport {AnimationLoop, Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.5, -0.5,\n      0.5, -0.5,\n      0.0, 0.5\n    ]));\n\n    const colorBuffer = new Buffer(gl, new Float32Array([\n      1.0, 0.0, 0.0,\n      0.0, 1.0, 0.0,\n      0.0, 0.0, 1.0\n    ]));\n\n    const vs = `\n      attribute vec2 position;\n      attribute vec3 color;\n\n      varying vec3 vColor;\n\n      void main() {\n        vColor = color;\n        gl_Position = vec4(position, 0.0, 1.0);\n      }\n    `;\n\n    const fs = `\n      varying vec3 vColor;\n\n      void main() {\n        gl_FragColor = vec4(vColor, 1.0);\n      }\n    `;\n\n    const model = new Model(gl, {\n      vs,\n      fs,\n      attributes: {\n        position: positionBuffer,\n        color: colorBuffer\n      },\n      vertexCount: 3\n    });\n\n    return {model};\n  },\n\n  onRender({gl, model}) {\n    clear(gl, {color: [0, 0, 0, 1]});\n    model.draw();\n  }\n});\n\nloop.start();\n```\n\n","slug":"docs/getting-started/hello-triangle","title":"Hello Triangle"},{"excerpt":"Hello Cube In this tutorial, we'll pull together several of the techniques we've looked at in the previous tutorials (and add a few new ones…","rawMarkdownBody":"# Hello Cube\n\nIn this tutorial, we'll pull together several of the techniques we've looked at in the previous tutorials (and add a few new ones) to render a more complex scene: a rotating 3D cube. We'll use luma.gl's built-in geometry primitives to create a cube mesh and handle 3D math using [math.gl](https://math.gl/). **math.gl** can be installed by running `npm i math.gl`\n\nAs always, we'll start with our imports:\n\n```js\nimport {AnimationLoop, Model, CubeGeometry} from '@luma.gl/engine';\nimport {Texture2D, clear} from '@luma.gl/webgl';\nimport {setParameters} from '@luma.gl/gltools';\nimport {Matrix4} from 'math.gl';\n```\n\nOur shaders are somewhat more involved that we've seen before:\n```js\nconst vs = `\\\n  attribute vec3 positions;\n  attribute vec2 texCoords;\n\n  uniform mat4 uMVP;\n\n  varying vec2 vUV;\n\n  void main(void) {\n    gl_Position = uMVP * vec4(positions, 1.0);\n    vUV = texCoords;\n  }\n`;\n\nconst fs = `\\\n  precision highp float;\n\n  uniform sampler2D uTexture;\n  uniform vec3 uEyePosition;\n\n  varying vec2 vUV;\n\n  void main(void) {\n    gl_FragColor = texture2D(uTexture, vec2(vUV.x, 1.0 - vUV.y));\n  }\n`;\n```\nThe two biggest additions to the shaders we've seen before are transforming the positions to rotate our model and create the 3D perspective effect (via the `uMVP` matrix) and sampling a texture to color fragments (via the `texture2D` call).\n\n\nThe set up to render in 3D involves a few extra steps compared to the triangles we've been drawing so far:\n```js\n  onInitialize({gl}) {\n    setParameters(gl, {\n      depthTest: true,\n      depthFunc: gl.LEQUAL\n    });\n\n    const texture = new Texture2D(gl, {\n      data: 'vis-logo.png'\n    });\n\n    const eyePosition = [0, 0, 5];\n    const viewMatrix = new Matrix4().lookAt({eye: eyePosition});\n    const mvpMatrix = new Matrix4();\n\n    const model = new Model(gl, {\n      vs,\n      fs,\n      geometry: new CubeGeometry(),\n      uniforms: {\n        uTexture: texture\n      }\n    });\n\n    return {\n      model,\n      viewMatrix,\n      mvpMatrix\n    };\n  }\n```\nSome of the new techniques we're leveraging here are:\n- Using `setParameters` to set up depth testing and ensure surfaces occlude each other properly. Compared to setting these parameters directly, the `setParameters` function has the advantage of tracking state and preventing redundant WebGL calls.\n- Creating a texture using the `Texture2D` class. For our purposes, this is as simple as passing a URL to the image location (the image used in this tutorial is available [here](https://github.com/uber/luma.gl/tree/8.0-release/examples/api/cubemap/vis-logo.png), but any JPEG or PNG image will do).\n- Creating view and MVP matrices using **math.gl**'s `Matrix4` class to store the matrices we'll pass to our shaders to perform the animation and perspective projection.\n- Generating attribute data using the `CubeGeometry` class and passing it to our `Model` using the `geometry` property. The geometry will automatically feed vertex position data into the `positions` attribute and texture coordinates (or UV coordinates) into the `texCoords` attribute.\n\n\nOur `onRender` is similar to what we've seen before with the extra step of setting up the transform matrix and passing it as a uniform to the `Model`:\n```js\n  onRender({gl, aspect, tick, model, mvpMatrix, viewMatrix}) {\n    mvpMatrix.perspective({fov: Math.PI / 3, aspect})\n      .multiplyRight(viewMatrix)\n      .rotateX(tick * 0.01)\n      .rotateY(tick * 0.013);\n\n    clear(gl, {color: [0, 0, 0, 1]});\n\n    model.setUniforms({uMVP: mvpMatrix})\n      .draw();\n  }\n```\nWe use `Matrix4`'s matrix operations to create our final transformation matrix, taking advantage of a few additional parameters that are passed to the `onRender` method:\n- `aspect` is the aspect ratio of the canvas and is used to set up the perspective projection.\n- `tick` is simply a counter that increments each frame. We use it to drive the rotation animation.\n\nIf all went well, you should see a rotating cube with the Uber Visualization logo painted on each side. The live demo is available [here](/examples/getting-started/hello-cube), and the full source code is listed below for reference:\n```js\nimport {AnimationLoop, Model, CubeGeometry} from '@luma.gl/engine';\nimport {Texture2D, clear} from '@luma.gl/webgl';\nimport {setParameters} from '@luma.gl/gltools';\nimport {Matrix4} from 'math.gl';\n\nconst vs = `\\\n  attribute vec3 positions;\n  attribute vec2 texCoords;\n\n  uniform mat4 uMVP;\n\n  varying vec2 vUV;\n\n  void main(void) {\n    gl_Position = uMVP * vec4(positions, 1.0);\n    vUV = texCoords;\n  }\n`;\n\nconst fs = `\\\n  precision highp float;\n\n  uniform sampler2D uTexture;\n  uniform vec3 uEyePosition;\n\n  varying vec2 vUV;\n\n  void main(void) {\n    gl_FragColor = texture2D(uTexture, vec2(vUV.x, 1.0 - vUV.y));\n  }\n`;\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    setParameters(gl, {\n      depthTest: true,\n      depthFunc: gl.LEQUAL\n    });\n\n    const texture = new Texture2D(gl, {\n      data: 'vis-logo.png'\n    });\n\n    const eyePosition = [0, 0, 5];\n    const viewMatrix = new Matrix4().lookAt({eye: eyePosition});\n    const mvpMatrix = new Matrix4();\n\n    const model = new Model(gl, {\n      vs,\n      fs,\n      geometry: new CubeGeometry(),\n      uniforms: {\n        uTexture: texture\n      }\n    });\n\n    return {\n      model,\n      viewMatrix,\n      mvpMatrix\n    };\n  },\n\n  onRender({gl, aspect, tick, model, mvpMatrix, viewMatrix}) {\n    mvpMatrix.perspective({fov: Math.PI / 3, aspect})\n      .multiplyRight(viewMatrix)\n      .rotateX(tick * 0.01)\n      .rotateY(tick * 0.013);\n\n    clear(gl, {color: [0, 0, 0, 1]});\n\n    model.setUniforms({uMVP: mvpMatrix})\n      .draw();\n  }\n});\n\nloop.start();\n```\n\n","slug":"docs/getting-started/hello-cube","title":"Hello Cube"},{"excerpt":"Hello Instancing (Low-level) In this tutorial, we'll work through how to do instanced drawing with luma.gl's low-level APIs. This…","rawMarkdownBody":"# Hello Instancing (Low-level)\n\nIn this tutorial, we'll work through how to do instanced drawing with luma.gl's low-level APIs. This essentially means writing our app using the WebGL API directly, using only a few low-level helper functions to manage shaders and polyfilling. We'll need to install the `gltools` module so we can get a polyfilled context without the `AnimationLoop`:\n```bash\nnpm i @luma.gl/gltools\n```\n\nNow we can update the imports:\n```js\nimport {polyfillContext} from '@luma.gl/gltools';\n```\n\nSince we aren't using the `AnimationLoop`, we'll create our canvas and get a WebGL context directly:\n```js\nconst canvas = document.createElement('canvas');\ncanvas.width = 800;\ncanvas.height = 600;\ndocument.body.appendChild(canvas);\n\nconst gl = polyfillContext(canvas.getContext(\"webgl\"));\ngl.clearColor(0, 0, 0, 1);\n```\nNote that we're creating a WebGL 1 context here. This will allow us to demonstrate the polyfilling. Creating our program is *a little* more verbose than before:\n```js\nconst vs = `\n  attribute vec2 position;\n  attribute vec3 color;\n  attribute vec2 offset;\n\n  varying vec3 vColor;\n\n  void main() {\n    vColor = color;\n    gl_Position = vec4(position + offset, 0.0, 1.0);\n  }\n`;\nconst fs = `\n  precision highp float;\n\n  varying vec3 vColor;\n\n  void main() {\n    gl_FragColor = vec4(vColor, 1.0);\n  }\n`;\n\nconst vShader = gl.createShader(gl.VERTEX_SHADER);\ngl.shaderSource(vShader, vs);\ngl.compileShader(vShader);\n\nconst fShader = gl.createShader(gl.FRAGMENT_SHADER);\ngl.shaderSource(fShader, fs);\ngl.compileShader(fShader);\n\nconst program = gl.createProgram();\ngl.attachShader(program, vShader);\ngl.attachShader(program, fShader);\ngl.linkProgram(program);\n```\n\nNext we'll create our vertex array:\n```js\nconst vertexArray = gl.createVertexArray();\ngl.bindVertexArray(vertexArray);\n```\nWait a minute... we're calling `createVertexArray` and `bindVertexArray` on a WebGL 1 context. But those functions aren't part of the WebGL 1 API! How is this working? The function `polyfillContext` that we used when creating our context will use WebGL extensions that are available to implement WebGL 2 functions on a WebGL 1 context. So we can just program against the WebGL 2 API!\n\nWell... mostly... Polyfilling will only work if the necessary extensions are available. And some WebGL 2 features like occlusion queries and transform feedback simply aren't supported by polyfills.\n\nMoving on... setting up the vertex array, concise as always in WebGL:\n```js\nconst vertexArray = gl.createVertexArray();\ngl.bindVertexArray(vertexArray);\n\nconst positionBuffer = gl.createBuffer();\ngl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);\ngl.bufferData(gl.ARRAY_BUFFER, new Float32Array([\n  -0.2, -0.2,\n  0.2, -0.2,\n  0.0, 0.2\n]), gl.STATIC_DRAW);\n\nconst positionLocation = gl.getAttribLocation(program, \"position\");\ngl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);\ngl.enableVertexAttribArray(positionLocation);\n\nconst colorBuffer = gl.createBuffer();\ngl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);\ngl.bufferData(gl.ARRAY_BUFFER, new Float32Array([\n  1.0, 0.0, 0.0,\n  0.0, 1.0, 0.0,\n  0.0, 0.0, 1.0,\n  1.0, 1.0, 0.0\n]), gl.STATIC_DRAW);\n\nconst colorLocation = gl.getAttribLocation(program, \"color\");\ngl.vertexAttribPointer(colorLocation, 3, gl.FLOAT, false, 0, 0);\ngl.vertexAttribDivisor(colorLocation, 1);\ngl.enableVertexAttribArray(colorLocation);\n\nconst offsetBuffer = gl.createBuffer();\ngl.bindBuffer(gl.ARRAY_BUFFER, offsetBuffer);\ngl.bufferData(gl.ARRAY_BUFFER, new Float32Array([\n  0.5, 0.5,\n  -0.5, 0.5,\n  0.5,  -0.5,\n  -0.5, -0.5\n]), gl.STATIC_DRAW);\n\nconst offsetLocation = gl.getAttribLocation(program, \"offset\");\ngl.vertexAttribPointer(offsetLocation, 2, gl.FLOAT, false, 0, 0);\ngl.vertexAttribDivisor(offsetLocation, 1);\ngl.enableVertexAttribArray(offsetLocation);\n\ngl.bindVertexArray(null);\n```\n\nAnd then we set up our draw loop:\n```js\nrequestAnimationFrame(function draw() {\n  requestAnimationFrame(draw);\n\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.bindVertexArray(vertexArray);\n  gl.useProgram(program);\n  gl.drawArraysInstanced(gl.TRIANGLES, 0, 3, 4);\n});\n```\n\nIf all went well, you should see the same scene as drawn by the high- and mid-level apps: four triangles of different colors. See the live demo [here](/examples/getting-started/hello-instancing-low).\n\nWe simply used luma.gl's `shadertools` and `gltools` to provide polyfilled instanced drawing and compose our shaders from modules. The full code for the app is available below:\n```js\nimport {polyfillContext} from '@luma.gl/gltools';\n\nconst canvas = document.createElement('canvas');\ncanvas.width = 800;\ncanvas.height = 600;\ndocument.body.appendChild(canvas);\nconst gl = polyfillContext(canvas.getContext(\"webgl\"));\ngl.clearColor(0, 0, 0, 1);\n\nconst vs = `\n  attribute vec2 position;\n  attribute vec3 color;\n  attribute vec2 offset;\n\n  varying vec3 vColor;\n\n  void main() {\n    vColor = color;\n    gl_Position = vec4(position + offset, 0.0, 1.0);\n  }\n`;\nconst fs = `\n  precision highp float;\n\n  varying vec3 vColor;\n\n  void main() {\n    gl_FragColor = vec4(vColor, 1.0);\n  }\n`;\n\nconst vShader = gl.createShader(gl.VERTEX_SHADER);\ngl.shaderSource(vShader, vs);\ngl.compileShader(vShader);\n\nconst fShader = gl.createShader(gl.FRAGMENT_SHADER);\ngl.shaderSource(fShader, fs);\ngl.compileShader(fShader);\n\nconst program = gl.createProgram();\ngl.attachShader(program, vShader);\ngl.attachShader(program, fShader);\ngl.linkProgram(program);\n\n\nconst vertexArray = gl.createVertexArray();\ngl.bindVertexArray(vertexArray);\n\nconst positionBuffer = gl.createBuffer();\ngl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);\ngl.bufferData(gl.ARRAY_BUFFER, new Float32Array([\n  -0.2, -0.2,\n  0.2, -0.2,\n  0.0, 0.2\n]), gl.STATIC_DRAW);\n\nconst positionLocation = gl.getAttribLocation(program, \"position\");\ngl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);\ngl.enableVertexAttribArray(positionLocation);\n\nconst colorBuffer = gl.createBuffer();\ngl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);\ngl.bufferData(gl.ARRAY_BUFFER, new Float32Array([\n  1.0, 0.0, 0.0,\n  0.0, 1.0, 0.0,\n  0.0, 0.0, 1.0,\n  1.0, 1.0, 0.0\n]), gl.STATIC_DRAW);\n\nconst colorLocation = gl.getAttribLocation(program, \"color\");\ngl.vertexAttribPointer(colorLocation, 3, gl.FLOAT, false, 0, 0);\ngl.vertexAttribDivisor(colorLocation, 1);\ngl.enableVertexAttribArray(colorLocation);\n\nconst offsetBuffer = gl.createBuffer();\ngl.bindBuffer(gl.ARRAY_BUFFER, offsetBuffer);\ngl.bufferData(gl.ARRAY_BUFFER, new Float32Array([\n  0.5, 0.5,\n  -0.5, 0.5,\n  0.5,  -0.5,\n  -0.5, -0.5\n]), gl.STATIC_DRAW);\n\nconst offsetLocation = gl.getAttribLocation(program, \"offset\");\ngl.vertexAttribPointer(offsetLocation, 2, gl.FLOAT, false, 0, 0);\ngl.vertexAttribDivisor(offsetLocation, 1);\ngl.enableVertexAttribArray(offsetLocation);\n\ngl.bindVertexArray(null);\n\nrequestAnimationFrame(function draw() {\n  requestAnimationFrame(draw);\n\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.bindVertexArray(vertexArray);\n  gl.useProgram(program);\n  gl.drawArraysInstanced(gl.TRIANGLES, 0, 3, 4);\n});\n```\n","slug":"docs/getting-started/hello-instancing-low","title":"Hello Instancing (Low-level)"},{"excerpt":"High, Medium, Low luma.gl is designed to provide support for development at whatever level the user requires. This can roughly be split into…","rawMarkdownBody":"# High, Medium, Low\n\nluma.gl is designed to provide support for development at whatever level the user requires. This can roughly be split into three levels of abstraction:\n- Low-level: Program directly with the WebGL API with some lightweight tools for managing the gl context, shaders and debugging. This will primarily involve using the `shadertools`, `gltools` and `debug` modules.\n- Mid-level: Program with convenient wrapper classes around the WebGL API. This involves using the `webgl` module.\n- High-level: Program using 3D engine constructs like models or resource managers. This primarily involves using the `engine` and `webgl` modules.\n\nTo demonstrate how luma.gl functions at these three levels, we'll implement the same scene, 4 instanced colored triangles, three times, once at each level of abstraction.\n","slug":"docs/getting-started/high-medium-low","title":"High, Medium, Low"},{"excerpt":"Shader Hooks In the previous tutorial, we used shader modules to insert re-usable functions into the shaders that use them. In this tutorial…","rawMarkdownBody":"# Shader Hooks\n\nIn the [previous tutorial](/docs/getting-started/shader-hooks), we used shader modules to insert re-usable functions into the shaders that use them. In this tutorial, we'll focus on another feature of shader modules: the ability to modify the behavior of shaders that use them via **shader hooks**. A shader hook is simply a function inserted into a vertex or fragment shader. By default, these functions will be no-ops, but they define entry points into which shader modules can inject code. For high-level API usage, shader hooks are exposed via [ProgramManagers](/docs/api-reference/engine/program-manager) (we'll look at low-level shader hooks later):\n\n```js\nconst pm = new ProgramManager(gl);\npm.addShaderHook('vs:MY_SHADER_HOOK(inout vec4 position)');\n\nconst vs = `\n  attribute vec4 pos;\n\n  void main() {\n    gl_Position = pos;\n    MY_SHADER_HOOK(gl_Position);\n  }\n`;\n```\n\n\nShader modules can then inject code into the hook via their `inject` property:\n\n```js\nconst myModule = {\n  name: 'myModule',\n  inject: 'position.x -= 0.1;'\n}\n```\n\nWe'll use these features to create a modified version of the previous tutorial, using shader hooks and modules to modify the behavior of a single set of vertex and fragment shaders.\n\n\nWe'll start by setting up our imports and defining our base vertex and fragment shaders:\n```js\nimport {AnimationLoop, Model, ProgramManager} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n\nconst vs = `\n  attribute vec2 position;\n\n  void main() {\n    gl_Position = vec4(position, 0.0, 1.0);\n    OFFSET_POSITION(gl_Position);\n  }\n`;\n\nconst fs = `\n  uniform vec3 color;\n\n  void main() {\n    gl_FragColor = vec4(color, 1.0);\n  }\n`;\n```\n\nHere we have a shader hook function, `OFFSET_POSITION`, called in our vertex shader. Next we'll create two shader modules that insert code into the shader hook:\n```js\nconst offsetLeftModule = {\n  name: 'offsetLeft',\n  inject: {\n    'vs:OFFSET_POSITION': 'position.x -= 0.5;'\n  }\n};\n\nconst offsetRightModule = {\n  name: 'offsetRight',\n  inject: {\n    'vs:OFFSET_POSITION': 'position.x += 0.5;'\n  }\n};\n```\n\nThese shader modules inject code into the shader hook that will modify the x-coordinate of the position passed in. The `inject` property maps shader hook names to the code to be injected into them. The `vs` prefix indicates that this is a vertex shader hook.\n\nThe `onInitialize` method of our `AnimationLoop` will be somewhat different from the previous example. To create a shader hook, we need access to a `ProgramManager` instance:\n\n```js\n  onInitialize({gl}) {\n    const programManager = new ProgramManager(gl);\n    programManager.addShaderHook('vs:OFFSET_POSITION(inout vec4 position)');\n\n    // ...\n  }\n```\n\nThe shader hook definition is the function signature with a prefix indicating whether it is intended for the vertex shader (`vs`) or fragment shader (`fs`). Shader hooks are always `void` funtions so they must return values to the caller via `out` or `inout` argurments. The rest of `onInitialize` is similar to what we've seen before with the exception of using the new shader modules and the `ProgramManager` to create our `Model`s:\n\n```js\n  onInitialize({gl}) {\n    const programManager = new ProgramManager(gl);\n    programManager.addShaderHook('vs:OFFSET_POSITION(inout vec4 position)');\n\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.3, -0.5,\n      0.3, -0.5,\n      0.0, 0.5\n    ]));\n\n    const model1 = new Model(gl, {\n      vs,\n      fs,\n      programManager,\n      modules: [offsetLeftModule],\n      attributes: {\n        position: positionBuffer\n      },\n      uniforms: {\n        color: [1.0, 0.0, 0.0]\n      },\n      vertexCount: 3\n    });\n\n    const model2 = new Model(gl, {\n      vs,\n      fs,\n      programManager,\n      modules: [offsetRightModule],\n      attributes: {\n        position: positionBuffer\n      },\n      uniforms: {\n        color: [0.0, 0.0, 1.0]\n      },\n      vertexCount: 3\n    });\n\n    return {model1, model2};\n  }\n```\n\nThe `onRender` method is the same as before. If all went well, a blue trangle and a red triangle should be drawn side-by-side on the canvas. The code injected by the modules into the shader hook is what offsets each triangle to the left or right. See the live demo [here](/examples/getting-started/shader-hooks).\n\nShader hooks allowed us to define our vertex and fragment shaders once and modify their behavior based on the shader module included.\n\nThe entire application should look like the following:\n```js\nimport {AnimationLoop, Model, ProgramManager} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n\nconst vs = `\n  attribute vec2 position;\n\n  void main() {\n    gl_Position = vec4(position, 0.0, 1.0);\n    OFFSET_POSITION(gl_Position);\n  }\n`;\n\nconst fs = `\n  uniform vec3 color;\n\n  void main() {\n    gl_FragColor = vec4(color, 1.0);\n  }\n`;\n\nconst offsetLeftModule = {\n  name: 'offsetLeft',\n  inject: {\n    'vs:OFFSET_POSITION': 'position.x -= 0.5;'\n  }\n};\n\nconst offsetRightModule = {\n  name: 'offsetRight',\n  inject: {\n    'vs:OFFSET_POSITION': 'position.x += 0.5;'\n  }\n};\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    const programManager = new ProgramManager(gl);\n    programManager.addShaderHook('vs:OFFSET_POSITION(inout vec4 position)');\n\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.3, -0.5,\n      0.3, -0.5,\n      0.0, 0.5\n    ]));\n\n    const model1 = new Model(gl, {\n      vs,\n      fs,\n      programManager,\n      modules: [offsetLeftModule],\n      attributes: {\n        position: positionBuffer\n      },\n      uniforms: {\n        color: [1.0, 0.0, 0.0]\n      },\n      vertexCount: 3\n    });\n\n    const model2 = new Model(gl, {\n      vs,\n      fs,\n      programManager,\n      modules: [offsetRightModule],\n      attributes: {\n        position: positionBuffer\n      },\n      uniforms: {\n        color: [0.0, 0.0, 1.0]\n      },\n      vertexCount: 3\n    });\n\n    return {model1, model2};\n  },\n\n  onRender({gl, model}) {\n    clear(gl, {color: [0, 0, 0, 1]});\n    model1.draw();\n    model2.draw();\n  }\n});\n\nloop.start();\n```\n\n","slug":"docs/getting-started/shader-hooks","title":"Shader Hooks"},{"excerpt":"Shader Modules (Low-level) So far, we've been using shader modules and hooks via the  class, but these tools are also available own their…","rawMarkdownBody":"# Shader Modules (Low-level)\n\nSo far, we've been using shader modules and hooks via the `Model` class, but these tools are also available own their via the the [assembleShaders](/docs/api-reference/shadertools/assemble-shaders) function in **@luma.gl/shadertools**. `assembleShaders` operates on the shader source as text, so it can be used in any framework or even with the WebGL API itself.\n\n`assembleShaders` takes the base vertex and fragment source, as well as any modules and hookFunctions we want to include, and returns a JavaScript object with the the final shader sources in the `vs` and `fs` properties:\n\n```js\nconst assembledShaders = assembleShaders(gl, {\n  vs,\n  fs,\n  modules: [offsetLeftModule],\n  hookFunctions: ['vs:OFFSET_POSITION(inout vec4 position)']\n});\n```\n\nTo demonstrate how this works, we'll re-implement the [shader hook tutorial](/docs/getting-started/shader-hooks) using WebGL calls directly. To start, we'll modify our imports:\n\n```js\nimport {assembleShaders} from '@luma.gl/shadertools';\n```\n\n\nOur shaders and modules will be the same as before:\n\n```js\nconst vs = `\n  attribute vec2 position;\n\n  void main() {\n    gl_Position = vec4(position, 0.0, 1.0);\n    OFFSET_POSITION(gl_Position);\n  }\n`;\n\nconst fs = `\n  uniform vec3 color;\n\n  void main() {\n    gl_FragColor = vec4(color, 1.0);\n  }\n`;\n\nconst offsetLeftModule = {\n  name: 'offsetLeft',\n  inject: {\n    'vs:OFFSET_POSITION': 'position.x -= 0.5;'\n  }\n};\n\nconst offsetRightModule = {\n  name: 'offsetRight',\n  inject: {\n    'vs:OFFSET_POSITION': 'position.x += 0.5;'\n  }\n};\n```\n\nWe then create two programs by first assembling our base shaders with the desired modules and shader hooks, and then using them to create WebGL program objects:\n```js\n//////////////\n// Program 1\n//////////////\n\n// Call assembleShaders to combine base source with modules.\nconst assembledShaders1 = assembleShaders(gl, {\n  vs,\n  fs,\n  modules: [offsetLeftModule],\n  hookFunctions: ['vs:OFFSET_POSITION(inout vec4 position)']\n});\n\n// Use assembled results to create our program.\nconst vShader1 = gl.createShader(gl.VERTEX_SHADER);\ngl.shaderSource(vShader1, assembledShaders1.vs);\ngl.compileShader(vShader1);\n\nconst fShader1 = gl.createShader(gl.FRAGMENT_SHADER);\ngl.shaderSource(fShader1, assembledShaders1.fs);\ngl.compileShader(fShader1);\n\nconst program1 = gl.createProgram();\ngl.attachShader(program1, vShader1);\ngl.attachShader(program1, fShader1);\ngl.linkProgram(program1);\ngl.useProgram(program1);\nconst colorLocation1 = gl.getUniformLocation(program1, 'color');\ngl.uniform3fv(colorLocation1, new Float32Array([1.0, 0.0, 0.0]));\n\n//////////////\n// Program 2\n//////////////\n\n// Call assembleShaders to combine base source with modules.\nconst assembledShaders2 = assembleShaders(gl, {\n  vs,\n  fs,\n  modules: [offsetRightModule],\n  hookFunctions: ['vs:OFFSET_POSITION(inout vec4 position)']\n});\n\n// Use assembled results to create our program.\nconst vShader2 = gl.createShader(gl.VERTEX_SHADER);\ngl.shaderSource(vShader2, assembledShaders2.vs);\ngl.compileShader(vShader2);\n\nconst fShader2 = gl.createShader(gl.FRAGMENT_SHADER);\ngl.shaderSource(fShader2, assembledShaders2.fs);\ngl.compileShader(fShader2);\n\nconst program2 = gl.createProgram();\ngl.attachShader(program2, vShader2);\ngl.attachShader(program2, fShader2);\ngl.linkProgram(program2);\ngl.useProgram(program2);\nconst colorLocation2 = gl.getUniformLocation(program2, 'color');\ngl.uniform3fv(colorLocation2, new Float32Array([0.0, 0.0, 1.0]));\n```\n\nWith our final programs created, we can draw as we would in any other WebGL application. The complete port of the shader hook demo is listed below and the live version is available [here](/examples/getting-started/shader-modules-low).\n\n\n```js\nimport {assembleShaders} from '@luma.gl/shadertools';\n\nconst vs = `\n  attribute vec2 position;\n  void main() {\n    gl_Position = vec4(position, 0.0, 1.0);\n    OFFSET_POSITION(gl_Position);\n  }\n`;\n\nconst fs = `\n  uniform vec3 color;\n  void main() {\n    gl_FragColor = vec4(color, 1.0);\n  }\n`;\n\nconst offsetLeftModule = {\n  name: 'offsetLeft',\n  inject: {\n    'vs:OFFSET_POSITION': 'position.x -= 0.5;'\n  }\n};\n\nconst offsetRightModule = {\n  name: 'offsetRight',\n  inject: {\n    'vs:OFFSET_POSITION': 'position.x += 0.5;'\n  }\n};\n\nconst canvas = document.createElement('canvas');\ncanvas.width = 800;\ncanvas.height = 600;\ndocument.body.appendChild(canvas);\n\nconst gl = canvas.getContext('webgl');\ngl.clearColor(0, 0, 0, 1);\n\n// Program 1\n\nconst assembled1 = assembleShaders(gl, {\n  vs,\n  fs,\n  modules: [offsetLeftModule],\n  hookFunctions: ['vs:OFFSET_POSITION(inout vec4 position)']\n});\n\nconst vShader1 = gl.createShader(gl.VERTEX_SHADER);\ngl.shaderSource(vShader1, assembled1.vs);\ngl.compileShader(vShader1);\n\nconst fShader1 = gl.createShader(gl.FRAGMENT_SHADER);\ngl.shaderSource(fShader1, assembled1.fs);\ngl.compileShader(fShader1);\n\nconst program1 = gl.createProgram();\ngl.attachShader(program1, vShader1);\ngl.attachShader(program1, fShader1);\ngl.linkProgram(program1);\ngl.useProgram(program1);\nconst colorLocation1 = gl.getUniformLocation(program1, 'color');\ngl.uniform3fv(colorLocation1, new Float32Array([1.0, 0.0, 0.0]));\n\n// Program 2\n\nconst assembled2 = assembleShaders(gl, {\n  vs,\n  fs,\n  modules: [offsetRightModule],\n  hookFunctions: ['vs:OFFSET_POSITION(inout vec4 position)']\n});\n\nconst vShader2 = gl.createShader(gl.VERTEX_SHADER);\ngl.shaderSource(vShader2, assembled2.vs);\ngl.compileShader(vShader2);\n\nconst fShader2 = gl.createShader(gl.FRAGMENT_SHADER);\ngl.shaderSource(fShader2, assembled2.fs);\ngl.compileShader(fShader2);\n\nconst program2 = gl.createProgram();\ngl.attachShader(program2, vShader2);\ngl.attachShader(program2, fShader2);\ngl.linkProgram(program2);\ngl.useProgram(program2);\nconst colorLocation2 = gl.getUniformLocation(program2, 'color');\ngl.uniform3fv(colorLocation2, new Float32Array([0.0, 0.0, 1.0]));\n\nconst positionBuffer = gl.createBuffer();\ngl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);\ngl.bufferData(gl.ARRAY_BUFFER, new Float32Array([\n  -0.3, -0.5,\n  0.3, -0.5,\n  0.0, 0.5\n]), gl.STATIC_DRAW);\n\nconst positionLocation1 = gl.getAttribLocation(program1, 'position');\ngl.vertexAttribPointer(positionLocation1, 2, gl.FLOAT, false, 0, 0);\ngl.enableVertexAttribArray(positionLocation1);\n\nconst positionLocation2 = gl.getAttribLocation(program2, 'position');\ngl.vertexAttribPointer(positionLocation2, 2, gl.FLOAT, false, 0, 0);\ngl.enableVertexAttribArray(positionLocation2);\n\nrequestAnimationFrame(function draw() {\n  requestAnimationFrame(draw);\n\n  gl.clear(gl.COLOR_BUFFER_BIT);\n  gl.useProgram(program1);\n  gl.drawArrays(gl.TRIANGLES, 0, 3);\n  gl.useProgram(program2);\n  gl.drawArrays(gl.TRIANGLES, 0, 3);\n});\n```\n","slug":"docs/getting-started/shader-modules-low","title":"Shader Modules (Low-level)"},{"excerpt":"Lighting This tutorial will expand on the previous one, but we'll add some lighting to enhance the feeling of 3D in the scene. To accomplish…","rawMarkdownBody":"# Lighting\n\nThis tutorial will expand on the [previous one](/examples/getting-started/hello-cube), but we'll add some lighting to enhance the feeling of 3D in the scene. To accomplish this, we'll use one of **luma.gl**'s built-in shader modules for the first time.\n\nTo start, we'll add the `phongLighting` module from **@luma.gl/shadertools** to our imports:\n```js\nimport {AnimationLoop, Model, CubeGeometry} from '@luma.gl/engine';\nimport {Texture2D, clear} from '@luma.gl/webgl';\nimport {setParameters} from '@luma.gl/gltools';\nimport {phongLighting} from '@luma.gl/shadertools';\nimport {Matrix4} from 'math.gl';\n```\nThe `phongLighting` shader module adds functions to our fragment shader to facilitate lighting calculations.\n\nWe'll modify our shaders to perform our lighting calculations in the following ways:\n- We'll input the surface `normals` as an attribute.\n- We'll pass the world positions and normals to the fragment shader in `varying`s\n- We'll call `lighting_getLightColor`, which will be added to our fragment shader by the `phongLighting` module, to calculate the final fragment color.\n\n```js\nconst vs = `\\\n  attribute vec3 positions;\n  attribute vec3 normals;\n  attribute vec2 texCoords;\n\n  uniform mat4 uModel;\n  uniform mat4 uMVP;\n\n  varying vec3 vPosition;\n  varying vec3 vNormal;\n  varying vec2 vUV;\n\n  void main(void) {\n    vPosition = (uModel * vec4(positions, 1.0)).xyz;\n    vNormal = mat3(uModel) * normals;\n    vUV = texCoords;\n    gl_Position = uMVP * vec4(positions, 1.0);\n  }\n`;\n\nconst fs = `\\\n  precision highp float;\n\n  uniform sampler2D uTexture;\n  uniform vec3 uEyePosition;\n\n  varying vec3 vPosition;\n  varying vec3 vNormal;\n  varying vec2 vUV;\n\n  void main(void) {\n    vec3 materialColor = texture2D(uTexture, vec2(vUV.x, 1.0 - vUV.y)).rgb;\n    vec3 surfaceColor = lighting_getLightColor(materialColor, uEyePosition, vPosition, normalize(vNormal));\n\n    gl_FragColor = vec4(surfaceColor, 1.0);\n  }\n`;\n```\n\nOur `onInitialize` method needs a few significant updates:\n```js\n  onInitialize({gl}) {\n    setParameters(gl, {\n      depthTest: true,\n      depthFunc: gl.LEQUAL\n    });\n\n    const texture = new Texture2D(gl, {\n      data: 'vis-logo.png'\n    });\n\n    const eyePosition = [0, 0, 5];\n    const modelMatrix = new Matrix4();\n    const viewMatrix = new Matrix4().lookAt({eye: eyePosition});\n    const mvpMatrix = new Matrix4();\n\n    const model = new Model(gl, {\n      vs,\n      fs,\n      geometry: new CubeGeometry(),\n      uniforms: {\n        uTexture: texture,\n        uEyePosition: eyePosition\n      },\n      modules: [phongLighting],\n      moduleSettings: {\n        material: {\n          specularColor: [255, 255, 255]\n        },\n        lights: [\n          {\n            type: 'ambient',\n            color: [255, 255, 255]\n          },\n          {\n            type: 'point',\n            color: [255, 255, 255],\n            position: [1, 2, 1]\n          }\n        ]\n      }\n    });\n\n    return {\n      model,\n      modelMatrix,\n      viewMatrix,\n      mvpMatrix\n    };\n  }\n```\nWe're splitting the model matrix out on its own so we can use it in our shaders to transform the positions and normals for the lighting calculations. The biggest change, however, is the `moduleSettings` parameter we're passing to our `Model` constructor. `moduleSettings` are passed on to shader modules to help them set up uniforms. In this case, we're passing some material and light properties that `phongLighting` uses to perform its lighting calculations in `lighting_getLightColor`.\n\n\nOur `onRender` doesn't change much except to set up the model matrix separately from the MVP matrix and pass it as a uniform:\n```js\n  onRender({gl, aspect, tick, model, mvpMatrix, viewMatrix}) {\n    modelMatrix\n      .identity()\n      .rotateX(tick * 0.01)\n      .rotateY(tick * 0.013);\n\n    mvpMatrix\n      .perspective({fov: Math.PI / 3, aspect})\n      .multiplyRight(viewMatrix)\n      .multiplyRight(modelMatrix);\n\n    clear(gl, {color: [0, 0, 0, 1], depth: true});\n\n    model.setUniforms({uMVP: mvpMatrix, uModel: modelMatrix}).draw();\n  }\n```\n\nIf all went well, you should see a scene almost identical to the one from the [previous tutorial](/examples/getting-started/hello-cube) but with some white light reflecting off the cube. The live demo is available [here](/examples/getting-started/lighting), and the full source code is listed below for reference:\n```js\nimport {AnimationLoop, Model, CubeGeometry} from '@luma.gl/engine';\nimport {Texture2D, clear} from '@luma.gl/webgl';\nimport {setParameters} from '@luma.gl/gltools';\nimport {phongLighting} from '@luma.gl/shadertools';\nimport {Matrix4} from 'math.gl';\n\nconst vs = `\\\n  attribute vec3 positions;\n  attribute vec3 normals;\n  attribute vec2 texCoords;\n\n  uniform mat4 uModel;\n  uniform mat4 uMVP;\n\n  varying vec3 vPosition;\n  varying vec3 vNormal;\n  varying vec2 vUV;\n\n  void main(void) {\n    vPosition = (uModel * vec4(positions, 1.0)).xyz;\n    vNormal = mat3(uModel) * normals;\n    vUV = texCoords;\n    gl_Position = uMVP * vec4(positions, 1.0);\n  }\n`;\n\nconst fs = `\\\n  precision highp float;\n\n  uniform sampler2D uTexture;\n  uniform vec3 uEyePosition;\n\n  varying vec3 vPosition;\n  varying vec3 vNormal;\n  varying vec2 vUV;\n\n  void main(void) {\n    vec3 materialColor = texture2D(uTexture, vec2(vUV.x, 1.0 - vUV.y)).rgb;\n    vec3 surfaceColor = lighting_getLightColor(materialColor, uEyePosition, vPosition, normalize(vNormal));\n\n    gl_FragColor = vec4(surfaceColor, 1.0);\n  }\n`;\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    setParameters(gl, {\n      depthTest: true,\n      depthFunc: gl.LEQUAL\n    });\n\n    const texture = new Texture2D(gl, {\n      data: 'vis-logo.png'\n    });\n\n    const eyePosition = [0, 0, 5];\n    const modelMatrix = new Matrix4();\n    const viewMatrix = new Matrix4().lookAt({eye: eyePosition});\n    const mvpMatrix = new Matrix4();\n\n    const model = new Model(gl, {\n      vs,\n      fs,\n      geometry: new CubeGeometry(),\n      uniforms: {\n        uTexture: texture,\n        uEyePosition: eyePosition\n      },\n      modules: [phongLighting],\n      moduleSettings: {\n        material: {\n          specularColor: [255, 255, 255]\n        },\n        lights: [\n          {\n            type: 'ambient',\n            color: [255, 255, 255]\n          },\n          {\n            type: 'point',\n            color: [255, 255, 255],\n            position: [1, 2, 1]\n          }\n        ]\n      }\n    });\n\n    return {\n      model,\n      modelMatrix,\n      viewMatrix,\n      mvpMatrix\n    };\n  },\n\n  onRender({gl, aspect, tick, model, mvpMatrix, viewMatrix}) {\n    modelMatrix\n      .identity()\n      .rotateX(tick * 0.01)\n      .rotateY(tick * 0.013);\n\n    mvpMatrix\n      .perspective({fov: Math.PI / 3, aspect})\n      .multiplyRight(viewMatrix)\n      .multiplyRight(modelMatrix);\n\n    clear(gl, {color: [0, 0, 0, 1], depth: true});\n\n    model.setUniforms({uMVP: mvpMatrix, uModel: modelMatrix}).draw();\n  }\n});\n\nloop.start();\n```\n\n","slug":"docs/getting-started/lighting","title":"Lighting"},{"excerpt":"Transform Feedback In this tutorial, we'll learn how to use transform feedback using luma.gl's high-level API. Transform feedback allows us…","rawMarkdownBody":"# Transform Feedback\n\nIn this tutorial, we'll learn how to use [transform feedback](https://www.khronos.org/opengl/wiki/Transform_Feedback) using luma.gl's high-level API. Transform feedback allows us to capture vertex shader results from one pass and use them in subsequent passes. It is a powerful tool that can be used to set up massively parrallelized animations or data transformations. Note that transform feedback can only be used with WebGL 2.\n\nIn luma.gl, transform feedback is primarily exposed via the [Transform](/docs/api-reference/engine/transform) class, which simplifies usage by managing input and output buffers. We'll demonstrate its usage by setting up a simple animation that runs completely on the GPU.\n\nTo start, we'll modify our imports to include `Transform` from **@luma.gl/engine**:\n\n```js\nimport {AnimationLoop, Transform, Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n```\n\nThen we'll define our shaders, which we'll write in GLSL ES 3.0 since we're using WebGL 2:\n```js\nconst transformVs = `\\\n#version 300 es\n#define SIN2 0.03489949\n#define COS2 0.99939082\n\nin vec2 position;\n\nout vec2 vPosition;\nvoid main() {\n    mat2 rotation = mat2(\n        COS2, SIN2,\n        -SIN2, COS2\n    );\n    vPosition = rotation * position;\n}\n`;\n\nconst renderVs = `\\\n#version 300 es\n\nin vec2 position;\nin vec3 color;\n\nout vec3 vColor;\nvoid main() {\n    vColor = color;\n    gl_Position = vec4(position, 0.0, 1.0);\n}\n`;\n\nconst renderFs = `\\\n#version 300 es\nprecision highp float;\n\nin vec3 vColor;\n\nout vec4 fragColor;\nvoid main() {\n    fragColor = vec4(vColor, 1.0);\n}\n`;\n```\nInternally, we'll be using two separate programs, one for transform feedback and the other for rendering, so we define shaders for both. By default, the `Transform` class will skip rasterization and doesn't require a fragment shader since transform feedback is an operation on vertex data. We define a vertex shader for a transform feedback pass that simply rotates each vertex by 2 degrees in the xy-plane. The rendering vertex and fragment shaders are identical to the ones used in the [Hello Triangle](/docs/getting-started/hello-triangle) tutorial aside from being written in GLSL ES 3.0.\n\n\nIn `onInitialize`, we create our `Transform` instance:\n```js\n  onInitialize({gl}) {\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.5, -0.5,\n      0.5, -0.5,\n      0.0, 0.5\n    ]));\n\n    const transform = new Transform(gl, {\n      vs: transformVs,\n      sourceBuffers: {\n        position: positionBuffer\n      },\n      feedbackMap: {\n        position: 'vPosition'\n      },\n      elementCount: 3\n    });\n\n    // More to come...\n\n  }\n```\n\nWe pass the vertex shader we defined, as well as the initial input buffer in the `sourceBuffers` property, which maps attribute names to buffers. The `feedbackMap` property maps input attributes to output varyings from the vertex shader. Internally it will create an output buffer of the same size as the input buffer into which transformed data will be written.\n\nFinally, we create a model instance to perform the rendering:\n\n```js\n  onInitialize({gl}) {\n    // Transform setup...\n\n    const colorBuffer = new Buffer(gl, new Float32Array([\n      1.0, 0.0, 0.0,\n      0.0, 1.0, 0.0,\n      0.0, 0.0, 1.0\n    ]));\n\n    const model = new Model(gl, {\n      vs: renderVs,\n      fs: renderFs,\n      attributes: {\n        position: transform.getBuffer('vPosition'),\n        color: colorBuffer\n      },\n      vertexCount: 3\n    });\n\n    return {transform, model};\n  }\n```\nWe set up the `Model` similarly to how we've done in other tutorials, with the exception that the `position` attribute is backed by the `vPosition` output buffer created by the `Transform`.\n\nOur `onRender` involves a few additional steps compared to what we've seen before:\n```js\n  onRender({gl, transform, model}) {\n    transform.run();\n\n    clear(gl, {color: [0, 0, 0, 1]});\n    model\n      .setAttributes({\n        position: transform.getBuffer('vPosition')\n      })\n      .draw();\n\n    transform.swap();\n  }\n```\nFirst, we run the transform feedback to write the rotated positions to the `vPosition` output buffer. We then  bind the `Model`'s `position` attribute to the `vPosition` output buffer from the last transform pass and draw. Finally, we swap the input and output buffers in the transform so that the newly rotated positions will be used as input for the next pass, allowing the animation to continue.\n\nIf all went well, you should see a tri-color triangle rotating on the screen. A live demo is available [here](/examples/getting-started/transform-feedback), and the complete application is listed below for reference:\n\n```js\nimport {AnimationLoop, Transform, Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n\nconst transformVs = `\\\n#version 300 es\n#define SIN2 0.03489949\n#define COS2 0.99939082\n\nin vec2 position;\n\nout vec2 vPosition;\nvoid main() {\n    mat2 rotation = mat2(\n        COS2, SIN2,\n        -SIN2, COS2\n    );\n    vPosition = rotation * position;\n}\n`;\n\nconst renderVs = `\\\n#version 300 es\n\nin vec2 position;\nin vec3 color;\n\nout vec3 vColor;\nvoid main() {\n    vColor = color;\n    gl_Position = vec4(position, 0.0, 1.0);\n}\n`;\n\nconst renderFs = `\\\n#version 300 es\nprecision highp float;\n\nin vec3 vColor;\n\nout vec4 fragColor;\nvoid main() {\n    fragColor = vec4(vColor, 1.0);\n}\n`;\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.5, -0.5,\n      0.5, -0.5,\n      0.0, 0.5\n    ]));\n\n    const transform = new Transform(gl, {\n      vs: transformVs,\n      sourceBuffers: {\n        position: positionBuffer\n      },\n      feedbackMap: {\n        position: 'vPosition'\n      },\n      elementCount: 3\n    });\n\n    const colorBuffer = new Buffer(gl, new Float32Array([\n      1.0, 0.0, 0.0,\n      0.0, 1.0, 0.0,\n      0.0, 0.0, 1.0\n    ]));\n\n    const model = new Model(gl, {\n      vs: renderVs,\n      fs: renderFs,\n      attributes: {\n        position: transform.getBuffer('vPosition'),\n        color: colorBuffer\n      },\n      vertexCount: 3\n    });\n\n    return {transform, model};\n  },\n\n  onRender({gl, model}) {\n    transform.run();\n\n    clear(gl, {color: [0, 0, 0, 1]});\n    model.setAttributes({position: transform.getBuffer('vPosition')}).draw();\n\n    transform.swap();\n  }\n});\n\nloop.start();\n```\n\n","slug":"docs/getting-started/transform-feedback","title":"Transform Feedback"},{"excerpt":"Shader Modules This tutorial will demonstrate how to use luma.gl shader modules to make reusable bits of functionality and dynamically…","rawMarkdownBody":"# Shader Modules\n\nThis tutorial will demonstrate how to use luma.gl shader modules to make reusable bits of functionality and dynamically insert them into your shaders. Most of this will be fairly similar to the [Hello Triangle](/docs/getting-started/hello-triangle) app.\n\nWe'll start by setting up our imports and defining our base vertex and fragment shaders:\n```js\nimport {AnimationLoop, Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n\nconst vs1 = `\n  attribute vec2 position;\n\n  void main() {\n    gl_Position = vec4(position - vec2(0.5, 0.0), 0.0, 1.0);\n  }\n`;\n\nconst fs1 = `\n  uniform vec3 hsvColor;\n\n  void main() {\n    gl_FragColor = vec4(color_hsv2rgb(hsvColor), 1.0);\n  }\n`;\n\nconst vs2 = `\n  attribute vec2 position;\n\n  void main() {\n    gl_Position = vec4(position + vec2(0.5, 0.0), 0.0, 1.0);\n  }\n`;\n\nconst fs2 = `\n  uniform vec3 hsvColor;\n\n  void main() {\n    gl_FragColor = vec4(color_hsv2rgb(hsvColor) - 0.3, 1.0);\n  }\n`;\n```\n\nWe have two vertex and fragment shader pairs: one will move vertices to the left, the other moves vertices to the right. Both fragment shaders take an [HSV color](https://en.wikipedia.org/wiki/HSL_and_HSV) as input  call a `color_hsv2rgb` to convert it to RGB. But `color_hsv2rgb` isn't defined anywhere, so these shaders will not compile as-is.\n\nWe define `color_hsv2rgb` in a shader module:\n```js\n// Taken from http://lolengine.net/blog/2013/07/27/rgb-to-hsv-in-glsl\nconst colorModule = {\n  name: 'color',\n  fs: `\n    vec3 color_hsv2rgb(vec3 hsv) {\n      vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);\n      vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);\n      vec3 rgb = c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);\n      return rgb;\n    }\n  `\n};\n```\n\nShader modules are simply JavaScript objects that contain at least a name and some shader code. They can be defined to inject code into the vertex shader, the fragment shader or both. Our `colorModule` defines the `color_hsv2rgb` function used by our fragment shaders. It converts the HSV value to RGB and returns it. We're applying a shader module best practice of prefixing our function with the module name (`color_`) to avoid name collisions.\n\nIn the `onInitialize` method of our `AnimationLoop`, we create two models with different vertex and fragment shader sources, but both including the our `colorModule`.\n\n```js\n  onInitialize({gl}) {\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.3, -0.5,\n      0.3, -0.5,\n      0.0, 0.5\n    ]));\n\n    const model1 = new Model(gl, {\n      vs: vs1,\n      fs: fs1,\n      modules: [colorModule],\n      attributes: {\n        position: positionBuffer\n      },\n      uniforms: {\n        hsvColor: [0.7, 1.0, 1.0]\n      },\n      vertexCount: 3\n    });\n\n    const model2 = new Model(gl, {\n      vs: vs2,\n      fs: fs2,\n      modules: [colorModule],\n      attributes: {\n        position: positionBuffer\n      },\n      uniforms: {\n        hsvColor: [1.0, 1.0, 1.0]\n      },\n      vertexCount: 3\n    });\n\n    return {model1, model2};\n  }\n```\n\nIn `onRender`, we simply draw both models:\n\n```js\n  onRender({gl, model1, model2}) {\n    clear(gl, {color: [0, 0, 0, 1]});\n    model1.draw();\n    model2.draw();\n  }\n```\nIf all went well, a blue trangle and a red triangle should be drawn side-by-side on the canvas. See the live demo [here](/examples/getting-started/shader-modules).\n\nShader modules allowed us to define our HSL to RGB conversion function once and use it across multiple programs.\n\nThe entire application should look like the following:\n```js\nimport {AnimationLoop, Model} from '@luma.gl/engine';\nimport {Buffer, clear} from '@luma.gl/webgl';\n\nconst vs1 = `\n  attribute vec2 position;\n\n  void main() {\n    gl_Position = vec4(position - vec2(0.5, 0.0), 0.0, 1.0);\n  }\n`;\n\nconst fs1 = `\n  void main() {\n    gl_FragColor = color_getColor();\n  }\n`;\n\nconst vs2 = `\n  attribute vec2 position;\n\n  void main() {\n    gl_Position = vec4(position + vec2(0.5, 0.0), 0.0, 1.0);\n  }\n`;\n\nconst fs2 = `\n  void main() {\n    gl_FragColor = color_getColor() - 0.3;\n  }\n`;\n\n// Taken from http://lolengine.net/blog/2013/07/27/rgb-to-hsv-in-glsl\nconst colorModule = {\n  name: 'color',\n  fs: `\n    vec3 color_hsv2rgb(vec3 c) {\n      vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);\n      vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);\n      return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);\n    }\n  `\n};\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    const positionBuffer = new Buffer(gl, new Float32Array([\n      -0.3, -0.5,\n      0.3, -0.5,\n      0.0, 0.5\n    ]));\n\n    const model1 = new Model(gl, {\n      vs: vs1,\n      fs: fs1,\n      modules: [colorModule],\n      attributes: {\n        position: positionBuffer\n      },\n      vertexCount: 3\n    });\n\n    const model2 = new Model(gl, {\n      vs: vs2,\n      fs: fs2,\n      modules: [colorModule],\n      attributes: {\n        position: positionBuffer\n      },\n      vertexCount: 3\n    });\n\n    return {model1, model2};\n  },\n\n  onRender({gl, model}) {\n    clear(gl, {color: [0, 0, 0, 1]});\n    model1.draw();\n    model2.draw();\n  }\n});\n\nloop.start();\n```\n\n","slug":"docs/getting-started/shader-modules","title":"Shader Modules"},{"excerpt":"Instanced Transform In this final tutorial, we'll pull together almost everything we've learned in past tutorials into a single scene…","rawMarkdownBody":"# Instanced Transform\n\nIn this final tutorial, we'll pull together almost everything we've learned in past tutorials into a single scene: lighing, textures, geometry, shader modules, instancing and transform feedback. Whew! This will build on the [previous tutorial](/examples/getting-started/lighting), so it might be helpful to start with its source code.\n\nWe'll be drawing 4 instanced cubes, textured and lit in the same way as in the lighting tutorial, but with the animations updated by transform feedback.\n\nThe `Transform` class is the only addition we need for our imports:\n```js\nimport {AnimationLoop, Model, Transform, CubeGeometry} from '@luma.gl/engine';\nimport {Buffer, Texture2D, clear} from '@luma.gl/webgl';\nimport {setParameters, isWebGL2} from '@luma.gl/gltools';\nimport {phongLighting} from '@luma.gl/shadertools';\nimport {Matrix4} from 'math.gl';\n```\nThe vertex shader for our transform feedback is quite simple. It just increments a scalar rotation value on each run:\n\n```js\nconst transformVs = `\n  attribute float rotations;\n\n  varying float vRotation;\n\n  void main() {\n    vRotation = rotations + 0.01;\n  }\n`;\n```\n\nIn order to handle rotation updates in the transform feedback, we have to move construction of the rotation matrix into the vertex shader. We'll use an [axis-angle](https://en.wikipedia.org/wiki/Rotation_matrix#Rotation_matrix_from_axis_and_angle), passing the axis and rotation angle as instanced attributes (with the rotation angles being updated by transform feedback):\n\n```js\nconst vs = `\\\n  attribute vec3 positions;\n  attribute vec3 normals;\n  attribute vec2 texCoords;\n  attribute vec2 offsets;\n  attribute vec3 axes;\n  attribute float rotations;\n\n  uniform mat4 uView;\n  uniform mat4 uProjection;\n\n  varying vec3 vPosition;\n  varying vec3 vNormal;\n  varying vec2 vUV;\n\n  void main(void) {\n    float s = sin(rotations);\n    float c = cos(rotations);\n    float t = 1.0 - c;\n    float xt = axes.x * t;\n    float yt = axes.y * t;\n    float zt = axes.z * t;\n    float xs = axes.x * s;\n    float ys = axes.y * s;\n    float zs = axes.z * s;\n\n    mat3 rotationMat = mat3(\n        axes.x * xt + c,\n        axes.y * xt + zs,\n        axes.z * xt - ys,\n        axes.x * yt - zs,\n        axes.y * yt + c,\n        axes.z * yt + xs,\n        axes.x * zt + ys,\n        axes.y * zt - xs,\n        axes.z * zt + c\n    );\n\n    vPosition = rotationMat * positions;\n    vPosition.xy += offsets;\n    vNormal = rotationMat * normals;\n    vUV = texCoords;\n    gl_Position = uProjection * uView * vec4(vPosition, 1.0);\n  }\n```\nWe also pass an `offsets` instanced attribute to position each cube.\n\nOur fragment shader doesn't change at all:\n```js\nconst fs = `\\\n  precision highp float;\n\n  uniform sampler2D uTexture;\n  uniform vec3 uEyePosition;\n\n  varying vec3 vPosition;\n  varying vec3 vNormal;\n  varying vec2 vUV;\n\n  void main(void) {\n    vec3 materialColor = texture2D(uTexture, vec2(vUV.x, 1.0 - vUV.y)).rgb;\n    vec3 surfaceColor = lighting_getLightColor(materialColor, uEyePosition, vPosition, normalize(vNormal));\n\n    gl_FragColor = vec4(surfaceColor, 1.0);\n  }\n`;\n```\n\nOur `onInitialize` method will need several updates. First we create buffers for our instanced data:\n```js\n  const offsetBuffer = new Buffer(gl, new Float32Array([\n    3, 3,\n    -3, 3,\n    3, -3,\n    -3, -3\n  ]));\n\n  const axisBufferData = new Float32Array(12);\n  for (let i = 0; i < 4; ++i) {\n    const vi = i * 3;\n    const x = Math.random();\n    const y = Math.random();\n    const z = Math.random();\n    const l = Math.sqrt(x * x + y * y + z * z);\n\n    axisBufferData[vi] = x / l;\n    axisBufferData[vi + 1] = y / l;\n    axisBufferData[vi + 2] = z / l;\n  }\n  const axisBuffer = new Buffer(gl, axisBufferData);\n\n  const rotationBuffer = new Buffer(gl, new Float32Array([\n    Math.random() * Math.PI * 2,\n    Math.random() * Math.PI * 2,\n    Math.random() * Math.PI * 2,\n    Math.random() * Math.PI * 2\n  ]));\n```\nThe `offsetBuffer` sets positions so the cubes will be in a square formation. The `axisBuffer` looks more complicated, but its simply a set of 4 normalized vectors about which we'll rotate our cubes. Finally, the `rotationBuffer` simply starts with 4 random angles between 0 and 2&pi;.\n\nThe `Transform` is straightforward to set up, simply taking the `rotationBuffer` and our vertex shader as input:\n```js\n  const transform = new Transform(gl, {\n    vs: transformVs,\n    sourceBuffers: {\n      rotations: rotationBuffer\n    },\n    feedbackMap: {\n      rotations: 'vRotation'\n    },\n    elementCount: 4\n  });\n```\n\nAnd the `Model` needs to be updated to take the instanced attributes and `instanceCount`:\n\n```js\n  const model = new Model(gl, {\n    vs,\n    fs,\n    geometry: new CubeGeometry(),\n    attributes: {\n      offsets: [offsetBuffer, {divisor: 1}],\n      axes: [axisBuffer, {divisor: 1}],\n      rotations: [rotationBuffer, {divisor: 1}]\n    },\n    uniforms: {\n      uTexture: texture,\n      uEyePosition: eyePosition,\n      uView: viewMatrix\n    },\n    modules: [phongLighting],\n    moduleSettings: {\n      material: {\n        specularColor: [255, 255, 255]\n      },\n      lights: [\n        {\n          type: 'ambient',\n          color: [255, 255, 255]\n        },\n        {\n          type: 'point',\n          color: [255, 255, 255],\n          position: [4, 8, 4]\n        }\n      ]\n    },\n    instanceCount: 4\n  });\n```\n\nOur `onRender` needs an update to perform the transform feedback and pass the transformed rotation buffer to the `Model`:\n```js\n  onRender({gl, aspect, model, transform, projectionMatrix}) {\n    projectionMatrix.perspective({fov: Math.PI / 3, aspect});\n\n    transform.run();\n\n    clear(gl, {color: [0, 0, 0, 1], depth: true});\n    model\n      .setAttributes({rotations: [transform.getBuffer('vRotation'), {divisor: 1}]})\n      .setUniforms({uProjection: projectionMatrix})\n      .draw();\n\n    transform.swap();\n  }\n```\n\nIf all went well, you should see 4 rotating cubes. This scene is significantly more complex than anything we've seen before, so take some time to play around with it and get to know the various parts. The live demo is available [here](/examples/getting-started/instanced-transform), and the full source code is listed below for reference:\n\n```js\nimport {AnimationLoop, Model, Transform, CubeGeometry} from '@luma.gl/engine';\nimport {Buffer, Texture2D, clear} from '@luma.gl/webgl';\nimport {setParameters, isWebGL2} from '@luma.gl/gltools';\nimport {phongLighting} from '@luma.gl/shadertools';\nimport {Matrix4} from 'math.gl';\n\nconst transformVs = `\n  attribute float rotations;\n\n  varying float vRotation;\n\n  void main() {\n    vRotation = rotations + 0.01;\n  }\n`;\n\nconst vs = `\\\n  attribute vec3 positions;\n  attribute vec3 normals;\n  attribute vec2 texCoords;\n  attribute vec2 offsets;\n  attribute vec3 axes;\n  attribute float rotations;\n\n  uniform mat4 uView;\n  uniform mat4 uProjection;\n\n  varying vec3 vPosition;\n  varying vec3 vNormal;\n  varying vec2 vUV;\n\n  void main(void) {\n    float s = sin(rotations);\n    float c = cos(rotations);\n    float t = 1.0 - c;\n    float xt = axes.x * t;\n    float yt = axes.y * t;\n    float zt = axes.z * t;\n    float xs = axes.x * s;\n    float ys = axes.y * s;\n    float zs = axes.z * s;\n\n    mat3 rotationMat = mat3(\n        axes.x * xt + c,\n        axes.y * xt + zs,\n        axes.z * xt - ys,\n        axes.x * yt - zs,\n        axes.y * yt + c,\n        axes.z * yt + xs,\n        axes.x * zt + ys,\n        axes.y * zt - xs,\n        axes.z * zt + c\n    );\n\n    vPosition = rotationMat * positions;\n    vPosition.xy += offsets;\n    vNormal = rotationMat * normals;\n    vUV = texCoords;\n    gl_Position = uProjection * uView * vec4(vPosition, 1.0);\n  }\n`;\n\nconst fs = `\\\n  precision highp float;\n\n  uniform sampler2D uTexture;\n  uniform vec3 uEyePosition;\n\n  varying vec3 vPosition;\n  varying vec3 vNormal;\n  varying vec2 vUV;\n\n  void main(void) {\n    vec3 materialColor = texture2D(uTexture, vec2(vUV.x, 1.0 - vUV.y)).rgb;\n    vec3 surfaceColor = lighting_getLightColor(materialColor, uEyePosition, vPosition, normalize(vNormal));\n\n    gl_FragColor = vec4(surfaceColor, 1.0);\n  }\n`;\n\nconst loop = new AnimationLoop({\n  onInitialize({gl}) {\n    setParameters(gl, {\n      depthTest: true,\n      depthFunc: gl.LEQUAL\n    });\n\n    const offsetBuffer = new Buffer(gl, new Float32Array([\n      3, 3,\n      -3, 3,\n      3, -3,\n      -3, -3\n    ]));\n\n    const axisBufferData = new Float32Array(12);\n    for (let i = 0; i < 4; ++i) {\n      const vi = i * 3;\n      const x = Math.random();\n      const y = Math.random();\n      const z = Math.random();\n      const l = Math.sqrt(x * x + y * y + z * z);\n\n      axisBufferData[vi] = x / l;\n      axisBufferData[vi + 1] = y / l;\n      axisBufferData[vi + 2] = z / l;\n    }\n    const axisBuffer = new Buffer(gl, axisBufferData);\n\n    const rotationBuffer = new Buffer(gl, new Float32Array([\n      Math.random() * Math.PI * 2,\n      Math.random() * Math.PI * 2,\n      Math.random() * Math.PI * 2,\n      Math.random() * Math.PI * 2\n    ]));\n\n    const texture = new Texture2D(gl, {\n      data: 'vis-logo.png'\n    });\n\n    const eyePosition = [0, 0, 10];\n    const viewMatrix = new Matrix4().lookAt({eye: eyePosition});\n    const projectionMatrix = new Matrix4();\n\n    const transform = new Transform(gl, {\n      vs: transformVs,\n      sourceBuffers: {\n        rotations: rotationBuffer\n      },\n      feedbackMap: {\n        rotations: 'vRotation'\n      },\n      elementCount: 4\n    });\n\n    const model = new Model(gl, {\n      vs,\n      fs,\n      geometry: new CubeGeometry(),\n      attributes: {\n        offsets: [offsetBuffer, {divisor: 1}],\n        axes: [axisBuffer, {divisor: 1}],\n        rotations: [rotationBuffer, {divisor: 1}]\n      },\n      uniforms: {\n        uTexture: texture,\n        uEyePosition: eyePosition,\n        uView: viewMatrix\n      },\n      modules: [phongLighting],\n      moduleSettings: {\n        material: {\n          specularColor: [255, 255, 255]\n        },\n        lights: [\n          {\n            type: 'ambient',\n            color: [255, 255, 255]\n          },\n          {\n            type: 'point',\n            color: [255, 255, 255],\n            position: [4, 8, 4]\n          }\n        ]\n      },\n      instanceCount: 4\n    });\n\n    return {\n      model,\n      transform,\n      projectionMatrix\n    };\n  },\n\n  onRender({gl, aspect, model, transform, projectionMatrix}) {\n    projectionMatrix.perspective({fov: Math.PI / 3, aspect});\n\n    transform.run();\n\n    clear(gl, {color: [0, 0, 0, 1], depth: true});\n    model\n      .setAttributes({rotations: [transform.getBuffer('vRotation'), {divisor: 1}]})\n      .setUniforms({uProjection: projectionMatrix})\n      .draw();\n\n    transform.swap();\n  }\n});\n\nloop.start();\n```\n\n","slug":"docs/getting-started/instanced-transform","title":"Instanced Transform"},{"excerpt":"Development Environment To get started developing luma.gl, first make sure to install all dependancies from the repository root:  luma.gl's…","rawMarkdownBody":"# Development Environment\n\nTo get started developing luma.gl, first make sure to install all dependancies from the repository root:\n\n`yarn bootstrap`\n\nluma.gl's source code is in the `modules/` directory. Development is most easily done by running the examples in development mode, e.g.:\n\n```\ncd examples/core/instancing\nyarn\nyarn start-local\n```\n\nAny modifications made to the source or example code will cause the example to rebuild and the page to refresh, making quick iterations on code changes straightforward.\n\nTesting against the full website can be done by running `yarn start` in the the `website/`. This full website take longer to build but makes it easier to test against all examples. This can be helpful when making core changes to luma.gl. As with running the examples in development mode, a rebuild and page refresh will be triggered whenever source or website code is updated.\n\n\n## Testing\n\nTesting is performed on Travis CI and using a precommit hook. Local testing is supported on these environments:\n\n* `yarn test` - runs tests under node using headless.gl and a headless Chrome instance (using [SwiftShader](https://github.com/google/swiftshader)).\n* `yarn test browser` - Tests in your browser, may be helpful to quickly debug test case failures since it autoreloads on changes and gives you full access to your browser's debugger.\n\nWhen adding new features, please add relevant unit tests to the `test/` directory in the relevant module.\n\n### Helpful Hints\n- To only run one test from the suite for debugging purposes, change a call to `test` in the relevant spec to `test.only`. Remember to change this back before committing!\n- If a test fails in `headless`, but not in the browser, it's likely due to a difference in the contexts created (WebGL 1 versus 2), or the extensions available. Running in a browser without WebGL 2 support (e.g. Safari), might help narrow the issue down.\n","slug":"docs/contributor-guide","title":"Development Environment"},{"excerpt":"Overview luma.gl is split into several modules that are each responsible for a particular part of the rendering stack: : High-level…","rawMarkdownBody":"# Overview\n\n**luma.gl** is split into several modules that are each responsible for a particular part of the rendering stack:\n\n- `engine`: High-level constructs such as `Model`, `AnimationLoop` and `Geometry` that allow a developer to work without worrying about rendering pipeline details.\n- `webgl`: Wrapper classes around WebGL objects such as `Program`, `Buffer`, `VertexArray` that allow a developer to manager the rendering pipeline directly but with a more convenient API.\n- `gltools`: A set of helper functions for instrumenting and managing state on an WebGL context. This allows developers to program directly against the WebGL API with some helpful polyfilling and state tracking.\n- `shadertools`: A system for modularizing and composing GLSL shader code.\n- `debug`: Tooling to aid in debugging.\n\n**luma.gl** also exposes a `core` module that simply re-exports key parts of the other modules. This can be helpful to just get started without worrying too much about fine-grained control of dependencies. The `core` module re-exports the following functions and classes from other modules:\n\n|Module|Exports|\n|------|-------|\n|engine|AnimationLoop, Model, Transform, ProgramManager, Timeline, Geometry, ClipSpace, ConeGeometry, CubeGeometry, CylinderGeometry, IcoSphereGeometry, PlaneGeometry, SphereGeometry, TruncatedConeGeometry|\n|webgl|lumaStats, FEATURES, hasFeature, hasFeatures, Buffer, Program, Framebuffer, Renderbuffer, Texture2D, TextureCube, clear, readPixelsToArray, readPixelsToBuffer, cloneTextureFrom, copyToTexture, Texture3D, TransformFeedback|\n|gltools|createGLContext, instrumentGLContext, isWebGL, isWebGL2, getParameters, setParameters, withParameters, resetParameters, cssToDeviceRatio, cssToDevicePixels|\n|shadertools|normalizeShaderModule, fp32, fp64, project, dirlight, picking, gouraudLighting, phongLighting, pbr|\n","slug":"docs/api-reference","title":"Overview"},{"excerpt":"What's Next? That concludes our luma.gl tutorial series. If you went through the full set of tutorials, you've taken a deep dive into some…","rawMarkdownBody":"# What's Next?\n\nThat concludes our **luma.gl** tutorial series. If you went through the full set of tutorials, you've taken a deep dive into some of **luma.gl**'s more powerful features, including polyfilling the WebGL context, shader modules and composition, instanced drawing, and transform feedback. To dig deeper into **luma.gl**'s API, we recommend playing around with the examples in the [examples directory](https://github.com/uber/luma.gl/tree/8.0-release/examples/core) of the repository, which demonstrate various parts of the API in more detail. They can also be browsed on the [website](https://luma.gl/examples).\n\nTo explore the examples, clone the **luma.gl** repo and run the following in a given example's directory:\n\n```bash\ngit clone git@github.com:uber/luma.gl.git\ncd luma.gl/examples/showcase/instancing\ngit checkout 8.0-release\nyarn\nyarn start\n```\n\nThis will start a local development server and open the page in your browser. The main application code is in `app.js` and the page will automatically refresh whenever it's udpated.\n\nNote that we checkout the latest release branch here (`8.0-release`), which is recommended as `master` is the active development branch.\n\nHappy exploring!\n","slug":"docs/getting-started/whats-next","title":"What's Next?"},{"excerpt":"Debug Warning: Debug contexts impose a significant performance penalty (due to waiting for the GPU after each WebGL call to check error…","rawMarkdownBody":"# Debug\n\n> Warning: Debug contexts impose a significant performance penalty (due to waiting for the GPU after each WebGL call to check error codes) and should not be used in production builds.\n\nluma.gl is pre-integrated with the Khronos group's WebGL debug tools (the [WebGLDeveloperTools](https://github.com/KhronosGroup/WebGLDeveloperTools)) and can use these to \"instrument\" `WebGLRenderingContext`s.\n\nThe `WebGLDeveloperTools` are automatically installed when luma.gl is installed, but are not actually bundled into the application unless explicitly imported. This avoids impacting the size of production bundles built on luma.gl that typically do not need debug support.\n\nTo use debug support, first import the debug tools, then call `createGLContext` or `instrumentGLContext` from [@luma.gl/gltools](/docs/api-reference/gltools/context) to create a debug context:\n\n```js\nimport {createGLContext} from '@luma.gl/gltools';\nimport '@luma.gl/debug';\nconst gl = createGLContext(gl, {debug: true});\n```\n\nIf the debug tools haven't been imported, both funcitons will print a warning and simply return the original context, so the debug code can be left in the applicatin even when debug support is not imported.\n\nDebug contexts perform the following:\n\n* **Detects WebGL Errors** - Check the WebGL error status after each WebGL call and throws an exception if an error was detected, taking care to extract helpful information into the error message.\n\n* **Checks WebGL Parameters** - Ensure that WebGL parameters are set to valid values.\n","slug":"docs/api-reference/debug","title":"Debug"},{"excerpt":"Accessor The  class is a helper class that describes how a buffers memory is structured and should be accessed. Accessors are used. The type…","rawMarkdownBody":"# Accessor\n\nThe `Accessor` class is a helper class that describes how a buffers memory is structured and should be accessed. Accessors are used.\n\nThe type of values, number of values per element, any offset and strides, etc. as well as some additional parameters relating to how the GPU should access buffer data (instance divisors, integer normalization etc).\n\nBy using multiple `Accessor` instances, the application can defined different \"views\" of the data in a single buffer.\n\nAccessors are immutable by design. Once they have been created they cannot be changed.\n\nAccessors can be resolved (merged) into a new Accessor. This is useful since while some accessor properties can be extracted directly from a program's shaders (and some can be extracted when data is set to the buffer), some properties needs to be set by the application.\n\n\n## Properties\n\n| Property    | Category    | Auto Deduce    | Default    | Comment |\n| ---         | ---         | ---            | ---        | ---     |\n| `offset`    | data layout | N/A            | `0`        | Byte offset to start of data in buffer |\n| `stride`    | data layout | N/A            | `0`        | Extra bytes between each successive data element |\n| `type`      | data type   | Vertex Shader/`Buffer.setData` | `GL.FLOAT` | Low level data type (`GL.BYTE`, `GL.SHORT`, ...) |\n| `size`      | data type   | Vertex Shader  | `1`        | Components per element (`1`-`4`) |\n| `divisor`   | instancing  | Attribute name | `0`        | Enables/disables instancing |\n| `normalize` | data access | N/A            | `false`    | Normalize integers to [-1,1], or [0,1] if unsigned |\n| `integer`   | data access | N/A            | `false`    | Disable conversion of integer values to floats **WebGL 2** |\n\nNotes:\n\n* `type` and `size` values for attributes are read from the shaders when a program is created and linked, and normally do not need to be supplied. Also any attribute with `instance` in its name will automatically be given an instance divisor of `1`.\n* `divisor` is automatically set to `1` for any attribute that has some capitalization of `instance` in the name.\n* `offset` and `stride` are typically used to interleave data in buffers and are normally left undefined (i.e. `0`).\n* `normalize` and `integer` need to be enabled by applications through an `Accessor`.\n\n\n### `offset`\n\nByte offset to start of data in buffer\n\n### `stride`\n\n### `type`\n\nLow level data type (GL.BYTE, GL.SHORT, GL.FLOAT, GL.INT, ...)\n\n### `size`\n\nNumber of (1-4 values per vertex)\n\n### `divisor`: Number\n\nEnables/disables instancing.\n\n### `normalize`\n\nIf `true` normalizes integer values (`GL.BYTE`, ...). Signed values are normalized to [-1,1] and unsigned values are normalized to [0,1].\n\n### `integer` **WebGL 2**\n\nDisable conversion of integer values to floats.\n\n\n## Static Methods\n\n### Accessor.merge(accessor1, accessor2, ...) : Accessor\n\nMerges a number of partial accessors into a merged accessor that can be used to set vertex attributes. Any unspecified accessor properties will be set to their default values.\n\nNote: Most applications do not need to merge accessors directly. Merging is done by the `VertexArray.setAttributes` method.\n\n\n## Methods\n\n### constructor(props : Object)\n\nCreates a new partial `Accessor`. The new object will be immutable, i.e. its values cannot be changed after creation.\n\n\n### `BYTES_PER_ELEMENT` : Number\n\nReturns the number of bytes per \"element\", based on the `type` field in the accessor. Asserts if type is not set.\n\n### `BYTES_PER_VERTEX` : Number\n\nReturns the number of bytes per \"vertex\", based on the `type` and `size` fields in the accessor. Asserts if `type` and `size` are not set.\n\n\n\n## Remarks: Auto-deduction\n\n* `type` and `size` are automatically inferred (through WebGL APIs that provide access to metadata extracted during compilation and linking of shader programs).\n* `divisor` - if attribute name starts with `instance...` this will be automatically set to `1`.\n* `offset` and `stride` are assumed to be 0 which corresponds to the simple non-interleaved case.\n* `integer` - if type is `GL.INT` or `GL.UINT`, then integer is automatically true, as floating point shader inputs cannot be mapped to such attributes.\n\n\n","slug":"docs/api-reference/webgl/accessor","title":"Accessor"},{"excerpt":"SnapshotTestRunner Client-side utility for browser-based WebGL render tests. This class is intended to be used with  from . Together they…","rawMarkdownBody":"# SnapshotTestRunner\n\nClient-side utility for browser-based WebGL render tests.\n\nThis class is intended to be used with `BrowserTestDriver` from `@probe.gl/test-utils`. Together they support the following workflow:\n\n* Launch a Puppeteer instance (headless or non-headless) to run a test application\n* In the test application, create a canvas and `WebGLContext`.\n* For each test case, render something to the `WebGLContext`, take a screenshot, and perform pixel-diffing with a pre-defined \"golden image\". Report the matching result.\n* Proceed to the next test case until done.\n\n## Example\n\nIn your node.js start script:\n\n```js\n// This is the script that runs in Node.js and starts the browser\nconst {BrowserTestDriver} = require('@probe.gl/test-utils');\nnew BrowserTestDriver().run({\n  server: {\n    // Bundles and serves the browser script\n    command: 'webpack-dev-server',\n    arguments: ['--env.render-test']\n  },\n  headless: true\n});\n```\n\nIn your script that is run on the browser:\n\n```js\nconst {SnapshotTestRunner} = require('@luma.gl/test-utils');\nconst {Cube} = require('@luma.gl/core');\n\nconst TEST_CASES = [\n  {\n    name: 'Render A Cube',\n    // `onRender` receives animation props from the AnimationLoop\n    onRender: ({gl, done}) => {\n      const model = new Cube(gl);\n      model.draw(...);\n      // ready for capture and diffing\n      done();\n    },\n    goldenImage: './test/render/golden-images/cube.png'\n  }\n];\n\nnew TestRender({width: 800, height: 600})\n  .add(TEST_CASES)\n  .run({\n    onTestFail: window.browserTestDriver_fail\n  })\n  .then(window.browserTestDriver_finish);\n```\n\n## Methods\n\n### constructor(props: Object)\n\n```\nnew SnapshotTestRunner(props)\n```\n\nCreate a SnapshotTestRunner instance. The `props` argument is forwarded to the [AnimationLoop](/docs/api-reference/core/animation-loop.md) constructor.\n\n### add(testCase: Array|Object)\n\nAdd one or a list of test cases. Each test case may contain the following fields:\n \n* `name` (String) - name of the test case.\n* `goldenImage` (String) - path to the golden image, relative to the root where the node script is executed.\n* `timeout` (Number) - time to wait for this test case to resolve (by calling the `done` callback) before aborting, in milliseconds. If not provided, fallback to the shared option that is passed to `SnapshotTestRunner.run`.\n* `imageDiffOptions` (Object) - image diffing options for this test case. See \"Image Diff Options\" section below.\n* `onInitialize` (Function) - called once when the test case starts. Receives a single object that is the [AnimationLoop callback parameters](/docs/api-reference/core/animation-loop.md#callback-parameters). If this callback returns an object or a promise, the content that it resolves to will be passed to `onRender` and `onFinalize` later.\n* `onRender` (Function) - called every animation frame when the test case is running. Receives a single object that is the [AnimationLoop callback parameters](/docs/api-reference/core/animation-loop.md#callback-parameters), plus the following:\n  - `done` (Function) - must be called when the test case is done rendering and ready for screen capture and comparison.\n* `onFinalize` (Function) - called once when the test case is done to finalize all resources. Receives a single object that is the [AnimationLoop callback parameters](/docs/api-reference/core/animation-loop.md#callback-parameters).\n\n### run(options: Object)\n\nRun all test cases.\n\nOptions:\n\n* `timeout` (Number) - time to wait for each test case to resolve (by calling the `done` callback) before aborting, in milliseconds. Default `2000`.\n* `imageDiffOptions` (Object) - image diffing options for all test cases. This will be overridden if a test case defines its own `imageDiffOptions`. See \"Image Diff Options\" section below.\n* `onTestStart` (Function) - callback when a test starts. Receives the current test case. Default logs the test name to console.\n* `onTestPass` (Function) - callback when a test passes. Receives the current test case and the diffing result. Default logs the pixel matching percentage to console.\n* `onTestFail` (Function) - callback when a test fails, either because the matching rate is below threshold or a critical error. Receives the current test case. Default logs the error message or the pixel matching percentage to console.\n\nReturns: a `Promise` that resolves when all test cases are done.\n\n\n## Members\n\n### isHeadless\n\nWhether the test is being run in headless mode. In headless mode, Chromium uses software render which behaves slightly differently from non-headless. Image diffing tolerance may need to be adjusted accordingly.\n\n\n## Image Diff Options\n\nThe test renderer and each test case may choose to override the default image diffing options. The following options from [captureAndDiffScreen](https://github.com/uber-web/probe.gl/blob/master/docs/api-reference/test-utils/browser-test-driver.md#browsertestdriver_captureanddiffscreenoptions--object) are supported:\n\n* `tolerance`\n* `threshold`\n* `includeAA`\n* `createDiffImage`\n* `saveOnFail`\n* `saveAs`\n\n","slug":"docs/api-reference/test-utils/snapshot-test-runner","title":"SnapshotTestRunner"},{"excerpt":"Buffer A  is a WebGL object that stores an chunk of memory allocated by the GPU. This memory can be accessed directly by the GPU and is used…","rawMarkdownBody":"# Buffer\n\nA `Buffer` is a WebGL object that stores an chunk of memory allocated by the GPU. This memory can be accessed directly by the GPU and is used to store things like vertex data, pixel data retrieved from images or the framebuffer, etc. The `Buffer` class provides mechanism for allocating such memory, together with facilities for copying data to and from the GPU (usually via JavaScript typed arrays).\n\nFor additional information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Buffer_Object).\n\n\n## Usage\n\n```js\nimport {Buffer} from '@luma.gl/webgl';\n```\n\nCreating a generic buffer\n```js\nconst buffer = new Buffer(gl);\n```\n\nCreating an elements buffer\n```js\nconst buffer = new Buffer(gl, {target: GL.ELEMENT_ARRAY_BUFFER});\n```\n\nAllocating memory in a buffer\n```js\nconst buffer = new Buffer(gl, {byteLength: 200});\nconst buffer = new Buffer(gl).initialize({byteLength: 200});\n```\n\nAllocating and initializing a buffer\n```js\nconst buffer = new Buffer(gl, {\n  target: GL.ELEMENTS_ARRAY_BUFFER,\n  data: new Uint32Array([1, 2, 3])\n});\nconst buffer = new Buffer(gl, new Float32Array([1, 2, 3])); // Allocate+init 12 bytes of GPU memory\nconst buffer = new Buffer(gl, 200); // Allocate 200 bytes of GPU memory\n```\n\nUpdating a buffer\n```js\nconst buffer = new Buffer(gl, {byteLength: 200})\nbuffer.subData(new Float32Array(...));\n```\n\nCopying data between buffers (WebGL 2)\n```js\nconst sourceBuffer = ...\nconst destinationBuffer = ...\n\n// To copy 32 bytes from sourceBuffer to destinationBuffer\ndestinationBuffer.copyData({sourceBuffer, size: 32});\n\n// To copy 32 bytes from sourceBuffer at 8 byte offset into\n// destinationBuffer at 16 byte offset.\ndestinationBuffer.copyData({\n  sourceBuffer,\n  readOffset: 8,\n  writeOffset: 16,\n  size: 32\n});\n```\n\nGetting data from a buffer (WebGL 2)\n```js\nconst buffer = ...;\n\n// To get all the data from buffer\nconst data = buffer.getData();\n\n// To get all the data from buffer starting from byteOffset 8\n// into existing ArrayBufferView.\nconst existingArray = ...\nconst data = buffer.getData({dstData: existingArray, srcByteOffset: 8});\n// Maximum possible elements will be copied based buffer and dstData size.\n\n// To get 5 elements from source buffer starting from byteOffset 8\n// into existing ArrayBufferView starting from 3rd element position.\nconst existingArray = ...\nconst data = buffer.getData({dstData: existingArray, srcByteOffset: 8, dstOffset: 3, length: 5});\n\n```\n\n\n## Members\n\n##### `handle` : `WebGLBuffer`\n\nHolds the underlying WebGL object reference.\n\n\n##### `byteLength` : Number\n\nNumber of bytes of allocated memory.\n\n\n#### `bytesUsed` : Number\n\nSame as `byteLength` unless the `Buffer.reallocate` has been called with a value smaller than the actual length of the buffer.\n\n\n##### `accessor` : `Accessor`\n\nHolds an `Accessor` instance. By default it contains type information that is automatically deducted from the type of data used to initialize the buffer, but the application can store any `Accessor` it wants with the `Buffer`. This can simplify handling of buffer related data in many basic use cases (e.g. when buffers are not shared by multiple attributes etc).\n\n\n## Constructor\n\n### Buffer(gl : WebGLRenderingContext, props : Object | TypedArray | Number)\n\nCreates a new `Buffer`. Multiple signatures are supported:\n\n```js\nconst buffer = new Buffer(gl, {target, ...initOptions, accessor, ...accessorOptions});\n```\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `target`= (*GLenum*, optional) - the type of buffer, see below.\n* `...initOptions` (*Object*) - options passed on to `initialize`.\n* `accessor` - options used to create the `accessor`\n* `...accessorOptions` (DEPRECATED) - options passed on to `setAccessor`. Use `accessor` instead.\n\n```js\nconst buffer = new Buffer(gl, typedArray);\n```\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `typedArray` - typed array with values that should be used to size and initialize the new GPU buffer. Short hand for `new Buffer({data: typedArray})`.\n\n```js\nconst buffer = new Buffer(gl, byteLength);\n```\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `byteLength` - specifies the number of bytes that should be allocated (but not initialized). Short hand for `new Buffer({byteLength})`.\n\nThe newly constructed buffer will either be a an \"element\" buffer used for storing vertex indices, or a \"generic\" buffer that can be used to store other things. To create an element buffer, specify `target: GL.ELEMENT_ARRAY_BUFFER`. If target is not specified, it will be a generic buffer that can be used in a variety of situations.\n\n* In WebGL 1, the default target is `GL.ARRAY_BUFFER` which will work as a \"generic\" (i.e. non-element) buffer.\n* In WebGL 2, the default target is `GL.COPY_READ_BUFFER` which means the buffer can work either as a generic buffer and an element buffer. This will be determined when it is first used with (bound to) a specific target. From that point on, WebGL will consider it either as an element buffer or a generic buffer.\n\n\n## Methods\n\n### initialize(props : Object) : Buffer\n\nAllocates and optionally initializes buffer memory/data store (releasing any previously allocated memory).\n\nAlso extracts characteristics of stored data, hints for vertex attribute.\n\n```js\nBuffer.initialize({data, byteLength, usage=, dataType=, size=, accessor=, ...accessorOptions})\nBuffer(gl, typedArray);\nBuffer(gl, byteLength);\n``````\n\n* `data` (ArrayBufferView) - contents\n* `byteLength` (Number) - the size of the buffer object's data store.\n* `usage`=`GL.STATIC_DRAW` (GLenum) - Allocation hint for GPU driver.\n* `accessor` (Object) - object with accessor props to be stored as accessor.\n* `...accessorOptions` (DEPRECATED) -  parameters passed to `setAccessor`\n\n\n### reallocate(byteLength : Number) : Buffer\n\nIf necessary, increases buffer size to `byteLength`. Does not decrease the buffer's size if already long enough.\n\n* `byteLength` (Number) - the minimum size of the buffer object's data store.\n\nReturns:\n\n* `true` - if reallocation happened (in which case any stored data was invalidated).\n* `false` - if the `Buffer` was already big enough in which case any uploaded data remains intact.\n\n\n### subData({data , offset=, srcOffset=, length=}) : Buffer\n\nUpdates part or all of a buffer's allocated memory.\n\n`Buffer.subData({data, offset=, srcOffset=, length=})`\n\n* `data` (`ArrayBufferView`) - length is inferred unless provided\n* `offset`=`0` - Offset into buffer\n* `srcOffset`=`0` -  WebGL 2: Offset into srcData\n* `length` - WebGL 2: Number of bytes to be copied\n\n\n### copyData(options : Object) : Buffer (WebGL 2)\n\nCopies part of the data of another buffer into this buffer. The copy happens on the GPU and is expected to be efficient.\n\n`Buffer.copyData({sourceBuffer, readOffset=, writeOffset=, size})`\n\n* `options.sourceBuffer` (`Buffer`) - the buffer to read data from.\n* `options.readOffset`=`0` (GLint) - byte offset from which to start reading from the buffer.\n* `options.writeOffset`=`0` (GLint) - byte offset from which to start writing to the buffer.\n* `options.size` (GLsizei) - byte count, specifying the size of the data to be copied.\n\nNote:\n\n* `readOffset`, `writeOffset` and `size` must all be greater than or equal to zero.\n* `readOffset + sizereadOffset + size` must not exceeed the size of the source buffer object\n* `writeOffset + sizewriteOffset + size` must not exceeed the size of the buffer bound to writeTarget.\n* If the source and destination are the same buffer object, then the source and destination ranges must not overlap.\n\n\n### getData() : TypedArray (WebGL 2)\n\nReads data from buffer into an `ArrayBufferView` or `SharedArrayBuffer`.\n\n`Buffer.getData({dstData, srcByteOffset, srcOffset, length})`\n\n* `dstData`=`null` (`ArrayBufferView` | `SharedArrayBuffer` | `null`)  - memory to which to write the buffer data. New ArrayBufferView allocated with correct type if not provided.\n* `srcByteOffset`=`0` (GLintptr) - byte offset from which to start reading from the buffer.\n* `srcOffset`=`0` (GLuint) - element index offset where to start reading the buffer.\n* `length`=`0` (GLuint)  Optional, Element count to be copied, optimal value calculated when not provided.\n\nReturns a typed array containing the data from the buffer (if `dstData` was supplied it will be returned, otherwise this will be a freshly allocated array).\n\n\n### getElementCount([accessor : Accessor]) : Number\n\nReturns number of elements in the buffer. In a buffer created with Float32Array typed array, each float is an element and takes 4 bytes (or 32 bits).\n\n\n### setAccessor(accessor : Accessor | Object) : Buffer\n\nAllows you to optionally describe the accessor properties of the data in the buffer. This does not affect the buffer itself, but if supplied can avoid having to supply this data again when you use this buffer as an attribute later (see `VertexArray.setAttributes`).\n\nFor details on accessor props, see the documentation for the [`Accessor`]() class.\n\n\n## Types\n\n### Usage\n\n| Usage             | WebGL 2 | WebGL 1 | Description |\n| ---               | ---    | ---    | ---         |\n| `GL.STATIC_DRAW`  | Yes    | Yes    | Buffer will be used often and not change often. Contents are written to the buffer, but not read. |\n| `GL.DYNAMIC_DRAW` | Yes    | Yes    | Buffer will be used often and change often. Contents are written to the buffer, but not read. |\n| `GL.STREAM_DRAW`  | Yes    | Yes    | Buffer will not be used often. Contents are written to the buffer, but not read. |\n| `GL.STATIC_READ`  | Yes    | No     | Buffer will be used often and not change often. Contents are read from the buffer, but not written. |\n| `GL.DYNAMIC_READ` | Yes    | No     | Buffer will be used often and change often. Contents are read from the buffer, but not written. |\n| `GL.STREAM_READ`  | Yes    | No     | Buffer will not be used often. Contents are read from the buffer, but not written. |\n| `GL.STATIC_COPY`  | Yes    | No     | Buffer will be used often and not change often. Contents are neither written or read by the user. |\n| `GL.DYNAMIC_COPY` | Yes    | No     | Buffer will be used often and change often. Contents are neither written or read by the user. |\n| `GL.STREAM_COPY`  | Yes    | No     | Buffer will be used often and not change often. Contents are neither written or read by the user. |\n\n### Parameters\n\n| Parameter         | Type   | Value |\n| ---               | ---    | ---   |\n| `GL.BUFFER_SIZE`  | GLint  | The size of the buffer in bytes   |\n| `GL.BUFFER_USAGE` | GLenum | The `usage` pattern of the buffer |\n\n\n### \"Manually\" Binding Buffers\n\nIf you are an experienced WebGL or OpenGL programmer you are probably used to constantly binding buffers. Buffer binding and unbinding is handled internal by luma.gl methods and applications typically do not need to bind buffers.\n\nTo support use cases integrating with external libraries or raw webgl code, it is of course possible to \"manually\" bind and unbind luma.gl `Buffer` instances:\n\n```js\nconst buffer = ...;\nbuffer.bind({target: GL.ARRAY_BUFFER});\n...\nbuffer.unbind({target: GL.ARRAY_BUFFER});\n```\nWebGL 2 examples\n```js\nbuffer.bind({target: GL.PIXEL_PACK_BUFFER});\nbuffer.bind({target: GL.PIXEL_UNPACK_BUFFER});\nbuffer.bind({target: GL.TRANSFORM_FEEDBACK_BUFFER, index: 0});\nbuffer.bind({target: GL.UNIFORM_BUFFER, index: 0, offset: ..., size: ...});\nbuffer.unbind({target: GL.UNIFORM_BUFFER, index: 0});\n```\n\n\n## Remarks\n\n* All instance methods in a buffer (unless they return some documented value) are chainable.\n* While transferring memory between CPU and GPU takes some time, once the memory is available as a buffer on the GPU it can be very efficiently used as inputs and outputs by the GPU.\n\nNote that in WebGL, there are two types of buffers:\n* \"element\" buffers. These can only store vertex attributes with indices (a.k.a \"elements\") and can only be used by binding them to the `GL.ELEMENT_ARRAY_BUFFER` before draw calls.\n* \"generic\" buffers. These can be used interchangeably to store different types of data, including (non-index) vertex attributes.\n\nFor more on the `GL.ELEMENT_ARRAY_BUFFER` restrictions in WebGL, see [this page](https://www.khronos.org/registry/webgl/specs/1.0/#webgl_gl_differences) for WebGL 1 and [this page](https://www.khronos.org/registry/webgl/specs/2.0/#webgl_gl_differences) for WebGL 2.\n","slug":"docs/api-reference/webgl/buffer","title":"Buffer"},{"excerpt":"Framebuffer A  is a WebGL container object that the application can use for \"off screen\" rendering. A framebuffer does not itself contain…","rawMarkdownBody":"# Framebuffer\n\nA `Framebuffer` is a WebGL container object that the application can use for \"off screen\" rendering. A framebuffer does not itself contain any image data but can optionally contain attachments (one or more color buffers, a depth buffer and a stencil buffer) that store data. Attachments must be in the form of `Texture`s and `Renderbuffer`s.\n\nFor additional information, see OpenGL Wiki [Framebuffer](https://www.khronos.org/opengl/wiki/Framebuffer) and [Framebuffer Object](https://www.khronos.org/opengl/wiki/Framebuffer_Object)\n\n\n## Functionality\n\nluma.gl adds\n\n\n\n## Usage\n\nCreating a framebuffer with default color and depth attachments\n\n```js\nconst framebuffer = new Framebuffer(gl, {\n  width: window.innerWidth,\n  height: window.innerHeight,\n  color: true,\n  depth: true\n});\n\n```\n\nAttaching textures and renderbuffers\n\n```js\nframebuffer.attach({\n  [GL.DEPTH_ATTACHMENT]: new Renderbuffer(gl, {...}),\n  [GL.COLOR_ATTACHMENT0]: new Texture(gl, {...}),\n  [GL.COLOR_ATTACHMENT1]: [new TextureCube(gl, {...}), GL.TEXTURE_CUBE_MAP_POSITIVE_X],\n  [GL.COLOR_ATTACHMENT2]: [new TextureArray2D(gl, {...}), 0],\n  [GL.COLOR_ATTACHMENT3]: [new TextureArray2D(gl, {...}), 1],\n  [GL.COLOR_ATTACHMENT4]: [new Texture3D(gl, {..., depth: 8}), 2]\n});\nframebuffer.checkStatus(); // optional\n```\n\nResizing a framebuffer to the size of a window. Resizes all attachements with a single `framebuffer.resize()` call\n\n\n```js\n// Note: this resizes (and possibly clears) all attachments\nframebuffer.resize({width: window.innerWidth, height: window.innerHeight});\n```\n\nClearing a framebuffer\n\n```js\nframebuffer.clear();\nframebuffer.clear({color: [0, 0, 0, 0], depth: 1, stencil: 0});\n```\n\nSpecifying a framebuffer for rendering in each render calls\n\n```js\nconst offScreenBuffer = new Framebuffer();\nprogram1.draw({\n  framebuffer: offScreenBuffer,\n  parameters: {}\n});\nmodel.draw({\n  framebuffer: null, // the default drawing buffer\n  parameters: {}\n});\n```\n\nBinding a framebuffer for multiple render calls\n\n```js\nconst framebuffer1 = ...;\nconst framebuffer2 = ...;\nwithParameters(gl, {framebuffer: framebuffer1}, () => {\n  // Any draw call that doesn't specify a framebuffer will now draw into framebuffer1\n  program1.draw({...}); // -> framebuffer1\n  program2.draw({...}); // -> framebuffer1\n  // Explicit specification of framebuffer overrides (for that call only)\n  program2.draw({framebuffer: framebuffer1, ...); // -> framebuffer2\n  program2.draw({...}); // -> framebuffer1\n});\n// framebuffer1 is not longer bound\n```\n\n### Reading, copying or blitting data from a Framebuffer attachment.\n\nFor reading data into CPU memory check [`readPixelsToArray`](/docs/api-reference/webgl/moving-data)\n\nFor reading into a Buffer object (GPU memory), doesn't result in CPU and GPU sync, check [`readPixelsToBuffer`](/docs/api-reference/webgl/moving-data)\n\nFor reading into a Texture object (GPU memory), doesn't result in CPU and GPU sync, check [`copyToTexture`](/docs/api-reference/webgl/moving-data)\n\nFor blitting between framebuffers (WebGL 2), check [`blit`](/docs/api-reference/webgl/moving-data)\n\n\n### Using Multiple Render Targets\n\nSpecify which framebuffer attachments the fragment shader will be writing to when assigning to `gl_FragData[]`\n\n```js\nframebuffer.update({\n  drawBuffers: [\n    GL.COLOR_ATTACHMENT0, // gl_FragData[0]\n    GL.COLOR_ATTACHMENT1, // gl_FragData[1]\n    GL.COLOR_ATTACHMENT2, // gl_FragData[2]\n    GL.COLOR_ATTACHMENT3  // gl_FragData[3]\n  ]\n})\n```\n\nWriting to multiple framebuffer attachments in GLSL fragment shader\n\n```\n#extension GL_EXT_draw_buffers : require\nprecision highp float;\nvoid main(void) {\n  gl_FragData[0] = vec4(0.25);\n  gl_FragData[1] = vec4(0.5);\n  gl_FragData[2] = vec4(0.75);\n  gl_FragData[3] = vec4(1.0);\n}\n```\n\nClearing a specific draw buffer in a framebuffer (WebGL 2)\n```js\nframebuffer.clear({\n  [GL.COLOR]: [0, 0, 1, 1], // Blue\n  [GL.COLOR]: new Float32Array([0, 0, 0, 0]), // Black/transparent\n  [GL.DEPTH_BUFFER]: 1, // Infinity\n  [GL.STENCIL_BUFFER]: 0, // no stencil\n});\n\nframebuffer.clear({\n  [GL.DEPTH_STENCIL_BUFFER]: [1, 0], // Infinity, no stencil\n});\n```\n\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nCreates a new framebuffer, optionally creating and attaching `Texture` and `Renderbuffer` attachments.\n\n```\nnew Framebuffer(gl, {\n  id,\n  width,\n  height,\n  attachments,\n  color,\n  depth,\n  stencil\n})\n```\n\n* `id`= - (*String*) - An optional name (id) of the buffer.\n* `width`=`1` - (*number*) The width of the framebuffer.\n* `height`=`1` - (*number*) The height of the framebuffer.\n* `attachments`={} - (*Object*, optional) - a map of Textures and/or Renderbuffers, keyed be \"attachment points\" (see below).\n* `color` - shortcut to the attachment in `GL.COLOR_ATTACHMENT0`\n* `depth` - shortcut to the attachment in `GL.DEPTH_ATTACHMENT`\n* `stencil` - shortcut to the attachment in `GL.STENCIL_ATTACHMENT`\n\nThe luma.gl `Framebuffer` constructor enables the creation of a framebuffer with all the proper attachments in a single step and also the `resize` method makes it easy to efficiently resize a all the attachments of a `Framebuffer` with a single method.\n\nWhen no attachments are provided during `Framebuffer` object creation, new resources are created and used as default attachments for enabled targets (color and depth).\nFor color, new `Texture2D` object is created with no mipmaps and following filtering parameters are set.\n\n| Texture parameter       | Value |\n| ---                     | --- |\n| `GL.TEXTURE_MIN_FILTER` | `GL.LINEAR` |\n| `GL.TEXTURE_MAG_FILTER` | `GL.LINEAR` |\n| `GL.TEXTURE_WRAP_S`     | `GL.CLAMP_TO_EDGE` |\n| `GL.TEXTURE_WRAP_T`     | `GL.CLAMP_TO_EDGE` |\n\nFor depth, new `Renderbuffer` object is created with `GL.DEPTH_COMPONENT16` format.\n\n\n### delete()\n\nDestroys the underlying WebGL object. When destroying `Framebuffer`s it can be important to consider that a `Framebuffer` can manage other objects that may also need to be destroyed.\n\n\n### initialize(props : Object) : Framebuffer\n\nInitializes the `Framebuffer` to match the supplied parameters. Unattaches any existing attachments, attaches any supplied attachments. All new attachments will be resized if they are not already at the right size.\n\n`Framebuffer.initialize({width, height})`\n\n* `width`=`1` - (*number*) The width of the framebuffer.\n* `height`=`1` - (*number*) The height of the framebuffer.\n* `attachments`={} - (*Object*, optional) - a map of Textures and/or Renderbuffers, keyed be \"attachment points\" (see below).\n* `color` - shortcut to the attachment in `GL.COLOR_ATTACHMENT0`\n* `depth` - shortcut to the attachment in `GL.DEPTH_ATTACHMENT`\n* `stencil` - shortcut to the attachment in `GL.STENCIL_ATTACHMENT`\n\n\n### update(options: Object) : Framebuffer\n\nUpdates Framebuffers attachments using provided Texture and Renderbuffer objects. Optionally sets read and draw buffers when using WebGL 2 context.\n\n* `attachments` - a map of attachments.\n* `readBuffer` - Buffer to be set as read buffer (WebGL 2)\n* `drawBuffers` - Buffers to be set as draw buffers (WebGL 2)\n* `clearAttachments` - When set to true, will first unattach all  binding points, default value is `false`.\n* `resizeAttachments` - When set to true, all attachments will be re-sized to Framebuffers size, default value is `true`.\n\n### resize({width: Number, height: Number}) : Framebuffer\n\n`Framebuffer.resize({width, height})`\n\nResizes all the `Framebuffer`'s current attachments to the new `width` and `height` by calling `resize` on those attachments.\n\n* `width` (GLint) - width of `Framebuffer` in pixels\n* `height` (GLint) - height of `Framebuffer` in pixels\n\nReturns itself to enable chaining\n\n* Each attachment's `resize` method checks if `width` or `height` have actually changed before reinitializing their data store, so calling `resize` multiple times with the same `width` and `height` does not trigger multiple resizes.\n* If a resize happens, `resize` erases the current content of the attachment in question.\n\nWebGL References see `initialize`.\n\n\n### attach(attachments : Object, options: Object) : Framebuffer\n\nUsed to attach or unattach `Texture`s and `Renderbuffer`s from the `Framebuffer`s various attachment points.\n\n`Framebuffer.attach(attachments)`\n\n* `attachments` - a map of attachments.\n* options\n  * `clearAttachments` - When set to true, will first unattach all  binding points, default value is `false`.\n  * `resizeAttachments` - When set to true, all attachments will be re-sized to Framebuffers size, default value is `true`.\n\n\nReturns itself to enable chaining.\n\nThe key of an attachment must be a valid attachment point, see below.\n\nThe following values can be provided for each attachment\n* `null` - unattaches any current binding\n* `Renderbuffer` - attaches the `Renderbuffer`\n* `Texture` - attaches the `Texture`\n* [`Texture`, layer=0 (Number), mipmapLevel=0 (Number)] - attaches the specific layer from the `Texture` (WebGL 2)\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.framebufferRenderbuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/framebufferRenderbuffer),\n[`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer),\n[`gl.framebufferTexture2D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/framebufferTexture2D),\n[`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer),\n[`gl.framebufferTextureLayer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/framebufferTextureLayer),\n[`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer) (This is for WebGL 2 only)\n\n\n### checkStatus() : Framebuffer\n\nCheck that the framebuffer contains a valid combination of attachments\n\n[`gl.checkFramebufferStatus`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/checkFramebufferStatus), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n\n### clear(options: Object) : Framebuffer\n\nClears the contents (pixels) of the framebuffer attachments.\n\n* `options.color` (Boolean or Array) - clears all active color buffers (any selected `drawBuffer`s) with either the provided color or the default color.\n* `options.depth`\n* `options.stencil`\n* `options.drawBuffers`=`[]` - An array of color values, with indices matching the buffers selected by `drawBuffers` argument.\n\nNotes:\n* The scissor box bounds the cleared region.\n* The pixel ownership test, the scissor test, dithering, and the buffer writemasks affect the operation of `clear`.\n* Alpha function, blend function, logical operation, stenciling, texture mapping, and depth-buffering are ignored by `clear`.\n\n### invalidate (WebGL 2)\n\nSignals to the GL that it need not preserve the pixels of a specified region of the framebuffer (by default all pixels of the specified framebuffer attachments are invalidated).\n\nParameters\n* attachments - list of attachments to invalidate\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.invalidateFramebuffer`](WebGL2RenderingContext.invalidateFramebuffer()), [`gl.invalidateSubFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/invalidateSubFramebuffer), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n## Limits\n\n* `GL.MAX_COLOR_ATTACHMENTS` - The maximum number of color attachments supported. Can be `0` in WebGL 1.\n* `GL.MAX_DRAW_BUFFERS` - The maximum number of draw buffers supported. Can be `0` in WebGL 1, which means that `gl_FragData[]` is not available in shaders.\n\nIt is possible that you can have a certain number of attachments, but you can't draw to all of them at the same time.\n\n\n## Framebuffer Parameters\n\n### Framebuffer Attachment Points\n\n| Attachment Point              | Description |\n| ---                           | --- |\n| `GL.COLOR_ATTACHMENT0`   | Attaches the texture to one of the framebuffer's color buffers |\n| `GL.COLOR_ATTACHMENT`{1-15}   | Attaches the texture to one of the framebuffer's color buffers |\n| `GL.DEPTH_ATTACHMENT`         | Attaches the texture to the framebuffer's depth buffer |\n| `GL.STENCIL_ATTACHMENT`       | Attaches the texture to the framebuffer's stencil buffer |\n| `GL.DEPTH_STENCIL_ATTACHMENT` | Combined depth and stencil buffer |\n\n* The attachment point `GL.BACK` refersn to the default framebuffer's back buffer.\n\n* The set of available attachments is larger in WebGL 2, and also the extensions `WEBGL_draw_buffers` and `WEBGL_depth_texture` provide additional attachments that match or exceed the WebGL 2 set.\n\n\n### Framebuffer Attachment Values\n\nThe following values can be provided for each attachment point\n* `null` - unattaches any current binding\n* `Renderbuffer` - attaches the `Renderbuffer`\n* `Texture2D` - attaches at mipmapLevel 0 of the supplied `Texture2D`.\n* [`Texture2D`, 0, mipmapLevel] - attaches the specified mipmapLevel from the supplied `Texture2D` (WebGL 2), or cubemap face. The second element in the array must be `0`. In WebGL 1, mipmapLevel must be 0.\n* [`TextureCube`, face (Number), mipmapLevel=0 (Number)] - attaches the specifed cubemap face from the `Texture`, at the specified mipmap level. In WebGL 1, mipmapLevel must be 0.\n* [`Texture2DArray`, layer (Number), mipmapLevel=0 (Number)] - attaches the specifed layer from the `Texture2DArray`, at the specified mipmap level.\n* [`Texture3D`, layer (Number), mipmapLevel=0 (Number)] - attaches the specifed layer from the `Texture3D`, at the specified mipmap level.\n\n\n## Remarks\n\n* In the raw WebGL API, creating a set of properly configured and matching textures and renderbuffers can require a lot of careful coding and boilerplate.\n* This is further complicated by many capabilities (such as support for multiple color buffers and various image formats) depending on WebGL extensions or WebGL versions.\n","slug":"docs/api-reference/webgl/framebuffer","title":"Framebuffer"},{"excerpt":"Moving Data  offers a set of functions that copy or blit data from and to Texture and Framebuffer objects. Image data can also be copied…","rawMarkdownBody":"# Moving Data\n\n`luma.gl` offers a set of functions that copy or blit data from and to Texture and Framebuffer objects. Image data can also be copied into Buffer, TypedArray, Images or Urls.\n\n\n## Readback Functions\n\n### readPixelsToArray(source : Framebuffer|Texture [, options: Object]) : TypedArray\n\nReads data from a `Framebuffer` or `Texture` object into a TypedArray object and returns it. A new TypedArray object is created when not provided. This method requires a sync between CPU and GPU as pixel values are copied from GPU texture memory to CPU Array object memory. This could introduce a delay as it waits for GPU to finish updating the texture. For asynchronous read, check `copyToBuffer` method.\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n\n  Optional parameters:\n  * `options.sourceX` - (*number*, default: 0) X offset of the area to be copied,\n  * `options.sourceY` - (*number*, default: 0) Y offset of the area to be copied,\n  * `options.sourceFormat` - (*GLenum*, default: GL.RGBA) The format of the data.\n  * `options.sourceAttachment` - (*GLenum*, default: `COLOR_ATTACHMENT0`) Used to deduce the `type` when not provided.\n  * `options.target` - (*TypedArray*, default: null) Array object, into which data to be copied, new object is created when not provided.\n  * `options.sourceWidth` - (*number*, default: source width) The width of the area to be copied.\n  * `options.sourceHeight` - (*number*, default: source height) The height of the area to be copied.\n  * `options.sourceType` - (*GLenum*, default: type of `pixelArray` or `UNSIGNED_BYTE`) The type of the data.\n\nNotes:\n  * Reading from floating point textures is dependent on an extension both in WebGL 1 and WebGL 2.\n  * When supported, the `{format: GL.RGBA, type: GL.FLOAT, ...}` combination becomes valid for reading from a floating-point color buffer.\n  * When color attachment is a float texture with format less than 4 channels, i.e, `GL.R32F`, or  `GL.RG32F`, `readPixels` should still be called with a 4 component `format`(`GL.RGBA`), and default value (R:0, G:0, B: 0 and A: 1) will be returned for un-used channel.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.readPixels`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/readPixels), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n### readPixelsToBuffer(source : Framebuffer|Texture, options: Object) : Buffer (WebGL 2)\n\nReads data from a `Framebuffer` or `Texture` object into A `Buffer` object and returns it. A new `Buffer` object is created when not provided. This method avoids a sync between CPU and GPU as pixel values are copied from GPU texture memory to GPU Buffer memory. This method returns right away without any delays.\n\nA CPU and GPU sync will be triggered when the returned buffer data is read using `buffer.getData()`, but applications can delay this read, which can reduces the delay due to the sync, or the sync can be completely avoided by using the `Buffer` as the source of input to the GPU (either as `ARRAY_BUFFER` or `PIXEL_UNPACK_BUFFER`).\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n\n  Optional parameters:\n  * `options.sourceX` - (*number*, default: 0) X offset of the area to be copied,\n  * `options.sourceY` - (*number*, default: 0) Y offset of the area to be copied,\n  * `options.sourceFormat` - (*GLenum*, default: GL.RGBA) The format of the data.\n  * `options.target` - (*Buffer*) Buffer object, into which data to be copied, new object is created when not provided.\n  * `options.targetByteOffset` - (*number*, default: 0) Byte offset from which data should be copied into buffer.\n  * `options.sourceWidth` - (*number*, default: source.width) The width of the area to be copied,\n  * `options.sourceHeight` - (*number*, default: source.height) The height of the area to be copied,\n  * `options.sourceType` - (*GLenum*, default: type of `target` or `UNSIGNED_BYTE`) The type of the data.\n\nNotes:\n  * Reading from floating point textures is dependent on an extension both in WebGL 1 and WebGL 2.\n  * When supported, the `{format: GL.RGBA, type: GL.FLOAT, ...}` combination becomes valid for reading from a floating-point color buffer.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.readPixels`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/readPixels), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer), [`gl.bindBuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindBuffer)\n\n\n## Copy Functions\n\n### copyToDataUrl(source : Framebuffer|Texture, options: Object) : Data URL\n\nReads data form a `Texture` or `Framebuffer` object and returns a `Data URL` containing the pixel data in PNG format.\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n\n  Optional parameters:\n  * `options.sourceAttachment` - (*GLenum*, default: `COLOR_ATTACHMENT0`) Used to deduce the `type` when not provided.\n  * `options.targetMaxHeight` - (*number*, default: Number.MAX_SAFE_INTEGER) Maximum height of the image to be in returned Data URL.\n\nNote:\n  * Works only under a browser environment, doesn't work under Node.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.readPixels`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/readPixels), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n### copyToImage(source : Framebuffer|Texture, options: Object) : Image\n\nReads data form a `Texture` or `Framebuffer` object and copies it to provided image, new `Image` instance is created if not provided.\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n\n  Optional parameters:\n  * `options.sourceAttachment` - (*GLenum*, default: `COLOR_ATTACHMENT0`) Used to deduce the `type` when not provided.\n  * `options.targetImage` - (`Image`, Optional) `Image` to to which pixel data to be copied, new one is created if not provide.\n\nNote:\n  * Works only under a browser environment, doesn't work under Node.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.readPixels`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/readPixels), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n\n### copyToTexture(source : Framebuffer|Texture, target: Texture|GL-enum, options: Object) : Texture\n\nCopies pixels from a `Framebuffer` or `Texture` object into the specified area of a two-dimensional texture image or cube-map texture image. (gl.copyTexImage2D, gl.copyTexSubImage2D and gl.copyTexSubImage3D wrapper)\n\n  * `source` (`Texture` or `Framebuffer`) - If provided this object will be bound and data copied from it.\n  * `target` (`Texture` or `GL enum`) - Texture object or GL enum specifying the target binding point, to which data to be copied. If target binding point is specified, it is assumed that a valid texture object is already bound.\n  * `options.sourceX` (`GLint`, optional, default: 0) - x coordinate of the lower left corner where to start copying.\n  * `options.sourceY` (`GLint`, optional, default: 0) - y coordinate of the lower left corner where to start copying.\n  * `options.targetX` (`GLint`, optional) - X offset with in target texture.\n  * `options.targetY` (`GLint`, optional) - Y offset with in target texture.\n  * `options.targetZ` (`GLint`, optional, WebGL 2) - Z offset with in target texture, when using copying into 2D Array of 3D texture.\n  * `options.width` (`GLint`, optional, default: texture.width) - Width of the pixel rectangle to be copied.\n  * `options.height` (`GLint`, optional, default: texture.height) - Height of the pixel rectangle to be copied.\n\nNotes:\n  * `targetX`, `targetY`, `targetZ` : when an offset is specified, it implies we are copying data into a sub region of the target texture and internally `gl.copyTexSubImage2D` or `gl.copyTexSubImage3D` are used based on the `target`, for these cases it is assumed that target texture has enough GPU memory already allocated. When none of the offsets are specified, `gl.copyTexImage2D` is used to copy data to entire target region and GPU memory is allocated if needed, target texture GPU memory doesn't have to be pre-allocated.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.copyTexImage2D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/copyTexImage2D), [`gl.copyTexSubImage2D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/copyTexSubImage2D) and [`gl,copyTexSubImage3D`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/copyTexSubImage3D)\n\n\n## Blit Functions\n\n### blit(options: Object) : (WebGL 2)\n\nCopies a rectangle of pixels from a `Texture` or `Framebuffer` object into a `Texture` or `Framebuffer` object.\n\n  * `source` (`Texture` or `Framebuffer`) - This object will be bound and data copied from it.\n  * `options.target` (`Texture` or `Framebuffer`) - This object will be bound and data is copied into it.\n  * `options.sourceAttachment` (`GLenum`, default: `COLOR_ATTACHMENT0`) - Attachment index from which data to be copied from.\n  * `options.sourceX0` (`GLint`, default: `0`) - Lower X bound of copy rectangle in source.\n  * `options.sourceY0` (`GLint`, default: `0`) - Lower Y bound of copy rectangle in source.\n  * `options.sourceX1` (`GLint`) - Higher X bound of copy rectangle in source.\n  * `options.sourceY1` (`GLint`) - Higher Y bound of copy rectangle in source.\n  * `options.targetX0` (`GLint`, default: `0`) - Lower X bound of copy rectangle in destination.\n  * `options.targetY0` (`GLint`, default: `0`) - Lower Y bound of copy rectangle in destination.\n  * `options.targetX1` (`GLint`) - Higher X bound of copy rectangle in destination.\n  * `options.targetY1` (`GLint`) - Higher Y bound of copy rectangle in destination.\n  * `options.mask` (`GLbitfild`, default: `0`) - A `GLbitfield` specifying a bitwise OR mask indicating which buffers are to be copied, possible buffers masks are `GL.COLOR_BUFFER_BIT`, `GL.DEPTH_BUFFER_BIT` and ` GL.STENCIL_BUFFER_BIT`\n  * `options.color` (`Boolean`, default: `true`) - When true `GL.COLOR_BUFFER_BIT` is added to the mask.\n  * `options.depth` (`Boolean`, default: `false`) - When true `GL.DEPTH_BUFFER_BIT` is added to the mask.\n  * `options.stencil` (`Boolean`, default: `false`) - When true `GL.STENCIL_BUFFER_BIT` is added to the mask.\n  * `options.filter`=`GL.NEAREST` - specifies interpolation mode if stretching is needed. `GL.LINEAR` can be used exclusively for color buffers.\n\nNotes:\n  * There are a number of restrictions when blitting between integer and floating point formats.\n\nThis function makes calls to the following WebGL APIs:\n\n[`gl.blitFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/blitFramebuffer), [`gl.readBuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/readBuffer), [`gl.bindFramebuffer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindFramebuffer)\n","slug":"docs/api-reference/webgl/moving-data","title":"Moving Data"},{"excerpt":"Resource Overview The  class is the base class of all WebGL resource classes (e.g. , , etc.) Usage Resources must be created through…","rawMarkdownBody":"# Resource\n\n## Overview\n\nThe `Resource` class is the base class of all WebGL resource classes (e.g. `Buffer`, `Texture`, etc.)\n\n## Usage\n\nResources must be created through subclasses, e.g.\n```js\nconst resource = new Buffer(gl);\n```\n\nDeleting a resource\n```js\nconst resource = new Buffer(gl);\nresource.delete();\n```\n\nGetting parameters\n```js\nconst resource = new Texture2d(gl);\nresource.getParameters(); // Returns object with values keyed by GL constants.\nresource.getParameters({keys: true}); // Returns object with keys and enum values converted to strings.\n```\n\n## Methods\n\n### constructor\n\n* `gl` - WebGL context, which is stored on the object.\n* `opts` - options\n* `opts.id` (string) - stores a string id, helpful for printing and debugging.\n* `opts.handle` - by supplying an existing handle, the object will be created\n  as a wrapper for that handle (instead of creating a new handle). This\n  allows you to use the luma.gl class methods to interface with WebGL resource\n  handles created using the raw WebGL API or through other WebGL frameworks.\n  luma.gl will make an attempt to extract information about the handle to\n  enable as much functionality as possible, although some operations may\n  not be possible on imported handles. Also, imported handles can\n  typically not be automatically reinitialized after context loss.\n\n### delete\n\n* Deletes any WebGL resources associated with this resources (i.e the underlying WebGLResource handle).\n\n### getParameter(pname)\n\nGets a given parameter from the resource.\n\n* Note querying for parameters in WebGL is slow and should be avoided in loops and other performance critical situations.\n\n### getParameters(parameters)\n\nGets list of parameters from the resource (or all parameters).\n\nIf the special parameter `keys` is set to true, keys and enumerations will be converted to strings.\n\n* Note querying for parameters in WebGL is slow and should be avoided in loops and other performance critical situations.\n* Note - querying without parameters returns all parameters. This can be useful during debugging.\n\n\n## Properties\n\n### `gl`\n\nThe WebGL context is stored on the object.\n\n### `id`\n\nStores a string id, helpful for printing and debugging.\n\n### `userData`\n\nAn empty object to which the application can add keys and values. Note that\nthe resource object. itself is sealed to prevent additional key being added,\nand any keys and values added directly to the underlying WebGL object will\nbe lost during WebGL context loss.\n","slug":"docs/api-reference/webgl/resource","title":"Resource"},{"excerpt":"Shader The  class are the base class for  class and  class Usage Create a pair of shaders Members  - holds the underlying  object…","rawMarkdownBody":"# Shader\n\nThe `Shader` class are the base class for `VertexShader` class and `FragmentShader` class\n\n\n## Usage\n\nCreate a pair of shaders\n```js\nconst fs = new VertexShader(gl, source);\nconst fs = new FragmentShader(gl, source);\n```\n\n## Members\n\n* `handle` - holds the underlying `WebGLShader` object\n\n\n## Constructor\n\n### Shader(gl : WebGLRenderingContext, source : String)\n\n* `source` - string containing shader instructions.\n\n\n\n## Remarks\n\n* Shader sources: A `Program` needs to be constructed with two strings containing source code for vertex and fragment shaders.\n* Default Shaders: luma.gl comes with a set of default shaders that can be used for basic rendering and picking.\n","slug":"docs/api-reference/webgl/shader","title":"Shader"},{"excerpt":"Renderbuffer s are WebGL Objects that contain textures. They are optimized for use as render targets, while vanilla s may not be, and are…","rawMarkdownBody":"# Renderbuffer\n\n`Renderbuffer`s are WebGL Objects that contain textures. They are optimized for use as render targets, while vanilla `Texture`s may not be, and are the logical choice when you do not need to sample (i.e. in a post-pass shader) from the produced image. If you do need to sample (such as when reading depth back in a second shader pass), use [`Texture`](/docs/api-reference/webgl/texture) instead. In addition, in WebGL 2, `Renderbuffer` can do [Multisampling (MSAA)](https://www.khronos.org/opengl/wiki/Multisampling) just like standard framebuffer.\n\nFor additional information, see [OpenGL Wiki](https://www.opengl.org/wiki/Renderbuffer_Object)\n\n\n## Usage\n\nCreating a `Renderbuffer`\n```js\nconst renderbuffer = new Renderbuffer(gl, {format: GL.RGBA4, width: 100, height: 100});\n```\n\nReformatting/reinitializing a `Renderbuffer`\n```js\nconst renderbuffer = new Renderbuffer(gl, {format: GL.RGBA4, width: 100, height: 100});\nrenderbuffer.initialize({format: GL.RGB565, width: 50, height: 50});\n```\n\nResizing a `Renderbuffer`\n```js\nconst renderbuffer = new Renderbuffer(gl, {format: GL.RGBA4});\nrenderbuffer.resize({width: 200, height: 200});\n```\n\nAttaching a `Renderbuffer` to a `Framebuffer` (automatically resizes the `Renderbuffer`)\n```js\nframebuffer.attach({\n  [GL.DEPTH_ATTACHMENT]: new Renderbuffer(gl, {format: GL.DEPTH_COMPONENT16})\n });\n```\n\n## Members\n\n* `id` (string) - id for debugging\n* `handle` (`WebGLRenderbuffer`) - the underlying WebGLRenderbuffer object\n* `width` (number) - width of renderbuffer in pixels\n* `height` (number) - height of renderbuffer in pixels\n* `format` (number) - internal format of the renderbuffer (e.g. `GL.DEPTH_COMPONENT16`)\n* `samples` (number) - samples (always `0` in non-WebGL 2 contexts)\n\n\n## Methods\n\n### getSamplesForFormat (static method)\n\nQueries valid sample counts for a `Renderbuffer` format. The sample counts can be provided as a parameter to the `Renderbuffer` constructor.\n\n`Renderbuffer.getSamplesForFormat({format})`\n\n* `format` (GLenum) - internal format of the renderbuffer (e.g. `GL.DEPTH_COMPONENT16`)\n\nReturns (Number[]) - An list of valid sample counts in descending order.\n\nIf multisampling is not supported the returned value will be `[0]`, e.g. signed and unsigned integer internal formats in WebGL 2. Note that this method always returns `[0]` in WebGL 1.\n\n### constructor\n\nCreates a new `Renderbuffer` and initalizes it by calling `initialize` with the provided parameters.\n\n`new Renderbuffer(gl, {id=, format, width, height, samples=})`\n\n* `gl` (WebGLRenderingContext) - gl context\n* `id`= (String) - optional string id\n* `format` (GLenum) - internal format of the renderbuffer (e.g. `GL.DEPTH_COMPONENT16`)\n* `width`=`1` (GLint) - width of renderbuffer in pixels\n* `height`=`1` (GLint) - height of renderbuffer in pixels\n* `samples`=0 (GLint) - (WebGL 2) number of samples to be used for storage.\n\nWebGL References [gl.createRenderbuffer](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/createRenderbuffer), also see `initialize`.\n\n### initialize\n\nCreates and initializes a renderbuffer object's data store. Used to update a `Renderbuffer`s format and size after it was initially created.\n\n`Renderbuffer.initialize({format, width, height, samples=})`\n\n* `format` (GLenum) - internal format of the renderbuffer (e.g. `GL.DEPTH_COMPONENT16`)\n* `width`=`1` (GLint) - width of renderbuffer in pixels\n* `height`=`1` (GLint) - height of renderbuffer in pixels\n* `samples`=0 (GLint) - (WebGL 2) number of samples to be used for storage.\n\nReturns itself to enable chaining\n\n* `initialize` erases the current content of the `Renderbuffer`.\n\n\nWebGL References [gl.renderbufferStorage](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/renderbufferStorage), [gl.renderbufferStorageMultisample](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/renderbufferStorageMultisample) (WebGL 2), [gl.bindRenderbuffer](WebGLRenderingContext.bindRenderbuffer())\n\n### resize\n\nReinitializes the `Renderbuffer`'s data store with the new `width` and `height` but unchanged `format` (and `samples`, if available).\n\n`Renderbuffer.resize({width, height})`\n\n* `width` (GLint) - width of `Renderbuffer` in pixels\n* `height` (GLint) - height of `Renderbuffer` in pixels\n\nReturns itself to enable chaining\n\n* Checks if `width` or `height` have actually changed before calling `initialize`.\n* If a resize happens, `resize` erases the current content of the `Renderbuffer`.\n\nWebGL References see `initialize`.\n\n## Renderbuffer Formats\n\nThe \"internal\" format of the `Renderbuffer`.\n\n| Value                  | Description |\n| ---                    | --- |\n| `GL.RGBA4`             |  4 red bits, 4 green bits, 4 blue bits 4 alpha bits |\n| `GL.RGB565`            |  5 red bits, 6 green bits, 5 blue bits |\n| `GL.RGB5_A1`           |  5 red bits, 5 green bits, 5 blue bits, 1 alpha bit |\n| `GL.DEPTH_COMPONENT16` |  16 depth bits |\n| `GL.STENCIL_INDEX8`    |  8 stencil bits |\n\nThis table lists the basic formats supported in WebGL 1. For a full table of formats supported in WebGL 2 and via WebGL extensions, see [Texture](/docs/api-reference/webgl/texture).\n\n| Sized Internal Format   | Format               | Type | Depth Bits | Stencil Bits |\n| ---                     | ---                  | ---  | ---        | --- |\n| `GL.DEPTH_COMPONENT16`  | `GL.DEPTH_COMPONENT` | `GL.UNSIGNED_SHORT`, `GL.UNSIGNED_INT` | 16 | 0 |\n| `GL.DEPTH_COMPONENT24`  | `GL.DEPTH_COMPONENT` | `GL.UNSIGNED_INT` | 24 | 0 |\n| `GL.DEPTH_COMPONENT32F` | `GL.DEPTH_COMPONENT` | `GL.FLOAT` | f32 | 0 |\n| `GL.DEPTH24_STENCIL8`   | `GL.DEPTH_STENCIL`   | `GL.UNSIGNED_INT_24_8` | 24 | 8 |\n| `GL.DEPTH32F_STENCIL8`  | `GL.DEPTH_STENCIL`   | `GL.FLOAT_32_UNSIGNED_INT_24_8_REV` | f32 | 8 |\n\n\nWhen using the WEBGL_depth_texture extension:\n`GL.DEPTH_COMPONENT`\n`GL.DEPTH_STENCIL`\nWhen using the EXT_sRGB extension:\n`EXT.SRGB_EXT`\n`EXT.SRGB_ALPHA_EXT`\n\nWhen using a WebGL 2 context, the following values are available additionally:\n* `GL.R8`\n* `GL.R16F`\n* `GL.R32F`\n* `GL.R8UI`\n* `GL.RG8`\n* `GL.RG16F`\n* `GL.RG32F`\n* `GL.RGUI`\n* `GL.RGB8`\n* `GL.SRGB8`\n* `GL.RGB565`\n* `GL.R11F_G11F_B10F`\n* `GL.RGB9_E5`\n* `GL.RGB16F`\n* `GL.RGB32F`\n* `GL.RGB8UI`\n* `GL.RGBA8`\n* `GL.SRGB_APLHA8`\n* `GL.RGB5_A1`\n* `GL.RGBA4444`\n* `GL.RGBA16F`\n* `GL.RGBA32F`\n* `GL.RGBA8UI`\n\n\n## Parameters\n\n| Parameter                          | Type   | Read/Write |Description |\n| ---                                | ---    | ---        | --- |\n| `GL.RENDERBUFFER_WIDTH`            | GLint  | R | height of the image of renderbuffer |\n| `GL.RENDERBUFFER_HEIGHT`           | GLint  | R | height of the image of renderbuffer |\n| `GL.RENDERBUFFER_INTERNAL_FORMAT`  | GLenum | R | See below |\n| `GL.RENDERBUFFER_GREEN_SIZE`       | GLint  | R | resolution (bits) of green color |\n| `GL.RENDERBUFFER_BLUE_SIZE`        | GLint  | R | resolution (bits) of blue color |\n| `GL.RENDERBUFFER_RED_SIZE`         | GLint  | R | resolution (bits) of red color |\n| `GL.RENDERBUFFER_ALPHA_SIZE`       | GLint  | R | resolution (bits) of alpha component |\n| `GL.RENDERBUFFER_DEPTH_SIZE`       | GLint  | R | resolution (bits) of depth component |\n| `GL.RENDERBUFFER_STENCIL_SIZE`     | GLint  | R | resolution (bits) of stencil component |\n| `GL.RENDERBUFFER_SAMPLES` (WebGL 2) | GLint  | R | |\n\n## Limits\n\n| Limit                      |                               | WebGL 2   | WebGL 1 |\n| ---                        |---                            | ---      | ---    |\n| `GL.MAX_RENDERBUFFER_SIZE` | Max renderbuffer width/height | `>=2048` | `>=1`  |\n| `GL.MAX_SAMPLES`           | Max samples for multisampling | `>=4`    | `0`    |\n\n\n## Remarks\n\n* The only way to work with a renderbuffer, besides creating it, is to attach it to a [`Framebuffer`](/docs/api-reference/webgl/framebuffer).\n* A `Renderbuffer` cannot be accessed by a shader in any way.\n* Multisampling is only available in WebGL 2\n","slug":"docs/api-reference/webgl/renderbuffer","title":"Renderbuffer"},{"excerpt":"Texture2D 2D textures hold basic \"single image\" textures (although technically they can contain multiple mipmap levels). They hold image…","rawMarkdownBody":"# Texture2D\n\n2D textures hold basic \"single image\" textures (although technically they can contain multiple mipmap levels). They hold image memory of a certain format and size, determined at initialization time. They can be read from using shaders and written to by attaching them to frame buffers.\n\nMost texture related functionality is implemented by and documented on the [Texture](/docs/api-reference/webgl/texture) base class. For additional information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Texture).\n\n\n## Usage\n\nConstruct a new texture from an image\n```js\nconst texture = new Texture2D(gl, {\n  data: image,\n  parameters: {\n    [GL.TEXTURE_MAG_FILTER]: GL.NEAREST,\n    [GL.TEXTURE_MIN_FILTER]: GL.NEAREST\n  },\n  pixelStore: {\n    [GL.UNPACK_FLIP_Y_WEBGL]: true,\n  },\n  mipmaps: true\n});\n```\n\nConstruct a texture initialized with a data array\n```js\nconst texture = new Texture2D(gl, {\n  width: 2,\n  height: 1,\n  format: GL.RGB,\n  data: new Uint8Array([255, 0, 0,  0, 0, 255]),\n  parameters: {\n    [GL.TEXTURE_MAG_FILTER]: GL.NEAREST,\n    [GL.TEXTURE_MIN_FILTER]: GL.NEAREST\n  },\n  pixelStore: {\n    [GL.UNPACK_FLIP_Y_WEBGL]: true\n  },\n  mipmaps: true\n});\n```\n\nConstruct an empty 1x1 texture\n```js\nconst texture = new Texture2D(gl);\n```\n\nResize it (this clears the texture).\n```js\ntexture.resize({width: 10, height: 10});\n```\n\nWrite a sub image into the texture\n```js\ntexture.setSubImageData({pixels, x, y, width, height, level, type, dataFormat});\n```\n\nAccessing elements\n```js\nconsole.log(\n  texture2D.width,\n  texture2D.height,\n  texture2D.format,\n  texture2D.type,\n  texture2D.getParameter(GL.TEXTURE_MAG_FILTER)\n);\n```\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object | data : any)\n\n```\nimport {Texture2D} from '@luma.gl/webgl'\nconst texture1 = new Texture2D(gl, {\n  data: ...,\n  width: ...,\n  height: ...,\n  mipmaps: ...,\n  format: ...,\n  type: ...,\n  dataFormat: ...,\n  parameters: ...\n});\n```\n\nThere is also a short form where the image data (or a promise resolving to the image data) can be the second argument of the constructor:\n\n```\nimport {Texture2D} from '@luma.gl/webgl';\nimport {loadImage} from '@loaders.gl/core';\n\nconst texture1 = new Texture2D(gl, loadImage(url));\n// equivalent to\nconst texture1 = new Texture2D(gl, {data: loadImage(url)});\n\n```\n\n* `gl` (WebGLRenderingContext) - gl context\n* `data`=null (*) - If not provided (null), a solid color texture will be allocated of the specified size.\n* `width`=`0` (*Number*) - The width of the texture.\n* `height`=`0` (*Number*) - The height of the texture.\n* `mipmaps`= - (*Boolean*) - Generates mipmaps when true.\n* `format`=`GL.RGBA` (*GLenum* ) - internal format that WebGL should use.\n* `type`= (*enum*) - type of pixel data (`GL.UNSIGNED_BYTE`, `GL.FLOAT` etc). Default is autodeduced from `format`.\n* `dataFormat`= (*GLenum*) - internal format that WebGL should use. Default is autodeduced from `format`.\n* `parameters`=`{}` (*object*) - map of texture sampler parameters.\n* `pixelStore`=`{}` (*object*) - map of pixel store parameters (controls how `data` is interpreted when Textures are initialized from memory)\n\nNotes:\n* setting `mipmaps` to true when `format` set to `RGB32F` will fail, even though `RGB32F` is supported texture format (with EXT_color_buffer_float), it is not supported as renderable format.\n\nNote that since many of the constructor parameters are common to all the `Texture` classes they are detailed in [`Texture`](/docs/api-reference/webgl/texture). Pixel store parameters are specified in [State Management](/docs/api-reference/gltools/parameter-setting)\n","slug":"docs/api-reference/webgl/texture-2d","title":"Texture2D"},{"excerpt":"Texture3D (WebGL 2) 3D textures hold basic volumetric textures and can be thought of 3-dimentional arrays with a width, height and depth…","rawMarkdownBody":"# Texture3D (WebGL 2)\n\n3D textures hold basic volumetric textures and can be thought of 3-dimentional arrays with a width, height and depth. They hold image memory of a certain format and size, determined at initialization time. They can be sampled in shaders using the `texture` function with a 3D texture coordinate.\n\nMost texture related functionality is implemented by and documented on the [Texture](/docs/api-reference/webgl/texture) base class. For additional information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Texture).\n\n\n## Usage\n\nCreate a new 3D texture\n```js\nif (Texture3D.isSupported()) {\n  texture3D = new Texture3D(gl, {...});\n}\n```\n\n\n## Members\n\n* `handle` - The underlying `WebGLTexture`\n* `target` - Always `GL.TEXTURE_3D`\n* `width` - width of texture\n* `height` - height of texture\n* `depth` - depth of the texture\n* `format` - format of texture\n\n\n## Methods\n\n`Texture3D` is a subclass of the [Texture](/docs/api-reference/webgl/texture) and [Resource](/docs/api-reference/webgl/resource) classes and inherit all methods and members of those classes. Note that `setSubImageData` is not currently supported for 3D textures.\n\n\n### Texture3D.isSupported(gl)\n\nReturns true if the context supports creation of `Texture3Ds`.\n\n\n### constructor\n\n`new Texture3D(gl, {parameters})`;\n\n```\nconst texture = new Texture3D(gl, {\n  width: TEXTURE_DIMENSIONS,\n  height: TEXTURE_DIMENSIONS,\n  depth: TEXTURE_DIMENSIONS,\n  data: textureData,\n  format: gl.RED,\n  dataFormat: gl.R8\n});\n```\n\n* `gl` (WebGLRenderingContext) - gl context\n* `data`=`null` (\\*) - See below.\n* `width`=`0` (*Number*) - The width of the texture.\n* `height`=`0` (*Number*) - The height of the texture.\n* `depth`=`0` (*Number*) - The depth of the texture.\n* `mipmaps`=`true` (*Boolean*) - whether to generate mipmaps\n* `format` (*enum*, default `GL.RGBA`) - internal format that WebGL should use.\n* `type` (*enum*, default is autodeduced from format) - type of pixel data (GL.UNSIGNED_BYTE, GL.FLOAT etc).\n* `dataFormat` (*enum*, default is autodeduced from `format`) - internal format that WebGL should use.\n* `parameters`=`{}` (object) - texture\n\n\n## Limits\n\n* The maximum size of a `Texture3D` (width/height/depth) is implementation defined, it can be queried via `GL.MAX_3D_TEXTURE_SIZE` (at least 256).\n","slug":"docs/api-reference/webgl/texture-3d","title":"Texture3D (WebGL 2)"},{"excerpt":"TextureCube A texture cube holds six textures that represent faces of the cube. A main feature of s are that they can be passed to shaders…","rawMarkdownBody":"# TextureCube\n\nA texture cube holds six textures that represent faces of the cube. A main feature of `TextureCube`s are that they can be passed to shaders and sampled with a direction vector (looking out from the center of the cube) rather than a normal set of texture coordinates, see Usage below.\n\n`TextureCube`s are typically used to store environment maps. As an example, by rendering an environment into a texture cube, reflections in objects can then be rendered efficiently.\n\nMost texture related functionality is implemented by and documented on the [Texture](/docs/api-reference/webgl/texture) base class. For additional information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Texture).\n\n\n# Usage\n\nCreating a `TextureCube`\n```js\nconst textureCube = new TextureCube(gl, {width, height, dataFormat, pixels: {\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_X]: imagePosX,\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Y]: imagePosY,\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Z]: imagePosZ,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_X]: imageNegX,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Y]: imageNegY,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Z]: imageNegZ\n}});\n```\n\nCreating a `TextureCube` using multiple level-of-detail (LODs) images.\n```js\nconst textureCube = new TextureCube(gl, {width, height, dataFormat, pixels: {\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_X]: [imagePosX_LOD_0, imagePosX_LOD_1, imagePosX_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Y]: [imagePosY_LOD_0, imagePosY_LOD_1, imagePosY_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Z]: [imagePosZ_LOD_0, imagePosZ_LOD_1, imagePosZ_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_X]: [imageNegX_LOD_0, imageNegX_LOD_1, imageNegX_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Y]: [imageNegY_LOD_0, imageNegY_LOD_1, imageNegY_LOD_2],\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Z]: [imageNegZ_LOD_0, imageNegZ_LOD_1, imageNegZ_LOD_2]\n}});\n```\n\nThis class supports _Async Textures_. You can provide promises (that resolve to images) instead of images.\nFor example `[GL.TEXTURE_CUBE_MAP_POSITIVE_X]: [promisePosX_LOD_0, promisePosX_LOD_1, promisePosX_LOD_2]`.\n\nReplacing one or more faces texture data\n```js\ntextureCube.setCubeMapImageData({width, height, dataFormat, pixels: {\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_X]: imagePosX,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Y]: imageNegY\n}});\n```\n\nPassing a `TextureCube` to a draw call...\n```js\nProgram.draw({\n  uniforms: {\n    cubemap: new TextureCube(gl, {...}),\n    textureDir: [1, 1, 1]\n  }\n});\n```\n\n...and accessing it in the shader\n\n```\n// GLSL\nuniform samplerCube cubemap;\nuniform vec3 textureDir;\n\nvoid main()\n{\n    vec4 color = texture(cubemap, textureDir);\n}\n```\n\n\n## Members\n\n* `handle` - the underlying `WebGLTexture`\n* `target` - Always `GL.TEXTURE_CUBE`\n* `depth` - Always `6`\n* `width` - width of the face textures\n* `height` - height of the face textures\n* `format` - format\n\n\n## Methods\n\n### TextureCube constructor\n\n```js\nnew Texture3D(gl, {\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_X]: faceSpecificationPosX,\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Y]: faceSpecificationPosY,\n  [GL.TEXTURE_CUBE_MAP_POSITIVE_Z]: faceSpecificationPosZ,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_X]: faceSpecificationNegX,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Y]: faceSpecificationNegY,\n  [GL.TEXTURE_CUBE_MAP_NEGATIVE_Z]: faceSpecificationNegZ,\n  parameters\n});\n```\n\n_faceSpecification_ can be:\n* A single image.\n* A single promise resolving in an image.\n* An array of images (for multiple _levels of detail_).\n* An array of promises each resolving in an image (for multiple _levels of detail_).\n\nFor every level of detail:\n* Needs to supply 6 images all of same size and format.\n* Images all need to be of the same square size, i.e. `width` and `height` must be the same.\n* The same `format`, `type` etc parameters will be applied to each cube face.\n\n\n## Limits\n\n* `GL.MAX_CUBE_MAP_TEXTURE_SIZE`\n","slug":"docs/api-reference/webgl/texture-cube","title":"TextureCube"},{"excerpt":"TransformFeedback (WebGL 2)  objects holds state needed to perform transform feedback operations. They store the buffer bindings that are…","rawMarkdownBody":"# TransformFeedback (WebGL 2)\n\n`TransformFeedback` objects holds state needed to perform transform feedback operations. They store the buffer bindings that are being recorded to. This makes it easy to switch between different sets of feedback buffer bindings (somewhat similar to how `VertexArrayObjects` hold input vertex buffers.\n\nThe state managed by `TransformFeedback` objects includes the buffers the GPU will use to record the requested varyings.\n\nWhen `TransformFeedback` objects must be \"activated\" (`TransformFeedback.begin`) before it can be used. There a number of caveats to be aware of when manually managing `TransformFeedback` object activation, see the remarks. For this reason, luma.gl [`Program.draw`](/docs/api-reference/webgl/program) call takes an optional `TransformFeedback` object as a parameter and activates and deactivates it before and after the draw call.\n\nFinally, note that when using transform feedback it is frequently desirable to turn off rasterization: `gl.enable(GL.RASTERIZER_DISCARD)` to prevent the fragment shader from running.\n\nFor more information, see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Transform_Feedback).\n\n\n## Usage\n\nSetting up a model object for transform feedback.\n\n```js\nconst model = new Model(gl, {\n  vs,\n  fs,\n  varyings: ['gl_Position', 'outputColor'],\n  ...\n});\n```\n\nSetting up a transform feedback object and binding buffers\n\n```js\nconst transformFeedback = new TransformFeedback(gl)\n  .setBuffer(0, bufferPosition)\n  .setBuffer(1, bufferColor);\n```\n\nWhen binding the buffers, index should be equal to the corresponding varying entry in `varyings` array passed to `Program` constructor.\n\nBuffers can also be bound using varying name if information about varyings are retrieved from `Program` object.\n\n```js\nconst transformFeedback = new TransformFeedback(gl, {\n  program: ..., // linked program, configuration will be read from it\n  buffers: {\n    outputColor: bufferColor,\n    gl_Position: bufferPosition\n  }\n});\n```\n\nRunning program (drawing) with implicit activation of transform feedback (will call `begin` and `end` on supplied `transformFeedback`)\n\n```js\nmodel.draw({\n  drawMode,\n  vertexCount,\n  ...,\n  transformFeedback\n});\n```\n\nRunning a transform feedback operation while turning off rasterization (drawing):\n\n```js\nmodel.transform({\n  drawMode,\n  ...,\n  transformFeedback\n});\n```\n\nor equivalently, just call draw with an additional parameter:\n\n```js\nconst parameters = {[GL.RASTERIZER_DISCARD]: true}\nmodel.draw({..., transformFeedback, parameters});\n```\n\n\n## Methods\n\n### constructor(gl : WebGL2RenderingContext, props: Object)\n\nSee `TransformFeedback.setProps` for parameters.\n\nWebGL APIs [`gl.createTransformFeedback`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/createTransformFeedback)\n\n\n### initialize(props : Object) : TransformFeedback\n\nReinitializes an existing `TransformFeedback` object with new props.\n\n\n### setProps(props : Object) : TransformFeedback\n\n* `props.program`= (Object) - Gets a mapping of varying name to buffer indices from a linked program if supplied.\n* `props.buffers`=(Object) - Map of location index or name to Buffer object or buffer parameters object. If buffer parameters object is supplied, it contains following fields.\n  * `buffer`=(Buffer) - Buffer object to be bound.\n  * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n  * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n* `props.bindOnUse`=`true` - If true, binds and unbinds buffers before and after use, rather than right away when set. Workaround for a possible [Khronos/Chrome bug](https://github.com/KhronosGroup/WebGL/issues/2346).\n\nNotes:\n\n* `buffers` - will get bound to indices in the `GL.TRANSFORM_FEEDBACK_BUFFER` target.\n\n\n### delete() : TransformFeedback\n\nDestroys a `TransformFeedback` object.\n\nWebGL APIS [`gl.deleteTransformFeedback`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/deleteTransformFeedback)\n\n\n### setBuffers(buffers: Object) : TransformFeedback\n\n* `buffers`=(Object) - Map of location index or name to Buffer object or buffer parameters object. If buffer parameters object is supplied, it contains following fields.\n  * `buffer`=(Buffer) - Buffer object to be bound.\n  * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n  * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n\nNotes:\n\n* To use `gl.bindBufferRange`, either `offsetInByts` or `byteSize` must be specified, when only one is specified, default value is used for the other, when both not specified, `gl.bindBufferBase` is used for binding.\n\nWebGL APIs [`gl.bindBufferBase`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/bindBufferBase), [`gl.bindBufferRange`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/bindBufferRange)\n\n\n### begin(primitiveMode : GLEnum) : TransformFeedback\n\nActivates transform feedback using the buffer bindings in this `TransformFeedback` object.\n\n* `primitiveMode` (`GLenum`) -\n\nreturns (`TransformFeedback`) - returns self to enable chaining\n\nNotes:\n\n* Buffers can not be accessed until `TransformFeedback.end` or `TransformFeedback.pause` have been called.\n* Buffers can not be changed until `TransformFeedback.end` or has been called, which includes doing anything which reads from or writes to any part of these buffers (outside of feedback writes, of course, or reallocating storage for any of these buffers).\n\n\nWebGL APIs [`gl.beginTransformFeedback`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/beginTransformFeedback)\n\n\n### end() : TransformFeedback\n\nreturns (`TransformFeedback`) - returns self to enable chaining\n\nWebGL APIs [`gl.endTransformFeedback`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/endTransformFeedback)\n\n\n## See also\n\n* `Program` constructor - `varyings` argument to specify which vertex shader outputs to expose to transform feedback operations.\n\n\n## Enumerations\n\n| Primitive Mode | Compatible Draw Modes |\n| ---            | --- |\n| `GL.POINTS`    | `GL.POINTS` |\n| `GL.LINES`     | `GL.LINES`, `GL.LINE_LOOP`, `GL.LINE_STRIP` |\n| `GL.TRIANGLES` | `GL.TRIANGLES`, `GL.TRIANGLE_STRIP`, `GL.TRIANGLE_FAN` |\n\n\n## Limits\n\n| Limit                                              | Value | Description |\n| ---                                                | ---   | --- |\n| `GL.MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS`       | >=4   | total number of variables that can be captured }\n| `GL.MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS`    | >=4   | number of components that any particular variable can contain |\n| `GL.MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS` | >= 64 |  total number of components in interleaved capture |\n| `GL.MAX_TRANSFORM_FEEDBACK_BUFFERS`                | TBD   | Advanced interleaving total number of buffers |\n\n\n## Remarks\n\nAbout `TransformFeedback` activation caveats\n\n* When activated, `TransformFeedback` are coupled to the \"current\" `Program`\n* Note that a started and unpaused TransformFeedback prevents the app from changing or re-linking the current program. So for instance, `Program.use` (`gl.useProgram`) cannot be called.\n","slug":"docs/api-reference/webgl/transform-feedback","title":"TransformFeedback (WebGL 2)"},{"excerpt":"Texture A  is a WebGL object that contains one or more images that all have the same image format. Shaders can read from textures (through a…","rawMarkdownBody":"# Texture\n\nA `Texture` is a WebGL object that contains one or more images that all have the same image format. Shaders can read from textures (through a sampler uniform) and they can be set up as render targets (by attaching them to a framebuffer).\n\nNote: This section describes the `Texture` base class that implements functionality common to all four types of WebGL:\n* [`Texture2D`](/docs/api-reference/webgl/texture-2d) - Contains a \"normal\" image texture\n* [`TextureCube`](/docs/api-reference/webgl/texture-cube) - Holds 6 textures representing sides of a cube.\n* [`Texture3D`](/docs/api-reference/webgl/texture-3d) (WebGL 2) - Holds a \"stack\" of textures which enables 3D interpolation.\n\nFor more details see [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Texture).\n\nNote that textures have a lot of optional capabilities made available by extensions, see the Limits section below.\n\n\n## Usage\n\n* For additional usage examples, `Texture` inherits from [`Resource`](/docs/api-reference/webgl/resource).\n\nConfiguring a Texture\n```js\nconst texture = new Texture2D(gl);\ntexture.setParameters({\n  [GL.TEXTURE_WRAP_S]: GL.CLAMP\n});\n```\n\nUsing Textures\n```js\nconst texture = new Texture2D(gl, ...);\n\n// For ease of use, the `Model` class can bind textures for a draw call\nmodel.draw({\n  uniforms({uMVMatrix: matrix, texture1: texture, texture2: texture})\n});\n\n// Alternatively, bind the textures using the `Texture` API directly\ntexture.bind(0);\ntexture.bind(1);\nmodel.draw({\n  uniforms({uMVMatrix: matrix})\n});\n```\n\n## Members\n\nA number of read only accessors are available:\n\n* `width` - width of one face of the cube map\n* `height` - height of one face of the cube map\n* `format` - internal format of the face textures\n* `border` - Always 0.\n\n* `type` - type used to create face textures\n* `dataFormat` - data format used to create face textures.\n* `offset` - offset used to create face textures. Always 0, unless specified using WebGL 2 buffer constructor.\n\n* `handle` - The underlying WebGL object.\n* `id` - An identifying string that is intended to help debugging.\n\nSampler parameters can be accessed using `Texture.getParameter`, e.g:\n\n`texture.getParameter(GL.TEXTURE_MAG_FILTER);`\n\n\n## Methods\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\nThe texture class cannot be constructed directly. It is a base class that provides common methods the the concrete texture classes.\n* [`Texture2D`](/docs/api-reference/webgl/texture-2d),\n* [`TextureCube`](/docs/api-reference/webgl/texture-cube) and\n* [`Texture3D`](/docs/api-reference/webgl/texture-3d).\n\nThe constructors for these classes should be used to create textures. They constructors all take common parameters, many of which are specified in this document.\n\n* Pixel store parameters are described in [`State Management`](/docs/api-reference/gltools/parameter-setting).\n\n### resize(options : Object) : Texture2D\n\nCall to resize a texture. If size has changed, reinitializes texture with current format. Note: calling `resize` clears image and mipmaps.\n\n* `width` (GLint) - width to resize to.\n* `height` (GLint) - height to resize to.\n* `mipmaps` (bool) - turn on/off mipmapping. default `false`.\n\n### generateMipmap() : Texture2D\n\nCall to regenerate mipmaps after modifying texture(s)\n\nWebGL References [gl.generateMipmap](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/generateMipmap)\n\n\n### setImageData(options : Object) : Texture2D\n\nAllocates storage and sets image data\n\n```js\n  Texture.setImageData({\n    target = this.target,\n    pixels = null,\n    data = null,\n    width,\n    height,\n    level = 0,\n    format = GL.RGBA,\n    type,\n    dataFormat,\n    offset = 0,\n    border = 0,\n    compressed = false,\n    parameters= {}\n  });\n```\n\n* `data` (*) - Image data. Can be one of several data types see table below\n* `pixels` (*) - alternative to  `data`\n* `width` (GLint) -\n* `height` (GLint) -\n* `level` (GLint) -\n* `format` (GLenum) - format of image data.\n* `type` (GLenum)\n - format of array (autodetect from type) or\n - (WEBGL2) format of buffer\n* `offset` (Number) - (WEBGL2) offset from start of buffer\n* `border` (GLint) - must be 0.\n* `compressed` (Boolean) -\n* `parameters` (Object) - GL parameters to be temporarily applied (most of the time, pixelStorage parameters) when updating the texture.\n\nValid image data types:\n\n* `null` - create empty texture of specified format\n* Typed array - initializes from image data in typed array according to `format`\n* `Buffer`|`WebGLBuffer` - (WEBGL2) initialized from image data in WebGLBuffer accoeding to `format`.\n* `HTMLImageElement`|`Image` - Initializes with content of image. Auto deduces texture width/height from image.\n* `HTMLCanvasElement` - Inits with contents of canvas. Auto width/height.\n* `HTMLVideoElement` - Creates video texture that continuously updates. Auto width/height.\n\n\n### setSubImageData(options : Object) : Texture2D\n\nRedefines an area of an existing texture\nNote: does not allocate storage\n\n```\n  Texture.setSubImageData({\n    target = this.target,\n    pixels = null,\n    data = null,\n    x = 0,\n    y = 0,\n    width,\n    height,\n    level = 0,\n    format = GL.RGBA,\n    type,\n    dataFormat,\n    compressed = false,\n    offset = 0,\n    border = 0,\n    parameters = {}\n  });\n```\n\n* `x` (`GLint`) - xOffset from where texture to be updated\n* `y` (`GLint`) - yOffset from where texture to be updated\n* `width` (`GLint`) - width of the sub image to be updated\n* `height` (`GLint`) - height of the sub image to be updated\n* `level` (`GLint`) - mip level to be updated\n* `format` (`GLenum`) - internal format of image data.\n* `typ` (`GLenum`) - format of array (autodetect from type) or (WEBGL2) format of buffer or ArrayBufferView\n* `dataFormat` (`GLenum`) - format of image data.\n* `offset` (`Number`) - (WEBGL2) offset from start of buffer\n* `border` (`GLint`) - must be 0.\n* parameters - temporary settings to be applied, can be used to supply pixel store settings.\n\nSee also [gl.compressedTexSubImage2D](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/compressedTexSubImage2D), [gl.texSubImage2D](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/texSubImage2D), [gl.bindTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindTexture), [gl.bindBuffer](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindBuffer)\n\n\n### getActiveUnit()\n\nReturns number of active textures.\n\n\n### bind()\n\nBinds itself to given textureUnit.\n\nThe following WebGL APIs are called in the function\n[gl.activeTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/activeTexture), [gl.bindTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindTexture)\n\n\n### unbind()\n\nThe following WebGL APIs are called in the function\n[gl.activeTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/activeTexture), [gl.bindTexture](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/bindTexture)\n\n\n## Texture Image Data\n\nWebGL allows textures to be created from a number of different data sources.\n\n| Type                               | Description  |\n| ---------------------------------- | -----------  |\n| `null`                             | A texture will be created with the appropriate format, size and width. Bytes will be \"uninitialized\". |\n| `typed array`                      | Bytes will be interpreted according to format/type parameters and pixel store parameters. |\n| `Buffer` or `WebGLBuffer` (`WebGL 2`) | Bytes will be interpreted according to format/type parameters and pixel store parameters. |\n| `Image` (`HTMLImageElement`)       | image will be used to fill the texture. width and height will be deduced. |\n| `Video` (`HTMLVideoElement`)       | video will be played, continously updating the texture. width and height will be deduced. |\n| `Canvas` (`HTMLCanvasElement`)     | canvas will be used to fill the texture. width and height will be deduced. |\n| `ImageData`                        | `canvas.getImageData()` - Used to fill the texture. width and height will be deduced. |\n\n\n\n## Texture Formats\n\n### Internal Format\n\nIf an application wants to store the texture at a certain resolution or in a certain format, it can request the resolution and format with `internalFormat`. WebGL will choose an internal representation with least the internal component sizes, and exactly the component types shown for that format, although it may not match exactly.\n\nWebGL 2 adds sized internal formats which enables the application to request\nspecific components sizes and types (float and integer formats). While sized formats offer more control, unsized formats do give the GPU freedom to select the most performant internal representation.\n\n\n| Unsized Internal Format | Components | Description |\n| ----------------------- | ---------- | ----------- |\n| `GL.RGB`                | 3          | sampler reads the red, green and blue components, alpha is 1.0 |\n| `GL.RGBA`               | 4          | Red, green, blue and alpha components are sampled from the color buffer. |\n| `GL.LUMINANCE`          | 1          | Each color contains a single luminance value. When sampled, rgb are all set to this luminance, alpha is 1.0. |\n| `GL.LUMINANCE_ALPHA`    | 2          | Each component is a luminance/alpha double. When sampled, rgb are all set to luminance, alpha from component. |\n| `GL.ALPHA`              | 1          | Discards the red, green and blue components and reads the alpha component. |\n| `GL.DEPTH_COMPONENT`    | 1          | WebGL 2 or `WEBGL_depth_texture` |\n| `GL.DEPTH_STENCIL`      | 2          | WebGL 2 or `WEBGL_depth_texture` |\n\n| Sized Internal Format   | Comp. |   Size   | Description   |\n| ----------------------- | ----- | -------- | ------------- |\n| `GL.R8` (WebGL 2)        | 1     | 8 bits   | red component |\n| `GL.R16F` (WebGL 2)      | 1     | 16 bits  | half float red component |\n| `GL.R32F` (WebGL 2)      | 1     | 32 bits | float red component |\n| `GL.R8UI` (WebGL 2)      | 1     | 8 bits | unsigned int red component, `usampler`, no filtering |\n| `GL.RG8` (WebGL 2)       | 1     | 16 bits | red and green components |\n| `GL.RG16F` (WebGL 2)     | 2     | 32 bits | red and green components, half float |\n| `GL.RG32F` (WebGL 2)     | 2     | 64 bits | red and green components, float |\n| `GL.RGUI` (WebGL 2)      | 2     | 16 bits | red and green components, `usampler`, no filtering |\n| `GL.RGB8` (WebGL 2)      | 3     | 24 bits | red, green and blue components |\n| `GL.SRGB8` (WebGL 2, EXT_sRGB) |3| 24 bits | Color values are encoded to/decoded from sRGB before being written to/read from framebuffer |\n| `GL.RGB565` (WebGL 2)    | 3     | 16 bits | 5 bit red, 6 bit green, 5 bit blue |\n| `GL.R11F_G11F_B10F` (WebGL 2) | 3| 32 bits | [11 and 10 bit floating point colors](https://www.opengl.org/wiki/Small_Float_Formats) |\n| `GL.RGB9_E5` (WebGL 2)   | 3     | 32 bits | [14 bit floating point RGB, shared exponent](https://www.opengl.org/wiki/Small_Float_Formats) |\n| `GL.RGB16F` (WebGL 2)    | 3     | 48 bits | half float RGB |\n| `GL.RGB32F` (WebGL 2)    | 3     | 96 bits | float RBG |\n| `GL.RGB8UI` (WebGL 2)    | 3     | 24 bits | unsigned integer 8 bit RGB: use `usampler`, no filtering |\n| `GL.RGBA8` (WebGL 2)     | 4     | 32 bits | 8 bit RGBA, typically what `GL.RGBA` \"resolves\" to |\n| `GL.SRGB_APLHA8` (WebGL 2, EXT_sRGB) | 4 | 32 bits | Color values are encoded to/decoded from sRGB before being written to/read from framebuffer |\n| `GL.RGB5_A1` (WebGL 2)   | 4     | 16 bits | 5 bit RGB, 1 bit alpha |\n| `GL.RGBA4444` (WebGL 2)  | 4     | 16 bits | 4 bit RGBA |\n| `GL.RGBA16F` (WebGL 2)   | 4     | 64 bits | half float RGBA |\n| `GL.RGBA32F` (WebGL 2)   | 4     | 128 bits | float RGA |\n| `GL.RGBA8UI` (WebGL 2)   | 4     | 32 bits | unsigned integer 8 bit RGBA, `usampler`, no filtering |\n\n\n### Texture Component Type\n\nDescribes the layout of each color component in memory.\n\n| Value                         | WebGL 2 | WebGL 1 | Description |\n| ---                           | ---    | ---    | --- |\n| `GL.UNSIGNED_BYTE`            | Yes    | Yes    | GLbyte 8 bits per channel for `GL.RGBA` |\n| `GL.UNSIGNED_SHORT_5_6_5`     | Yes    | Yes    | 5 red bits, 6 green bits, 5 blue bits |\n| `GL.UNSIGNED_SHORT_4_4_4_4`   | Yes    | Yes    | 4 red bits, 4 green bits, 4 blue bits, 4 alpha bits |\n| `GL.UNSIGNED_SHORT_5_5_5_1`   | Yes    | Yes    | 5 red bits, 5 green bits, 5 blue bits, 1 alpha bit |\n| `GL.BYTE`                     | Yes    | No     | |\n| `GL.UNSIGNED_SHORT`           | Yes    | `WEBGL_depth_texture` | |\n| `GL.SHORT`                    | Yes    | No     | |\n| `GL.UNSIGNED_INT`             | Yes    | `WEBGL_depth_texture` | |\n| `GL.INT`                      | Yes    | No     | |\n| `GL.HALF_FLOAT`               | Yes    | `OES_texture_half_float` | |\n| `GL.FLOAT`                    | Yes    | `OES_texture_float` |\n| `GL.UNSIGNED_INT_2_10_10_10_REV`   |Yes| No     | |\n| `GL.UNSIGNED_INT_10F_11F_11F_REV`  |Yes| No     | |\n| `GL.UNSIGNED_INT_5_9_9_9_REV`      |Yes| No     | |\n| `GL.UNSIGNED_INT_24_8`             |Yes| `WEBGL_depth_texture` | |\n| `GL.FLOAT_32_UNSIGNED_INT_24_8_REV`|Yes| No     | (pixels must be null) |\n\n\n### Texture Format Combinations\n\nThis a simplified table illustrating what combinations of internal formats\nwork with what data formats and types. Note that luma.gl deduces `dataFormat` and `type` from `format` by taking the first value from the data format and data type entries in this table.\n\nFor more details, see tables in:\n* [WebGL 2 spec](https://www.khronos.org/registry/webgl/specs/latest/2.0/)\n* [OpenGL ES spec](https://www.khronos.org/opengles/sdk/docs/man3/html/glTexImage2D.xhtml)\n\n| Internal Format          | Data Format       | Data Type          |\n| ------------------------ | ----------------- | ------------------ |\n| `GL.RGB`                 | `GL.RGB`          | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_5_6_5` |\n| `GL.RGBA`                | `GL.RGBA`         | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_4_4_4_4` `GL.UNSIGNED_SHORT_5_5_5_1` |\n| `GL.LUMINANCE_ALPHA`     | `GL.LUMINANCE_ALPHA` | `GL.UNSIGNED_BYTE` |\n| `GL.LUMINANCE`           | `GL.LUMINANCE`    | `GL.UNSIGNED_BYTE` |\n| `GL.ALPHA`               | `GL.ALPHA`        | `GL.UNSIGNED_BYTE` |\n| `GL.R8`                  | `GL.RED`          | `GL.UNSIGNED_BYTE` |\n| `GL.R16F`                | `GL.RED`          | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.R32F`                | `GL.RED`          | `GL.FLOAT`         |\n| `GL.R8UI`                | `GL.RED_INTEGER`  | `GL.UNSIGNED_BYTE` |\n| `GL.RG8`                 | `GL.RG`           | `GL.UNSIGNED_BYTE` |\n| `GL.RG16F`               | `GL.RG`           | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RG32F`               | `GL.RG`           | `GL.FLOAT`         |\n| `GL.RG8UI`               | `GL.RG_INTEGER`   | `GL.UNSIGNED_BYTE` |\n| `GL.RGB8`                | `GL.RGB`          | `GL.UNSIGNED_BYTE` |\n| `GL.SRGB8`               | `GL.RGB`          | `GL.UNSIGNED_BYTE` |\n| `GL.RGB565`              | `GL.RGB`          | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_5_6_5` |\n| `GL.R11F_G11F_B10F`      | `GL.RGB`          | `GL.UNSIGNED_INT_10F_11F_11F_REV` `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RGB9_E5`             | `GL.RGB`          | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RGB16FG`             | `GL.RGB`          | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RGB32F`              | `GL.RGB`          | `GL.FLOAT`         |\n| `GL.RGB8UI`              | `GL.RGB_INTEGER`  | `GL.UNSIGNED_BYTE` |\n| `GL.RGBA8`               | `GL.RGBA`         | `GL.UNSIGNED_BYTE` |\n| `GL.SRGB8_ALPHA8`        | `GL.RGBA`         | `GL.UNSIGNED_BYTE` |\n| `GL.RGB5_A1`             | `GL.RGBA`         | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_5_5_5_1` |\n| `GL.RGBA4`               | `GL.RGBA`         | `GL.UNSIGNED_BYTE` `GL.UNSIGNED_SHORT_4_4_4_4` |\n| `GL.RGBA16F`             | `GL.RGBA`         | `GL.HALF_FLOAT` `GL.FLOAT` |\n| `GL.RGBA32F`             | `GL.RGBA`         | `GL.FLOAT`         |\n| `GL.RGBA8UI`             | `GL.RGBA_INTEGER` | `GL.UNSIGNED_BYTE` |\n\n\n## Limits and Capabilities\n\n| Optional capabilities                                       | controlled by extensions |\n| ---                                                         | --- |\n| Create floating point textures (`GL.NEAREST` sampling only) | `TEXTURE_FLOAT` |\n| Create half-floating point textures (`GL.NEAREST` sampling) | `TEXTURE_HALF_FLOAT` |\n| Floating point textures are color-renderable and readable   | `COLOR_BUFFER_FLOAT` |\n| Half float textures are color-renderable and readable       | `COLOR_BUFFER_HALF_FLOAT` |\n| sRGB format support                                         | `SRGB` |\n| depth texture support                                       | `DEPTH_TEXTURE` |\n| anisotropic filtering                                       | `TEXTURE_FILTER_ANISOTROPIC` |\n| `GL.LINEAR_*` sampling of floating point textures           | `TEXTURE_FILTER_LINEAR_FLOAT` |\n| `GL.LINEAR_*` sampling of half-floating point textures      | `TEXTURE_FILTER_LINEAR_HALF_FLOAT` |\n\n## NPOT Textures (WebGL 1)\n\n* Any texture with a `non power of two` dimension (width or height) is referred as `NPOT` texture, under WebGL 1 NPOT textures have following limitations.\n\n| State              | Limitation |\n| ---                | --- |\n| Mipmapping         | Should be disabled |\n| `GL.TEXTURE_MIN_FILTER` | Must be either `GL.LINEAR` or `GL.NEAREST` |\n| `GL.TEXTURE_WRAP_S`     | Must be `GL.CLAMP_TO_EDGE` |\n| `GL.TEXTURE_WRAP_T`     | Must be `GL.CLAMP_TO_EDGE` |\n\n* 'Texture' class will perform above settings when NPOT texture resource is created. When un-supported filtering is set using `Texture.setParameters`, those will be overwritten with above supported values (`GL.TEXTURE_MIN_FILTER` will be set to `GL.LINEAR`). This only happens for NPOT textures when using WebGL 1, and a warning log will be printed every time a setting is overwritten.\n\n\n## Remarks\n\n* Textures can be supplied as uniforms to shaders that can sample them using texture coordinates and color pixels accordingly.\n* Parameters that affect texture sampling can be set on textures or sampler objects.\n* Textures can be created from a number of different sources, including typed arrays, HTML Images, HTML Canvases, HTML Videos and WebGLBuffers (WebGL 2).\n* The WebGL Context has global \"pixel store\" parameters that control how pixel data is laid out, including Y direction, color space etc.\n* Textures are read from supplied data and written to the specified format/type parameters and pixel store parameters.\n","slug":"docs/api-reference/webgl/texture","title":"Texture"},{"excerpt":"Query A  object provides single unified API for using WebGL asynchronus queries, which include query objects ('Occlusion' and 'Transform…","rawMarkdownBody":"# Query\n\nA `Query` object provides single unified API for using WebGL asynchronus queries, which include query objects ('Occlusion' and 'Transform Feedback') and timer queries.\n\nSee also:\n\n* WebGL 1 timer extension: [`EXT_disjoint_timer_query`](https://www.khronos.org/registry/webgl/extensions/EXT_disjoint_timer_query/)\n* WebGL 2 timer extension: [`EXT_disjoint_timer_query_webgl2`](https://www.khronos.org/registry/webgl/extensions/EXT_disjoint_timer_query_webgl2/)\n\n\n## Usage\n\nUse a query to time GPU calls\n```js\nimport {GL} from '@luma.gl/constants';\nimport {Query} from '@luma.gl/webgl';\n...\nconst timerQuery = new Query(gl);\n\n\n// In animation loop\nif (timerQuery.isResultAvailable() && !timerQuery.isTimerDisjoin()) {\n  result = timerQuery.getResult();\n}\n\n\n// Option #1\ntimerQuery.beginTimeElapsedQuery();\n// Option #2\n// timerQuery.begin(GL.TIME_ELAPSED_EXT)\n\n// Issue GPU calls\n\ntimerQuery.end();\n```\n\n\n## Query Types\n\nA query can be started by passing following query type to to `begin()` or by using corresponding begin* method.\n\n| Query Type | begin method | Description |\n| ------------------------------------------ | --------------------- | ------------ |\n| `GL_TIME_ELAPSED_EXT`                      | `beginTimeElapsedQuery()` | Time taken by GPU to fully complete a set of GL commands |\n| `GL.ANY_SAMPLES_PASSED`                    | `beginOcclusionQuery({conservative: false})` | Occlusion query: these queries detect whether an object is visible (whether the scoped drawing commands pass the depth test and if so, how many samples pass).\n| `GL.ANY_SAMPLES_PASSED_CONSERVATIVE`                    | `beginOcclusionQuery({conservative: true})` | Same as above above, but less accurate and faster version.\n| `GL.TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN`  | `beginTransformFeedbackQuery()` | Number of primitives that are written to transform feedback buffers.\n\nIn addition to above queries, Query object also provides `getTimeStamp` which returns GPU time stamp at the time this query is executed by GPU. Two sets of these methods can be used to calculate time taken by GPU for a set of GL commands.\n\n## Methods\n\n### static Query.isSupported(gl : WebGLRenderingContext, options : Object)\n\nReturns true if Query is supported by the WebGL implementation\n(depends on the EXT_disjoint_timer_query extension)/\nCan also check whether timestamp queries are available.\n\n* options.queries=false {Object}  - If true, checks if Query objects (occlusion/transform feedback) are supported\n* options.timers=false {Object}  - If true, checks if 'TIME_ELAPSED_EXT' queries are supported\n\nReturns: {Boolean} - Query API is supported with specified configuration\n\nOptions\n* queries = false,\n* timers = false,\n\n\n### constructor(gl : WebGLRenderingContext, props : Object)\n\n`new Query(gl, {})`\n\n\n### delete()\n\nDestroys the WebGL object. Rejects any pending query.\n* return {Query} - returns itself, to enable chaining of calls.\n\n\n### beginTimeElapsedQuery()\n\nShortcut for timer query (dependent on extension in both WebGL 1 and 2)\n\n\n### Query.beginOcclusionQuery({conservative = false})\n\nShortcut for occlusion query (dependent on WebGL 2)\n\n\n### beginTransformFeedbackQuery()\n\nShortcut for transform feedback query (dependent on WebGL 2)\n\n\n### Query.begin(target)\n\nMeasures GPU time delta between this call and a matching `end` call in the GPU instruction stream.\n\nRemarks:\n* Due to OpenGL API limitations, after calling `begin()` on one Query\n  instance, `end()` must be called on that same instance before\n  calling `begin()` on another query. While there can be multiple\n  outstanding queries representing disjoint `begin()`/`end()` intervals.\n  It is not possible to interleave or overlap `begin` and `end` calls.\n* Triggering a new query when a Query is already tracking an\n  unresolved query causes that query to be cancelled.\n\n* target {GLenum}  - target to query\n* return {Query} - returns itself, to enable chaining of calls.\n\n\n### end\n\nInserts a query end marker into the GPU instruction stream.\nNote: Can be called multiple times.\n\nreturn {Query} - returns itself, to enable chaining of calls.\n\n\n### isResultAvailable\n\nreturn {Boolean} - true if query result is available\n\n\n### getResult\n\nReturns the query result\n\nreturn {Number} - query result. Semantics depend on query type\n\n\n### getTimerMilliseconds\n\nShorthand for getting timer query results and converting to milliseconds to match JavaScript conventions.\n\nreturn {Number} - measured time or timestamp, in milliseconds\n\n### isTimerDisjoint\n\nReturns `true` if the timer query was disjoint, indicating that timing results are invalid.\nThis is rare and might occur, for example, if the GPU was throttled while timing.\n\nreturn {Boolean} - true if timer query was disjoint\n\n\n### createPoll(limit = Number.POSITIVE_INFINITY)\n\nBegins polling `Query` once per frame to check if results are available.\n\n* limit {Number}  - Maximum number of frames to poll before rejecting the `Promise`.\n\nreturn {Promise} - Resolves to the `Query` result if it becomes available before `limit`\nframes have elapsed, and is rejected otherwise.\n\n\n## Remarks\n\n* Even when supported, timer queries can fail whenever a change in the GPU occurs that will make the values returned by this extension unusable for performance metrics, for example if the GPU is throttled mid-frame. This occurance is captured in `isTimerDisjoint` method.\n* Note that from a JavaScript perspective, where callback driven APIs are the norm, the functionality of the WebGL `Query` class seems limited. Many operations that require expensive roundtrips to the GPU (such as `readPixels`) that would obviously benefit from asynchronous queries, are not covered by the `Query` class.\n","slug":"docs/api-reference/webgl/query","title":"Query"},{"excerpt":"Program A  contains a matched pair of vertex and fragment shaders that can be exectued on the GPU by calling . Programs handle compilation…","rawMarkdownBody":"# Program\n\nA `Program` contains a matched pair of vertex and fragment [shaders](/docs/api-reference/webgl/shader) that can be exectued on the GPU by calling `Program.draw()`. Programs handle compilation and linking of shaders, and store uniform values. They provide `draw` call which allows the application to run the shaders on specified input data.\n\n## Usage\n\nCreating a program\n\n```js\n  const program = new Program(gl, {\n    id: 'my-program',\n    vs: vertexShaderSourceString,\n    fs: fragmentShaderSourceString\n  });\n```\n\nSet or update uniforms, in this case world and projection matrices\n\n```js\nprogram.setUniforms({\n  uMVMatrix: view,\n  uPMatrix: projection\n});\n```\n\nCreate a `VertexArray` to store buffer values for the vertices of a triangle and drawing\n\n```js\nconst program = new Program(gl, {vs, fs});\n\nconst vertexArray = new VertexArray(gl, {program});\n\nvertexArray.setAttributes({\n  aVertexPosition: new Buffer(gl, {data: new Float32Array([0, 1, 0, -1, -1, 0, 1, -1, 0])})\n});\n\nprogram.draw({vertexArray, ...});\n```\n\nCreating a program for transform feedback, specifying which varyings to use\n\n```js\nconst program = new Program(gl, {vs, fs, varyings: ['gl_Position']});\n```\n\n\n## Members\n\n* `gl` : `WebGLRenderingContext`\n* `handle` : `WebGLProgram` - The WebGL `WebGLProgram` instance.\n* `id` : `String` - `id` string for debugging.\n\n\n## Constructor\n\n### Program(gl : WebGLRenderingContext, props : Object)\n\nCreates a new program using the supplied vertex and fragment shaders. The shaders are compiled into WebGLShaders and is created and the shaders are linked.\n\n```js\n\tconst program = new Program(gl, {\n    id: 'my-identifier',\n    vs: vertexShaderSource,\n    fs: fragmentShaderSource,\n    varyings: ['gl_Position', 'vColor']\n  });\n```\n\n* `id` (`string`, optional) - string id (to help indentify the program during debugging).\n* `vs` (`VertexShader`|`String`) - A vertex shader object, or source as a string.\n* `fs` (`FragmentShader`|`String`) - A fragment shader object, or source as a string.\n* `varyings` WebGL 2 (`String[]`) - a list of names of varyings.\n* `bufferMode`=`GL.SEPARATE_ATTRIBS` WebGL 2 (`GLenum`) - Optional, specifies how transform feedback should store the varyings.\n\n| `GL.TRANSFORM_FEEDBACK_BUFFER_MODE` | Description |\n| ---                                 | --- |\n| `GL.SEPARATE_ATTRIBS`               | One varying per buffer |\n| `GL.INTERLEAVED_ATTRIBS`            | Multiple varyings per buffer |\n\nWebGL References [WebGLProgram](https://developer.mozilla.org/en-US/docs/Web/API/WebGLProgram), [gl.createProgram](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/createProgram)\n\n\n### delete() : Program\n\nDeletes resources held by program. Note: Does not currently delete shaders (to enable shader caching).\n\n\n## Methods\n\n### initialize(props : Object) : Program\n\nRelinks a program. Takes the same options as the constructor\n\n\n### setUniforms(uniforms : Object) : Program\n\nSets named uniforms from a map, ignoring names\n\n* `key` (*String*) - The name of the uniform to be set. The name of the uniform will be matched with the name of the uniform declared in the shader. You can set more uniforms on the Program than its shaders use, the extra uniforms will simply be ignored.\n* `value` (*mixed*) - The value to be set. Can be a float, an array of floats, a typed array, a boolean, `Texture` etc. The values must match the declarations in the shader.\n\n[gl.useProgram](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/useProgram)\n\n\n### draw(opts) : Program\n\n`Program.draw` is the entry point for running shaders, rendering and (optionally calculating data using transform feedback techniques).\n\n```js\n  Program.draw({\n    vertexArray,\n\n    uniforms = {},\n    transformFeedback = null,\n    samplers = {},\n    parameters = {},\n\n    drawMode = GL.TRIANGLES,\n    vertexCount,\n    offset = 0,\n    isIndexed = false,\n    indexType = GL.UNSIGNED_SHORT,\n    isInstanced = false,\n    instanceCount = 0,\n\n    start = 0,\n    end=\n  })\n```\n\nMain parameters\n\n* `vertexArray` - a `VertexArray` object that will be bound and unbound before and after the draw call.\n* `uniforms`=`{}` - a map of uniforms that will be set just before the draw call (and remain set after the call).\n* `samplers`=`{}` - a map of texture `Sampler`s that will be bound before the draw call.\n* `parameters` - temporary gl settings to be applied to this draw call.\n* `transformFeedback`=`null` - optional `TransformFeedback` object containing buffers that will receive the output of the transform feedback operation.\n\nPotentially autodeduced parameters\n\n* `drawMode`=`GL.TRIANGLES` - geometry primitive format of vertex data\n* `vertexCount` - number of vertices to draw\n* `offset`=`0` - first vertex to draw\n* `isIndexed`=`false` - use indices in the \"elements\" buffer\n* `indexType`=`GL.UNSIGNED_SHORT` - must match the type of the \"elements\" buffer\n* `isInstanced`=`false` - Set to enable instanced rendering.\n* `instanceCount`=`0` - Number of instances\n\nParameters for drawing a limited range (WebGL 2 only)\n\n* `start` - hint to GPU, activates `gl.drawElementsRange` (WebGL 2)\n* `end` - hint to GPU, activates `gl.drawElementsRange` (WebGL 2)\n\nReturns: `true` if successful, `false` if draw call is blocked due to missing resources.\n\nNotes:\n\n* Runs the shaders in the program, on the attributes and uniforms.\n* Indexed rendering uses the element buffer (`GL.ELEMENT_ARRAY_BUFFER`), make sure your attributes or `VertexArray` contains one.\n* If a `TransformFeedback` object is supplied, `transformFeedback.begin()` and `transformFeedback.end()` will be called before and after the draw call.\n* A `Sampler` will only be bound if there is a matching Texture with the same key in the supplied `uniforms` object.\n* Once a uniform is set, it's size should not be changed. This is only a concern for array uniforms.\n\nThe following WebGL APIs are called in this function:\n\n[gl.useProgram](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/useProgram),\n[gl.drawElements](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/drawElements),\n[gl.drawRangeElements](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/drawRangeElements) (WebGL 2),\n[gl.drawArrays](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/drawArrays),\n[gl.drawElementsInstanced](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/drawElementsInstanced) (WebGL 2),\n[gl.drawArraysInstanced](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/drawArraysInstanced) (WebGL 2),\n[gl.getExtension](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/getExtension), [ANGLE_instanced_arrays](https://developer.mozilla.org/en-US/docs/Web/API/ANGLE_instanced_arrays),\n[gl.drawElementsInstancedANGLE](https://developer.mozilla.org/en-US/docs/Web/API/ANGLE_instanced_arrays/drawElementsInstancedANGLE),\n[gl.drawArraysInstancedANGLE](https://developer.mozilla.org/en-US/docs/Web/API/ANGLE_instanced_arrays/drawArraysInstancedANGLE)\n\n\n## Constants\n\n### Limits\n\n| Limit                               | Value          | Description |\n| ---                                 | ---            | --- |\n| `GL.MAX_VERTEX_TEXTURE_IMAGE_UNITS` | >= 0 (GLint)   | |\n| `GL.MAX_RENDERBUFFER_SIZE`          | >= 1 (GLint)   | |\n| `GL.MAX_VARYING_VECTORS`            | >= 8 (GLint)   | |\n| `GL.MAX_VERTEX_ATTRIBS`             | >= 8 (GLint)   | |\n| `GL.MAX_VERTEX_UNIFORM_VECTORS`     | >= 128 (GLint) | |\n| `GL.MAX_FRAGMENT_UNIFORM_VECTORS`   | >= 16 (GLint)  | |\n| `GL.TRANSFORM_FEEDBACK_VARYING_MAX_LENGTH` (WebGL 2)  | - | - |\n\n\n### Parameters\n\nUse with `Program.getParameter(parameter)`\n\n| Parameter | Type | Description\n| --- | --- | --- |\n| `GL.DELETE_STATUS`     | GLboolean | If true, program has been flagged for deletion (by calling `Program.delete()`), but the delete is pending because program is still part of current rendering state |\n| `GL.LINK_STATUS`       | GLboolean | Indicates whether last link operation was successful. Program linking is performed by luma on program initialization |\n| `GL.VALIDATE_STATUS`   | GLboolean | Result of last `gl.validateProgram()` operation |\n| `GL.ATTACHED_SHADERS`  | GLint     | Number of attached shaders (`0`, `1` or `2`) |\n| `GL.ACTIVE_ATTRIBUTES` | GLint     | Number of active attribute variables to a program |\n| `GL.ACTIVE_UNIFORMS`   | GLint     | Number of active attribute variables to a program |\n| `GL.TRANSFORM_FEEDBACK_BUFFER_MODE`  | GLenum |  (WebGL 2) Buffer capture mode, `GL.SEPARATE_ATTRIBS` or `GL.INTERLEAVED_ATTRIBS` |\n| `GL.TRANSFORM_FEEDBACK_VARYINGS`     | GLint  | (WebGL 2) Number of varying variables to capture in transform feedback mode. |\n| `GL.ACTIVE_UNIFORM_BLOCKS`           | GLint  | (WebGL 2) Number of uniform blocks containing active uniforms. |\n","slug":"docs/api-reference/webgl/program","title":"Program"},{"excerpt":"VertexArrayObject The WebGL  object holds a map of \"buffers\" that will be made available as input data to shaders during a draw call…","rawMarkdownBody":"# VertexArrayObject\n\nThe WebGL `VertexArrayObject` object holds a map of \"buffers\" that will be made available as input data to shaders during a draw call, similar to how a `TransformFeedback` object holds a set of `Buffer` instances that will receive output data from shaders.For `Buffer` objects, the `VertexArrayObject` also stores some additional information about how that data in the buffer should be accessed, such as offsets, strides, etc.\n\nHowever, the use of `VertexArrayObject` is problematic in WebGL 1. While it is crucial for the operation of a program, its presence under WebGL 1 is dependent on an [extension](https://webglstats.com/webgl/extension/OES_vertex_array_object) that is fairly common, but not universally available. In particular it is not available in headless gl which is essential for running tests under Node.js.\n\nTherefore, in basic WebGL environments where the `VertexArrayObject` is not supported, luma.gl ensures that one (\"fake\") instance of the `VertexArrayObject` class can still be obtained, emulating the default (`null` handle) `VertexArrayObject`. This instance has the `isDefaultArray` flag set, and applications can adapt their behavior accordingly, while still using the same API to manage vertex attributes, albeit with a small performance loss. Since there is a considerable amount of work required to handle both cases, luma.gl also provides a higher level `VertexArray` class that works around these issues and provided additional conveniences.\n\n> It is usually not necessary to create neither `VertexArrayObject` nor `VertexArray` instances in luma.gl applications. It is often simpler to just provides attributes directly to the [`Model`](/docs/api-reference/engine/model) class. Still, it can be useful to review this documentation to understand how attributes are handled by WebGL.\n\nFor more information on WebGL `VertexArrayObject`s, see the [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Vertex_Specification#Vertex_Array_Object).\n\n\n## Usage\n\nImport the `VertexArrayObject` class so that your app can use it:\n\n```js\nimport {VertexArrayObject} from '@luma.gl/webgl';\n```\n\nGetting the global `VertexArrayObject` for a WebGL context\n\n```js\nconst vertexArray = VertexArray.getDefaultArray(gl);\n```\n\nCreate a new VertexArray\n\n```js\nconst vao = new VertexArray(gl);\n}\n```\n\nAdding attributes to a VertexArray\n\n```js\nconst vertexArray = new VertexArray(gl);\nvertexArray.setBuffer(location, buffer);\n```\n\nDeleting a VertexArray\n\n```js\nvertexArrayObject.delete();\n```\n\nSetting a constant vertex attribute\n\n```js\nimport {VertexArray} from '@luma.gl/webgl';\nconst vao = new VertexArray(gl);\nvao.setConstant(0, [0, 0, 0]);\n```\n\n## Methods\n\n`VertexArrayObject` inherits from `Resource`.\n\n\n### VertexArray(gl : WebGLRenderingContext, props : Object)\n\nCreates a new VertexArray\n\n* `props` (Object) - passed through to `Resource` superclass constructor and to `initialize`\n\n\n### VertexArray.getDefaultArray() : VertexArray\n\nReturns the \"global\" `VertexArrayObject`.\n\nNote: The global `VertexArrayObject` object is always available. Binds the `null` VertexArrayObject.\n\n\n### initialize(props : Object) : VertexArray\n\nReinitializes a `VertexArrayObject`.\n\n* `attributes`=`{}` (`Object`) - map of attributes, can be keyed by index or names, can be constants (small arrays), `Buffer`, arrays or typed arrays of numbers, or attribute descriptors.\n* `elements`=`null` (`Buffer`) - optional buffer representing elements array (i.e. indices)\n* `program` - Transfers information on vertex attribute locations and types to this vertex array.\n\n\n### setConstant(values : Array) : VertexArray\n\nSets a constant value for a vertex attribute. When this `VertexArrayObject` is used in a `Program.draw()` call, all Vertex Shader invocations will get the same value.\n\n`VertexArray.setConstant(location, array);`\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `location` (*GLuint*) - index of the attribute\n\nWebGL APIs:\n[vertexAttrib4[u]{f,i}v](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/vertexAttrib)\n\n\n### setBuffer(nameOrLocation, buffer : Buffer [, accessor : Object]) : VertexArray\n\nBinds the specified attribute in this vertex array to the supplied buffer\n\n* Set a location in vertex attributes array to a buffer, specifying\n* its data layout and integer to float conversion and normalization flags\n\n`setBuffer(location, buffer);`\n`setBuffer(location, buffer, {offset = 0, stride = 0, normalized = false, integer = false});`\n\n* `location` (*GLuint* | *String*) - index/ordinal number of the attribute\n* `buffer` (*WebGLBuffer*|*Buffer*) - WebGL buffer to set as value\n\n[gl.vertexAttrib{I}Pointer](), [gl.vertexAttribDivisor](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/vertexAttribDivisor)\n\n\n### getParameter(pname, location) : *\n\nQueries a vertex attribute location.\n\n* `pname` (GLenum) - Which parameter to query. See table of parameter constants below for values.\n* **location** (*Number*) - index of attributes\n\nNote that in WebGL queries are generally slow and should be avoided in performance critical code sections.\n\n\n## Types, Constants, Enumarations\n\n\n### getParameter Constants\n\n| Parameter                           | Type         | Value |\n| ---                                 | ---          | ---   |\n| `GL.VERTEX_ATTRIB_ARRAY_BUFFER_BINDING` | `WebGLBuffer` (not `Buffer`) | Get currently bound buffer |\n| `GL.VERTEX_ATTRIB_ARRAY_ENABLED`    | `GLboolean`  | true if the vertex attribute at this index is enabled |\n| `GL.VERTEX_ATTRIB_ARRAY_SIZE`       | `GLint`      | indicating the size of an element of the vertex array. |\n| `GL.VERTEX_ATTRIB_ARRAY_STRIDE`     | `GLint`      | indicating the number of bytes between successive elements in  |the array. 0 means that the elements are sequential.\n| `GL.VERTEX_ATTRIB_ARRAY_TYPE`       | `GLenum`     | The array type. One of\n`GL.BYTE`, `GL.UNSIGNED_BYTE`, `GL.SHORT`, `GL.UNSIGNED_SHORT`, `GL.FIXED`, `GL.FLOAT`. |\n| `GL.VERTEX_ATTRIB_ARRAY_NORMALIZED` | `GLboolean`  | true if fixed-point data types are normalized for the vertex attribute array at the given index. |\n| `GL.CURRENT_VERTEX_ATTRIB`          | `Float32Array(4)` | The current value of the vertex attribute at the given index. |\nWhen using a WebGL 2 context, the following values are available additionally:\n| `GL.VERTEX_ATTRIB_ARRAY_INTEGER`    | `GLboolean`  | true if an integer data type is in the vertex attribute array at the given index. |\n| `GL.VERTEX_ATTRIB_ARRAY_DIVISOR`    | `GLint`      | The frequency divisor used for instanced rendering. |\n\n\n## Attribute Accessors\n\nWhen setting `Buffer` attributes, additional data can be provided to specify how the buffer should be accessed. This data can be stored directly on the `Buffer` accessor or supplied to `.setBuffer`.\n\n* `target`=`buffer.target` (*GLuint*, ) - which target to bind to\n* `size` (*GLuint*)  - number of values (components) per element (1-4)\n* `type` (*GLuint*)  - type of values (e.g. gl.FLOAT)\n* `normalized` (*boolean*, false) - normalize integers to [-1,1] or [0,1]\n* `integer` (*boolean*, false) - `WebGL 2` disable int-to-float conversion\n* `stride` (*GLuint*, 0) - supports strided arrays\n* `offset` (*GLuint*, 0) - supports strided arrays\n* `layout.normalized`=`false` (GLbool) - normalize integers to [-1,1], [0,1]\n* `layout.integer`=`false` (GLuint) - WebGL 2 only, disable int-to-float conv.\n\n* `divisor` - Sets the frequency divisor used for instanced rendering (instances that pass between updates of attribute). Usually simply set to 1 or 0 to enable/disable instanced rendering. 0 disables instancing, >=1 enables it.\n\nNotes:\n\n* The application can enable normalization by setting the `normalized` flag to `true` in the `setBuffer` call.\n* **WebGL 2** The application can disable integer to float conversion when running under WebGL 2, by setting the `integer` flag to `true`.\n* [`glVertexAttribIPointer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/vertexAttribIPointer) specifies *integer* data formats and locations of vertex attributes. Values are always left as integer values. Only accepts the integer types gl.BYTE, gl.UNSIGNED_BYTE, gl.SHORT, gl.UNSIGNED_SHORT, gl.INT, gl.UNSIGNED_INT\n\nNotes about Instanced Rendering\n\n* About setting `divisor` in attributes: Instanced attributes requires WebGL 2 or a (widely supported) WebGL 1 extension. Apps can use the luma.gl feature detection system to determine if instanced rendering is available, though the extension is so ubiquitously supported that many apps just make the assumption: [instanced_arrays](https://webglstats.com/webgl/extension/ANGLE_instanced_arrays).\n* An attribute is referred to as **instanced** if its divisor value is non-zero.\n* The divisor modifies the rate at which vertex attributes advance when rendering multiple instances of primitives in a single draw call.\n* If divisor is zero, the attribute at slot index advances once per vertex.\n* If divisor is non-zero, the attribute advances once per divisor instances of the set(s) of vertices being rendered.\n\n\n","slug":"docs/api-reference/webgl/vertex-array-object","title":"VertexArrayObject"},{"excerpt":"Shader Assembly luma.gl's module shader system is primarily exposed via the function  which composes base vertex and fragment shader source…","rawMarkdownBody":"# Shader Assembly\n\nluma.gl's module shader system is primarily exposed via the function `assembleShaders` which composes base vertex and fragment shader source with shader modules, hook functions and injections to generate the final vertex and fragment shader source that can be used to create a program.\n\n### `assembleShaders`\n\nTakes the source code of a vertex shader and a fragment shader, and a list of modules, defines, etc. Outputs resolved source code for both shaders, after adding prologue, adding defines, importing and transpiling modules, and injecting any shader fragments).\n\n* `vs` - vertex shader source\n* `fs` - fragment shader source code\n* `id` - `id` for the shader, will be used to inject shader names (using `#define SHADER_NAME`) if not already present in the source.\n* `prologue`=`true` (Boolean) - Will inject platform prologue (see below)\n* `defines`=`{}` (Object) - a map of key/value pairs representing custom `#define`s to be injected into the shader source\n* `modules`=`[]` (Array) - list of shader modules (either objects defining the module, or names of previously registered modules)\n* `inject`=`{}` (Object) - map of substituions,\n* `hookFunctions`=`[]` Array of hook functions descriptions. Descriptions can simply be the hook function signature (with a prefix `vs` for vertex shader, or `fs` for fragment shader) or an object with the hook signature, and a header and footer that will always appear in the hook function. For example:\n\n```js\n[\n  'vs:MY_HOOK_FUNCTION1(inout vec4 color)',\n  {\n    hook: 'fs:MY_HOOK_FUNCTION2(inout vec4 color)',\n    header: 'if (color.a == 0.0) discard;\\n',\n    footer: 'color.a *= 1.2;\\n'\n  }\n]\n```\n\nReturns:\n* `vs` - the resolved vertex shader\n* `fs` - the resolved fragment shader\n* `getUniforms` - a combined `getUniforms` function covering all modules.\n* `moduleMap` - a map with all resolved modules, keyed by name\n\n\n## Shader Hooks and Module Injections\n\nShader hooks and module injections are a system that allows for shader to be written in a generic manner, with behaviour modified when modules are included. For example if we define a shader hook as `fs:MY_HOOK_FUNCTION(inout vec4 color)`, `assembleShader` will inject the following function automatically into our fragment shader:\n```c\nvoid MY_HOOK_FUNCTION(inout vec4 color) {\n\n}\n```\nWe can the write our fragment shader as follows:\n\n```c\nprecision highp float;\n\nvoid main() {\n  vec4 color = vec4(1.0);\n  gl_FragColor = MY_HOOK_FUNCTION(color)\n}\n```\nBy default, the hook function is a no-op, so this doesn't do anything. However, if we add a module injection like the following:\n\n```js\n{\n  picking: {\n    'fs:VERTEX_HOOK_FUNCTION': 'color = vec4(1.0, 0.0, 0.0, 1.0);'\n  }\n}\n```\n\nAnd pass the `picking` module to `assembledShaders`, the hook function will be updated as follows:\n\n```c\nvoid MY_HOOK_FUNCTION(inout vec4 color) {\n  color = vec4(1.0, 0.0, 0.0, 1.0);\n}\n```\n\nThe hook function now changes the color from white to red.\n\n\n## Constants and Values\n\n### Predefined Injection Hooks\n\n| Key              | Shader   | Description      |\n| ---              | ---      | ---              |\n| `vs:#decl`       | Vertex   | Inject at top of shader (declarations) |\n| `vs:#main-start` | Vertex   | Injected at the very beginning of main function |\n| `vs:#main-end`   | Vertex   | Injected at the very end of main function |\n| `fs:#decl`       | Fragment | Inject at top of shader (declarations) |\n| `fs:#main-start` | Fragment | Injected at the very beginning of main function |\n| `fs:#main-end`   | Fragment | Injected at the very end of main function |\n\n**NOTE**: Injections assume that the `main` function appears last in a shader.\n\n## Usage\n\n### Injection Map\n\n`assembleShaders` (and `Model` constructor) will take an `inject` argument that contains a map of:\n\n* keys indicating hooks (predefined or functions)\n* values representing code to be injected. This can be either a simple string or an object containing the `injection` string and an `order` indicating its priority.\n\nExamples:\n\n```\n  inject: {\n    'fs:#main-end': '  gl_FragColor = picking_filterColor(gl_FragColor)'\n  }\n```\n\n```js\nProgramManager.getDefaultProgramManager(gl).addShaderHook('fs:MYHOOK_fragmentColor(inout vec4 color)');\n\nnew Model(gl, {\n  vs,\n  fs: `void main() {\n    MYHOOK_fragmentColor(gl_FragColor);\n  }`,\n  modules: [picking]\n  inject: {\n    'fs:#main-start': 'gl_FragColor = vec4(1., 0., 0., 1.);';\n    'fs:MYHOOK_fragmentColor': {\n      injection: '  color = picking_filterColor(color);',\n      order: 9999\n  }\n});\n```\n\n\n\n","slug":"docs/api-reference/shadertools/assemble-shaders","title":"Shader Assembly"},{"excerpt":"Core Shader Modules picking Provides support for color-coding-based picking. In particular, supports picking a specific instance in an…","rawMarkdownBody":"# Core Shader Modules\n\n## picking\n\nProvides support for color-coding-based picking. In particular, supports picking a specific instance in an instanced draw call.\n\nColor based picking lets the application draw a primitive with a color that can later be used to index this specific primitive.\n\n### Usage\n\nIn your vertex shader, your inform the picking module what object we are currently rendering by supplying a picking color, perhaps from an attribute.\n\n```glsl\nattribute vec3 aPickingColor;\nmain() {\n  picking_setPickingColor(aPickingColor);\n  ...\n}\n```\n\nIn your fragment shader, you simply apply (call) the `picking_filterPickingColor` filter function at the very end of the shader. This will return the normal color, or the highlight color, or the picking color, as appropriate.\n\n```glsl\nmain() {\n  gl_FragColor = ...\n  gl_FragColor = picking_filterPickingColor(gl_FragColor);\n}\n```\n\nIf you would like to apply the highlight color to the currently selected element call `picking_filterHighlightColor` before calling `picking_filterPickingColor`. You can also apply other filters on the non-picking color (vertex or highlight color) by placing those instruction between these two function calls.\n\n```glsl\nmain() {\n  gl_FragColor = picking_filterHighlightColor(color);\n  //  ... apply any filters on gl_FragColor ...\n  gl_FragColor = picking_filterPickingColor(gl_FragColor);\n}\n```\n\n### JavaScript Functions\n\n#### getUniforms\n\n`getUniforms` returns an object with key/value pairs representing the uniforms that the `picking` module shaders need.\n\n`getUniforms({pickingActive, ...})`\n\n* `pickingActive`=`false` (*boolean*) - Renders the picking colors instead of the normal colors. Normally only used with an off-screen framebuffer during picking.\n* `pickingSelectedColor`=`null` (*array|null*) - The picking color of the selected (highlighted) object.\n* `pickingHighlightColor`= `[0, 255, 255, 255]` (*array*) - Color used to highlight the currently selected object.\n* `pickingAttribute`=`false` (*boolean*) - Renders a color that encodes an attribute value. Normally only used with an off-screen framebuffer during picking.\n\n\n### Vertex Shader Functions\n\n#### picking_setPickingColor\n\nSets the color that will be returned by the fragment shader if color based picking is enabled. Typically set from a `pickingColor` uniform or a `pickingColors` attribute (e.g. when using instanced rendering, to identify the actual instance that was picked).\n\n`void picking_setPickingColor(vec3 pickingColor)`\n\n#### picking_setPickingAttribute\n\nSets the attribute value that needs to be picked.\n\n`void picking_setPickingAttribute(float value)`\n`void picking_setPickingAttribute(vec2 value)`\n`void picking_setPickingAttribute(vec3 value)`\n\n### Fragment Shader Functions\n\n#### picking_filterPickingColor\n\nIf picking active, returns the current vertex's picking color set by `picking_setPickingColor`, otherwise returns its argument unmodified.\n\n`vec4 picking_filterPickingColor(vec4 color)`\n\n#### picking_filterHighlightColor\n\nReturns picking highlight color if the pixel belongs to currently selected model, otherwise returns its argument unmodified.\n\n`vec4 picking_filterHighlightColor(vec4 color)`\n\n### Remarks\n\n* It is strongly recommended that `picking_filterPickingColor` is called last in a fragment shader, as the picking color (returned when picking is enabled) must not be modified in any way (and alpha must remain 1) or picking results will not be correct.\n","slug":"docs/api-reference/shadertools/core-shader-modules","title":"Core Shader Modules"},{"excerpt":"Context Management gltools provides functions to initialize, instrument and manipulate WebGL contexts. Usage Create a WebGL context…","rawMarkdownBody":"# Context Management\n\n**gltools** provides functions to initialize, instrument and manipulate WebGL contexts.\n\n## Usage\n\nCreate a WebGL context, autocreating a canvas\n```js\nimport {createGLContext} from '@luma.gl/gltools';\nconst gl = createGLContext(); // Prefers WebGL 2 but falls back to WebGL 1\n```\n\nCreate a WebGL 2 context.\n```js\nimport {createGLContext} from '@luma.gl/gltools';\nconst gl = createGLContext({\n  webgl1: false,\n  throwOnError: false\n});\nif (!gl) {\n  console.error('WebGL 2 not supported');\n}\n```\n\nPolyfill a WebGL context with features available in extensions.\n```js\nimport {polyfillContext} from '@luma.gl/gltools';\n\nconst gl = canvas.createContext('webgl'); // A WebGL 1 context\npolyfillContext(gl);\n\n// Using extension via WebGL 2 API\nconst vao = gl.createVertexArray();\n```\n\nInstrument an externally-created context to work with other luma.gl classes.\n```js\nimport {instrumentGLContext} from '@luma.gl/gltools';\nimport {Model} from '@luma.gl/engine';\n\nconst gl = canvas.createContext('webgl');\n\ninstrumentGLContext(gl);\n\n// Instrumentation ensures the context works with higher-level classes.\nconst model = new Model(gl, options);\n```\n\n## Functions\n\n### createGLContext\n\nCreates and returns a WebGL context, both in browsers and in Node.js.\n\n```\nconst gl = createGLContext(options);\n```\n\n* `options` (*Object*) - key/value pairs containing context creation options\n\n| Parameter               | Default | Description |\n| ---                     | ---     | ---         |\n| `webgl2`                | `true`  | If `true`, will attempt to create a WebGL 2 context. Will silently fall back to WebGL 1 contexts unless `webgl1` is set to `false`. |\n| `webgl1`                | `true`  | If `true`, will attempt to create a WebGL 1 context. The `webgl2` flag has higher priority. |\n| `throwOnError`          | `true`  | Normally the context will throw an error on failure. If `false`, it will log to console instead. |\n| `break`          | `[]`  | Insert a break point (`debugger`) if one of the listed gl functions is called. |\n| `manageState`           | `true`  | Instrument the context to enable state caching and `withParameter` calls. Leave on unless you have special reasons not to. |\n| `debug`                 | `false` | WebGL API calls will be logged to the console and WebGL errors will generate JavaScript exceptions. **NOTE:** requires importing [@luma.gl/debug](/docs/api-reference/debug). |\n| `canvas`                | `null`  | A *string* containing the `id` of an existing HTML element or a *DOMElement* instance. If `null` or not provided, a new canvas will be created. |\n| `alpha`                 | `true`  | Default render target has an alpha buffer. |\n| `depth`                 | `true`  | Default render target has a depth buffer of at least 16 bits. |\n| `stencil`               | `false` | Default render target has a stencil buffer of at least 8 bits. |\n| `antialias`             | `true`  | Boolean that indicates whether or not to perform anti-aliasing. |\n| `premultipliedAlpha`    | `true`  | Boolean that indicates that the page compositor will assume the drawing buffer contains colors with pre-multiplied alpha.\n| `preserveDrawingBuffer` | `false` | Default render target buffers will not be automatically cleared and will preserve their values until cleared or overwritten |\n| `failIfMajorPerformanceCaveat` |`false`|Do not create if the system performance is low.\n\n### instrumentGLContext\n\nInstrument an externally-created context with the same options as `createGLContext`. This performs WebGL 2 polyfilling (which is required for higher-level luma.gl classes) as well as optional state tracking and debug context creation.\n\n```\ninstrumentGLContext(gl, options);\n```\n\n* `gl` (*Object*) - An externally-created WebGL context.\n* `options` (*Object*) - key/value pairs containing context creation options (same as for `createGLContext`).\n\n\n### polyfillContext\n\nPolyfill a WebGL context integrating available extensions.\n\n```js\npolyfillContext(gl)\n```\n\n* `gl` {WebGLRenderingContext} - A WebGL context\n\n\n\n### resizeGLContext\n\nResize the drawing surface.\n\n```\nresizeGLContext(gl, options);\n```\n* `gl` (*Object*) - A WebGL context.\n* `options` (*Object*) - key/value pairs containing resize options.\n  * **width**: New drawing surface width.\n  * **height**: New drawing surface height.\n  * **useDevicePixels**: Whether to scale the drawing surface using the device pixel ratio.\n\n### getContextDebugInfo\n\nGet debug information about a WebGL context. Depends on `WEBGL_debug_renderer_info` extension.\n\n`getContextDebugInfo(gl)`\n\n* `gl` (*Object*) - A WebGL context.\n\nReturns (Object):\n- **vendor**: GPU vendor (unmasked if possible)\n- **renderer**: Renderer (unmasked if possible)\n- **vendorMasked**: Masked GPU vendor\n- **rendererMasked**: Masked renderer\n- **version**: WebGL version\n- **shadingLanguageVersion**: shading language version\n\n### isWebGL\n\nTest if an object is a WebGL 1 or 2 context, including correctly identifying a luma.gl debug context (which is not a subclass of a `WebGLRendringContext`).\n\n`isWebGL(gl)`\n\n* `gl` (Object) - Object to test.\nReturns true if the context is a WebGL 1 or 2 Context.\n\n### isWebGL2\n\nTest if an object is a WebGL 1 or 2 context, including correctly identifying a luma.gl debug context (which is not a subclass of a `WebGL2RendringContext`).\n\n`isWebGL2(gl)`\n\n* `gl` (Object) - Object to test.\nReturns true if the context is a WebGL 2 Context.\n\n","slug":"docs/api-reference/gltools/context","title":"Context Management"},{"excerpt":"Device Pixels Many modern devices support retina or UHD displays can render 2 or 4 times the number of pixels indicated by the CSS…","rawMarkdownBody":"# Device Pixels\n\nMany modern devices support retina or UHD displays can render 2 or 4 times the number of pixels indicated by the CSS dimensions. By rendering to a drawing surface that matches the device and then down sampling it to the smaller (CSS) area, sharper images can be produced but at the cost of rendering more pixels.\n\nThe [resizeGLContext](/docs/api-reference/gltools/context) function takes a `useDevicePixels` option that can resize the drawing buffer without resizing the the canvas as displayed on the screen. The following functions are provided to simplify calculations between the display size and device size of the drawing buffer:\n\n### cssToDeviceRatio(gl): Number\n\nReturns the ratio of device buffer resolution size to displayed resolution.\n\n* `gl` (WebGLContext) - WebGL context.\n\nReturns: ratio (Number).\n\n\n### cssToDevicePixels(gl, cssPixel, yInvert) : Object\n\nConverts CSS pixel location to Device pixel range.\n\n* `gl` (WebGLContext) - WebGL context.\n* `cssPixels` (Array) - Array in [x, y] form, where x and y are location in CSS window.\n* `yInvert` (Boolean, optional, default: true) - when true it will perform y-inversion when converting to Device pixels.\n\nReturns an Object, `{x, y, width, height}` that represents entire range of device pixels that correspond to given cssPixel location. Following fields define the rectangle.\n * `x` (Number): lower x-coordinate\n * `y` (Number): lower y-coordinate\n * `width` (Number): width in pixels\n * `height` (Number): height in pixels\n When `devicePixelRatio` is <=1, `width` and `height` are equal to `one`, otherwise `width` and `height` are greater than one.\n","slug":"docs/api-reference/gltools/device-pixels","title":"Device Pixels"},{"excerpt":"Context Properties luma.gl provides several helper functions for testing properties of a WebGL context: : get resource limits for a context…","rawMarkdownBody":"# Context Properties\n\nluma.gl provides several helper functions for testing properties of a WebGL context:\n- `getContextLimits`: get resource limits for a context\n- `getGLContextInfo`: get various properties of a gl context (using WebGL enums as keys)\n- `getContextInfo`: get various properties of a gl context (using strings as keys)\n\n## Usage\n\n```\n\nCheck a certain limit (whether through an extension under WebGL 1 or through WebGL 2)\n```js\nimport GL from '@luma.gl/constants';\nimport {getContextLimits} from '@luma.gl/webgl';\nconst limits = getContextLimits(gl);\nif (limits[GL.MAX_COLOR_ATTACHMENTS] > 0) { // it will be 0 for WebGL 1\n   ...\n}\n```\n\nThere are a few additional capability query functions sprinkled through the luma.gl API. In particular, WebGL 2 specific classes have an `isSupported` method that duplicates some of the queryies that can be made using the capability system\n```js\nimport {Query} from '@luma.gl/webgl';\nif (Query.isSupported(gl)) {\n  ...\n}\n```\n\n## Functions\n\n### getContextLimits(gl)\n\nReturns an object with limits, each limit is an object with multiple values\n- `value` - the value of the limit in the current context\n- `webgl1` - the minimum allowed value of the limit for WebGL 1 contexts\n- `webgl2` - the minimum allowed value of the limit for WebGL 2 contexts\n\n### WebGL Limits\n\nIn addition to capabilities, luma.gl can also query the context for all limits.\n\n| Limits                               | WebGL 2 | WebGL 1 | Description |\n| ---                                  | ---    | ---    | --- |\n| `GL.ALIASED_LINE_WIDTH_RANGE`        |        | [1, 1] | |\n| `GL.ALIASED_POINT_SIZE_RANGE`        |        | [1, 1] | |\n| `GL.MAX_TEXTURE_SIZE`                | 2048   | 64     | |\n| `GL.MAX_CUBE_MAP_TEXTURE_SIZE`       |        | 16     | |\n| `GL.MAX_TEXTURE_IMAGE_UNITS`         |        | 8      | |\n| `GL.MAX_COMBINED_TEXTURE_IMAGE_UNITS`|        | 8      | |\n| `GL.MAX_VERTEX_TEXTURE_IMAGE_UNITS`  |        | 0      | |\n| `GL.MAX_RENDERBUFFER_SIZE`           |        | 1      | |\n| `GL.MAX_VARYING_VECTORS`             |        | 8      | |\n| `GL.MAX_VERTEX_ATTRIBS`              |        | 8      | |\n| `GL.MAX_VERTEX_UNIFORM_VECTORS`      |        | 128    | |\n| `GL.MAX_FRAGMENT_UNIFORM_VECTORS`    |        | 16     | |\n| `GL.MAX_VIEWPORT_DIMS`               |        | [0, 0] | |\n| `GL.MAX_TEXTURE_MAX_ANISOTROPY_EXT`  |  1.0   | 1.0    | ['EXT_texture_filter_anisotropic'](https://developer.mozilla.org/en-US/docs/Web/API/EXT_texture_filter_anisotropic) |\n\n| WebGL 2 Limits                        | WebGL 2 | WebGL 1 (mock) | Description\n| ---                                  | ---    | ---           | --- |\n| `GL.MAX_3D_TEXTURE_SIZE`             | `256`  | `0`    | |\n| `GL.MAX_ARRAY_TEXTURE_LAYERS`        | `256`  | `0`    | |\n| `GL.MAX_CLIENT_WAIT_TIMEOUT_WEBGL`   | `0`    | `0`    | |\n| `GL.MAX_COLOR_ATTACHMENTS`           | `4`    | `0`    | |\n| `GL.MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS`| `0`|`0` | |\n| `GL.MAX_COMBINED_UNIFORM_BLOCKS`     | `0`    | `0`    | |\n| `GL.MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS`|`0`| `0`   | |\n| `GL.MAX_DRAW_BUFFERS`                | `4`    | `0`    | |\n| `GL.MAX_ELEMENT_INDEX`               | `0`    | `0`    | |\n| `GL.MAX_ELEMENTS_INDICES`            | `0`    | `0`    | |\n| `GL.MAX_ELEMENTS_VERTICES`           | `0`    | `0`    | |\n| `GL.MAX_FRAGMENT_INPUT_COMPONENTS`   | `0`    | `0`    | |\n| `GL.MAX_FRAGMENT_UNIFORM_BLOCKS`     | `0`    | `0`    | |\n| `GL.MAX_FRAGMENT_UNIFORM_COMPONENTS` | `0`    | `0`    | |\n| `GL.MAX_PROGRAM_TEXEL_OFFSET`        | `0`    | `0`    | |\n| `GL.MAX_SAMPLES`                     | `0`    | `0`    | |\n| `GL.MAX_SERVER_WAIT_TIMEOUT`         | `0`    | `0`    | |\n| `GL.MAX_TEXTURE_LOD_BIAS`            | `0`    | `0`    | |\n| `GL.MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS`|`0`|`0`| |\n| `GL.MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS` |`0`| `0` | |\n| `GL.MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS`|`0`|`0`| |\n| `GL.MAX_UNIFORM_BLOCK_SIZE`          | `0`    | `0`    | |\n| `GL.MAX_UNIFORM_BUFFER_BINDINGS`     | `0`    | `0`    | |\n| `GL.MAX_VARYING_COMPONENTS`          | `0`    | `0`    | |\n| `GL.MAX_VERTEX_OUTPUT_COMPONENTS`    | `0`    | `0`    | |\n| `GL.MAX_VERTEX_UNIFORM_BLOCKS`       | `0`    | `0`    | |\n| `GL.MAX_VERTEX_UNIFORM_COMPONENTS`   | `0`    | `0`    | |\n| `GL.MIN_PROGRAM_TEXEL_OFFSET`        | `0`    | `0`    | |\n| `GL.UNIFORM_BUFFER_OFFSET_ALIGNMENT` | `0`    | `0`    | |\n\n### getGLContextInfo(gl)\nReturns an object with following parameters as keys and corresponding value for each key.\n\n| parameter |\n| --- |\n| 'GL.VENDOR' |\n| 'GL.RENDERER' |\n| 'GL.UNMASKED_VENDOR_WEBGL' |\n| 'GL.UNMASKED_RENDERER_WEBGL' |\n| 'GL.VERSION' |\n| 'GL.SHADING_LANGUAGE_VERSION' |\n\n\n\n### getContextInfo(gl)\n\nReturns an object containing following details.\n* vendor: info[GL.UNMASKED_VENDOR_WEBGL] || info[GL.VENDOR],\n* renderer: info[GL.UNMASKED_RENDERER_WEBGL] || info[GL.RENDERER],\n* version: info[GL.VERSION],\n* shadingLanguageVersion: info[GL.SHADING_LANGUAGE_VERSION],\n* info,\n* limits,\n* webgl1MinLimits: gl.luma.webgl1MinLimits,\n* webgl2MinLimits: gl.luma.webgl2MinLimits\n\n\n## Remarks\n\n* WebGL 1 only supports one color buffer format (RBG32F is deprecated)\n* WebGL 2 supports multiple color buffer formats\n* Some extensions will not be enabled until they have been queries. luma always queries on startup to enable, app only needs to query again it wants to test platform.\n* The capability detection system works regardless of whether the app is running in a browser or in headless mode under Node.js.\n* Naturally, given that queries to driver and GPU are typically expensive in WebGL, the capabilities system will cache any queries.\n","slug":"docs/api-reference/webgl/context/context-properties","title":"Context Properties"},{"excerpt":"Parameter Setting luma.gl simplifies the usage of WebGL parameters by providing a unified API for setting and getting values. Any GL…","rawMarkdownBody":"# Parameter Setting\n\nluma.gl simplifies the usage of WebGL parameters by providing a unified API for setting and getting values. Any GL parameter can be queried or set using `getParameters` and `setParameters` (no need to keep track of what underlying WebGL calls are required), and luma.gl also provide *setting names* that allow the normal WebGL setter functions (like `gl.blendEquation` or `gl.clearColor`) to be specified as keys in a `setParameters` call.\n\nIn addition, state queries are done towards cached values and are thus much faster than working directly with the WebGL API, where synchronous WebGL queries can be a performance bottleneck.\n\nThe following functions are provided:\n* `getParameters` - Returns the values of some or all GL context parameters\n* `setParameters` - Sets a the value(s) of the specified GL context parameters\n* `resetParameters` - Resets all gl context parameters to default values\n\n## Usage\n\nSet a global parameter value using a WebGL GLenum\n```js\nconst value = setParameters(gl, {\n  [gl.DEPTH_TEST]: true\n});\n```\n\nSet a global parameter value using a luma.gl setting function name\n```js\nconst value = setParameters(gl, {\n  depthTest: true\n});\n```\n\nGet all gl parameter values (values will be an object map keyed with parameter names)\n```js\nconst values = getParameters(gl);\n```\n\nSet parameters temporarily for a function call (automatically restoring them after the call)\n```js\nconst returnValue = withParameters(gl, {\n  depthTest: true\n}, () = {\n  // execute code with new parameters temporarily applied\n  program.draw(...);\n  // ...\n  // parameters will be restored even the function throws an exception\n  if (...) {\n    throw new Error('Exception after setting parameters');\n  }\n\n  // Return value of the function will be returned from `withParameters`\n  return true;\n});\n\n// previous parameters are restored here\n```\n\n## Functions\n\n### getParameters\n\nGets the values of a gl context parameter.\n\n```js\ngetParameters(gl, values)\n```\n\n* `gl` {WebGLRenderingContext} - context\n* `values`= {Object | GLenum[] | null}  - parameters, either as keys in object or elements of array. Defaults to all parameters.\nReturns {Object} - object with keys and values corresponding to supplied parameter names and the current values of those parameters.\n\n\n### setParameters\n\nSets a number of parameters.\n\n```js\nsetParameters(gl, {key: value, ...})\n```\n\n* `gl` {WebGLRenderingContext} - context\n* `key` {String} - parameter names, (, either )luma.gl setting name or a GL parameter constants\n* `value` {*} - parameter value\nReturns {*} - \"normalized\" parameter value after assignment\n\nNote:\n* If both luma.gl setting names and GL parameter constants representing the same value are submitted the results are undefined.\n* value may be \"normalized\" (in case a short form is supported). In that case the normalized value is returned.\n\n### resetParameters\n\n```js\nresetParameters(gl)\n```\nResets all gl context parameters to default values.\n\n* `gl` {WebGLRenderingContext} - context\nReturns no value.\n\nNote that technically, resetting context parameters does not fully reset the context, as buffer binding, z buffer values etc are not reset.\n\n### withParameters\n\nExecutes a function after temporarily setting the parameters. Will restore the parameters to their previously value after the completion of the function, even if the function exits with an exception.\n\n```js\nwithParameters(gl, {...params}, func)\n```\n* `gl` {WebGLRenderingContext} - context\n* `params` {Object} - any parameter names accepted by `setParameters`\n\nReturns: the value returned by `func`, if any.\n\n\n## Parameters\n\nDescribes luma.gl setting names and values\n\n### Blending\n\n| Function style        | Sets parameter(s)      |\n| --------------------- | ---------------------- |\n| [blendColor](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/blendColor)        | `GL.BLEND_COLOR`       |\n| [blendEquation](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/blendEquation)     | [`GL.BLEND_EQUATION_RGB`, `GL.BLEND_EQUATION_ALPHA`] |\n| [blendFunc](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/blendFunc)         | [`GL.BLEND_SRC_RGB`, `GL.BLEND_SRC_ALPHA`] |\n| [blendFuncSeparate](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/blendFuncSeparate) | [`GL.BLEND_SRC_RGB`, `GL.BLEND_SRC_ALPHA`, `GL.BLEND_DST_RGB`, `GL.BLEND_DST_ALPHA`] |\n\n| Parameter                 | Type            | Default         | Description |\n| ------------------------- | --------------- | --------------- | -------- |\n| `GL.BLEND`                | GLboolean       | `false`         | Blending enabled |\n| `GL.BLEND_COLOR`          | Float32Array(4) | `[0, 0, 0, 0]`  | |\n| `GL.BLEND_EQUATION_RGB`   | GLenum          | `GL.FUNC_ADD`   | |\n| `GL.BLEND_EQUATION_ALPHA` | GLenum          | `GL.FUNC_ADD`   | |\n| `GL.BLEND_SRC_RGB`        | GLenum          | `GL.ONE`        | srcRgb |\n| `GL.BLEND_SRC_ALPHA`      | GLenum          | `GL.ZERO`       | srcAlpha |\n| `GL.BLEND_DST_RGB`        | GLenum          | `GL.ONE`        | dstRgb |\n| `GL.BLEND_DST_ALPHA`      | GLenum          | `GL.ZERO`       | dstAlpha |\n\n\n### Clear Color\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [clearColor](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/clearColor) | GL.COLOR_CLEAR_VALUE |\n\n| Parameter              | Type            | Default  | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.COLOR_CLEAR_VALUE` | new Float32Array(4) | [0, 0, 0, 0] | . |\n\n\n### Color Mask\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [colorMask](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/colorMask) | GL.COLOR_WRITEMASK |\n\n| Parameter              | Type            | Default  | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.COLOR_WRITEMASK` | [GLboolean, GLboolean, GLboolean, GLboolean] | [true, true, true, true] | . |\n\n\n### Depth Test\n\n| Function style   | Sets parameters        |\n| ---------------- | ---------------------- |\n| [clearDepth](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/clearDepth)     | `GL.DEPTH_CLEAR_VALUE` |\n| [depthFunc](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/depthFunc)      | `GL.DEPTH_FUNC`        |\n| [depthRange](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/depthRange)     | `GL.DEPTH_RANGE`       |\n| [depthMask](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/depthMask)      | `GL.DEPTH_WRITEMASK`   |\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.DEPTH_TEST`        | GLboolean       | false |  |\n| `GL.DEPTH_CLEAR_VALUE` | GLfloat         | true |  |\n| `GL.DEPTH_FUNC`        | GLenum          | null |  |\n| `GL.DEPTH_RANGE`       | Float32Array(2) | [null, null] // TBD |  |\n| `GL.DEPTH_WRITEMASK`   | GLboolean       | null |  |\n\n\n### Derivative Hints (WebGL 2 or extension)\n\nRequires WebGL 2 or `OES_standard_derivatives`.\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.FRAGMENT_SHADER_DERIVATIVE_HINT` | GLenum     | `GL.DONT_CARE` | Accuracy of derivates in built-in GLSL functions |\n\n\n#### Hints\n\n| Value          | Description        |\n| -------------- | ---------------------- |\n| `GL.FASTEST`   | The most efficient behavior should be used |\n| `GL.NICEST`    | The most correct or the highest quality option should be used |\n| `GL.DONT_CARE` | There is no preference for this behavior |\n\n\n### Dithering\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.DITHER` | GLboolean | `true` | Enable dithering of color components before they get written to the color buffer |\n\n* Note: Dithering is driver dependent and typically has a stronger effect when the color components have a lower number of bits.\n\n\n### Face Culling\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [cullFace](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/cullFace)  | `GL.CULL_FACE_MODE` |\n| [frontFace](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/frontFace) | `GL.FRONT_FACE` |\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.CULL_FACE`         | GLboolean | `false` | Enable face culling |\n| `GL.CULL_FACE_MODE`    | GLenum    | `GL.BACK` | Which face to cull |\n| `GL.FRONT_FACE`        | GLenum    | `GL.CCW` | Which face is front |\n\n#### Cull Face Modes\n\n| Value               | Description            |\n| ------------------- | ---------------------- |\n| `GL.FRONT`          | Clock wise             |\n| `GL.BACK`           | Counter clock wise     |\n| `GL.FRONT_AND_BACK` | No polygons are drawn (but LINES and POINTS are) |\n\n#### Face orientation\n\n| Value          | Description        |\n| -------------- | ------------------ |\n| `GL.CW`        | Clock wise         |\n| `GL.CCW`       | Counter clock wise |\n\n\n### MipmapHint\n\nHint for quality of images generated with glGenerateMipmap\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.GENERATE_MIPMAP_HINT` | GLenum | `GL.DONT_CARE` | . |\n\n#### Mipmap Hints\n\n| Value          | Description            |\n| -------------- | ---------------------- |\n| `GL.FASTEST`   | The most efficient behavior should be used |\n| `GL.NICEST`    | The most correct or the highest quality option should be used |\n| `GL.DONT_CARE` | There is no preference for this behavior |\n\n\n### LineWidth\n\nLine widths are between 1 and GL.ALIASED_LINE_WIDTH_RANGE.\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [lineWidth](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/lineWidth) | `GL.LINE_WIDTH` |\n\n| Parameter              | Type            | Default | Description |\n| ---------------------- | --------------- | -------- | -------- |\n| `GL.LINE_WIDTH` | GLfloat | 1 | . |\n\nExample:\n```js\n// Set viewport to maximum supported size\nconst lineWidthRange = getLimits(gl)[GL.ALIASED_LINE_WIDTH_RANGE];\nsetState(gl, {\n  lineWidth: lineWidthRange[1]\n});\n```\n\n* Note: Line widths will be clamped to [1, `GL.ALIASED_LINE_WIDTH_RANGE`]. This is different from `gl.lineWidth` which generates errors on lineWidth 0.\n* Caution: line aliasing is driver dependent and `GL.LINES` may not give desired results.\n\n\n### PolygonOffset\n\nAdd small offset to fragment depth values (by factor × DZ + r × units)\nUseful for rendering hidden-line images, for applying decals to surfaces,\nand for rendering solids with highlighted edges.\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [polygonOffset](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/polygonOffset) | [GL.POLYGON_OFFSET_FACTOR, GL.POLYGON_OFFSET_UNITS] |\n\n| Parameter                  | Type          | Default  | Description             |\n| -------------------------- | ------------- | -------- | ----------------------- |\n| `GL.POLYGON_OFFSET_FILL`   | GLboolean     |  `false` | . |\n| `GL.POLYGON_OFFSET_FACTOR` | GLfloat       |      `0` | . |\n| `GL.POLYGON_OFFSET_UNITS`  | GLfloat       |      `0` | . |\n\n* Note: The semantics of polygon offsets are loosely specified by the WebGL standard and results can thus be driver dependent.\n\n\n### Rasterization (WebGL 2)\n\nPrimitives are discarded immediately before the rasterization stage, but after the optional transform feedback stage. `gl.clear()` commands are ignored.\n\n| Parameter                           | Type          | Default  | Description             |\n| ----------------------------------- | ------------- | -------- | ----------------------- |\n| `GL.RASTERIZER_DISCARD`             | GLboolean     | `false`  | Disable rasterization |\n\n\n### Sampling\n\nSpecify multisample coverage parameters\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [sampleCoverage](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/sampleCoverage) | [`GL.SAMPLE_COVERAGE_VALUE`, `GL.SAMPLE_COVERAGE_INVERT`] |\n\n| Parameter                          | Type          | Default  | Description             |\n| ---------------------------------- | ------------- | -------- | ----------------------- |\n| `GL_SAMPLE_COVERAGE`               | GLboolean | `false` | Activates the computation of a temporary coverage value determined by the alpha value. |\n| `GL_SAMPLE_ALPHA_TO_COVERAGE`      | GLboolean | `false` | Activates ANDing the fragment's coverage with the temporary coverage value |\n| `GL.SAMPLE_COVERAGE_VALUE`         | GLfloat   | 1.0     |  |\n| `GL.SAMPLE_COVERAGE_INVERT`        | GLboolean | `false` |  |\n\n\n### Scissor Test\n\nSettings for scissor test and scissor box.\n\n| Function  | Sets parameters                    |\n| --------- | ---------------------------------- |\n| [scissor](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/scissor) | `GL.SCISSOR_BOX`                   |\n| scissorTest | GL.SCISSOR_TEST |\n\n| Parameter                          | Type          | Default  | Description             |\n| ---------------------------------- | ------------- | -------- | ----------------------- |\n| `GL.SCISSOR_TEST`                  | GLboolean     | `false`  |\n| `GL.SCISSOR_BOX`                   | Int32Array(4) | [null, null, null, null]), // TBD |\n\n\n### Stencil Test\n\nSetting any value will enable stencil testing (i.e. enable `GL.STENCIL_TEST`).\n\n| Function | Parameters Set |\n| -------- | -------------- |\n| [clearStencil](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/clearStencil) | `GL.STENCIL_CLEAR_VALUE` |\n| [stencilMask](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilMask) | [`GL.STENCIL_WRITEMASK`] |\n| [stencilMaskSeparate](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilMaskSeparate) | [`GL.STENCIL_WRITEMASK`, `GL.STENCIL_BACK_WRITEMASK`] |\n| [stencilFunc](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilFunc) | [`GL.STENCIL_FUNC`, `GL.STENCIL_REF`, `GL.STENCIL_VALUE_MASK`] |\n| [stencilFuncSeparate](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilFuncSeparate) | [`GL.STENCIL_FUNC`, `GL.STENCIL_REF`, `GL.STENCIL_VALUE_MASK`, `GL.STENCIL_BACK_FUNC`, `GL.STENCIL_BACK_REF`, `GL.STENCIL_BACK_VALUE_MASK` ]\n| [stencilOp](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilOp) | [`GL.STENCIL_FAIL`, `GL.STENCIL_FAIL_DEPTH_FAIL`, `GL.STENCIL_FAIL_DEPTH_PASS`]|\n| [stencilOpSeparate](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/stencilOpSeparate) | [`GL.STENCIL_FAIL`, `GL.STENCIL_FAIL_DEPTH_FAIL`, `GL.STENCIL_FAIL_DEPTH_PASS`, `GL.STENCIL_BACK_FAIL`, `GL.STENCIL_BACK_FAIL_DEPTH_FAIL`, `GL.STENCIL_BACK_FAIL_DEPTH_PASS`]|\n\n| Parameter                         | Type      | Default      | Description             |\n| --------------------------------- | --------- | ------------ | ----------------------- |\n| `GL.STENCIL_TEST`                 | GLboolean | `false`      | Enables stencil testing |\n| `GL.STENCIL_CLEAR_VALUE`          | GLint     | `0`          | Sets index used when stencil buffer is cleared. |\n| `GL.STENCIL_WRITEMASK`            | GLuint    | `0xFFFFFFFF` | Sets bit mask enabling writing of individual bits in the stencil planes |\n| `GL.STENCIL_BACK_WRITEMASK`       | GLuint    | `0xFFFFFFFF` | Sets bit mask enabling writing of individual bits in the stencil planes |\n| `GL.STENCIL_FUNC`                 | GLenum    | `GL.ALWAYS`  | |\n| `GL.STENCIL_REF`                  | GLint     | `0`          | |\n| `GL.STENCIL_VALUE_MASK`           | GLuint    | `0xFFFFFFFF` | Sets bit mask |\n| `GL.STENCIL_BACK_FUNC`            | GLenum    | `GL.ALWAYS`  | |\n| `GL.STENCIL_BACK_REF`             | GLint     | `0`          | |\n| `GL.STENCIL_BACK_VALUE_MASK`      | GLuint    | `0xFFFFFFFF` | Sets bit mask enabling writing of individual bits in the stencil planes |\n| `GL.STENCIL_FAIL`                 | GLenum    | `GL.KEEP`    | stencil test fail action |\n| `GL.STENCIL_PASS_DEPTH_FAIL`      | GLenum    | `GL.KEEP`    | depth test fail action |\n| `GL.STENCIL_PASS_DEPTH_PASS`      | GLenum    | `GL.KEEP`    | depth test pass action |\n| `GL.STENCIL_BACK_FAIL`            | GLenum    | `GL.KEEP`    | stencil test fail action, back |\n| `GL.STENCIL_BACK_PASS_DEPTH_FAIL` | GLenum    | `GL.KEEP`    | depth test fail action, back |\n| `GL.STENCIL_BACK_PASS_DEPTH_PASS` | GLenum    | `GL.KEEP`    | depth test pass action, back |\n\n#### Stencil Test Functions\n\nValues for `GL.STENCIL_TEST`\n\n| Value          | Description            |\n| -------------- | ---------------------- |\n| `GL.NEVER`     | Never pass |\n| `GL.LESS`      | Pass if (ref & mask) <  (stencil & mask) |\n| `GL.EQUAL`     | Pass if (ref & mask) =  (stencil & mask) |\n| `GL.LEQUAL`    | Pass if (ref & mask) <= (stencil & mask) |\n| `GL.GREATER`   | Pass if (ref & mask) >  (stencil & mask) |\n| `GL.NOTEQUAL`  | Pass if (ref & mask) != (stencil & mask) |\n| `GL.GEQUAL`    | Pass if (ref & mask) >= (stencil & mask) |\n| `GL.ALWAYS`    | Always pass |\n\n#### Stencil Operations\n\n| Value          | Description            |\n| -------------- | ---------------------- |\n| `GL.KEEP`      | Keeps the current value |\n| `GL.ZERO`      | Sets the stencil buffer value to 0 |\n| `GL.REPLACE`   | Sets the stencil buffer value to the reference value as specified by `stencilFunc` |\n| `GL.INCR`      | Increments the current stencil buffer value. Clamps to the maximum representable unsigned value |\n| `GL.INCR_WRAP` | Increments the current stencil buffer value. Wraps to zero when incrementing the maximum representable unsigned value |\n| `GL.DECR`      | Decrements current stencil buffer value. Clamps to 0 |\n| `GL.DECR_WRAP` | Decrements  current stencil buffer value, wraps to maximum unsigned value when decrementing 0 |\n| `GL.INVERT`    | Inverts the current stencil buffer value bitwise |\n\nAction when the stencil test fails, front and back.\n* stencil test fail action,\n* depth test fail action,\n* pass action\n\n\n## Viewport\n\nSpecifies the transformation from normalized device coordinates to\nwindow/framebuffer coordinates. The maximum supported value, is defined by the\n`GL.MAX_VIEWPORT_DIMS` limit.\n\n| Function     | Parameters     |\n| ------------ | -------------- |\n| [viewport](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/viewport) | `GL.VIEWPORT`  |\n\n| Parameter                          | Type          | Default   | Description             |\n| ---------------------------------- | ------------- | --------- | ----------------------- |\n| `GL.VIEWPORT`                      | Int32Array(4) | [...] TBD | Viewport                |\n\nExample:\n```js\n// Set viewport to maximum supported size\nconst maxViewport = getLimits(gl)[GL.MAX_VIEWPORT_DIMS];\nsetState(gl, {\n  viewport: [0, 0, maxViewport[0], maxViewport[1]]\n});\n```\n\n## Pixel Pack/Unpack Modes\n\nSpecifies how bitmaps are written to and read from memory\n\n| Parameter                             | Type          | Default  | Description             |\n| ------------------------------------- | ------------- | -------- | ----------------------- |\n| `GL.PACK_ALIGNMENT`                   | GLint         |        4 | Byte alignment of pixel row data in memory (1,2,4,8 bytes) when storing data |\n| `GL.UNPACK_ALIGNMENT`                 | GLint         |        4 | Byte alignment of pixel row data in memory (1,2,4,8 bytes) when reading data |\n| `GL.UNPACK_FLIP_Y_WEBGL`              | GLboolean     |  `false` | Flip source data along its vertical axis |\n| `GL.UNPACK_PREMULTIPLY_ALPHA_WEBGL`   | GLboolean     |  `false` | Multiplies the alpha channel into the other color channels |\n| `GL.UNPACK_COLORSPACE_CONVERSION_WEBGL` | GLenum      | `GL.BROWSER_DEFAULT_WEBGL` | Use default or no color space conversion. |\n\n\n## Pixel Pack/Unpack Modes **WebGL 2**\n\nSpecifies how bitmaps are written to and read from memory\n\n| Parameter                          | Type          | Default  | Description               |\n| ---------------------------------- | ------------- | -------- | ------------------------- |\n| `GL.PACK_ROW_LENGTH`               | GLint         |      `0` | Number of pixels in a row |\n| `GL.PACK_SKIP_PIXELS`              | GLint         |      `0` | Number of pixels skipped before the first pixel is written into memory |\n| `GL.PACK_SKIP_ROWS`                | GLint         |      `0` | Number of rows of pixels skipped before first pixel is written to memory |\n| `GL.UNPACK_ROW_LENGTH`             | GLint         |      `0` | Number of pixels in a row. |\n| `GL.UNPACK_IMAGE_HEIGHT`           | GLint         |      `0` | Image height used for reading pixel data from memory |\n| `GL.UNPACK_SKIP_PIXELS`            | GLint         |      `0` | Number of pixel images skipped before first pixel is read from memory |\n| `GL.UNPACK_SKIP_ROWS`              | GLint         |      `0` | Number of rows of pixels skipped before first pixel is read from memory |\n| `GL.UNPACK_SKIP_IMAGES`            | GLint         |      `0` | Number of pixel images skipped before first pixel is read from memory |\n\n\n## Remarks\n\nWebGL State Management can be quite complicated.\n* A large part of the WebGL API is devoted to parameters. When reading, querying individual values using GL constants is the norm, and when writing, special purpose functions are provided for most parameters. luma.gl supports both forms for both reading and writing parameters.\n* Reading values from WebGL can be very slow if it requires a GPU roundtrip. To get around this, luma.gl reads values once, caches them and tracks them as they are changed through luma functions. The cached values can get out of sync if the context is shared outside of luma.gl.\n* luma.gl's state management enables \"conflict-free\" programming, so that even when setting global state, one part of the code does not need to worry about whether other parts are changing the global state.\n* Note that to fully support the conflict-free model and detect changes done e.g. in other WebGL libraries, luma.gl needs to hook into the WebGL context to track state changes.\n","slug":"docs/api-reference/gltools/parameter-setting","title":"Parameter Setting"},{"excerpt":"Effects Shader Modules Screen space effects packaged as reusable shader modules in  based on the glfx library. Attribution / License This is…","rawMarkdownBody":"# Effects Shader Modules\n\n\nScreen space effects packaged as reusable shader modules in `@luma.gl/shadertools` based on the [glfx library](http://evanw.github.io/glfx.js/).\n\n\n## Attribution / License\n\nThis is a repackaging of shader code from [Evan Wallace](https://github.com/evanw/glfx.js)'s glfx library.\n\nThe code and documentation is included here under MIT license.\n\n## Usage\n\nImport brightnessContrast shader module\n\n```js\n    import {brightnessContrast} from '@luma.gl/shadertools';\n```\n\n## Shader Modules\n\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/mountain.jpg\" />\n        <p><i>Original Image</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### brightnessContrast\n\nProvides additive brightness and multiplicative contrast control.\n\n* `brightness` -1 to 1 (-1 is solid black, 0 is no change, and 1 is solid white). Default value is `0`.\n* `contrast`   -1 to 1 (-1 is solid gray, 0 is no change, and 1 is maximum contrast). Default value is `0`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/brightness.jpg\" />\n        <p><i>Brightness / Contrast Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n### hueSaturation\n\nProvides rotational hue and multiplicative saturation control. RGB color space can be imagined as a cube where the axes are the red, green, and blue color values.\n\nHue changing works by rotating the color vector around the grayscale line, which is the straight line from black (0, 0, 0) to white (1, 1, 1).\n\nSaturation is implemented by scaling all color channel values either toward or away from the average color channel value.\n\n* `hue` -1 to 1 (-1 is 180 degree rotation in the negative direction, 0 is no change, and 1 is 180 degree rotation in the positive direction). Default value is `0`.\n* `saturation` -1 to 1 (-1 is solid gray, 0 is no change, and 1 is maximum contrast). Default value is `0`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/hue.jpg\" />\n        <p><i>Hue / Saturation Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### noise\n\nAdds black and white noise to the image.\n\n* `amount`   0 to 1 (0 for no effect, 1 for maximum noise). Default value is `0.5`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/noise.jpg\" />\n        <p><i>Noise Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### sepia\n\n\nGives the image a reddish-brown monochrome tint that imitates an old photograph.\n\n* `amount` 0 to 1 (0 for no effect, 1 for full sepia coloring). Default value is `0.5`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/sepia.jpg\" />\n        <p><i>Sepia Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### vibrance\n\nModifies the saturation of desaturated colors, leaving saturated colors unmodified.\n\n* `amount` -1 to 1 (-1 is minimum vibrance, 0 is no change, and 1 is maximum vibrance). Default value is `0`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/vibrance.jpg\" />\n        <p><i>Vibrance Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### vignette\n\nAdds a simulated lens edge darkening effect.\n\n* `size`     0 to 1 (0 for center of frame, 1 for edge of frame). Default value is `0.5`.\n* `amount`   0 to 1 (0 for no effect, 1 for maximum lens darkening). Default value is `0.5`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/vignette.jpg\" />\n        <p><i>Vignette Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### tiltShift\n\nSimulates the shallow depth of field normally encountered in close-up photography, which makes the scene seem much smaller than it actually is. This filter assumes the scene is relatively planar, in which case the part of the scene that is completely in focus can be described by a line (the intersection of the focal plane and the scene). An example of a planar scene might be looking at a road from above at a downward angle. The image is then blurred with a blur radius that starts at zero on the line and increases further from the line.\n\n * `start`          [x, y] coordinate of the start of the line segment. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0, 0]`.\n * `end`            [x, y] coordinate of the end of the line segment. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[1, 1]`.\n * `blurRadius`     The maximum radius of the pyramid blur in pixels. Default value is `15`.\n * `gradientRadius` The distance in pixels from the line at which the maximum blur radius is reached. Default value is `200`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/tilt_shift.jpg\" />\n        <p><i>Tilt Shift Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### triangleBlur\n\nThis is the most basic blur filter, which convolves the image with a pyramid filter. The pyramid filter is separable and is applied as two perpendicular triangle filters.\n\n* `radius` The radius of the pyramid in pixels convolved with the image. Default value is `20`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/triangle_blur.jpg\" />\n        <p><i>Triangle Blur Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### zoomBlur\n\nBlurs the image away from a certain point, which looks like radial motion blur.\n\n* `center`  [x, y] coordinate of the blur origin. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `strength` The strength of the blur. Values in the range 0 to 1 are usually sufficient, where 0 doesn't change the image and 1 creates a highly blurred image. Default value is `0.3`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/zoom_blur.jpg\" />\n        <p><i>Zoom Blur Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n###  colorHalftone\n\n Simulates a CMYK halftone rendering of the image by multiplying pixel values with a four rotated 2D sine wave patterns, one each for cyan, magenta, yellow, and black.\n\n* `center` [x, y] coordinate of the pattern origin. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `angle`  The rotation of the pattern in radians. Default value is `1.1`.\n* `size`   The diameter of a dot in pixels. Default value is `4`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/color_halftone.jpg\" />\n        <p><i>Color Halftone Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### dotScreen\n\nSimulates a black and white halftone rendering of the image by multiplying pixel values with a rotated 2D sine wave pattern.\n\n* `center`  [x, y] coordinate of the pattern origin. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `angle`   The rotation of the pattern in radians. Default value is `1.1`.\n* `size`    The diameter of a dot in pixels. Default value is `3`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/dot_screen.jpg\" />\n        <p><i>Dot Screen Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### edgeWork\n\nPicks out different frequencies in the image by subtracting two copies of the image blurred with different radii.\n\n* `radius` The radius of the effect in pixels. Default value is `2`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/edge_work.jpg\" />\n        <p><i>Edge Work Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### hexagonalPixelate\n\nRenders the image using a pattern of hexagonal tiles. Tile colors are nearest-neighbor sampled from the centers of the tiles.\n\n* `center` [x, y] coordinate of the pattern center. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `scale`  The width of an individual tile in pixels. Default value is `10`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/hexagon.jpg\" />\n        <p><i>Hexagonal Pixelate Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### ink\n\nSimulates outlining the image in ink by darkening edges stronger than a certain threshold. The edge detection value is the difference of two copies of the image, each blurred using a blur of a different radius.\n\n* `strength` The multiplicative scale of the ink edges. Values in the range 0 to 1 are usually sufficient, where 0 doesn't change the image and 1 adds lots of black edges. Negative strength values will create white ink edges instead of black ones. Default value is `0.25`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/ink.jpg\" />\n        <p><i>Ink Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### bulgePinch\n\nBulges or pinches the image in a circle.\n\n* `center`  [x, y] coordinate of the center of the circle of effect. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `radius`  The radius of the circle of effect in pixels. Default value is `200`.\n* `strength` -1 to 1 (-1 is strong pinch, 0 is no effect, 1 is strong bulge). Default value is `0.5`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/bulge_pinch.jpg\" />\n        <p><i>Bulge Pinch Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n### swirl\n\nWarps a circular region of the image in a swirl.\n\n* `center` [x, y] coordinate of the center of the circular region. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner. Default value is `[0.5, 0.5]`.\n* `radius` The radius of the circular region in pixels. Default value is `200`.\n* `angle`  The angle in radians that the pixels in the center of the circular region will be rotated by. Default value is `3`.\n\n<table style=\"border: 0;\" align=\"center\">\n  <tbody>\n    <tr>\n      <td align=\"center\">\n        <img height=340 src=\"https://raw.githubusercontent.com/uber-common/deck.gl-data/master/images/samples/glfx/results/swirl.jpg\" />\n        <p><i>Swirl Effect</i></p>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## Remarks\n\n* Coordinate is based on the original image. `[0, 0]` is the bottom left corner, `[1, 1]` is the up right corner.\n","slug":"docs/api-reference/shadertools/effects-shader-modules","title":"Effects Shader Modules"},{"excerpt":"Feature Checking Provides WebGL feature detection. WebGL capabilities can vary quite dramatically between browsers (from minimal WebGL 1 (e…","rawMarkdownBody":"# Feature Checking\n\nProvides WebGL feature detection.\n\nWebGL capabilities can vary quite dramatically between browsers (from minimal WebGL 1 (e.g. headless-gl) to WebGL 1 with dozens of extensions to full WebGL 2, which also has a growing number of extensions). Unfortunately, the raw WebGL API sometimes expose the same functionalities through APIs that are slightly different and not exactly compatible.\n\nTo simplify detecting and working with conditionally available capabilities (or \"features\") luma.gl provides:\n\n* A set of functions that enable you to check if the application is currently running on an environment that supports a certain feature (regardless of whether it is supported through e.g. WebGL 2 or a WebGL 1 extension).\n\nIn addition, luma.gl's WebGL classes transparently use WebGL extensions or WebGL 2 APIs as appropriate, meaning that the amount of conditional logic in application code can be kept to a minimum. Once you have established that a capability exists, luma.gl offers you one unified way to use it.\n\n\n## Usage\n\nCheck if a feature is available (whether as a WebGL 1 or WebGL 2 extension or through WebGL 2)\n```js\nimport {hasFeature, FEATURES} from '@luma.gl/webgl';\nif (hasFeature(gl, FEATURES.INSTANCED_RENDERING)) {\n   // Will work both on WebGL 1 (via extension) and WebGL 2 via the standard API\n   program.draw({instanceCount: ..., ....});\n}\n```\n\nAnother example of feature detection\n```js\nimport {hasFeature, FEATURES} from '@luma.gl/webgl';\n// Checks if `Query` objects can do async queries of GPU timings\nif (hasFeature(gl, FEATURES.TIMER_QUERY)) {\n   ...\n}\n// Alternatively - do the same query using raw extensions\nif (hasFeature(gl, 'EXT_disjoint_timer_query') || hasFeature(gl, 'EXT_disjoint_timer_query_webgl2')) {\n   ...\n}\n```\n\n\nThere are a few additional capability query functions sprinkled through the luma.gl API. In particular, WebGL 2 specific classes have an `isSupported` method that duplicates some of the queryies that can be made using the capability system\n```js\nimport {Query} from '@luma.gl/webgl';\nif (Query.isSupported(gl)) {\n  ...\n}\n```\n\n## Functions\n\n### hasFeature\n\nAllows the app to query whether a capability is supported without being concerned about how it is being provided (WebGL 2, an extension etc)\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* capability (`String`) - capability name (can be a webgl extension name or a luma.gl `FEATURES` constant).\n\n### hasFeatures\n\nAllows the app to query whether a capability is supported without being concerned about how it is being provided (WebGL 2, an extension etc)\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* feature (`String`|`String[]`) - capability name (can be a webgl extension name or a luma.gl `FEATURES` constant).\n\n### getFeatures\n\nThis function returns an object containing all available features.\n\n## WebGL Feature Detection\n\n### WebGL 2 Classes with some WebGL 1 support\n\nNote that luma has a few WebGL 2 classes that **can** be instantiated under WebGL 1\n* `VertexAttributeObject`. Can be instanitated under WebGL 1 if the commonly supported extension is available. Also, luma.gl treats the global vertex array as a \"default\" VertexArrayObject, so that can always be accessed.\n* `Query` objects use GPU timing extensions if available. They can always be created but obviously queries will fail if capabilities are not present.\n* `UniformBufferLayout` - this class does not create any WebGL resources, it just helps the application access memory in the layout format expected by WebGL 2 uniform buffers.\n\n`VertexAttributeObject` and `Query` have a static `isSupported()` method that you can call instead of checking for WebGL 2.\n\n### WebGL 2 Classes that only work in WebGL 2\n\nA list of luma classes that can only be instantiated under WebGL 2:\n* `Texture3D` - e.g for volumetric rendering\n* `Texture2DArray` - an array of textures, e.g. a texture atlas\n* `Sampler` - holds a separate set of texture sampler parameters\n* `TransformFeedback` - holds a list of output buffers for shaders to write to.\n* `Sync` -\n\nEach of these classes has a static `isSupported()` method that you can call instead of checking for WebGL 2.\n\n### WebGL 2-only Features\n\nA partial list of features that are only available in WebGL 2:\n\n* Non-power-of-2 textures - non-POT textures can have mipmaps in WebGL 2\n* Sized texture formats -\n* Integer based texture formats and attributes -\n* Multi-Sampled renderbuffers -\n* Guaranteed texture access in vertex shaders - WebGL 1 is not required to support this (although it often does)\n\n\n### GLSL 3.00\n\n* `textureSize` - query **size of texture** from within shaders\n* `texelFetch` - access textures by **pixel** coordinates (0-width, 0-height) instead of **texel** coordinates (0-1)\n* `inverse` and `transpose` Matrix operations available in GLSL\n* loop restrictions removed\n\n\n### Optional Feature Detection\n\nThe WebGL standard comes with an elaborate \"extension\" system allowing applications to check for the availability of features beyond the base WebGL 1 and WebGL 2 standards. These extensions tend to be rather technical, plus they have to be used differently in WebGL 1 and WebGL 2, so luma provides a simplified feature detection system. Following table lists all the available features, and their support under WebGL 1 and WebGL 2 , `NO` implies not supported, 'YES' implies supported and `*` implies supported through an extension.\n\nParameters to `hasFeatures`:\n\n| `FEATURE`                             | WebGL 2  | WebGL 1 | Description |\n| ---                                   | ---     | ---    | ---         |\n| **General WebGL Features**            |         |        | |\n| `FEATURES.WEBGL2`                     | **YES** | **NO** | True for WebGL 2 Context |\n| `FEATURES.INSTANCED_RENDERING`        | **YES** | *      | Instanced rendering (via instanced vertex attributes) [`ANGLE_instanced_arrays`](https://developer.mozilla.org/en-US/docs/Web/API/ANGLE_instanced_arrays) |\n| `FEATURES.VERTEX_ARRAY_OBJECT`        | **YES** | *      | `VertexArrayObjects` can be created [`OES_vertex_array_object`](https://developer.mozilla.org/en-US/docs/Web/API/OES_vertex_array_object) |\n| `FEATURES.ELEMENT_INDEX_UINT32`       | **YES** | *      | 32 bit indices available for `GL.ELEMENT_ARRAY_BUFFER`s [`OES_element_index_uint`](https://developer.mozilla.org/en-US/docs/Web/API/OES_element_index_uint) |\n| `FEATURES.BLEND_MINMAX`               | **YES** | *      | `GL.MIN`, `GL.MAX` blending modes are available: [`EXT_blend_minmax`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_blend_minmax) |\n| `FEATURES.TIMER_QUERY`                | *       | *      | [`Query`](/docs/api-reference/webgl/query.md) objects support asynchronous GPU timings [`EXT_disjoint_timer_query_webgl2`](https://www.khronos.org/registry/webgl/extensions/EXT_disjoint_timer_query_webgl2/), [`EXT_disjoint_timer_query`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_disjoint_timer_query) |\n| **`Texture`s and `Framebuffer`s** |    |        | |\n| `FEATURES.TEXTURE_FLOAT`              | **YES** | *      | Floating point (`Float32Array`) textures can be created and set as samplers (Note that filtering and rendering need to be queried separately, even in WebGL 2)  [`OES_texture_float`](https://developer.mozilla.org/en-US/docs/Web/API/OES_texture_float) |\n| `FEATURES.TEXTURE_HALF_FLOAT`         | **YES** |        | Half float (`Uint16Array`) textures can be created and set as samplers [`OES_texture_half_float`](https://developer.mozilla.org/en-US/docs/Web/API/OES_texture_half_float) [`WEBGL_color_buffer_float`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_color_buffer_float) |\n| `FEATURES.MULTIPLE_RENDER_TARGETS`    | **YES** | *      | `Framebuffer`s can have multiple color attachments that fragment shaders can access, see `Framebuffer.drawBuffers` [`WEBGL_draw_buffers`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_draw_buffers) |\n| `FEATURES.COLOR_ATTACHMENT_RGBA32F`   | *      | *      | Floating point `Texture`s using the `GL.RGBA32F` format are renderable and readable [`EXT_color_buffer_float`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_color_buffer_float) [`WEBGL_color_buffer_float`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_color_buffer_float) |\n| `FEATURES.COLOR_ATTACHMENT_FLOAT`     | *       | **NO** | Floating point `Texture`s are renderable and readable, i.e. can be attached to `Framebuffer`s and written to from fragment shaders, and read from with `readPixels` etc. Note that the formats include `GL.RGBA32F`. [`EXT_color_buffer_float`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_color_buffer_float) |\n| `FEATURES.COLOR_ATTACHMENT_HALF_FLOAT`| *       | **NO** | Half float format `Texture`s are renderable and readable[`EXT_color_buffer_half_float`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_color_buffer_half_float) |\n| `FEATURES.FLOAT_BLEND`| *       | *     | Blending with 32-bit floating point color buffers[`EXT_float_blend`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_float_blend) |\n| [`WEBGL_depth_texture`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_depth_texture) |\n| `FEATURES.TEXTURE_DEPTH_BUFFERS`      | **YES** | *      | Depth buffers can be stored in `Texture`s, e.g. for shadow map calculations |\n| `TEXTURE_FILTER_LINEAR_FLOAT`      | **YES** | * | Linear texture filtering for floating point textures [`OES_texture_float_linear`](https://developer.mozilla.org/en-US/docs/Web/API/OES_texture_float_linear) |\n| `FEATURES.TEXTURE_FILTER_LINEAR_HALF_FLOAT` | **Yes** | * | Linear texture filtering for half float textures [`OES_texture_half_float_linear`](https://developer.mozilla.org/en-US/docs/Web/API/OES_texture_half_float_linear) |\n| `FEATURES.TEXTURE_FILTER_ANISOTROPIC` | *       | *      | Anisotropic texture filtering [`EXT_texture_filter_anisotropic`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_texture_filter_anisotropic) |\n| `FEATURES.SRGB`                       | **YES** | *      | sRGB encoded rendering is available [`EXT_sRGB`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_sRGB) |\n| extensions**          |         |        | |\n| `FEATURES.SHADER_TEXTURE_LOD`         | `ES300` | *      | Enables shader control of LOD [`EXT_shader_texture_lod`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_shader_texture_lod) |\n| `FEATURES.FRAGMENT_SHADER_DRAW_BUFFERS` | `ES300` | *      | Fragment shader can draw to multiple render targets [`WEBGL_draw_buffers`](https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_draw_buffers) |\n| `FEATURES.FRAGMENT_SHADER_DEPTH`      | `ES300` | *  | Fragment shader can control fragment depth value [`EXT_frag_depth`](https://developer.mozilla.org/en-US/docs/Web/API/EXT_frag_depth) |\n| `FEATURES.FRAGMENT_SHADER_DERIVATIVES`| `ES300` | *      | Derivative functions are available in GLSL [`OES_standard_derivatives`](https://developer.mozilla.org/en-US/docs/Web/API/OES_standard_derivatives) |\n\n## Remarks\n\n* WebGL 1 only supports one color buffer format (RBG32F is deprecated)\n* WebGL 2 supports multiple color buffer formats\n* Some extensions will not be enabled until they have been queries. luma always queries on startup to enable, app only needs to query again it wants to test platform.\n* The capability detection system works regardless of whether the app is running in a browser or in headless mode under Node.js.\n* Naturally, given that queries to driver and GPU are typically expensive in WebGL, the capabilities system will cache any queries.\n","slug":"docs/api-reference/webgl/context/feature-checking","title":"Feature Checking"},{"excerpt":"Caveat Emptor! Modules in  are incomplete and not officially supported. Use at your own risk!","rawMarkdownBody":"# Caveat Emptor!\n\n> Modules in `@luma.gl/experimental` are incomplete and not officially supported. Use at your own risk!\n","slug":"docs/api-reference/experimental/warning","title":"Caveat Emptor!"},{"excerpt":"Built-in Geometries @luma.gl/engine provides several built in geometry primitives (subclasses of Geometry). The generated geometry instances…","rawMarkdownBody":"# Built-in Geometries\n\n**@luma.gl/engine** provides several built in geometry primitives (subclasses of [Geometry](/docs/api-reference/engine/geometry)). The generated geometry instances will have `indices` and `POSITION`, `NORMAL` and `TEXCOORD_0` attributes.\n\n## ConeGeometry\n\nCreate a `ConeGeometry` of base radius 2 and height 3.\n```js\nimport {ConeGeometry} from '@luma.gl/engine';\nconst cone = new ConeGeometry({\n  radius: 2,\n  height: 3,\n  cap: true\n});\n```\n\n### constructor(props : Object)\n\n- `props.radius` (*number*): The radius of the base of the cone.\n- `props.cap`=`false` (*boolean*, optional): Whether to put the cap on the base of the cone.\n- `props.nradial`=`10` (*number*): Number of vertices used to create the disk for a given height.\n- `props.nvertical`=`10` (*number*): Number of vertices for the height.\n\n\n## CubeGeometry\n\n```js\nimport {CubeGeometry} from '@luma.gl/engine';\nconst cube = new CubeGeometry();\n```\n\n\n## CylinderGeometry\n\nCreate a `CylinderGeometry` of radius 2 and height 3.\n\n```js\nimport {CylinderGeometry} from '@luma.gl/engine';\nconst cylinder = new CylinderGeometry({\n  radius: 2,\n  height: 3\n});\n```\n\n### constructor(props : Object)\n\n* `props.height`= - (*number*) The height of the cylinder.\n* `props.radius`= - (*number*) The radius of the cylinder.\n* `props.nradial`=`10` - (*number*) The number of vertices for the disk.\n* `props.nvertical`=`10` - (*number*) The number of vertices for the height.\n* `props.verticalAxis`=`y` - (*string*) The axis along which the height is measured. One of `x`, `y`, `z`.\n* `props.topCap`=`false` - (*boolean*) Whether to put the cap on the top of the cylinder.\n* `props.bottomCap`=`false` - (*boolean*) Whether to put the cap on the bottom\n  part of the cylinder.\n\n\n## IcoSphereGeometry\n\nCreate an IcoSphereGeometry of radius 1\n\n```js\nimport {IcoSphereGeometry} from '@luma.gl/engine';\nconst sphere = new IcoSphereGeometry({\n  iterations: 1\n});\n```\n\n### constructor(props : Object)\n\n* `props.iterations`=`0` - (*number*) The number of iterations used to subdivide the Icosahedron.\n\n\n## PlaneGeometry\n\nCreate a XZ plane.\n```js\nimport {PlaneGeometry} from '@luma.gl/engine';\nconst plane = new PlaneGeometry({\n  type: 'x,z',\n  xlen: 10,\n  zlen: 20,\n  nx: 5,\n  nz: 5,\n  offset: 0\n});\n```\n\n### constructor(props : Object)\n\n* `props.type` - (*string*) Whether is a XY, YZ or XZ plane. Possible values are `x,y`, `x,z`, `y,z`.\n* `props.xlen` - (*number*) The length along the x-axis. Only used in `x,z` or `x,y` planes.\n* `props.ylen` - (*number*) The length along the y-axis. Only used in `y,z` or `x,y` planes.\n* `props.zlen` - (*number*) The length along the z-axis. Only used in `x,z` or `y,z` planes.\n* `props.nx` - (*number*) The number of subdivisions along the x-axis. Only used in `x,z` or `x,y` planes.\n* `props.ny` - (*number*) The number of subdivisions along the y-axis. Only used in `y,z` or `x,y` planes.\n* `props.nz` - (*number*) The number of subdivisions along the z-axis. Only used in `x,z` or `y,z` planes.\n* `props.offset` - (*number*) For XZ planes, the offset along the y-axis. For XY planes, the offset along the z-axis. For YZ planes, the offset along the x-axis.\n\n## SphereGeometry\n\n```js\nimport {SphereGeometry} from '@luma.gl/engine';\nconst sphere = new SphereGeometry({\n  radius: 2\n});\n```\n\n### constructor(props : Object)\n\n* `props.nlat`=`10` - (*number*, optional) The number of vertices for latitude.\n* `props.nlong`=`10` - (*number*, optional) The number of vertices for longitude.\n* `props.radius`=`1` - (*number*, optional) The radius of the sphere.\n","slug":"docs/api-reference/engine/geometries","title":"Built-in Geometries"},{"excerpt":"Geometry The Geometry class holds a collection of vertex array attributes representing a geometric primitive. A geometry is considered a…","rawMarkdownBody":"# Geometry\n\nThe Geometry class holds a collection of vertex array attributes representing a geometric primitive.\n\nA geometry is considered a \"primitive\" when it can be rendered with a single GPU draw call. Multiple geometry primitives can be composed into a composite geometry using the `Mesh` and `Model` classes.\n\nTo learn more about attributes refer to the `Accessor` class that holds metadata for each attributes.\n\n\n## Usage\n\nCreate a pyramid geometry (used in lesson 4 of learning WebGL examples).\n```js\nconst pyramidGeometry= new Geometry({\n  attributes: {\n    positions: new Float32Array([ ... ]),\n    colors: {\n      size: 4,\n      value: new Float32Array([ ... ])\n    }\n  }\n});\n```\n\n## Properties\n\n### `id` - (*string*, optional)\n\nAn id for the model. If not provided, a random unique identifier will be created.\n\n\n### drawMode : Number\n\nThe draw mode, or primitive type.\n\nSome options are `GL.TRIANGLES` (default), `GL.TRIANGLE_STRIP`, `GL.POINTS`, `GL.LINES`.\n\n\n### `attributes` - (*object*, optional)\n\nAn object with buffer/attribute names and buffer/attribute descriptors to be set before rendering the model.\n\n\n### attributes : Object\n\nA map of `Accessor` instances describing the geometry of this primitive.\n\n\n### indices : Accessor\n\nAn optional `Accessor` instance that contains the indices (aka elements) for this geometry. Can be `null` or `undefined` if this primitive doesn't use indices. Note that indices can also be stored inside `attributes`.\n\n\n### material : Object\n\nAn object with key/value pairs that indicate how various uniforms should be set up before the GPU draw call. The `Geometry` class itself does not directly use the contents of the `material` field, however other classes such as `Mesh` will refer to it if available, and normally expects it to be set to an instance of the `Material` class.\n\n\n## Methods\n\n### constructor(props : Object)\n\nThe constructor for the `Geometry` class. Use this to create a new `Geometry`.\n\n```js\nconst geometry = new Geometry(props);\n```\n\n\n### setProps(props : Object)\n\nUpdate properties\n\n\n\n## Types and Enumerations\n\n### drawMode\n\nFollows glTF/OpenGL/WebGL conventions:\n\n| Value | Primitive Mode   |\n| ---   | ---              |\n| `0`   | `POINTS`         |\n| `1`   | `LINES`          |\n| `2`   | `LINE_LOOP`      |\n| `3`   | `LINE_STRIP`     |\n| `4`   | `TRIANGLES`      |\n| `5`   | `TRIANGLE_STRIP` |\n| `6`   | `TRIANGLE_FAN`   |\n\n\n### Typical Attributes\n\n| Attribute      | Description      |\n| ---            | ---              |\n| `indices`      | (*array*, optional) An array of numbers describing the vertex indices for each face. |\n| `positions`    | (*array*, optional) An array of floats that describe the vertices of the model. |\n| `normals`      | (*array*, optional) An array of floats that describe the normals of the model. |\n| `texCoords`    | (*mixed*, optional) Can be an array of floats indicating the texture coordinates for the texture to be used or an object that has texture ids as  |keys and an array of floats as values.\n| `colors`       | (*array*, optional) An array of colors in RGBA. If just one color is specified that color will be used for all faces. |\n| `pickingColors` | (*array*, optional) A custom set of colors to render the object to texture when performing the color picking algorithm. |\n\n\n## Remarks\n\n* The Geometry class does not take a `WebGLRenderingContext` and is intentionally \n* The `Geometry` class holds the [glTF2 \"primitive\" specification](https://github.com/KhronosGroup/glTF/tree/master/specification/2.0), although morph `targets` are not yet supported.\n","slug":"docs/api-reference/engine/geometry","title":"Geometry"},{"excerpt":"ProgramManager The  manages the creation and caching of programs. It allows the application to request a program based on a vertex shader…","rawMarkdownBody":"# ProgramManager\n\nThe `ProgramManager` manages the creation and caching of programs. It allows the application to request a program based on a vertex shader, fragment shader and set of defines, modules and code injections. The `ProgramManager` will return the requested program, creating it the first time, and re-using a cached version if it is requested more than once. It also allows for the definition of hook functions and module code injections to be inserted into shaders.\n\n\n## Usage\n\n```js\nconst pm = new ProgramManager(gl);\n\nconst vs = `\nattribute vec4 position;\n\nvoid main() {\n#ifdef MY_DEFINE\n  gl_Position = position;\n#else\n  gl_Position = position.wzyx;\n#endif\n}\n`;\n\nconst fs = `\nvoid main() {\n  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);\n  MY_SHADER_HOOK(gl_FragColor);\n}\n`;\n\npm.addShaderHook('fs:MY_SHADER_HOOK(inout vec4 color)');\n\npm.addDefaultModule(dirlight); // Will be included in all following programs\n\nconst program1 = pm.get({vs, fs});   // Basic, no defines, only default module\nconst program2 = pm.get({vs, fs});   // Cached, same as program 1, use count 2\nconst program3 = pm.get({  // New program, with different source based on define\n  vs,\n  fs,\n  defines: {\n    MY_DEFINE: true\n  }\n});\n\nconst program4 = pm.get({  // New program, with different source based on module and its injection\n  vs,\n  fs,\n  defines: {\n    MY_DEFINE: true\n  },\n  modules: [picking]\n});\n\nconst program5 = pm.get({  // Cached, same as program 4, use count 2\n  vs,\n  fs,\n  defines: {\n    MY_DEFINE: true\n  },\n  modules: [picking]\n});\n\npm.release(program1); // Cached program still available, use count 1\npm.release(program2); // Cached program deleted\npm.release(program3); // Cached program deleted\npm.release(program4); // Cached program still available, use count 1\npm.release(program5); // Cached program deleted\n```\n\n\n## Methods\n\n### get(opts : Object) : Program\n\nGet a program that fits the parameters provided. If one is already cached, return it, otherwise create and cache a new one.\n`opts` can include the following (see `assembleShaders` for details):\n* `vs`: Base vertex shader source.\n* `fs`: Base fragment shader source.\n* `defines`: Object indicating `#define` constants to include in the shaders.\n* `modules`: Array of module objects to include in the shaders.\n* `inject`: Object of hook injections to include in the shaders.\n\n### `addDefaultModule(module: Object)`\n\nAdd a module that will automatically be added to any programs created by the program manager.\n\n### `removeDefaultModule(module: Object)`\n\nRemove a module that is automatically being added to programs created by the program manager.\n\n### `addShaderHook(hook : String, [opts : Object])`\n\nCreates a shader hook function that shader modules can injection code into. Shaders can call these functions, which will be no-ops by default. If a shader module injects code it will be executed upon the hook function call. This mechanism allows the application to create shaders that can be automatically extended by included shader modules.\n\n- `hook`: `vs:` or `fs:` followed by the name and arguments of the function, e.g. `vs:MYHOOK_func(inout vec4 value)`. Hook name without arguments\nwill also be used as the name of the shader hook\n- `opts.header` (optional): code always included at the beginning of a hook function\n- `opts.footer` (optional): code always included at the end of a hook function\n\n### getUniforms(program : Program) : Object\n\nReturns an object containing all the uniforms defined for the program. Returns `null` if `program` isn't managed by the `ProgramManager`.\n\n### release(program : Program)\n\nIndicate that a program is no longer in use. When all references to a program are released, the program is deleted.\n\n\n","slug":"docs/api-reference/engine/program-manager","title":"ProgramManager"},{"excerpt":"AnimationLoop Manages an animation loop and optionally a WebGL context and a WebGL canvas. It provides a number of features related to…","rawMarkdownBody":"# AnimationLoop\n\nManages an animation loop and optionally a WebGL context and a WebGL canvas. It provides a number of features related to initialization and animation of a WebGL context.\n\n* Provides a number of commonly needed variables as part of the `context` object which is passed to `onRender` and `onFinalize` callbacks.\n* Objects returned by `onInitialize` will be appended to `context` object hence available to `onRender` and `onFinalize`.\n* To avoid problems with page load timing, move context creation to the `onCreateContext` method.\n* By default, `onRender` method manages resizing of canvas, viewport and framebuffer.\n* Makes it easy to wait for the HTML page to load before creating a canvas and WebGL resources.\n\nReferences:\n\n* [WebGL Fundamentals](https://webglfundamentals.org/webgl/lessons/webgl-anti-patterns.html#drawingbuffer) contains excellent information on the subtleties of the how the WebGL context's drawing buffer and the HTML canvas interact.\n* When running in the browser, this class uses [`requestAnimationFrame`](https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame)\n\n\n## Usage\n\nAutocreates a canvas/context\n```js\nimport {AnimationLoop, ClipSpace} from '@luma.gl/engine';\n\nconst animationLoop = new AnimationLoop({\n  onInitialize({gl}) {\n    // Keys in the object returned here will be available in onRender\n    return {\n      clipSpaceQuad: new ClipSpace({gl, fs: FRAGMENT_SHADER})\n    };\n  },\n  onRender({tick, clipSpaceQuad}) {\n    // Tick is autoupdated by AnimationLoop\n    clipSpaceQuad.setUniforms({uTime: tick * 0.01}).draw();\n  }\n});\n\nanimationLoop.start();\n```\n\nUse a canvas in the existing DOM through its HTML id\n```js\nanimationLoop.start({canvas: 'my-canvas'});\n```\n\n## Methods\n\n### constructor(props : Object)\n\n```js\nnew AnimationLoop({\n  onCreateContext,\n  onInitialize,\n  onFinalize,\n  onRender,\n\n  autoResizeViewport,\n  autoResizeDrawingBuffer\n});\n```\n\n* `props.onCreateContext`=`null` (callback) - function without parameters that returns a `WebGLRenderingContext`. This callback will be called exactly once, after page load completes.\n* `props.onInitialize` (callback) - if supplied, will be called once after first `start()` has been called, after page load completes and a context has been created.\n* `props.onRender`=`null` (callback) - Called on every animation frame.\n* `props.onFinalize`=`null` (callback) - Called once when animation is stopped. Can be used to delete objects or free any resources created during `onInitialize`.\n* `props.autoResizeViewport`=`true` - If true, calls `gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight)` each frame before `onRender` is called. Set to false to control viewport size.\n* `props.autoResizeDrawingBuffer`=`true` - If true, checks the canvas size every frame and updates the drawing buffer size if needed.\n* `props.useDevicePixels` - Whether to use `window.devicePixelRatio` as a multiplier, e.g. in `autoResizeDrawingBuffer` etc. Refer to `Experimental API` section below for more use cases of this prop.\n* `props.gl`=`null` (WebGLContext) - If supplied, will render into this external context instead of creating a new one.\n* `props.glOptions`=`{}` (object) - Options to create the WebGLContext with. See [createGLContext](/docs/api-reference/gltools/context).\n* `props.debug`=`false` (bool) - Enable debug mode will provide more validations and error messages, but less performant.\n* `props.createFramebuffer`=`false` (bool) - If true, will make a `framebuffer` (FrameBuffer) parameter available to `onInitialize` and `onRender` callbacks.\n\n\n### start([options : Object]) : AnimationLoop\n\nRestarts the animation\n\n`animationLoop.start(options)`\n\n* `options`=`{}` (object) - Options to create the WebGLContext with. See [createGLContext](/docs/api-reference/gltools/context).\n\n### stop() : AnimationLoop\n\nStops the animation\n\n`animationLoop.stop()`\n\n### waitForRender() : Promise\n\nReturns a promise which resolves in the next frame after rendering and the `onRender` callback have completed.\n\n```js\nconst loop = await animationLoop.waitForRender()\n// can now read pixels from webgl context\nloop.gl.readPixels(...)\n```\n\n### redraw() : AnimationLoop\n\nImmediately invokes a redraw (call `onRender` with updated animation props). Only use if the canvas must be updated synchronously.\n\n### setNeedsRedraw(reason : String) : AnimationLoop\n\n`animationLoop.setNeedsRedraw(reason)`\n\n* `reason` (`String`) - A human readable string giving a hint as to why redraw was needed (e.g. \"geometry changed\").\n\nIf set, the value will be provided as the `needsRedraw` field to the `onRender` callback.\n\nNotes:\n* `onRender` will be called for each animation frame regardless of whether this flag is set, and the redraw reason is automatically cleared.\n* If called multiple times, the `reason` provided in the first call will be remembered.\n* `AnimationLoop` automatically sets this flag if the WebGL context's drawing buffer size changes.\n\n\n### setProps(props : Object) : AnimationLoop\n\n`animationLoop.setProps({...props})`\n\n* `props.autoResizeViewport` - Call `gl.viewport` before each call to `onRender()`\n* `props.autoResizeDrawingBuffer` - Update the drawing buffer size to match the canvas size before each call to `onRender()`\n* `props.useDevicePixels` - Whether to use `window.devicePixelRatio` as a multiplier, e.g. in `autoResizeDrawingBuffer` etc.\n\n### attachTimeline(timeline: Timeline)\n\nAttach an `Timeline` object to the animation loop. Allows time produced for animations to be paused, played, etc. See `Timeline` documentation for more info.\n\n\n### detachTimeline()\n\nDetach the currently attached timeline from the animation loop.\n\n\n### toDataURL\n\nReturns returns a `Promise` that resolves to the data URL of the canvas once drawing operations are complete for the current frame. The data URL can be used as the `src` for an HTML image element.\n\n`animationLoop.toDataURL()`\n\n\n## Callback Parameters\n\nThe callbacks `onInitialize`, `onRender` and `onFinalize` that the app supplies to the `AnimationLoop`, will be called with an object containing named parameters:\n\n| Parameter | Type | Description |\n| ---       | ---  | --- |\n| `_animationLoop` | `AnimationLoop` | (**experimental**) The calling `AnimationLoop` instance |\n| `gl`      | `WebGLRenderingContext` | This `AnimationLoop`'s gl context. |\n| `canvas`  | `HTMLCanvasElement` or `OffscreenCanvas` | The canvas associated with this context. |\n| `width`   | The drawing buffer width, in \"device\" pixels (can be different from canvas.width). |\n| `height`  | The drawing buffer height, in \"device\" pixels (can be different from canvas.width). |\n| `aspect`  | The canvas aspect ratio (width/height) to update projection matrices |\n| `useDevicePixels` | Boolean indicating if canvas is utilizes full resolution of Retina/\n| `needsRedraw` | `String` | Redraw flag (will be automatically set if drawingBuffer resizes) |\n| `time`    | `Number` | Milliseconds since `AnimationLoop` was created (monotonic). |\n| `tick`    | `Number` | Counter that updates for every frame rendered (monotonic). |\n| `framebuffer` | `FrameBuffer` | Availabel if `createFrameBuffer: true` was passed to the constructor. |\n| `_mousePosition` | `[x, y]` or `null` | (**experimental**) Current mouse position over the canvas. |\n| `_offScreen` | `Boolean` | (**experimental**) If the animation loop is rendering to an OffscreenCanvas. |\n| `_timeline` | `Trimeline` | (**experimental**) `Timeline` object tracking the animation timeline and channels. |\n| ...       | Any fields in the object that was returned by the `onInitialize` method. |\n\n### Frame timers\n* The animation loop tracks GPU and CPU render time of each frame the in member properties `cpuTime` and `gpuTime`. If `gpuTime` is set to `-1`, then the timing for the last frame was invalid and should not be used (this rare and might occur, for example, if the GPU was throttled mid-frame).\n\n\n## Experimental API (`useDevicePixels`)\n\n`useDevicePixels` can accept a custom ratio (Number), instead of `true` or `false`. This allows rendering to a much smaller or higher resolutions. When using high value (usually more than device pixel ratio), it is possible it can get clamped down, this happens due to system memory limitation, in such cases a warning will be logged to the browser console. For additional details check device pixels [`document`]((/docs/api-reference/gltools/device-pixels)).\n\n## Remarks\n\n* You can instantiate multiple `AnimationLoop` classes in parallel, rendering into the same or different `WebGLRenderingContext`s.\n* Works both in browser and under Node.js.\n* All `AnimationLoop` methods can be chained.\n* Postpones context creation until the page (i.e. all HTML) has been loaded. At this time it is safe to specify canvas ids when calling [`createGLContext`](/docs/api-reference/gltools/context).\n* The supplied callback function must return a WebGLRenderingContext or an error will be thrown.\n* This callback registration function should not be called if a `WebGLRenderingContext` was supplied to the AnimationLoop constructor.\n","slug":"docs/api-reference/engine/animation-loop","title":"AnimationLoop"},{"excerpt":"GroupNode A  is a subclass of  that holds a list of  children. Since . A  can be a child of another  and thus be used to create hierarchical…","rawMarkdownBody":"# GroupNode\n\nA `GroupNode` is a subclass of `ScenegraphNode` that holds a list of `ScenegraphNode` children. Since . A `GroupNode` can be a child of another `GroupNode` and thus be used to create hierarchical scene graphs.\n\n\n## Usage\n\nAdd a moon and a box models to the group.\n```js\n// Add objects to the group\ngroup.add(moon, box);\n```\n\nAdd a moon and a box models to the group. Then remove them.\n```js\n// Add objects to the group\ngroup.add(moon, box);\n// Remove the moon\ngroup.remove(moon);\n```\n\n\n## Properties\n\n`Model` extends the `ScenegraphNode` class and inherits the transformation matrix properties from that class.\n\n\n### children : ScenegraphNode[]\n\n\n## Methods\n\n\n### constructor(props : Object)\n\nCreate an instance of `GroupNode`.\n\n\n### setProps(props : Object)\n\nUpdates properties.\n\n\n### add(node : ScenegraphNode [, ...])\n\nAdd one or more `ScenegraphNode` objects to the `GroupNode`.\n\n`group.add(model);`\n\nA variable argument list of [ScenegraphNode](/docs/api-reference/experimental/scenegraph/scenegraph-node) instances.\n\n\n### remove(node: Node)\n\nRemoves an [ScenegraphNode](/docs/api-reference/experimental/scenegraph/scenegraph-node) object from the GroupNode.\n\n    group.remove(model);\n\n* model - (*object*) The scene graph node to be removed.\n","slug":"docs/api-reference/experimental/scenegraph/group-node","title":"GroupNode"},{"excerpt":"Model A  is a subclass of  that holds a reference to a mesh with a transformation matrix that describes its position and orientation. A…","rawMarkdownBody":"# Model\n\nA `Group` is a subclass of `ScenegraphNode` that holds a reference to a mesh with a transformation matrix that describes its position and orientation.\n\nA `Model` holds all the data necessary to draw an object, e.g.:\n\n* **shaders** (via a [`Program`](/docs/api-reference/webgl/program) instance)\n* **uniforms** these can also reference textures.\n* **vertex attributes** (holds a [`Mesh`] or a [`Geometry`](/docs/api-reference/engine/geometry) instance, plus any additional attributes for instanced rendering)\n\nThe `Model` class also provides the following features:\n\n* Shader Module integration: [see `Shader Assembly`](/docs/api-reference/shadertools/assemble-shaders)\n* Automatic creation of GPU `Buffer`s from typed array attributes\n* Detailed debug logging of draw calls\n* Exposes the functionality provided by the managed WebGL resources\n\n## Usage\n\n### Provide attribute data using Geometry object\n\nCreate model object by passing shaders, uniforms, geometry and render it by passing updated uniforms.\n\n```js\n// construct the model.\nconst model =  new Model(gl, {\n  vs: VERTEX_SHADER,\n  fs: FRAGMENT_SHADER,\n  uniforms: {uSampler: texture},\n  geometry: geometryObject,\n})\n\n// and on each frame update any uniforms (typically matrices) and call render.\nmodel\n  .setUniforms({\n    uPMatrix: currentProjectionMatrix,\n    uMVMatrix: current ModelViewMatrix\n  })\n  .draw();\n```\n\n### Provide attribute data using Buffer\n\nWhen using `Buffer` objects, data remains on GPU and same `Buffer` object can be shared between multiple models.\n\n```js\n// construct the model.\nconst model =  new Model(gl, {\n  vs: VERTEX_SHADER,\n  fs: FRAGMENT_SHADER,\n  uniforms: {uSampler: texture},\n  attributes: {\n    attributeName1: bufferObject,\n    attributeName2: [new Buffer(gl, new Float32Array(...)), {size: 3, type: GL.FLOAT}]\n  }\n  drawMode: gl.TRIANGLE_FAN,\n  vertexCount: 3,\n})\n\n// and on each frame update any uniforms (typically matrices) and call render.\nmodel\n  .setUniforms({\n    uPMatrix: currentProjectionMatrix,\n    uMVMatrix: current ModelViewMatrix\n  })\n  .draw();\n```\n\n### Provide attribute data using VertexArray object\n\nA `VertexArray` object can be build and passed to `Model.draw()` to provide attribute data. Attribute data can be changed by changing `VertexArray` object.\n\n```js\n// construct the model.\nconst model =  new Model(gl, {\n  vs: VERTEX_SHADER,\n  fs: FRAGMENT_SHADER,\n  uniforms: {uSampler: texture},\n  drawMode: gl.TRIANGLE_FAN,\n  vertexCount: 3,\n})\n\nconst ATTRIBUTE1_LOCATION = 0;\nconst ATTRIBUTE2_LOCATION = 1;\nconst vertexArray1 = new VertexArray(gl, {\n  buffers: {\n    [ATTRIBUTE1_LOCATION]: buffer1,\n    [ATTRIBUTE2_LOCATION]: buffer2\n  }\n});\nconst vertexArray2 = new VertexArray(gl, {\n  buffers: {\n    [ATTRIBUTE1_LOCATION]: buffer3,\n    [ATTRIBUTE2_LOCATION]: buffer4\n  }\n});\n\n//Render using attribute data from vertexArray1.\nmodel.draw({\n  uniforms: {\n    uPMatrix: currentProjectionMatrix,\n    uMVMatrix: currentModelViewMatrix\n  },\n  vertexArray: vertexArray1\n});\n\n// Switch attribute data to vertexArray2\nmodel.draw({\n  uniforms: {\n    uPMatrix: currentProjectionMatrix,\n    uMVMatrix: currentModelViewMatrix\n  },\n  vertexArray: vertexArray2\n});\n```\n\n## Properties\n\n`Model` extends the `BaseModel` class and inherits all properties from that class.\n\n\n### moduleSettings : Object\n\nany uniforms needed by shader modules.\n\n\n### uniforms : Object\n\nuniform values to be used for drawing.\n\n\n### onBeforeRender\n\nfunction to be called before every time this model is drawn.\n\n\n### onAfterRender\n\nfunction to be called after every time this model is drawn.\n\n\n### mesh\n\n`Mesh` instance.\n\n\n## Deprecated Properties in v7\n\n\n### geometry\n\n`Geometry` object, from which attributes, vertex count and drawing mode are deduced.\n\n\n### isInstanced : Boolean\n\ndefault value is false.\n\n\n### instanceCount : Number\n\ndefault value is 0.\n\n\n### vertexCount : Number\n\nwhen not provided will be deduced from `geometry` object.\n\n\n\n\n## Constructor\n\n### Model(gl: WebGLRenderingContext, props: Object)\n\nThe constructor for the Model class. Use this to create a new Model.\n\nThe following props can only be specified on construction:\n\n* `vs` - (VertexShader|*string*) - A vertex shader object, or source as a string.\n* `fs` - (FragmentShader|*string*) - A fragment shader object, or source as a string.\n* `varyings` (WebGL 2) - An array of vertex shader output variables, that needs to be recorded (used in TransformFeedback flow).\n* `bufferMode` (WebGL 2) - Mode to be used when recording vertex shader outputs (used in TransformFeedback flow). Default value is `gl.SEPARATE_ATTRIBS`.\n* `modules` - shader modules to be applied.\n* `program` - pre created program to use, when provided, vs, ps and modules are not used.\n* `shaderCache` - (ShaderCache) - Compiled shader (Vertex and Fragment) are cached in this object very first time they got compiled and then retrieved when same shader is used. When using multiple Model objects with duplicate shaders, use the same shaderCache object for better performance.\n\n\n### delete() : Model\n\nFree WebGL resources associated with this model\n\n\n## Methods\n\n### setProps(props : Object) : Model\n\nUpdates properties\n\n\n### isAnimated() : Boolean\n\nReturns `true` if the model is animated (i.e. needs to be redrawn every frame).\n\n\n### getProgram() : Program\n\nGet model's `Program` instance\n\n\n### getUniforms() : Object\n\nReturns map of currently stored uniforms\n\n### setUniforms(uniforms : Object) : Model\n\nStores named uniforms {key, value}\n\n\n### updateModuleSettings(moduleSettings : Object) : Model\n\n\n### draw(options : Object) : Model\n\nRenders the model with provided uniforms, attributes and samplers\n\n```js\nmodel.draw({\n  moduleSettings = null,\n  uniforms = {},\n  attributes = {},\n  samplers = {},\n  parameters = {},\n  settings,\n  framebuffer = null,\n  vertexArray = null,\n  transformFeedback = null\n});\n```\n\n`Model.draw()` calls `Program.draw()` but adds and extends the available parameters as follows:\n\n* `moduleSettings`=`null` (Object) - any uniforms needed by shader modules.\n* `attributes`=`{}` (Object) - attribute definitions to be used for drawing. In additions to `Buffer` and constant values, `Model`s can also accept typed arrays and attribute descriptor objects which it converts to buffers.\n* `uniforms`=`{}` (Object) - uniform values to be used for drawing. In addition to normal uniform values, `Model` can also accept function valued uniforms which will be evaluated before every draw call.\n* `animationProps` (Object) - if any function valued uniforms are set on the `Model`, `animationProps` must be provided to the draw call. The `animationProps` are passed as parameter to the uniform functions.\n\nThe remaining draw options are passed directly to `Program.draw()`:\n\n* `uniforms`=`{}` (Object) - uniform values to be used for drawing.\n* `samplers`=`{}` (Object) - texture mappings to be used for drawing.\n* `parameters`=`{}` (Object) - temporary gl settings to be applied to this draw call.\n* `framebuffer`=`null` (`Framebuffer`) - if provided, renders into the supplied framebuffer, otherwise renders to the default framebuffer.\n* `transformFeedback` - an instance `TranformFeedback` object, that gets activated for this rendering.\n* `vertexArray` - an instance of `VertexArray` object, that holds required buffer bindings for vertex shader inputs.\n\n\n### transform(options : Object) : Model\n\nRenders the model with provided uniforms, and samplers. Calls `Program.draw()` with rasterization turned off.\n\n* `discard`=`true` (Boolean) - Turns off rasterization\n* `feedbackBuffers`=`null` (Object) - Optional map of feedback buffers. A `TransformFeedback` object will be created, initialized with these buffers, and passed to `Model.draw`.\n* `unbindModels`=`[]` (Model[]) - Array of models whose VertexAttributes will be temporarily unbound during the transform feeback to avoid triggering a possible [Khronos/Chrome bug](https://github.com/KhronosGroup/WebGL/issues/2346).\n.\n\n```js\nmodel.transform({\n  discard:\n});\n```\n\n\n\n## Deprecated Methods in v7\n\n### getDrawMode() : Enum\n\nGets the WebGL drawMode\n\n\n### getVertexCount() : GLInt\n\nGets vertex count\n\nNote: might be autocalculated from `Geometry`\n\n\n### getInstanceCount() : GLInt\n\nDefaults to 0\n\n\n### getAttributes() : Object\n\nGet a map of named attributes\n\n\n### setDrawMode() : Model\n\nSets the WebGL `drawMode`.\n\n`GL.POINTS` etc.\n\n\n### setVertexCount() : Model\n\nSets the number of vertices\n\n\n### setInstanceCount() : Model\n\nHow many instances will be rendered\n\n\n### setGeometry() : Model\n\nUse a `Geometry` instance to define attribute buffers\n\n\n### setAttributes(attributes : Object) : Model\n\nSets map of attributes (passes through to [VertexArray.setAttributes](/docs/api-reference/webgl/vertex-array))\n\n\n## Remarks\n\n* The `Model` class is arguably the most useful class for typical applications. It manages the WebGL resources needed to perform draw calls and provide additional functionality as described below.\n","slug":"docs/api-reference/engine/model","title":"Model"},{"excerpt":"Transform (WebGL 2) The  class provides easy interface to perform Transform Feedback operations on given data. Applications can use this…","rawMarkdownBody":"# Transform (WebGL 2)\n\nThe `Transform` class provides easy interface to perform Transform Feedback operations on given data. Applications can use this class to move data processing from CPU to GPU, where multiple parallel execution units will be used for processing. Data is handled in form of `Buffer` objects, i.e. data resides in the GPU memory. Output of this class can directly set as attributes on `Model` or `VertexArray` for regular rendering operations, CPU access is not required hence avoids expensive CPU and GPU sync.\n\n`Transform` class creates and holds `Model` and `TransformFeedback` instances.\n\nThis class is only supported when using `WebGL2RenderingContext`.\n\n\n### Use case : Specify source and destination buffers.\n\nCreate a `Transform` object by passing, vs (vertex shader), source buffer(s), varyings (output variable names in vertex shader) and destination buffers. Then call `run` to perform one transform feedback iteration.\n\n```js\nconst VS = `\\\n#version 300 es\nattribute float inValue;\nvarying float outValue;\n\nvoid main()\n{\n  outValue = 2.0 * inValue;\n}\n`;\n\nconst sourceData = new Float32Array([10, 20, 31, 0, -57]);\nconst sourceBuffer = new Buffer(gl, {data: sourceData});\n\n// Default values applied for size (1) and type (gl.FLOAT)\nconst feedbackBuffer = new Buffer(gl, {byteLength: sourceData.length * 4});\n\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inValue: sourceBuffer\n  },\n  feedbackBuffers: {\n    outValue: feedbackBuffer\n  },\n  vs: VS,\n  varyings: ['outValue'],\n  elementCount: 5\n});\n\n// Perform one transform feedback iteration\ntransform.run();\n```\n\n### Use case : Create destination buffers automatically.\n\n`Transform` can internally create destination buffers (i.e. feedback buffers), when `feedbackMap` is provided. Each destination buffer is created with same settings and layout as corresponding source buffer as per `feedbackMap`.\n\n```js\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inValue: sourceBuffer\n  },\n  feedbackMap: {\n    inValue: 'outValue'\n  },\n  vs: VS,\n  varyings: ['outValue'],\n  elementCount: 5\n});\n\n```\n### Use case : Multiple iterations using swap().\n\nWhen `feedbackMap` is specified buffers can be swapped using a single call to `swap()`, this is useful for cases like particle simulation, where output of one transform feedback iteration is piped as input to the next iteration.\n\n```js\n\n// Setup Transform with `feedbackMap` as above\n\ntransform.run();\n\nlet bufferWithNewValues = transform.getBuffer('outValue');\n...\n// Render using 'bufferWithNewValues'\n...\n\n//swap buffers\ntransform.swap();\ntransform.run();\nbufferWithNewValues = transform.getBuffer('outValue');\n...\n// Render using 'bufferWithNewValues'\n...\n```\n\n### Use case : Update one or more buffers using update() method..\n\nOnce `Transform` object is constructed and used, one or more source or destination buffers can be updated using `update`.\n\n```js\n// transform is set up as above\n...\n\n// update buffer binding for 'inValue' attribute\nconst newSourceBuffer = new Buffer(gl, {data: newSourceData});\ntransform.update({\n  sourceBuffers: {\n    inValue: newSourceBuffer\n  }\n});\n\n// now data is provided from newly bound buffer.\ntransform.run();\n```\n\n### Use case : Reading source data from texture object (Experimental)\n\nIn addition to reading data from Buffer objects, Transform can read from texture objects. Transform allows to access texture data in the same way as buffer data and internally generates required texture co-ordinates and sample instructions.\n\n```js\n// simple shader that adds data from a buffer and texture to generate new buffer.\n\nconst vs = `\\\n#version 300 es\nin float inBuffer;\nin float inTexture;\nout float outBuffer;\n\nvoid main()\n{\n  outBuffer = inTexture + inBuffer;\n}`;\n\nconst sourceBuffer = new Buffer(...);\nconst sourceTexture = new Texture2D(...);\n\nconst transform = new Transform(gl2, {\n  sourceBuffers: {\n    inBuffer: sourceBuffer\n  },\n  // specify source texture object using input attribute name\n  _sourceTextures: {\n    inTexture: sourceTexture\n  },\n  vs,\n  feedbackMap: {\n    inBuffer: 'outBuffer'\n  },\n  elementCount\n});\n\ntransform.run();\n\n// resulting buffer contains sum of input buffer and texture data.\nconst outData = transform.getBuffer('outBuffer').getData();\n\n```\n\n### Use case : Generating a texture object (Experimental)\n\nIn addition to reading data from a texture object, Transform can generate texture object, by rendering data into it offline. Source data can be either buffer(s), texture(s) or any combination.\n\n```js\nconst vs = `\\\n#version 300 es\nin vec4 inTexture;\nout vec4 outTexture;\n\nvoid main()\n{\n  outTexture = 2. *  inTexture;\n}\n`\nconst sourceTexture = new Texture2D(...);\nconst transform = new Transform(gl2, {\n  _sourceTextures: {\n    inTexture: sourceTexture\n  },\n  _targetTexture: 'inTexture',\n  _targetTextureVarying: 'outTexture',\n  vs,\n  elementCount\n});\n\ntransform.run();\n\nconst outTexture = transform._getTargetTexture();\n\n```\n\n\n## Constructor\n\n### Transform(gl : WebGL2RenderingContext, props: Object)\n\nConstructs a `Transform` object. It then creates destination buffers if needed and binds the buffers to `Model` and `TransformFeedback` objects.\n\n* `gl` (`WebGL2RenderingContext`) gl - context\n* `props.sourceBuffers` (`Object`) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Attribute`, `Buffer` or attribute descriptor object.\n* `props.feedbackBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader varying and value is the corresponding `Buffer` object or buffer params object. If a buffer params object is specified, it will contain following fields, these can be used to capture data into the buffer a particular offset and size.\n  * `buffer`=(Buffer) - Buffer object to be bound.\n  * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n  * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n* `props.vs` (`String`) - vertex shader string.\n* `props.modules` - shader modules to be applied.\n* `props.varyings` (`Array`) - Array of vertex shader varyings names. When not provided this can be deduced from `feedbackMap`. Either `varyings` or `feedbackMap` must be provided.\n* `props.feedbackMap` (`Object`, Optional) - key and value pairs, where key is a vertex shader attribute name and value is a vertex shader varying name.\n* `props.drawMode` (`GLEnum` = gl.POINTS, Optional) - Draw mode to be set on `Model` and `TransformFeedback` objects during draw/render time.\n* `props.elementCount` (`Integer`) - Number set to vertex count when rendering the model.\n#### Experimental ####\n* `props._sourceTextures` (`Object`) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Texture2D` object.\n* `props._targetTexture` (`Texture2D` or `String`) - Defines texture object that is used as color attachment for rendering. If `Texture2D` object, it is used as is, if `String`, it must be one of the source texture attributes name, a new texture object is cloned from corresponding texture and used as color attachment.\n* `props._targetTextureVarying` (`String`) : varying name used in vertex shader who's data should go into target texture.\n* `props._swapTexture` (`String`) : source texture attribute name, that is swapped with target texture every time `swap()` is called.\n* `props._fs` (`String`, Optional) - fragment shader string, when rendering to a texture, fragments can be processed using this custom shader, when not specified, pass through fragment shader will be used.\n\nNotes:\n\n* Internally, creates `Model`, `TransformFeedback` and `Framebuffer` instances.\n\n\n### delete() : Transform\n\nDeletes all owned resources, `Model`, `TransformFeedback` and any `Buffer` objects that are crated internally.\n\n\n## Methods\n\n### getBuffer(varyingName : String) : Buffer\n\nReturns current destination buffer corresponding to given varying name.\n\n* `varyingName` (`String`) - varying name.\n\n\n### getData([options : Object]) : ArrayBufferView\n\nReads and returns data from current destination buffer corresponding to the given varying name. When no 'varyingName' is provided, it reads and returns data from current target texture.\n\n* `options.varyingName` (`String`, Optional) - when specified, first checks if there is a corresponding feedback buffer, if so reads data from this buffer and returns. When not specified, there must be target texture and data is read from this texture and returned.\n* `options.packed` (Boolean, Optional, Default: false) - applicable only when reading data from target texture, when true, data is packed to the actual size varyings. When false return array contains 4 values (R, G, B and A) for each element. Un-used element value will be 0 for R, G and B and 1 for A channel.\n\n\n### getFramebuffer() : Framebuffer\n\nWhen rendering to a texture, i.e. `_targetTexture` is set, `Transform` class internally setups a `Framebuffer` object. `getFramebuffer()` returns this `Framebuffer` object.\n\n### run({uniforms : Object, unbindModels : Object}) : Transform\n\nPerforms one transform feedback iteration.\n\n* `uniforms`=`null` (`Object` = {}, Optional) - Sets uniforms before rendering.\n* `unbindModels`=`[]` (Model[]) - Array of models whose VertexAttributes will be temporarily unbound during the transform feedback to avoid triggering a possible [Khronos/Chrome bug](https://github.com/KhronosGroup/WebGL/issues/2346).\n\n\n### update(props) : Transform\n\nUpdates buffer bindings with provided buffer objects for one or more source or destination buffers.\n\n* `props.sourceBuffers` (`Object`) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Attribute`, `Buffer` or attribute descriptor object.\n* `props.feedbackBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader varying and value is the corresponding `Buffer` object.\n* `props.elementCount` (`Integer`, Optional) - Number set to vertex count when rendering the model. If not supplied, the previously set element count is used.\n\n\n### swap() : Transform\n\nSwaps source and destination buffers and textures. Buffer swapping is performed when `feedbackMap` is provided and texture swapping is performed when `_swapTexture` is provided. If buffer swapping is needed, `sourceBuffers` and `feedbackBuffers` supplied to the constructor and/or the `update` method must be `Buffer` objects.\n\n\n### \\_getTargetTexture() : Texture2D/null (EXPERIMENTAL)\n\nWhen transform is setup to render to a texture, returns current target texture, otherwise null.\n","slug":"docs/api-reference/engine/transform","title":"Transform (WebGL 2)"},{"excerpt":"ModelNode  is simply a  that contains a  for drawing. Constructor  If a WebGL context is passed, a  will be created internally, otherwise…","rawMarkdownBody":"# ModelNode\n\n`ModelNode` is simply a `ScenegraphNode` that contains a `Model` for drawing.\n\n## Constructor\n\n`ModelNode(webglContextOrModel, props: Object)`\n\n* If a WebGL context is passed, a `Model` will be created internally, otherwise the passed `Model` will be used.\n* `props` is the same props as `Model`, plus `props.managedResources`, an array of resources that this model owns.\n\n## Methods\n\n`ModelNode` wraps the following `Model` method and simply proxies them to its internal `Model`:\n* `draw`\n* `setUniforms`\n* `setAttributes`\n* `updateModuleSettings`\n* `delete` (calls `Model.delete` and also deletes managed resource)\n\n","slug":"docs/api-reference/experimental/scenegraph/model-node","title":"ModelNode"},{"excerpt":"ScenegraphNode The  is a base class for objects in the luma.gl scene graph, such as ,  and . It holds the transformation matrix (i.e. the…","rawMarkdownBody":"# ScenegraphNode\n\nThe `ScenegraphNode` is a base class for objects in the luma.gl scene graph, such as `Model`, `Group` and `Camera`. It holds the transformation matrix (i.e. the position, orientation and scale) of the object.\n\n\n## Usage\n\n`ScenegraphNode` is a base class, normally only instantiated via base classes.\n\n```\nconst model = new Model();\nmodel\n  .setPosition([0, 1, 2])\n  .update();\n```\n\n\n\n## Properties\n\nA Model instance has a number of public properties that can be accessed/modified:\n\n* `position` (*object*) - A `Vector3` indicating the position of the Model.\n* `rotation` (*object*) - A `Vector3` indicating the rotation of the Model.\n* `scale` (*object*) - A `Vecto3` indicating the scaling of the Model.\n* `matrix` (*object*) - A `Matrix4` containing information about position, rotation and scale.\n\nThis matrix gets updated each time the method `update` is called on a Model instance.\n\n\n## Properties\n\n### matrix (`Number[16]`)\n\nThe model matrix of this scenegraph node.\n\n\n## Methods\n\n### constructor(props : Object)\n\n```\nvar node = new Model(gl, props);\n```\n\n\n### setProps(props: Object)\n\n* `position` (`Number[3]`) - Sets the position part of the matrix\n* `rotation` (`Number[3]`) - Sets the rotation part of the matrix\n* `scale` (`Number[3]`) - Sets the scale part of the matrix\n\n\nNote that setting orientation props does not actually update the object's matrix. `update()` must be called.\n\n\n### update() - DEPRECATED\n\nUpdate the model matrix. Useful to update changes to the `position`, `rotation` or `scale` properties.\n\n```\nnode.update();\n```\n\n\n## Remarks\n\n* Before luma.gl v7, `ScenegraphNode` was called `Object3D`.\n","slug":"docs/api-reference/experimental/scenegraph/scenegraph-node","title":"ScenegraphNode"},{"excerpt":"BufferTransform  is an internal helper class for , responsible for managing resources and state required for reading from and/or writing to…","rawMarkdownBody":"# BufferTransform\n\n`BufferTransform` is an internal helper class for `Transform`, responsible for managing resources and state required for reading from and/or writing to `Buffer` objects. It auto creates `feedbackBufferes` when requested, creates `TransformFeedback` objects. Maintains all buffer bindings, when swapping is eanbled, two binding objects are created for easy switching of all WebGL resource binginds.\n\nNOTE: In following sections 'buffer transform' is used to refer to 'reading from and/or writing to `Buffer` objects'.\n\n## Constructor\n\n### Transform(gl : WebGL2RenderingContext, props: Object)\n\n* `gl` (`WebGLRenderingContext`) gl - context\n* `props` (`Object`, Optional) - contains following data.\n  * `sourceBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Attribute`, `Buffer` or attribute descriptor object.\n  * `feedbackBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader varying and value is the corresponding `Buffer` object or buffer params object. If a buffer params object is specified, it will contain following fields, these can be used to capture data into the buffer at particular offset and size.\n    * `buffer`=(Buffer) - Buffer object to be bound.\n    * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n    * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n  * `varyings` (`Array`, Optional) - Array of vertex shader varyings names. When not provided this can be deduced from `feedbackBuffers`.\n\n  NOTE: If only reading from `Buffer` objects, above optional props doesn't have to be supplied during construction, but can be supplied using `update` method. If writing to `Buffer` objects, either `varyings` or `feedbackBuffers` must be supplied.\n\n\n## Methods (Model props)\n\n### getDrawOptions(opts: Object) : Object\n\nReturns resources required when performing `Model.draw()` options.\n\n* `opts` (`Object`) - Any existing `opts.attributes` will be merged with new attributes.\n\nReturns an Object : {attributes, transformFeedback}.\n\n### updateModelProps(props: Object) : Object\n\nUpdates input `props` object with data required for buffer transform.\n\n  * `opts` (`Object`) - If writing to `Buffer` objects, `opts.varying` will be updated.\n\nReturns updated object.\n\n## Methods (Resource management)\n\n### setupResources(opts: Object)\n\nSets up internal resources needed writing to buffers.\n\n  * `opts` (`Object`) - contains following data.\n    * `model` (`Model`, Optional) - `Model` object that is used to perform draw operations.\n\n### swap()\n\nIf `feedbackMap` is provided during construction, performs source and feedback buffers swap as per the `feedbackMap`.\n\n### update(props: Object)\n\nUpdates buffer bindings for one or more source or feedback buffers.\n\n  * `props` (`Object`) - contains following data.\n    * `sourceBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Attribute`, `Buffer` or attribute descriptor object.\n    * `feedbackBuffers` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader varying and value is the corresponding `Buffer` object or buffer params object. If a buffer params object is specified, it will contain following fields, these can be used to capture data into the buffer at particular offset and size.\n      * `buffer`=(Buffer) - Buffer object to be bound.\n      * `byteOffset`=(Number, default: 0) - Byte offset that is used to start recording the data in the buffer.\n      * `byteSize`=(Number, default: remaining buffer size) - Size in bytes that is used for recording the data.\n\n\n## Methods (Accessors)\n\n### getBuffer(varyingName : String) : Buffer\n\nReturns current feedback buffer corresponding to given varying name.\n\n  * `varyingName` (`String`) - varying name.\n\n### getData([options : Object]) : ArrayBufferView\n\nReads and returns data from current feedback buffer corresponding to the given varying name.\n\n  * `options.varyingName` (`String`, Optional) - when specified, first checks if there is a corresponding feedback buffer, if so reads data from this buffer and returns. When not specified, there must be target texture and data is read from this texture and returned.\n","slug":"docs/api-reference/engine/transform/buffer-transform","title":"BufferTransform"},{"excerpt":"TextureTransform  is an internal helper class for , responsible for managing resources and state required for reading from and/or writing to…","rawMarkdownBody":"# TextureTransform\n\n`TextureTransform` is an internal helper class for `Transform`, responsible for managing resources and state required for reading from and/or writing to `Texture` objects. It auto creates `Texture` objects when requested, creates `Framebuffer` objects. Maintains all texture bindings, when swapping is eanbled, two binding objects are created for easy switching of all WebGL resource binginds.\n\nNOTE: In following sections 'texture transform' is used to refer to 'reading from and/or writing to `Texture` objects'.\n\n## Constructor\n\n### Transform(gl : WebGL2RenderingContext, props: Object)\n\n* `gl` (`WebGLRenderingContext`) gl - context\n* `props` (`Object`, Optional) - contains following data.\n  * `sourceTextures` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Texture` object.\n  * `targetTexture` (`Texture`|`String`, Optional) - `Texture` object to which data to be written. When it is a `String`, it must be one of the source texture attributes name, a new texture object is cloned from it.\n  * `targetTextureVarying` (`String`) : varying name used in vertex shader who's data should go into target texture.\n  * `swapTexture` (`String`) : source texture attribute name, that is swapped with target texture every time `swap()` is called.\n  * `fs` (`String`, Optional) - fragment shader string, when rendering to a texture, fragments can be processed using this custom shader, when not specified, pass through fragment shader will be used.\n\n\n## Methods (Model props)\n\n### getDrawOptions(opts: Object) : Object\n\nReturns options required when performing `Model.draw()` options.\n\n* `opts` (`Object`) - Any existing `opts.attributes` , `opts.parameters`, and `opts.uniforms` will be merged with new values.\n\nReturns an Object : {attributes, framebuffer, uniforms, discard, parameters}.\n\n### updateModelProps(props: Object) : Object\n\nUpdates input `props` object used to build `Model` object,  with data required for texture transform.\n\n  * `props` (`Object`) -  props for building `Model` object, it will updated with required options (`{vs, fs, modules, uniforms, inject}`) for texture transform.\n\nReturns updated object.\n\n## Methods (Resource management)\n\n### swap()\n\nIf `swapTexture` is provided during construction, performs source and feedback buffers swap as per the `swapTexture` mapping.\n\n### update(props: Object)\n\nUpdates bindings for source and target texture.\n\n  * `props` (`Object`) - contains following data.\n    * `sourceTextures` (`Object`, Optional) - key and value pairs, where key is the name of vertex shader attribute and value is the corresponding `Texture` object.\n    * `targetTexture` (`Texture`|`String`, Optional) - `Texture` object to which data to be written. When it is a `String`, it must be one of the source texture attributes name, a new texture object is cloned from it.\n\n\n## Methods (Accessors)\n\n### getTargetTexture() : Texture\n\nReturns current target texture object.\n\n### getData([options : Object]) : ArrayBufferView\n\nReads and returns data from current target texture.\n\n  * `options.packed` (Boolean, Optional, Default: false) - When true, data is packed to the actual size varyings. When false return array contains 4 values (R, G, B and A) for each element. Un-used element value will be 0 for R, G and B and 1 for A channel.\n\n### getFramebuffer() : Framebuffer\n\nReturns current `Framebuffer` object.\n","slug":"docs/api-reference/engine/transform/texture-transform","title":"TextureTransform"},{"excerpt":"KeyFrames Manages key frame animation data. Associates time points with arbitrary data and provides methods to access key times and data…","rawMarkdownBody":"# KeyFrames\n\nManages key frame animation data. Associates time points with arbitrary data and provides methods to access key times and data, and an interpolation factor, based on the current time.\n\n\n## Usage\n\n```js\nconst keyFrames = new KeyFrames([\n  [0, { val1: [1, 0, 1], val2: 0} ],\n  [500, { val1: [1, 1, 1], val2: 2} ],\n  [800, { val1: [0, 0, 1], val2: 1} ],\n  [1200, { val1: [0, 1, 0], val2: 4} ],\n  [1500, { val1: [1, 0, 1], val2: 5} ]\n]);\n\nkeyFrames.setTime(1000);\n\nkeyFrames.startIndex;      // => 2                            (i.e. key frame at time=800)\nkeyFrames.endIndex;        // => 3                            (i.e. key frame at time=1200)\nkeyFrames.factor;          // => 0.5                          (i.e. halfway between 800 and 1200)\nkeyFrames.getStartTime();  // => 800                          (i.e. time at index 2)\nkeyFrames.getEndTime();    // => 1200                         (i.e. time at index 3)\nkeyFrames.getStartData();  // => { val1: [0, 0, 1], val2: 1}  (i.e. data at index 2)\nkeyFrames.getEndData();    // => { val1: [0, 1, 0], val2: 4}  (i.e. data at index 3)\n\n```\n\n## Properties\n- `startIndex` (Number): Current start key frame index (i.e. the index of the key frame being interpolated from).\n- `endIndex` (Number): Current end key frame index (i.e. the index of the key frame being interpolated to).\n- `factor` (Number): A value between 0 and 1 representing the interpolation factor between the start and end key frame pair.\n\n## Methods\n\n### constructor(keyFrameData: Array)\n\nTakes an array of `[time, data]` pairs to initialize the key frames.\n\n\n### setKeyFrames(keyFrameData: Array)\n\nReplaces the current set of key frames with a new one. Takes the same argument as the constructor.\n\n\n### getStartTime() : Number\n\nReturns the time at the current start key frame index.\n\n\n### getEndTime() : Number\n\nReturns the time at the current end key frame index.\n\n\n### getStartData() : Any\n\nReturns the data at the current start key frame index (i.e. the data being interpolated from).\n\n\n### getEndData() : Any\n\nReturns the data at the current end key frame index (i.e. the data being interpolated to).\n\n\n### setTime(time: Number)\n\nSet the current time of the key frames.\n","slug":"docs/api-reference/engine/animation/key-frames","title":"KeyFrames"},{"excerpt":"VertexArray The  class (like its lower level counterpart, the ) manages an \"array\" of values (\"buffers\") that will be made available as…","rawMarkdownBody":"# VertexArray\n\nThe `VertexArray` class (like its lower level counterpart, the `VertexArrayObject`) manages an \"array\" of values (\"buffers\") that will be made available as input data to shaders during a draw call. For each WebGL `Buffer`, the `VertexArray` also stores some additional information about how that data in the buffer should be accessed, such as offsets, strides, etc, and whether the attribute is instanced.\n\nThe `VertexArray` class provides the following features on top of the lower level `VertexArrayObject` class:\n\n* Reads a \"program configuration\", enabling attributes to be set using names instead of locations\n* Avoids duplicating information already specified in shaders, such as size and type of attributes.\n* Automatic deduction of draw parameters from currently set attributes\n* Handles the \"constant attribute 0\" complication that is common on desktop WebGL browsers.\n* Can generated debug output of attribute bank\n\n* Can fall back to sharing single `VertexArrayObject` across all `VertexArray` objects.\n\n> The `VertexArray` is a wrapper class around the `VertexArrayObject` class which encapsulates the underlying WebGL object. The `VertexArrayObject` class has a number of complications that the `VertexArray` takes care of.\n\n> It is usually not necessary to create `VertexArray` instances in luma.gl applications. The application can just supply a map of `attributes` to the [`Model`](/docs/api-reference/core/model.md) class, and rely on that class to automatically manage the vertex attributes array and supply it to any draw calls (e.g. when rendering, picking etc). Still, it can be useful to review this documentation to better understand how attributes are handled.\n\nFor more information on the WebGL `VertexArrayObject`, see the [OpenGL Wiki](https://www.khronos.org/opengl/wiki/Vertex_Specification#Vertex_Array_Object).\n\n\n## Usage\n\nImport the `VertexArray` class so that your app can use it:\n\n```js\nimport {VertexArray} from '@luma.gl/webgl';\n```\n\nCreate a new VertexArray\n\n```js\nconst vao = new VertexArray(gl);\n}\n```\n\nDeleting a VertexArray\n\n```js\nvertexArrayObject.delete();\n```\n\nAdding attributes to a VertexArray: without program metadata, buffers must be specified using location indices\n\n```\nconst vertexArray2 = new VertexArray(gl);\nvertexArray2.setBuffers({\n  0: new Buffer({data: new Float32Array([...]), ...})\n});\n```\n\nAdding attributes to a VertexArray: adding a program configuration enables setting attributes by name\n\n```js\n// Register attribute info extracted from program shaders\nconst program = new Program(gl, ...);\nconst vertexArray = new VertexArray(gl, {program});\n\n// Now it is possible to set buffers using attribute names\nvertexArray.setAttributes({\n  aColor: new Buffer(gl, new Uint8Array([...]))\n});\n\nSetting a set of attributes and an elements array\n\n```js\nconst vertexArray = new VertexArray(gl, {\n  attributes: {\n    elements: new Buffer(gl, {target: GL.ELEMENT_ARRAY_BUFFER, data: new Uint32Array([...])}),\n  \tpositions: new Buffer(gl, {data: new Float32Array([...])})\n  }\n}\n\nSetting a constant vertex attribute\n\n```js\nimport {VertexArray} from '@luma.gl/webgl';\nconst vao = new VertexArray(gl);\nvao.setConstant(0, [0, 0, 0]);\n```\n\n## Constructor\n\n### VertexArray(gl : WebGLRenderingContext, props : Object)\n\nCreates a new VertexArray\n\n* `props` (Object) - passed through to `Resource` superclass constructor and to `initialize` it.\n\n\n## Methods\n\n### initialize(props : Object) : VertexArray\n\nReinitializes a `VertexArray`.\n\n* `attributes`=`{}` (`Object`) - map of attributes, can be keyed by index or names, can be constants (small arrays), `Buffer`, arrays or typed arrays of numbers, or attribute descriptors.\n* `elements`=`null` (`Buffer`) - optional buffer representing elements array (i.e. indices)\n* `program` - Transfers information on vertex attribute locations and types to this vertex array.\n\n\n### setAttributes(attributes : Object) : VertexArray\n\nSets named uniforms from a map.\n\n```js\nprogram.setAttributes(attributes : Object);\n```\n\n* `attributes` - (*object*) An object with key value pairs matching a buffer name and its value respectively.\n\nAttributes is an object with key-value pairs: `{nameOrLocation: value, ....}`.\n\n* `nameOrLocation` - (*string|number*) The name of the attribute as declared in the shader, or the location specified by a layout qualifier in the shader. The name can contain an offset to the actual location in the format of `name__LOCATION_0`. This is useful for setting *mat* type attributes. See the section at the bottom for more details.\n* `value` - (*Buffer|Array|typed array*) An attribute value must be a `Buffer` or a typed array.\n\nEach value can be an a `Buffer`, an `Array` starting with a `Buffer` or a typed array.\n\n* Typed Array - Sets a constant value as if `.setConstant(value)`  was called.\n* `Buffer` - Binds the atttribute to a buffer, using buffer's accessor data as if `.setBuffer(value)` was called.\n* `Array` - Binds the atttribute to a buffer, with extra accessor data overrides. Expects a two element array with `[buffer : Buffer, accessor : Object]`. Binds the attribute to the buffer as if ` .setBuffer(buffer, accessor)` was called.\n\n\n### setConstant(value : Array  [, accessor : Object]) : VertexArray\n\nSets a constant value for a vertex attribute. When this `VertexArray` is used in a `Program.draw()` call, all Vertex Shader invocations will get the same value.\n\n`VertexArray.setConstant(location, array);`\n\n* `gl` (`WebGLRenderingContext`) - gl context\n* `location` (*GLuint*) - index of the attribute\n\nWebGL APIs:\n[vertexAttrib4[u]{f,i}v](https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/vertexAttrib)\n\n\n### setBuffer(nameOrLocation, buffer : Buffer [, accessor : Object]) : VertexArray\n\nBinds the specified attribute in this vertex array to the supplied buffer\n\n* Set a location in vertex attributes array to a buffer, specifying\n* its data layout and integer to float conversion and normalization flags\n\n`setBuffer(location, buffer);`\n`setBuffer(location, buffer, {offset = 0, stride = 0, normalized = false, integer = false});`\n\n* `location` (*GLuint* | *String*) - index/ordinal number of the attribute\n* `buffer` (*WebGLBuffer*|*Buffer*) - WebGL buffer to set as value\n\n[gl.vertexAttrib{I}Pointer](), [gl.vertexAttribDivisor](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/vertexAttribDivisor)\n\n\n### setElementBuffer(buffer : Buffer [, accessor : Object]) : VertexArray\n\nBinds the supplied buffer as index buffer (`GL.ELEMENT_ARRAY_BUFFER`).\n\n\n## Attribute Accessors\n\nWhen setting `Buffer` attributes, additional data can be provided to specify how the buffer should be accessed. This data can be stored directly on the `Buffer` accessor or supplied to `.setBuffer`.\n\n* `target`=`buffer.target` (*GLuint*, ) - which target to bind to\n* `size` (*GLuint*)  - number of values (components) per element (1-4)\n* `type` (*GLuint*)  - type of values (e.g. gl.FLOAT)\n* `normalized` (*boolean*, false) - normalize integers to [-1,1] or [0,1]\n* `integer` (*boolean*, false) - `WebGL 2` disable int-to-float conversion\n* `stride` (*GLuint*, 0) - supports strided arrays\n* `offset` (*GLuint*, 0) - supports strided arrays\n* `layout.normalized`=`false` (GLbool) - normalize integers to [-1,1], [0,1]\n* `layout.integer`=`false` (GLuint) - WebGL 2 only, disable int-to-float conv.\n\n* `divisor` - Sets the frequency divisor used for instanced rendering (instances that pass between updates of attribute). Usually simply set to 1 or 0 to enable/disable instanced rendering. 0 disables instancing, >=1 enables it.\n\n\n## Notes about Integer Attributes\n\n* The application can enable normalization by setting the `normalized` flag to `true` in the `setBuffer` call.\n* **WebGL 2** The application can disable integer to float conversion when running under WebGL 2, by setting the `integer` flag to `true`.\n* [`glVertexAttribIPointer`](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/vertexAttribIPointer) specifies *integer* data formats and locations of vertex attributes. Values are always left as integer values. Only accepts the integer types gl.BYTE, gl.UNSIGNED_BYTE, gl.SHORT, gl.UNSIGNED_SHORT, gl.INT, gl.UNSIGNED_INT\n\n\n## Notes about Instanced Rendering\n\n* About setting `divisor` in attributes: Instanced attributes requires WebGL 2 or a (widely supported) WebGL 1 extension. Apps can use the luma.gl feature detection system to determine if instanced rendering is available, though the extension is so ubiquitously supported that many apps just make the assumption: [instanced_arrays](https://webglstats.com/webgl/extension/ANGLE_instanced_arrays).\n* An attribute is referred to as **instanced** if its divisor value is non-zero.\n* The divisor modifies the rate at which vertex attributes advance when rendering multiple instances of primitives in a single draw call.\n* If divisor is zero, the attribute at slot index advances once per vertex.\n* If divisor is non-zero, the attribute advances once per divisor instances of the set(s) of vertices being rendered.\n\n## Notes about setting *mat* type attributes\n\n* Setting a **mat** type in the shader requires to manually add an *offset* to the location.\n* This can be done by using special name format `name__LOCATION_0`. This will add 0 to the *LOCATION* resulting in no change. `name__LOCATION_1` will add **1**.\n* For example:\n  * if we have the following declaration in the shader:\n```\nattribute mat4 matrix;\n```\n  * We should specify `matrix__LOCATION_0`, `matrix__LOCATION_1`, `matrix__LOCATION_2` **and** `matrix__LOCATION_3` as *vec4*.\n","slug":"docs/api-reference/webgl/vertex-array","title":"VertexArray"},{"excerpt":"UniformBufferLayout (WebGL 2) A helper class that lets the application describe the contents of a uniform block and then perform  calls on…","rawMarkdownBody":"# UniformBufferLayout (WebGL 2)\n\nA helper class that lets the application describe the contents of a uniform block and then perform `setUniforms({uniform: value})` calls on it, manipulating individual values without concern for memory layout requirements.\n\n\n## Usage\n\nCreate a `UniformBufferLayout` that matches the uniform block declaration in your shader\n\n```js\n#version 300 es\nlayout (std140) uniform matrix {\n    mat4 mvp;\n} matrixBlock;\n```\n\n```js\nconst matrixBlockLayout = new UniformBufferLayout({\n  mvp: GL.FLOAT_MAT4\n});\n```\n\nSetting values on a `UniformBufferLayout`:\n\n```js\n.setValues({\n  mvp: [1, 0, 0, 0,  0, 1, 0, 0,  0, 0, 1, 0,  0, 0, 0, 1]\n});\n```\n\nCreating a uniform buffer to hold the data required by the layout\n\n```js\nconst layout = new UniformBufferLayout({...});\nconst buffer = new Buffer(gl, {size: layout.getBytes()});\n```\n\nUpdating your actual uniform buffer\n\n```js\nconst layout = ...\nlayout.setValues({...})\nbuffer.subData({data: layout.getData()})\n```\n\nUpdating a minimal part of the actual uniform buffer\n\n```js\nconst {data, offset} = layout.getSubData();\nbuffer.subData({data, offset})\n```\n\nBinding your uniform buffer\n\n```js\nTBA\n```\n\n\n## Methods\n\n### constructor\n\nTakes a layout object and creates an internal layout description. Once constructed the layout cannot be changed. Once constructed the size of the required memory buffer is known, and the buffer layout provides a convenient interface for updating values.\n\nNote: The order and type of the uniforms in the layout object provided to the constructor must match the order and type of the uniform declarations in the GLSL uniform block\n\n\n### setValues\n\nSets uniform values.\n\n\n### getBytes\n\nReturns the number of bytes needed to hold all the uniforms in the layout, which can be used to create a `Buffer` with enough data to hold the entire memory layout.\n\n\n### getData\n\nReturns a `Float32Array` representing all the memory in the layout. The length of this array (* 4) will correspond to the value returned by `getBytes()`\n\n\n### getSubData\n\nReturns a `Float32Array` representing all the memory in the layout. The length of this array (* 4) will correspond to the value returned by `getBytes()`\n\n\n## Types\n\nUse the following WebGL types to declare uniforms corresponding to your GLSL data types.\n\n| GLSL Type | WebGL type |\n| ---       | --- |\n| `float`   | `GL.FLOAT` |\n| `vec2`    | `GL.FLOAT_VEC2` |\n| `vec3`    | `GL.FLOAT_VEC3` |\n| `vec4`    | `GL.FLOAT_VEC4` |\n| `int`     | `GL.INT` |\n| `ivec2`   | `GL.INT_VEC2` |\n| `ivec3`   | `GL.INT_VEC3` |\n| `ivec4`   | `GL.INT_VEC4` |\n| `uint`    | `GL.UNSIGNED_INT` |\n| `uvec2`   | `GL.UNSIGNED_INT_VEC2` |\n| `uvec3`   | `GL.UNSIGNED_INT_VEC3` |\n| `uvec4`   | `GL.UNSIGNED_INT_VEC4` |\n| `bool`    | `GL.BOOL` |\n| `bvec2`   | `GL.BOOL_VEC2` |\n| `bvec3`   | `GL.BOOL_VEC3` |\n| `bvec4`   | `GL.BOOL_VEC4` |\n| `mat2`    | `GL.FLOAT_MAT2` |\n| `mat3`    | `GL.FLOAT_MAT3` |\n| `mat4`    | `GL.FLOAT_MAT4` |\n| `mat2x3`  | `GL.FLOAT_MAT2x3` |\n| `mat2x4`  | `GL.FLOAT_MAT2x4` |\n| `mat3x2`  | `GL.FLOAT_MAT3x2` |\n| `mat3x4`  | `GL.FLOAT_MAT3x4` |\n| `mat4x2`  | `GL.FLOAT_MAT4x2` |\n| `mat4x3`  | `GL.FLOAT_MAT4x3` |\n\n\n## Remarks\n\n* WebGL requires the data representing the uniforms in to be laid out in memory according to specific rules (essentially some padding needs to be injected between successive values to facilitate memory access by the GPU).\n* Note that WebGL 2 uniform buffers are just [Buffer](/docs/api-reference/webgl/buffer) objects and can be manipulated directly. The `UniformBufferLayout` class is not a WebGL 2 object, it is just an optional helper class that makes it easy to create and update a block of memory with the required layout.\n* More information on the `std140` layout specification: [OpenGL spec](https://khronos.org/registry/OpenGL/specs/gl/glspec45.core.pdf#page=137)\n","slug":"docs/api-reference/webgl/uniform-buffer-layout","title":"UniformBufferLayout (WebGL 2)"},{"excerpt":"Timeline Manages an animation timeline, with multiple channels that can be running at different rates, durations, etc. Many methods…","rawMarkdownBody":"# Timeline\n\nManages an animation timeline, with multiple channels that can be running at different rates, durations, etc. Many methods (`play`, `pause`) assume that the `update` method is being called once per frame with a \"global time\". This automatically done for `AnimationLoop.timeline` object.\n\n## Parallel Times\n\nThe key concept at work in the `Timeline` is running multiple time frames in parallel:\n* Global Time: The \"system time\" as determined by the application. Used by `Timeline` to determine the rate at which to play.\n* Timeline Time: The \"parent\" time of all channels on the timeline. Can be played at the same rate as \"Global Time\" or manipulated manually.\n* Channel Time: Will update in lock step with \"Timeline Time\", but may move at different rates, loop, etc. depending on channel parameters.\n\n## Usage\n\nAutomatic update usage (assume `update` method is being called once per frame):\n```js\nanimationLoop.attachTimeline(new Timeline());\nconst timeline = animationLoop.timeline;\nconst channel1 = timeline.addChannel({\n  rate: 0.5,\n  duration: 4000,\n  repeat: Number.POSITIVE_INFINITY\n});\nconst channel2 = timeline.addChannel({\n  rate: 2,\n  delay: 500,\n  duration: 1000,\n  repeat: 3\n});\n\ntimeline.pause();\ntimeline.play();\n\nmodel.setUniforms({\n  uValue1: timeline.getTime(channel1);\n  uValue2: timeline.getTime(channel2);\n});\n```\n\nManual usage:\n```js\nconst timeline = new Timeline();\nconst channel1 = timeline.addChannel({\n  rate: 0.5,\n  duration: 4000,\n  repeat: Number.POSITIVE_INFINITY\n});\nconst channel2 = timeline.addChannel({\n  rate: 2,\n  delay: 500,\n  duration: 1000,\n  repeat: 3\n});\ntimeline.setTime(500);\n\nmodel.setUniforms({\n  uValue1: timeline.getTime(channel1);\n  uValue2: timeline.getTime(channel2);\n});\n```\n\n\n## Methods\n\n### addChannel([props: Object]) : Number\n\nAdd a new channel to the timeline. Returns a handle to the channel that can be use for subsequent interactions. Valid propeties are:\n* `rate` the speed of the channel's time relative to timeline time.\n* `delay` offset into timeline time at which channel time starts elapsing, in timeline time units.\n* `duration` the length of the channel time frame, in timeline time units.\n* `repeat` how many time to repeat channel time's timeline. Only meaningful if `duration` is finite.\n\n### removeChannel(handle : Number)\n\nRemove a channel from the timeline. `handle` should be a value that was returned by `addChannel`.\n\n### isFinished(handle : Number) : Boolean\n\nReturns whether the channel's time has completely elapsed.\n\n### getTime([handle : Number]) : Number\n\nReturn the current time of the channel indicated by `handle`. If no handle is provided, return timeline time.\n\n### setTime(time : Number)\n\nSet the timeline time to the given value.\n\n### play\n\nAllow timeline time to be updated by calls to `update`.\n\n### pause\n\nPrevent timeline time from being updated by calls to `update`.\n\n### reset\n\nReset timeline time to `0`.\n\n### attachAnimation(animation: Object, [channelHandle : Number]) : Number\n\nAttach an animation object (can be any object with a `setTime` method, e.g. [KeyFrames](/docs/api-reference/engine/animation/key-frames), `GLTFAnimator`) to the timeline, optionally attached to a specific channel referenced by `channelHandle`.\nThe animation object's time will be updated whenever the timeline updates. Returns a handle that can be used to reference the animation attachement.\n\n### detachAnimation(handle : Number)\n\nDetach an animation object from the timeline. `handle` should be a value that was returned by `attachAnimation`.\n\n### update(globalTime : Number)\n\nExpected to be called once per frame, with whatever is considered the \"system time\". Required for `play` and `pause` to work properly.\n","slug":"docs/api-reference/engine/animation/timeline","title":"Timeline"}]}}}